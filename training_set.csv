key,id,title,text,label
1947342,10022,Reconnection at multiply-connected null points,"Global magnetic field models have shown that nulls in the solar atmosphere are configured in a variety of complex ways. Little is known about the reconnection that takes place here, except at an idealised single separator connecting two nulls. This research aims to better understand reconnection at 3d null points by studying the simplest example of a system of multiply-connected nulls. This system consists of two nulls (with opposite polarity) connected by two separators. The work will begin by deriving the double separator potential field before smoothly introducing a current by the addition of a non-potential component to the magnetic field. This new field will form the basis for a numerical relaxation experiment performed using the Lare3d code to solve the ideal MHD equations, from which the initial condition for the reconnection experiment will be gathered. The reconnection will subsequently be studied by running the same code but with an anomalous resistivity switched on, such that the resistive MHD equations will be solved at grid points whose current exceeds a critical value. The energy changes during this experiment (and accompanying heating terms) will be studied and compared with those found in the single separator case. We will also pay close attention to the reconnection rate and the behaviour of the waves (and plasma flows) released from the diffusion region. One of the key questions the research will address is whether the reconnection rate in multiply-connected null points is higher due to recursive reconnection of fieldlines between the neighbouring diffusion regions.",0
EP/P03280X/1,24394,Tailorable and Adaptive Connected Digital Additive Manufacturing (TACDAM),"The aim of the project is to create complex designs for heat exchangers by additive manufacturing. Additive manufacturing will use metallic powders which are laser sintered. The unused powder can cause issues if it is retained in the manufactured product and compromise the performance of the heat exchangers. Vibration is used to remove the unused powder from the system. In order to design the optimum vibration response of the product to remove this powder it is essential to be able to understand the vibration characteristics of the product and this will be the key role that ASDEC will undertake for the project.

The Advanced Structural Dynamics Evaluation Centre (ASDEC) of the University of Leicester is a unique facility for measuring vibration of complex components and structures by non-contact methods. ASDEC has world leading systems and capability in the measurement, assessment and analysis of vibration. Critically for this project, we have the ability to measure surface vibration in a non-contact and non-distructive manner up to 1MHz. ASDEC combines the combination of a Robovib system, LMS Modal Analysis and Virtual Correlation tools and a portable laser vibrometry system that can be used in the manufacturing environment. The 3D laser vibrometry equipment will allow repeatable measurements to be performed in unparalleled detail and accuracy on the complex structures that will be produced by our project partners. These measurements would be unachievable using other measurement techniques. 

Modal analysis of the vibration of the components will be used to optimise the powder shake-out and therefore allow for optimisation of the manufacturing routes. Additive manufacturing is highly attractive as it allows structures and architectures for products that are unachievable by conventional manufacturing routes. In addition to the capability of the ASDEC facility, the key staff have 40 years combined experience in vibration and acoustic engineering and development as well as signal processing and analysis.",0
2106291,29256,Impacts of novel control strategies for Spotted Winged Drosophila on ecosystem services and crop production in raspberries,"Project motivation and aims (&lt;300 words):
Raspberries are an increasingly important high value crop in the UK with opportunities to increase the market in the near future. Raspberry production is under threat however from a number of key pests including spotted winged drosophila (Drosophila suzukii, SWD) but chemical control options (primarily, cyantraniliprole, spinosad and lambda-cyhalothrin) are limited with restrictions on use, and repeated insecticide applications are unsustainable and could cause future insecticide resistance of SWD. Even with current insecticide control options, SWD control breaks down, particularly towards the end of the season when populations increase. Insect mesh is increasingly being employed to limit the impact of SWD by reducing numbers that enter the crop from neighbouring habitats. However, this novel control strategy has implications for crop pollination and pest control by excluding wild pollinating insects and natural enemies. It may also effect poly-tunnel climatic conditions increasing risks of disease and crop loss. If insect mesh is to become the mainstay of SWD control then it is crucially important to understand what impact this may have for pollination, biocontrol and crop production and we need to identify effective methods of integrating mesh into raspberry production which maximize control of SWD but minimize negative effects on ecosystem services. 

The risks and benefits of incorporating insect mesh to control SWD has been identified as a key knowledge gap by the industry and so the aim of this project is to quantify its effects on raspberry production and identify how it can be integrated into management systems to maximise the benefits to the growers. The specific Research Objective of this project include:

1. Test the effectiveness of insect mesh to provide economically acceptable control of SWD in raspberries.
2. Investigate the potential impacts of insect mesh on insect pollination, natural pest control, disease and the tunnel environment and resulting fruit yield and quality.
3. Field test different management practices for integrating insect mesh into raspberry production in order to identify an optimal strategy that is economically feasible and delivers effective IPM.


Programme of research (&lt;300 words):
Using Berryworld's extensive network of raspberry growers, we will implement a replicated trial to address our three research objectives. Working closely with growers we will compare poly-tunnels which have installed insect mesh to control SWD with those that have not. Treatments will be replicated within and across different farms allowing us to understand the impacts of insect mesh across a number of different geographic and management contexts.

Objective 1: Testing effectiveness of insect mesh in controlling SWD. Throughout season 1 and 2, SWD populations will be surveyed using standard semiochemical monitoring traps inside and outside insect mesh and control poly-tunnels. The impact of SWD on the crop will be measured using flotation and emergence tests. This allows us to quantify the direct effects of insect mesh on SWD fruit damage, and by tracking SWD populations, we will identify how well mesh prevents SWD entering the crop throughout the growing season.

Objective 2: Understanding impacts of insect mesh on other ecosystem services. In season 1 and 2, pollination services (transect walks), natural pest regulation (bait cards) and the tunnel environment (temperature and humidity) will be compared between insect mesh and control tunnels. Levels of fungal disease in the fruit, and final crop output will be measured to understand if insect mesh compromises production by affecting these other key factors.
Objective 3: Developing and testing optimal strategies for incorporating mesh into sustainable raspberry production. Informed by Objectives 1 and 2, in season 3 and 4, difference SWD control strategies will be compared including raising and low",0
710756,29505,PyroGen - End of life plastic to oil pyrolysis for a closed loop energy from waste process,"The UK is increasing its adoption of alternative waste disposal options including increased
material recovery &amp; recycling, &amp; processes that enable the recovery of energy from waste
such as anaerobic digestion (AD), incineration &amp; advanced thermal treatment processes such
as pyrolysis &amp; gasification to reduce landfilled waste &amp; meet the UK窶冱 increasing energy
needs. Currently, UK waste disposal facilities (MRFs, AD plants, composting facilities, etc.)
send 27,000kt of end-of-life plastics to landfill at a total cost of ~&pound;70M (gate fees of &pound;80/t)
per annum, placing the UK in the bottom 7 of the EU27 for diversion from landfill &amp; at risk
of reaching landfill capacity by 2018.
Pyrolysis provides a viable solution for the conversion of these end of life plastics back into
oil. Smaller scale pyrolysis technologies in operation have been designed to handle a
consistent organic biomass feedstock &amp; are limited in scale by pre-treatment &amp; refinement
processes. Due to the inconsistent mix of plastics in the municipal solid waste (MSW) stream,
the quality of oil products derived from ELPs is low and further processing is required to give
a quality fuel product. Pearwalk propose a novel integrated pyrolysis system which uses a
continuous process that will allow for a closed loop/continuous system across a variety of
scales using smaller but more frequent waste streams. The technology will provide a
significant opportunity for AD plant operators &amp; material recover facilities (MRFs) to turn
their unsorted, unwashed waste end of life plastics into clean low sulphur fuels (for heating &amp;
energy generation) without the need for extensive, complex &amp; costly pre-treatment or
refinement processes. The project aims to design a small scale pyrolysis rig prototype &amp; to
evaluate its use with a variety of mixed end of life plastic feedstocks to ensure that sufficient
output yields can be achieved for a commercially viable energy from waste solution to be
developed.",0
NE/P001130/1,24330,Reciprocal interaction between microbial evolution and community structure in soil,"Evolutionary change can occur over comparable time scales to changes in community composition, hence rapid evolution can play a key role in community ecology and vice versa. However, we have little understanding of the significance of, or mechanisms underlying, this interaction in nature. Here, we will identify how and why the presence versus absence of a range of natural soil microbial communities affects the molecular and phenotypic evolution of a focal species of bacteria adapting to a novel environment (elevated temperature), and in turn how and why evolution of the focal species affects community composition.",0
EP/R043868/1,33745,Handheld quantum wireless for financial transactions,"Mobile phones and handheld devices are increasingly being used for wireless financial transactions, and maintaining the
security of these is paramount. This work will combine a quantum secure wireless link with secure software to create a
demonstration of how quantum technologies can play a role in payments and other financial transactions. We will work on
both the physical hardware for the link, building on existing expertise, and the software that is required to enable the
transaction.",0
1921615,29623,Novel optical fibres for mid-infrared applications,"In this project we aim to develop a set of novel mid-IR delivery fibres. We will target the development of thermal imaging bundles for the remote endoscopic thermal analysis of hard to reach areas, and of mid-IR transmitting hollow core fibres that circumvent the lack of durable and low-loss glasses at these wavelengths in the 5-10um spectral range. The student will develop a manufacturing platform for compound-glass-based fibre bundles made of chalcogenides and polymers, and for hollow-core fibres based on novel air-guiding designs and made of lower phonon energy, 'softer', glasses.",0
511653,37160,University of Warwick and AstraZeneca UK Limited,To apply Solid-State NMR crystallography to provide better quality products and improved manufacturing processes for disordered active pharmaceutical ingredients such as hydrates.,0
ST/R002916/1,20269,Visitor funding for disadvantaged Southern African PDRAs to the UK,"There is an urgent unmet economic need for skilled STEM workers in South Africa, but majority non-white participation in higher education is more than four times lower than among white South Africans, exacerbated by the fact that still more than 86% of full professors in South Africa are white. We propose to address this with a programme of visiting research fellowships from disadvantaged Southern African postdoctoral researchers to UK institutions partnering in the Southern African Large Telescope, addressing the following UN Sustainable Development Goals: (4) Quality Education (10) Reduced Inequalities (17) Partnerships for the Goals. This project is spectacularly cost-effective: with the fellows' salaries generously being paid directly by South Africa, and UK institutions waiving the estates/indirect costs, this project leverages more than a factor of ten more funding than the size of the STFC grant award.",0
1864953,22194,Outlier detection in social behaviour in latent class and group-based latent trajectory models,"This application relates to an issue that is important for criminology and other social science
disciplines - that of detecting small outlier classes in large datasets. Latent Class Analysis(LCA)
(Lazarsfeld and Henry, 1968) and group-based trajectory models (GBTM) (Nagin, 2005) are now used
extensively in the social sciences to detect classes of individuals based on behaviour or survey
responses.
For example, in criminology, LCA has been used for detecting patterns in criminological offending
activity in the types of offending carried out (Francis, Soothill and Fligelstone, 2004). Such models
however fail to identify small latent classes. These unusual patterns of behaviour are probably the
most important to identify, but such individuals will instead be forced into other clusters,
contaminating these clusters and losing the important aberrant behaviour. Thus, there will be
individuals who focus their criminal activity on violent and sexual offending (Hodgins, 2004) but
these are rare in the population of offenders. LCA has failed to identify such individuals, instead
merging them into other latent classes. Extending into longitudinal data, GBTMs identify classes of
trajectory patterns over time in the frequency of offending. Again, there may be patterns of
behaviour in large datasets (such as very late starters) that are not detected through conventional
GBTM methods.",0
2104630,3169,Overcoming the Era of #FakeNews: A Contingency Learning Approach,"In the age of the Internet, the increased prevalence of fake news is supporting an increase in beliefs that are not founded on evidence (Carroll, 2015). Algorithms used by social media and search engines exacerbate the impact of false beliefs by favouring information that echoes people's cherished ideas and beliefs. The resulting myths become increasingly difficult to eradicate (Lewandowsky et al., 2012). Research indicates that showing people facts is not enough to eradicate false beliefs (Yarritu &amp; Matute, 2015). Clearly, a systematic, fundamental understanding of belief in fake news is essential to develop effective counter-measures.
At the root of false beliefs, such as those propagated by fake news, lies the phenomenon of contingency learning: the process by which people learn to associate one variable with another. My objective is to understand this process in context of false beliefs. By doing so, I will develop a strategy to prevent false beliefs from forming and, consequently, prevent people from sharing these fake stories with others.
Contingency theory (Allan, 1980) provides a normative account of causal belief, stating that the belief should correspond with the difference in the probability that two events co-occur, P (Event 1|Event 2), and the probability that one of these events occurs in isolation, P (Event 1|No Event 2). This difference is quantified as the degree of contingency.
Unfortunately, people do not adhere to this normative account; contingency beliefs are often biased. People tend to believe that events that occur often are somehow related, even if they are not (Allan &amp; Jenkins, 1983; Byrom et al., 2015). People also use irrelevant contextual cues to infer causality (Van Tilburg &amp; Igou, 2014) yet fail to consider information relevant to their judgement (Matute et al., 2015). These discoveries in contingency learning research offer an ideal basis for understanding why people believe fake news, and what can be done to counter these beliefs.
Many people believe that taking Vitamin C cures the common cold. A systematic review found that there was no trial evidence for the efficacy of Vitamin C (Hemila &amp; Chalker, 2013). As people tend to recover with or without Vitamin C supplement, they are at risk of incorrectly attributing their recovery to Vitamin C. 
The relationship between Vitamin C and the common cold is a low-cost scenario. However, the situation becomes troubling when considering the unconfirmed belief that cannabis oil is a natural treatment for cancer. Facebook pages echoing this claim are followed by many thousands. People have inferred a correlation between cancer remission with taking cannabis oil and may choose to use cannabis oil as a treatment for cancer, which have had disastrous health consequences. 
Research into false beliefs by examining their roots in contingency learning may provide crucial insight into understanding and preventing the negative impact of fake news. To date, most work has been focused on either scenarios where participants make judgements of their control over events or they passively observed the relationship between two events. 
I will test if and how contingency learning shapes belief in fake news, by examining how people evaluate the truthfulness of a 'news headline' that claims a statistical relationship between two events (e.g. &quot;cannabis oil cures cancer&quot;) on basis of information presented to them. For example, participants will be presented with cases of hypothetical individuals who are described as being administered cannabis oil or not, and as experiencing a remission in cancer or not. Similar headlines on different topics will be used to assess the universality of effects. This approach places the contingency learning paradigm in a context directly relevant to understanding belief in fake news. Based on these results a second pair of experiments will test how well and long effect of training to identify fake news will last.",0
2116936,33900,Assessing the complexity of embryonic somites with single cell genomics,"A fascinating question in biology asks how multicellular organisms arise from a single cell: the fertilized egg. During embryogenesis, na&iuml;ve and still plastic progenitor cells communicate with each other, first to form different layers and to organize the main body axes, and later to build specialized organs with highly differentiated cell types and functions. The cells in an embryo coordinate these complex events by activating gene expression programmes, often in response to extrinsic signals. The control of cell differentiation is important throughout the life of an organism, for example to repair tissue after injury or for growth and remodeling using tissue resident stem cells, which activate cellular differentiation programmes similar to those used in the embryo. However, many details of how cells progressively differentiate - at the right time and in the right place - are still poorly understood. This will be addressed here in developing somites, paired segments along the axis of vertebrate embryos, which generate much of the musculoskeletal system from an initially homogenous population of cells. The project will use advanced (low input) sequencing techniques to determine molecular profiles of progenitor cells present in early somites. By looking at different stages of somite differentiation we will characterize cellular intermediates and transition states as more specialised cell types arise.",0
1966167,45788,Gene Therapy for Surfactant Disorders,"At birth, some babies fail to breathe due to a failure to inflate their lungs and often this is due to genetic diseases resulting in a lack of surfactant protein. Surfactant forms a thin film that covers the gas exchange surface in the lung. It is required to prevent the lung from collapse. Several proteins are crucial to normal surfactant metabolism, for example, surfactant protein B, surfactant protein C and ABCA3. Absence or reduced function of such proteins due to genetic mutation leads to severe respiratory distress. The outlook for affected babies can be poor and progress in developing treatments has been slow as the majority of such diseases are very rare. In my DPhil project I am investigating gene therapy for surfactant disorders. The principle is to deliver the correct genetic information to specific cells in the lung called alveolar type II cells, the site of surfactant metabolism, using adeno-associated virus (AAV) as a vehicle for delivery. AAV is a non-pathogenic virus which is known for its ability to infect different target tissues with a good safety profile in gene therapy applications. If the delivered genes are expressed long-term in the lung this approach has the potential to treat surfactant disorders. Importantly, even partial correction may have a benefit, for example by extending the window in which lung transplantation could be offered.",0
1630466,12408,The AGN-star formation connection with ALMA,"Using state of the art infrared observations, including ALMA, the project will explore the connection between AGN activity and star formation. The analyses will include comparing the star formation rates against AGN luminosity and comparing star-formation rate distributions of AGN with those of star formation galaxies and normal galaxies. The overall objective of the project is to explore whether AGN effect their environment in some way, as predicted by the leading models of galaxy formation; e.g., the AGN shutting down or enhancing star formation activity. The project will also investigate whether UV-near-IR observations can be used to constrain star formation rates in AGN for sources not detected by ALMA.",0
1789861,31157,Stimuli Responsive Catalysis,"Stimuli-responsive catalysis has had a considerable impact on catalyst reusability and recyclability through combining the reactivity of homogenous catalysis with the ease of recovery of heterogeneous catalysis. This has primarily been achieved through the development of thermo- or pH-reponsive polymer- or gel-based catalytic systems as recyclable catalysts for organic synthesis. However, examples of controlling catalytic activity through stimuli other than pH or temperature, are lacking by comparison. Recently a pro-ligand approach has been developed to activate metal complexes to carry out selective synthetic transformations only in the presence of specific enzymes (Chem. Sci., 2015, 6, 4978-4985.). 
The challenges are inter-disciplinary and focus on developing fundamental new science in stimuli-responsive catalysis. Specifically, each new target-configured reagent system requires: (a) Stable latent catalyst; (b) Biocompatible conditions; (c) Fast, selective and irreversible activation; (d) Well understood mechanism of activation; (e) No activation by impurities; (f) Low background reaction; (g) Fast, selective functional group transformation. To address these challenges the project will focus on the three principal elements of recognition, activation and response. There are opportunities for the student to direct the project into the research areas that interest them the most - this a concept driven project that could find application in chemical diagnostics, the repair or recycling of materials or drug discovery. A particularly ambitious approach would be to develop two enantiomeric complexes that could be selectively activated to synthesise either enantiomer of a desired product (e.g. amino acid). As enantiomeric compounds are known to often have very different biological properties this could be the basis of a smart catalyst system that could make a specific drug in the presence of one enzyme (stimulus) and another in the presence of a different enzyme. 
The preliminary communication of this concept was submitted to Nature Chemistry and was selected to go out to referee but narrowly rejected. Our publication strategy is therefore to remain ambitious, we have confidence that this project area is of interest to a broad range of scientists and will pass editorial review at the highest level: Nature, Science and J. Am. Chem. Soc. It is clear that this concept could form the basis of a competitive grant application to EPSRC responsive mode and this will be pursued whilst continuing to build a critical mass of preliminary results and publications.",0
ST/P00055X/1,26899,"Fields, Strings and Lattices: From the Inflationary Universe to High-Energy Colliders","Research in particle physics and cosmology connects the largest scales, those of the Universe as a whole, with the smallest, namely those of fundamental particles and strings. By trying to understand how the Universe evolved after the Big Bang, we may gain insight into which particles are yet to be discovered at e.g. the Large Hadron Collider at CERN, and vice versa, a fascinating prospect!

It is commonly assumed that the early Universe went through a period of rapid expansion, dubbed inflation. The mechanisms underlying inflation can be investigated in a number of ways. In the so-called bottom-up approach, one aims to find predictions that are independent of details of models, but only depend on symmetries and the nature of the source of inflation. It is then possible to extract universal features leading to observational predictions and point towards physics beyond our currently known Standard Models of Particle Physics and Cosmology. In the complementary top-down approach, one starts with the given theory, e.g. one that is motivated by string theory, and derives its consequences, which, again might be testable by observations. These approaches can also be used to study the period of cosmic acceleration our Universe is currently going through, i.e. dark energy.

String theory is a theory of gravity (and other forces) operating at very high-energy scales. Besides its possible role as a fundamental theory, it has many intricate aspects which require a level of understanding deeply rooted in symmetries and dualities (a transformation that leads to two 'dual' formulations which are superficially very different but yet equivalent). By studying those, one may not only understand string theory better, but also arrive at dual theories which are relevant for e.g. physics beyond the Standard Model (BSM) probed at the LHC, especially if the BSM model is strongly coupled.

In order to make predictions for the LHC, it is necessary to perform very precise calculations, in BSM models and in the Standard Model itself. Some of these calculations can be done by expanding in a small parameter. This does not mean that the computation is easy though, since many scattering processes may contribute. However, it might be that by re-organising these contributions a new, more efficient, formulation can be found.

When there is no small parameter, a theory has to be solved as it stands. Often this can be attempted numerically, by formulating it on a space-time lattice. Since this involves very many degrees of freedom, typically one has to employ the largest supercomputers in the world. The theory of the strong interaction, Quantum Chromodynamics (QCD), is one of those theories in which a small parameter is absent. Although it is formulated in the terms of quarks (as matter particles) and gluons (as force carriers), these are not the particles that appear in the spectrum, which are instead protons, neutrons, pions etc. However, since QCD is so hard to solve, there may be other particles not yet detected and also not yet understood theoretically: examples are so-called glueballs and hybrid mesons. By studying QCD on the lattice, these ideas can be tested quantitatively.

A related question concerns what happens with all these particles when the temperature (as in the early Universe) or the matter density (as in neutron stars) is increased. Also this can be studied numerically and a transition to a new phase of matter at high temperature, the quark-gluon plasma, has been observed. Since this phase is currently being explored at the LHC, by colliding heavy ions, quantitative predictions on the spectrum and on transport properties, such as how viscous the plasma is, are needed here as well. 

Some BSM models also lack a small parameter and hence are studied using similar lattice computing techniques. By scanning models with distinct features, again hints for the LHC may be found, e.g. with regard to unusual spectral features.",0
EP/S001921/1,13516,An intelligent approach to the automatic characterisation and design of synthetic promoters in mammalian cells,"Synthetic Biology (SynBio) is an emerging engineering discipline with an ambitious goal: empowering scientists with the ability to programme new functions into cells, just like we would do with computers. Despite a thriving community and notable successes, however, writing &quot;functioning algorithms&quot; for cells remains extremely time-consuming. This is a roadblock towards the engineering of mammalian cells, an area uniquely positioned to develop potentially groundbreaking therapeutic applications. This translates into high development costs that, in turn, are limiting the pace at which Synthetic Biology progresses towards applications. Model-Based System Engineering (MBSE) is the answer the engineering community found to similar problems and is widely used to streamline manufacturing. In this framework, mathematical models are used to screen candidate designs via simulations and bring to testing only the most promising solutions.

Despite being an engineering discipline, SynBio lacks a MBSE framework. This is largely due to three connected issues: (a) the scarcity of accurate mathematical models of parts (e.g. promoters) in the first place. Such a shortage (b) makes it difficult to &quot;reverse engineer&quot; the connection between the DNA sequence and the kinetics of the transcribed mRNA (e.g. promoter sequence and leakiness of expresion). This means that (c) the inverse &quot;re-design&quot; problem, i.e. finding the optimal DNA sequence of a part, cannot be solved, let alone automatically.

With this fellowship, I aim at filling this gap and develop a &quot;Model-Based Biosystem Engineering&quot; (MBBE) framework to automate the Design-Build-Test-Learn (DBTL) cycle in Synthetic Biology. Given their role in cell and gene therapy, with my team, we will focus on synthetic promoters for mammalian cells. Prompted by the recent successes and challenges of CAR T cells -immune cells engineered to kill cancer cells, we will use the framework to engineer a hypoxia-inducible promoter that optimises a set of criteria we will determine and prioritise with our collaborator Prof. Chen at UCLA.

We will first focus on the development of the MBBE framework; to this aim we will tackle the three issues mentioned above by: (a) developing a high-throughput microfluidic device that allows to infer, with minimum experimental efforts (via Optimal Experimental Design), reliable mathematical models of hundreds of variants of a promoter, (b) using these results to automatically learn/predict gene expression dynamics from promoter sequence via machine learning and (c) combining this prediction scheme with computational optimisation to identify and refine promoter sequences so that they satisfy given specifications and maximise pre-determined objectives.

To develop a hypoxia-inducible promoter, we will start from an initial pool of 600 sequences -designed to cover a fraction of the design space as big as possible, and we will iterate twice over our automatic DBTL loop to finally obtain promoter(s) that can be used to overcome the current limitations of CAR T cells.

Besides automating the DBTL cycle, the approach I propose has three main benefits: it allows to obtain, and publicly share, reliable models (1) faster -as we will use Optimal Experimental Design methods to minimise experimental efforts, (2) cost-effectively -as microfluidics drastically reduces the use of reagents and automation renders human intervention unnecessary; (3) in a reproducible way -as all the data and the steps in the inference are tracked and immediately made publicly available.",0
ES/P006043/1,20701,Partnership Schools for Liberia: Impact on Accountability Mechanisms and Education Outcomes,"Liberia's public education system is moribund. The civil war of 1999-2003 and the Ebola epidemic of 2014 have left the Ministry of Education with little capacity to run a national school system. An effort to clean thousands of ghost teachers from Ministry payrolls was cut short (New York Times, 2016), and while systematic data is scarce, teacher absenteeism appears common (Mulkeen, 2009). Nearly two-thirds of primary aged children are not in school, including over 80 percent of children in the poorest quintile, placing Liberia in the lowest percentile of net enrollment rates in the world, and at the 7th percentile in youth (15-24) literacy (EPDC, 2014).

Faced with these dire statistics, the Liberian Ministry of Education announced in early 2016 that it would contract the operation of government primary schools to a group of private companies. Key features of this public-private partnership are that (a) all schools will remain free to students, and (b) teachers will be unionized civil servants, drawing from the existing teaching corps.

We propose a large-scale field experiment to study the effect of this new Partnership Schools for Liberia (PSL), comparing 120 schools that have been delegated to management by private operators to 120 control schools under government management. The randomized field experiment will allow us to investigate three main aspects of accountability:

1. Managerial accountability (of teachers to private operators). A central hypothesis underlying Liberia's charter school program is that private operators with greater capacity to implement routine performance management systems, regularly monitor teacher attendance, and provide teachers with frequent feedback and support will help to overcome teacher absenteeism and low education quality. This is not about carrots and sticks. We will test private operators' ability to generate accountability without authority to fire teachers or hire new teachers on flexible contracts.

2. Bottom-up accountability (of teachers and operators to parents). An underlying hypothesis behind charter schools is that they will be more reactive to parents demands than traditional public schools because their funding is linked directly to enrollment numbers. We will test this by comparing student transfers (exit) and parental involvement (voice) in PSL and control schools.

3. Top-down, results-based accountability (of private operators to the Ministry of Education). Charter school operators' contracts can be terminated if they do not achieve certain pre-established standards, commonly known as results-based accountability. The first year of the PSL pilot (2016/17) will lack any formal mechanism to hold operators accountable for results. A major innovation and focus of the year 2 expansion under study here is to develop and test different forms of top-down accountability based on measurable learning gains.

This proposal seeks support for a follow-up study to track the longer-term effects of the PSL program in years two and three of operation (2017/18 and 2018/19) focused on scalability and sustainability. A separate evaluation of the first year PSL pilot (2016/17) is already underway and will be nearing completion when DFID-ESRC funding decisions are made. The longer-term follow-up study is of paramount importance for several reasons. First, it is important to document whether any learning gains achieved in year 1 can be maintained over a longer horizon. Second, the year 1 pilot has been heavily subsidized and disproportionately concentrated in Monrovia, whereas years 2 and 3 will focus on more cost-effective and sustainable models, including new schools in more remote and underserved areas. Third, in years 2 and 3 the program will introduce new top-down results-based accountability measures mentioned above, which are a major focus of our current proposal.",0
1912377,12128,Liquidity and the making of unconventional monetary policy,"This research project addresses the role of liquidity in the making of this unconventional monetary policy in the United States and the United Kingdom. While liquidity problems were mentioned frequently following the crisis, there remains very little agreement about what the concept actually means. Instead, we often encounter liquidity only as a metaphor: for example, we are told that during the crisis, markets that were previously 'awash with liquidity' suddenly 'dried up'. But how exactly do policymakers make sense of the policy challenges associated with liquidity if the concept itself remains so elusive? 
Liquidity typically describes the convertibility of an asset into a form of money. Yet the term remains conceptually ambiguous because it encompasses both the 'money-ness' of individual assets, and a state of financial markets more generally in which such assets can be exchanged. Liquidity is never inherent in any asset but always rests on the speculative confidence that the financial community as a whole places in the continued 'money-ness' of financial assets (Orl&eacute;an 2014). Conversely, liquidity evaporates when economic actors lose confidence in the ability of economic models to accurately forecast future movements in risk and value (Colander et al. 2009; Bryan and Rafferty 2013; Davidson 2010). Every financial crisis is therefore also a crisis of valuation. The financial crisis of 2008 has been a powerful reminder of this. To avoid a total financial meltdown, it then becomes the responsibility of the state to assume hitherto unconventional powers in the attempt to restore confidence in the internal cohesion of the market's valuation regime (Mehrling 2011). 
I suggest that making sense of liquidity is a highly political process: it always legitimates specific courses of actions and economic discourses at the expense of others (cf. Admati and Hellwig 2013; Langley 2014). Until now, there has been very little research on how policymakers draw on different idea of liquidity in their attempt to make sense of the policy challenges at hand. Building on recent studies of the micro-dynamics of sensemaking and narration that shape the communicative strategies of central banks (e.g. Abolafia 2010; Abolafia and Hatmaker 2013; Braun 2015; Fligstein et al. 2014; Holmes 2016), I seek to critically analyse how the relationship between liquidity and monetary policy has been recast in the imagination of central bank researchers and policymakers since the financial crisis, and has legitimated a specific set of political responses. 
The aim of this project is therefore to provide a genealogy of liquidity. Drawing on the methodological framework of pragmatist sociology, I emphasise that, historically, multiple and fragmented meanings have been attached to the concept of liquidity. A genealogy offers the possibility to create a better understanding of how different approaches to liquidity have always co-existed and underpinned very different ideas about the relationship between the state and the market. Based on this approach, I ask specifically how researchers and policymakers at the Federal Reserve have (re)interpreted their relationship to liquidity during and after the financial crisis of 2008. By focusing on the imaginary dimension of crisis - i.e. how different interpretative practices feed the diagnosis and negotiation of crisis and post-crisis episodes - I ask how different historical judgements and critiques of liquidity are struggled over and incorporated into a coherent narrative of (unconventional) monetary policymaking. 
In order to achieve these research goals, I will need to conduct interviews with relevant policymakers in London and New York. Overseas fieldwork in the form of archival work at the Federal Reserve in New York and at the Bank for International Settlements in Basel will also be necessary.",0
1775865,5745,Magnetohydrodynamics in hot Jupiters,"The field of exoplanet research is relatively young with the first exoplanet orbiting a main-sequence star discovered in 1995. &quot;Hot Jupiters&quot; (Jupiter sized planets orbiting
close to their host stars) were the earliest discoveries and are the best characterized exoplanets due to their favorable observing conditions. They are also substantially
different than the giant planets in our own solar system. For both of these reasons, hot Jupiters are an ideal test bed for theories of dynamical processes in gas spheres.
Two of the most fundamental and long standing observational mysteries associated with these objects are: 1) How did hot Jupiters get to their current close positions
(i.e. how did they form)? and 2) Why are they so big? In this project we will be focusing on the second of these two problems.

Recent observations of hot Jupiters indicate that these objects are often substantially larger than standard evolutionary theory predicts. The inflated radii can only be explained by an injection of heat into the planetary interior, which halts gravitational contraction as the planet evolves. One of the leading theories is that Ohmic
heating, due to the dissipation of electric currents, may cause this inflation. This project will use numerical simulations of the magnetohydrodynamic (MHD) equations in both cartesian and spherical geometry to quantify Ohmic dissipation under a variety of parameters typical of the observed hot Jupiters. More specifically, this project will investigate the effect of a fully temperature dependent magnetic diffusivity on the wind structure, magnetic field geometry and Ohmic dissipation within the atmosphere.

The theories developed in this project will be incorporated into planetary evolution models and compared to observations of hot Jupiters. Such observations are already in abundance, but will multiply rapidly with current and future space missions dedicated. Additionally, our simulations will also inform on atmospheric dynamics, atmospheric loss rates and planetary spin down.",0
2275015,43784,Monoclonal antibodies for Lassa fever vaccine design and therapeutics,"Using new improved methods for plasma cell Ig-cloning and to investigate antigen-staining memory B cell enrichment to isolate novel monoclonal antibodies to Lassa fever. There will also be the opportunity to utilise phage display techniques as an alternative approach to antibody isolation. Whilst antibody cloning is a key element of the work, the majority of the project will be spent characterising the antibodies to include epitope mapping, development of replication-competent chimeric VSV isolates and their use in antibody escape.",0
971690,41219,HECall - The use of eCall data to identify road incidents and hazards,"Since April 2018, an innovative service has been fitted to all UK new cars and light goods vehicles. Called 窶彳Call窶・ it is now mandated by law. It detects if the vehicle airbag is activated, or a user presses an emergency button. eCall then connects the occupants to talk to 999, and provides extra data on the path and location of the vehicle and identity. There are already 3500 UK eCall activations per month, and this is rising exponentially. Whilst the voice aspect is valuable, currently absolutely nothing is currently done with this valuable additional data in the UK. But Highways England (HE) has a challenge in quickly and accurately locating incidents, understanding their severity and then developing a timely response. This is a particular challenge on non-motorway roads where there are few cameras or other assets such as Traffic Officers. With voice eCall only currently being used, details of an incident could take minutes to get to an RCC or maintainer compared to the direct transfer of data. In the voice only system, vital data such as vehicle location and identity needs to be transcribed between systems and people. This is not sustainable. Using the data from eCall offers HE an operational tool that could provide a new input to CHARM to aid RCC responses, and a source for 窶彙ig data窶・analysis of the entire HE and indeed UK network, especially to assist the issue of unreported incidents in STATS19. eCall has previously been seen as an additional cost to users rather than part of the car itself as now, and so the business case for HE has not until now been positive. However, with eCall now paid for by the vehicle owner, this situation has fundamentally changed. eCall is now here and operating, it is no longer a 窶徇ight be.窶・HE customers will rightly expect HE to be involved in the eCall chain, and so will the media. This is especially so on a 窶徂i tech窶・smart motorway. We believe that if HE does not use eCall data, you may be open to at least a reputational risk if not more serious implications. Hence this feasibility study looks at a service that harvests currently unused yet valuable eCall data, filters it and verifies it to reduce false alarms on RCCs. It publishes it to CHARM and potentially to other users such as National Vehicle Recovery and managing agents. It looks at the costs and benefits of a new approach, working through GDPR and develops a conceptual design focussed on HE operational needs that could be a commercial product of value for non-HE roads, for DfT and for export. We call this service 窶廩ECall窶・ It is promoted by a team with unrivalled expertise in RCC operations, eCall, CHARM and driver information who will ensure the operational day to day feasibility of this as a tool will be fully explored, and then can be converted into a commercially exploitable innovative service for wider UK roads and potentially export markets.",0
MC_UP_1201/13,14261,Mechanisms of polarized trafficking induced by cytoskeleton asymmetries,"The hallmark of cell division is to divide the cellular contents equally between the two daughter cells. Cell division is, however, not always symmetric. In so-called asymmetric divisions, the two daughter cells do not receive the same information from the mother cell, and thereby may adopt different cell fate. This is true for instance in stem cells, where one daughter cell specialises to perform a specific function in the organism, while the other becomes another stem cell that keeps the ability to divide. Failure in this process has been linked to tumor formation (in case when the division outputs only stem cells) and aging (when the division outputs only differentiated cells).
 We are trying to understand how fate determinants segregate asymmetrically during asymmetric division. In particular, we aim to understand physically how polarity signals are 窶忤ritten窶・onto the inner scaffold of the cell, called the cytoskeleton, and how in turn these polarity signals are 窶徨ead窶・by fate determinants to segregate asymmetrically. We combine state-of-the-art imaging of stem cell division in a model organism, Drosophila melanogaster, together with in vitro reconstitution using purified proteins, relying on theoretical physics to bridge these different scales. Our ultimate endeavor is to expand the potential of our work towards mammalian stem cells, in the hope to restore this ability in situations where it has been lost.",0
1948684,3336,The impact of socio-economic polarisation and inequalities of wealth and income on sensorimotor development in children,"This project will study the specific role that children's motor skill development plays as an intermediary link in the pathway between SEP and cultural factors, and resultant inequalities in wellbeing and attainment. Movement underpins the learning of many more abstract skills and thus is a plausible 'bridge' through which factors in learning environments may have knock-on impacts on how effective children's wellbeing, affected by cultural biases and being strongly predicted by underlying socioeconomic status. This studentship will draw upon these insights and will explore them using robust longitudinal methods in a uniquely rich dataset - transforming our knowledge and understanding of the developmental pathways that likely play a significant contributory role in determining later life inequalities in social mobility and wellbeing.",0
EP/T517604/1,35935,Industrial CASE Account - University of Southampton 2019,"Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes, see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.",0
ST/N001230/1,32274,STFC Capital Bid from the HEP Group to STFC 2015,"This provides essential capital hardware to develop experimental detectors to support our research and provide potential spin-outs.
This research is aimed at understanding the properties of the basic building blocks of the Universe (the elementary particles) and the nature of the fundamental forces that govern the interactions of these particles. In so doing, deep insights will be gained about the origin and evolution of the Universe, especially in the first moments after the Big Bang.
The Lancaster research programme covers all the main types of accelerator facilities and is based on hadron collider physics with the LHC (CERN) machine, and the observation of long baseline neutrino oscillations in Japan and elsewhere. All of this work will be underpinned by Lancaster's expertise in characterising and understanding the properties of heavily irradiated silicon particle detectors, in operating high performance computing facilities on the Grid and in writing offline event reconstruction software.
The hadron collider physics is expected to reveal detailed properties of B hadrons (containing heavy b-quarks) including the mixing of neutral B mesons containing strange quarks, and CP violation which is related to the existence of the matter- antimatter asymmetry in the Universe. Searches for new physics at the LHC will focus on understanding role and nature of the Higgs boson, the existence of new symmetries of nature (e.g. supersymmetry) and extra spatial dimensions.
The neutrino oscillations programme is expected to provide important information about the masses of and the amount of mixing amongst the three known species of neutrinos. If the appearance of electron neutrinos can be well measured in a muon neutrino beam then it may be possible, in a further phase of the research, to establish the existence of CP violation in the neutrino sector of the Standard Model. This could have wide reaching implications for the understanding of the matter- antimatter asymmetry of the Universe.
The development of new particle accelerator technology for high energy particle physics and a broad range of alternative applications is the mission of the Cockcroft Institute. The Lancaster group were co-founders of the Institute and remain committed to supporting its evolution. Equally, we work to develop particle detectors (silicon strip, pixel, LAr TPC) and technologies (CMOS) to benefit the field, but also with potential spin-out benefit to science and society.",0
2114823,23339,The diversity of supernova explosions,"Exploding stars, or supernovae, are important probes of the extragalactic universe, from finding the lowest metallicity environments, to studying the large-scale dynamical effects of dark energy. However, many aspects of supernovae as a population of events remain unclear, including the variety of supernova types, their luminosities, and their progenitor stars. This project will use data from two large, recently-completed surveys of supernovae - the Dark Energy Survey and the OzDES survey - to probe and understand the statistics of the supernova population. These data, on thousands of supernova explosions, will be the first census of the high-redshift explosive transient population, with a particular focus on the diversity of the core collapse supernova population.

These results will then be used to prepare for two major new facilities that will revolutionise the study of supernovae. The first is the Large Synoptic Survey Telescope (LSST), an 8-m survey telescope that will image the whole sky every 2-5 days, and which will find new supernova explosions at an unprecedented rate. The second is the ESO 4MOST multi-object spectrograph, which will study thousands of supernova explosions and their host galaxies in great detail as part of its TIme Domain Extragalactic Survey (TIDES). Our project will provide the data needed to optimise these two experiments, enabling us to ensure that the combination of facilities will provide the ultimate cosmological sample of type Ia supernovae, and probe completely new parts of time-domain parameter space.",0
509806,33913,University of Strathclyde and Brightwake Limited,"To transfer key device simulation, modelling and blood processing skills to enable development of a novel extracorporeal treatment for sepsis.",0
MR/R014094/1,14887,"Developing a theory of change, outcome measures and evaluation design for an evaluation of the impact of the Daily Mile on obesity and health","Getting children to be more physically active is important. Many do not currently do enough exercise to protect their health. This contributes to the growing problem of obesity. To address these problems, the UK Obesity Strategy has many recommendations: one is that primary schools take part in The Daily Mile. This involves children running or walking/jogging for 15 minutes every day, in school, in which time most children will average at least one mile in distance. It is a popular scheme which started in Scotland and is now being rolled out widely, with over 750 schools in England already taking part. There are many potential health benefits from The Daily Mile. If it increases the physical activity children do, it improves their fitness and may help protect from obesity and other health problems in later life. The physical benefits may also improve children's concentration and behaviour in the classroom. However, there are also some potential negative effects. The scheme may take school time away from other, more beneficial, activities. It may put some children off doing sports or other activity in later years. We would like to understand more about all the possible health effects from the Daily Mile, and (if these are positive) how it works best. What is needed for it to work? What stops it working? Does it have different effects for different kinds of children or schools?
These are difficult questions to answer because we cannot just compare children who have taken part with those who haven't. Schools that choose to take part are likely to be different from the ones that don't, and health differences we find may reflect this, not the effect of The Daily Mile. This is a common problem in public health research. An additional problem is that policy makers need to know whether a scheme will work in their area. Schools will want information on what the necessary conditions for success are, and how to implement the scheme to get the most benefit. 

We aim to look at all the possible ways that The Daily Mile might impact on children's health. We are particularly interested in obesity. All children are weighed and measured at age 5/6 and again at age 10/11, so we can compare differences in weights over time within schools which have and have not taken part. We also want to find out what other possible outcomes might be included in a study, and whether there is available information about these. Finally, we aim to develop new ways of using case studies of implementation. We will look in detail at Lewisham, talking to children, teachers, parents, heads, and public health specialists to look at what happens when a school decides to get involved in The Daily Mile. This is important because policies are taken up in complex, and varied, settings. We need to understand better how these settings affect whether something works, for whom, and why. Issues such as who decides the school will take part; what kind of school it is; what kinds of children are enrolled at the school might change what happens. We will use this information to help us understand whether The Daily Mile might have different effects for different children - such as for boys and girls, or those from different backgrounds. At the end of this study, we will have: 1) A detailed description of The Daily Mile, using a checklist used by public health researches to describe interventions; 2) A full map of all the possible health outcomes from The Daily Mile; 3) A plan for a study that can evaluate these across England. We are working in collaboration with partners who have an interest in what works to improve children's health.These include colleagues from The Daily Mile Foundation, public health specialists from Lewisham, teachers, governors and parents from schools in Lewisham and other areas, and other academic colleagues. This partnership will ensure that our findings are taken to the next stage, which will be a national evaluation of The Daily Mile.",0
AH/M011305/1,2834,Unlocking the Medinan Qur'an,"My project aims to advance and transform the scholarly understanding of a particularly challenging portion of the Qur'an - namely, of those surahs (= approximately, chapters) and passages which are associated with the period after Muhammad's and his followers' emigration (hijrah) from Mecca to Medina, an event traditionally dated 622 CE. Given its distinctive stylistic and thematic profile, these surahs and passages - which I propose to call the &quot;Medinan Qur'an&quot; - are defensibly viewed as constituting a discrete stratum of the Islamic scripture. It includes the longest and most bewildering texts in the Qur'anic corpus (surahs 2-5 and 8-9) and also comprises a considerable number of putative Medinan insertions to earlier Qur'anic proclamations. 

The Medinan Qur'an occupies a key position in the formative history of Islam: It fundamentally shaped later Islamic convictions about the paradigmatic authority of Muhammad and thereby inspired the post-Qur'anic emergence and compilation of a multitude of reports about his extra-scriptural utterances and actions (the so-called hadith). The Medinan Qur'an also forms the ultimate inspiration for Islam's development into a religion with a strong focus on law. Finally, it is only in Medinan texts that we find Qur'anic injunctions to militancy and religiously motivated warfare as well as an explicit demarcation of Islam from Judaism and Christianity.

Despite the Medinan Qur'an's vital importance for the emergence of classical Islam, its scholarly analysis is still lagging behind. Are the long Medinan surahs merely agglomerations of self-contained paragraphs or do they constitute unified compositions? Can we reconstruct their literary emergence, including subsequent processes of revision and editing? What was the communal function or &quot;setting in life&quot; which Muhammad's Medinan proclamations originally served? How does the Medinan understanding of righteous behaviour, of Muhammad's prophetic and political authority, and of the nature of the Islamic community diverge from that of the earlier Meccan texts? To what extent is the stylistic, literary, and thematic shift that is visible between the Meccan and the Medinan layers of the Qur'an underpinned by the appropriation and transformation of pre-Qur'anic ideas, concepts, and modes of expression? To what extent, how, and why does the Medinan Qur'an, despite this shift, engage with and reinterpret the earlier Meccan material?

My research seeks to subject the Medinan parts of the Qur'an to a multi-dimensional and rigorous sequence of analytic steps. This will include an analysis of their compositional structure and their most important literary forms and phraseological conventions, the reconstruction of processes of textual expansion and revision, and the juxtaposition of Qur'anic passages and notions with possible Rabbinic and Christian parallels. Through my research on the Medinan Qur'an, which will be published as part of a comprehensive synthesis of the current state of historical-critical Qur'an scholarship, I shall showcase a rich and non-reductive way of studying the Islamic scripture in its historical context of origin which will provide a methodological paradigm for future contributions to the field. In parallel with my own work, I shall also launch a collaborative investigation into the Medinan Qur'an by a group of internationally renowned scholars. To this end, I shall convene a conference which will lead up to the production of an authoritative reference work. Finally, I shall undertake a range of additional activities aiming at a wider dissemination of my research both among the academic community and the general public.",0
BB/N004981/1,26489,15 BEDREST Effects of bed rest on the circadian organisation of the human transcriptome as a model for temporal dysregulation in an ageing population,"Circadian (about a day) rhythms in behaviour and physiology synchronise our activity to the outside world. The importance of robust, well-synchronised circadian rhythms is evident from the negative effects experienced during jet lag or sleep deprivation, and also disruption of sleep and circadian rhythms that occurs during spaceflight. The strength and the timing of circadian signals become reduced and disrupted during spaceflight and ageing and may account for many changes observed with sleep/wake activity in astronauts and the elderly. Circadian clocks around the body regulate most physiological processes such as metabolism, cardiovascular function, and the immune system and both long duration spaceflight and ageing may disrupt the circadian regulation of these processes and be associated with related negative health outcomes.

Circadian clocks also regulate hormones such as melatonin (which peaks in the night) and cortisol (which peaks on awakening). Cortisol is an important circulating signal that regulates the expression of many genes, including those that make proteins involved in immunity and inflammation. Cortisol secretion is also disrupted during spaceflight and ageing and could change the regulation of the expression of many genes.

Blood circulates around the body and is increasingly viewed as a 'window' on the whole-body state. For example, blood biomarkers are now used to diagnose and to monitor disease progression in many different diseases ranging from Alzheimer's to cancer. Temporal organisation in the expression of genes to make proteins is important - certain proteins need to be made at particular times of day or night - and in any given tissue around 6-10% of all genes are expressed with a circadian rhythm, including in blood. In two separate human studies, we have shown that one-week of insufficient sleep or mistimed sleep (as occurs in jet lag) leads to dramatic disruption (both timing and amplitude) to the circadian rhythms of blood gene expression. This included disruption to genes normally expressed during the day (immune response, inflammation, oxidative stress) and those normally expressed during the night (regulation of protein synthesis), as well as core clock genes central to the generation of circadian rhythmicity itself.

Spaceflight and its bed rest model result in circadian disruption to melatonin and cortisol. This circadian disruption likely extends to the temporal disruption of gene expression in blood, although nobody has investigated this to date. Thus, during bed rest there is disruption to circadian signals, elevated circulating cortisol, changes in blood circulation, changes to cardiovascular function, including suppressed immune function, all of which are also found in ageing. Therefore, many of the negative health effects found in astronauts and the elderly could be directly associated with temporal disruption to the circadian regulation of gene expression in blood. The main aim of the research proposed here is to perform a careful study of gene expression in blood of people who are undertaking a bed rest protocol. By comparing a series of blood samples collected through the day and night at different stages during the bed rest period with similar timed samples collected at baseline and during recovery, we will be able to identify networks of genes whose disruption affects specific biological processes, which may include the immune system and other processes not yet shown to be affected by bed rest. It is difficult to study these effects directly during long duration spaceflight or during ageing over extended time periods and the bed rest protocol provides a practical means to explore changes in defined laboratory conditions. It is assumed that bed rest models ageing and we will also use this model to assess the methodological aspects of whether blood sampling is a viable approach to monitor effects of temporal disruption in ageing and to assess the effects of countermeasures.",0
MR/M023281/1,8443,Modelling and Predicting CKD Progression,"An overarching objective of this research is to revisit the problem of modelling the progression of Chronic Kidney Disease (CKD) using state-of-the-art machine learning techniques and methodologies. We introduce three innovations in this project. 

First, we shall investigate statistical models that directly predict key clinical variables so that clinicians can make more informed decisions. This approach is more consistent with guidelines-based prescribing that is used by general practitioners. 

Second, we will develop a way to identify patient groups by using data-driven methods. The approach used is similar to 'market segmentation' used in Business Intelligence. The hypothesis is that patients can be divided into groups not by their disease or stages (as currently practised) but by their patient records that essentially capture their health history. In essence, this method of grouping will naturally group patients with similar treatments including drugs and procedures and similar physiological and pathological characteristics. 

Third, as part of the process in predicting the efficacy of kidney function, we will develop a risk model for predicting and detecting Acute Kidney Injury (AKI). This novel model will inform clinicians how likely it is that a patient will suffer from AKI. In short, we propose a unified framework to predict the efficacy of kidney function that also considers the possibility of AKI. This represents a potential advancement in modelling and understanding CKD because the risks of end-stage of CKD and AKI are so far often treated independently. 

The potential advantages of the proposed method include: (1) better tailoring of the method to patient subgroups via data-driven stratification; (2) ability to exploit many more variables that are specific to each patient stratum; (3) ability to predict eGFR and ACR that can be used in conjunction with guidelines-based prescribing; (4) ability to predict Acute Kidney Injury. 

The main outputs of this proposal are: (1) patient-tailored eGFR predictor, (2) patient-tailored ACR predictor, (3) probabilistic AKI estimator, and (4) data-driven patient stratification. By patient tailoring, we understand that the model is capable of considering additional variables that are specific to a patient stratum.",0
720688,7633,PLD <U+0096> Precision LineScan Detector,"Portable X-ray inspection systems are frequently the first technology used by the authorities to
assess the potential threat from a suspect device and their ability to generate an image of the
device has allowed both terrorist incidents and false alarms to be avoided. A portable X-ray
system consists of an X-ray generator, an X-ray detector panel and a user terminal, typically a
PC or tablet computer. Important performance parameters include X-ray penetration, good
image resolution, and more recently the ability to discriminate between materials. Our
proposal is to utilise the IBEX materials classification technology, which uses a Multi
Absorption Plate (MAP) and advanced software algorithms to create materials discrimination
from a conventional amorphous silicon detector with a single energy scan. The enhanced
capabilities of the proposed system are expected to lead to higher detection rates of small
threat objects, and greater discrimination of organic-based materials such as homemade
explosives and biological threats",0
2126041,10169,Basketball's cultural value and contribution to national sport heritage,"Established in 2016, the National Basketball Heritage Archive and Study Centre (NBHASC) is a new contributor to the country's sport heritage landscape. Reflecting the sport's approximately 120-year history within the UK and its strong supporter base, the NBHASC serves as the key repository for a raft of social and cultural artefacts associated with the sport and its followers. The project examines the collections and the organisational operation of the NBHASC, based at The Hive in Worcester. Unlike other sports in the UK, basketball originated from abroad and its development, histories, and cultural reference points have been influenced by its international (specifically American) origins. Transnational influences and exchange have shaped the sport's organisational structures, participant demographics, fan culture and the production of heritage artefacts. As a tool for social development, basketball plays a discernible role in the lives of many young people, including those within Black, Migrant and Ethnic populations. Basketball is now ranked the second most popular sport in the UK among the 11-15-year-old demographic. The project will reflect upon the key aims of the NBHASC to 1) promote the contents of the collection to demonstrate basketball's cultural and social value; and, 2) To develop and encourage activity that engages members of the basketball community and wider public with the sport's histories and heritage.",0
700621,21880,Market Study of New Applications for a novel colour monitoring technology platform,"These have to be unrolled and re-rolled by machines to give
the correct stretch prior to automatic cutting. This presents an ideal opportunity for automatic
scanning to detect colour variation before machines cut pieces that workers sew into a
finished garment. We have demonstrated added value to both garment manufacturers and
fabric dyers and printers. We sell slightly different versions of our technology to these two
groups of customers. Our current system has been adapted to swimwear and lingerie and we
now want to diversify into other fabric types.
We have identified several different fabric types, for which C-tex colour could improve
manufacturing processes. Each will need specific adjustments to hardware and software of the
core technology. The purpose of this study is to identify:
Which sectors will benefit most from colour variation monitoring?
How large each of those sectors are; i.e. are they worth us developing variants for?
What technical adjustments do we need to make, and how much will it cost to develop a
prototype for these?
Ours is a market worth &pound;120Bn worldwide, growing at a CAGR of 14.02%. We export 90%
of our products, adding to the &pound;5bn of exports that textiles contributes to UK exports and
&pound;37Bn to the UK economy overall.",0
2097366,20615,Utilising microbial community dynamics to shape beneficial plant root microbiomes,"MIBTP CASE students undertake a period of training before confirming a final PhD project description. The training period will include: quantitative skills training (programming, statistics, DNA Sequence Analysis and modelling), a series of bespoke masterclasses and a three-month mini-project.",0
2249362,41198,CDT in Connected Electronic and Photonic Systems,"This is a 1+3 year programme consisting of a 1 year MRes and 3 year PhD. Students will spend the first year of the programme being trained in a broad range of enabling skills at both University of Cambridge and UCL, which will equip them to become leading edge researchers in the field. A Master's degree (MRes) will be awarded on completion of the first year programme. Students will then register at either University of Cambridge or UCL for a 3-year PhD degree, working on projects defined by research groups active in photonics from across both universities.

First MRes project
Dates: Nov 2019 - May 2020
Topic: Porous GaN waveguides for infra-red gas sensing applications.
Supervisor: Prof Rachel Oliver, University of Cambridge.",0
103969,5250,Improving Card Tap Compliance,"Incomplete journeys (where passengers forget or are otherwise unable to touch their card on a ticket validator at beginning or end of journey) are an issue for passengers and operators alike, leading to passenger frustration, revenue loss and additional administration costs for the operator. This project addresses this issue by taking a human-centred approach in designing and implementing an innovative reminder system which will prompt individual passengers who are identified being at risk of having missed a tap. Improved passenger experience will be an immediate benefit of this system, however, indirect benefits such as increased uptake of smart ticketing and capacity improvements are also foreseen. Having gained an understanding of the reasons behind incomplete journeys, the project will design and test user interface concepts and then deploy and test the most compelling candidates into a live station for an extended pilot. We will gather feedback throughout the pilot duration and work in an agile way to improve the concept in a quick but controlled fashion. Combining cutting edge vision based tracking technologies with existing validator systems and novel feedback mechanisms the project outcomes will be applicable in a much wider scope, in particular around innovation in gateline technology and future ticket detection systems.",0
511341,20287,Sheffield Hallam University and Kingspan Access Floors Limited,"To develop high performance, low embodied energy core materials for the Kingspan raised access flooring system as used in buildings worldwide. Develop models to predict in-service performance such as strength and deflection. Use advanced techniques for monitoring defects for enhanced quality assurance.",0
BB/M002578/1,30163,The mechanics of epithelial tissues,"Many of the cavities and free surfaces of the human body (e.g. gut, lungs, blood vessels) are lined by tissues just a few cells thick. These epithelial tissues separate the body's internal environment from the external environment. As part of their normal function, epithelial tissues are continuously exposed to large mechanical deformations: lung alveoli deform during respiration, intestinal epithelia resist peristaltic movements in the gut, and endothelia are exposed to pulsatile fluid shear stresses in blood flow. The mechanical function of epithelia is particularly apparent in disease when mutations or pathogens affecting the cell skeleton (cytoskeleton) or junctions linking cells to one another result in fragile tissues that tear during routine function (e.g. epidermis bullosa, staphylococcus blistering). Cells within epithelial tissues are tightly connected to one another by intercellular junctions: some junctions form a barrier restricting the passage of solutes across the tissue whilst others integrate the cytoskeletons of neighbouring cells to form a strong multicellular tissue that can withstand mechanical stresses. Despite their clear mechanical role, little is currently known about the mechanics of epithelial tissues and how this derives from the mechanical properties of the cells that make up the tissue and the proteins that make up the cells. This is primarily due to the lack of specific experimental techniques to measure the intrinsic mechanical properties of tissues while monitoring cellular and subcellular traits.

We have developed a novel tool to quantify the mechanics of epithelial tissues by stretching cultured epithelia. During tissue deformation, the applied mechanical tension can be measured and the tissues can be simultaneously imaged at subcellular, cellular and tissue length scales, such that the architecture of the sub-cellular components, the shape of the cells and their eventual reorganisation can be accurately monitored as a function of the imposed force. To complement this experimental tool, we have developed a novel computational model of epithelial tissues that can serve as a means to interpret and refine our experiments.

We now propose to use our new techniques to understand what proteins play a role in setting the mechanical properties of epithelial tissues. To do this, we will focus on three aims:

1) Develop a systematic methodology for characterizing the mechanics of tissues
2) Discover what proteins set tissue mechanical properties
3) Incorporate our findings into a computational model of tissues.

Aim1 is geared at creating a systematic methodology for collecting all of the necessary information to fully characterise the mechanics of normal tissues.

In aim 2, we will ask how the absence of a given protein affects the mechanics of a tissue. To answer this question, we will reduce the level of expression of a chosen gene in the cells that make up the tissue and measure how this affects the mechanics of the tissue. We will also examine how gene depletion changes the organization of the tissue and the cells that compose it. We will pay particular attention to proteins identified in clinical studies of fragile epithelia, as they have direct relevance to patients and potential palliative therapies.
In aim 3, we will use computational and statistical approaches to identify what cellular structures are the most important for setting tissue mechanics using the results of aim 2. Moreover, this analysis and the experiments from aim 2 will directly support the development of a model specifically tailored to study tissue mechanics at large deformation and used to refine our understanding of how changes in protein expression within cells can lead to failure of epithelial sheets, as in clinical cases.

In summary, the proposed investigations will greatly enhance our understanding of the mechanics of epithelial tissues and how pathologies can affect tissue strength.",0
113190,34628,FANTASTICAL (FAN Testing And STatistical Integrity CALibration),"&quot;UltraFan Demonstrator is the &quot;&quot;first of family&quot;&quot; future Civil Large Engine products that will see a highly efficient engine architecture deployed across a range of engines for future airframes. The UltraFan engine will be the ultimate turbofan, delivering 24,000 - 100,000lbf. It will be available to the civil aviation market from 2025\.

The FANTASTICAL project will deliver larger than ever UltraFan low-speed carbon composite fan blades for both rig test and engine testing. The project will validate predictions secured through research at leading UK universities where methods to evaluate fan blade performance under harsh environmental conditions will be developed.&quot;",0
1956519,27143,Founder Imprinting and Entrepreneurship,"This research will explore the effect of founder imprinting on long-term outcomes for UK businesses. It will seek to establish the extent to which the strategic choices (the imprint) that the founding entrepreneur makes at start-up subsequently influences how the business develops over time. In particular we will seek to identify robust empirical evidence relating to the following 3 research questions;

1. How long does this founding entrepreneurial imprint continue to impact on business outcomes? 
2. Does the strength of this founding entrepreneurial imprint change (strengthen or weaken) over time? 
3. Compared to other aspects and characteristics of the business, how important is the basic founding imprint in explaining long-term outcomes 

The potential impact of this research is substantive as policy-makers in the UK have begun to reallocate their resources away from policies directed at increasing the entrepreneurial population per se, and towards policies directed at entrepreneurial ventures with high growth potential. And this research would directly address this latter question of who, in terms of what types of entrepreneurs and entrepreneurial ventures, to target the governments increasingly scarce resources in this policy area at. There is also the potential for business support agencies and advisors to bring the research evidence into their more practical offers to new and young businesses. At the academic level, this research also has the potential to extend our understanding of long-term outcomes of new business start-ups and define new avenues for future research.",0
511657,40340,Brunel University and Haes Systems Limited,"To develop a comprehensive communication solution, both wired and wireless, for fire alarm products to communicate with each other and 3rd party services while meeting industry standards.",0
MC_EX_MR/P00735X/1,3036,LMB - CoEN 2016 - Using C. elegans to understand seeding and spreading of tau aggregation,"With age, people become susceptible to multiple neurodegenerative diseases, such as Alzheimer窶冱 and Parkinson窶冱 diseases. These disorders are caused by an accumulation of proteins that are incorrectly folded, leading neurons to malfunction and die. We are interested in why these proteins misfold with age, and how misfolded proteins might spread through the brain, leading to an increase in disease symptoms over time.
This project focuses on one of these disease-causing misfolded proteins, called tau, which is associated with several neurodegenerative diseases, including Alzheimer窶冱 disease. We aim to find out whether other proteins that misfold as cells get older lead tau to misfold. We then aim to use a species of nematode worm, C. elegans, as a model for tau-related disease, creating worms that produce tau in different cells so that we can observe how tau misfolds and spreads from cell to cell in a living organism. We will then use these C. elegans models to manipulate genes that produce proteins we believe cause tau to misfold and spread, to see whether this affects disease symptoms in these animals.
Together, these studies will help us to understand why neurodegenerative diseases involving tau begin and develop, and suggest new therapeutic approaches to address them.",0
BBS/E/J/000CA598,20037,Regulating Tomato quality through Expression,"The twin objectives of RegulaTomE are to determine the importance of transcriptional regulation of the metabolic pathways defining quality traits in tomato and to identify such transcriptional regulators at the molecular level. The selected quality traits include antioxidant capacity which impacts shelf life and nutritional value as well as traits determining fruit flavor and over-ripening which influence organoleptic properties and shelf-life. RegulaTomE will use the natural variation available in introgression lines (ILs) resulting from wild species crosses to tomato to assess the importance of transcriptional regulation, identify additional regulatory genes and assess underlying genetic and epigenetic variation. RegulaTomE will assess the potential for direct or indirect use of natural variation from an untapped wild species resource for crop improvement. To identify genes regulating metabolic pathways using the Solanum lycopersicoides ILs, and to capture genetic and epigenetic variation for application to gene discovery and tomato improvement, resources need to be developed, including a genome reference sequence for S. lycopersicoides and metabolite, DNA methylation and transcriptome profiles of IL fruit. RegulaTomE will lead to regulatory gene identification and new tools for metabolic engineering of fruit quality. The natural variation in fruit quality revealed by the S.lycopersicoides ILs could be applied to tomato improvement either directly through introgression into cultivated varieties or indirectly through the identification of target loci and corresponding allelic variation making positive contributions to quality traits within S. lycopersicum breeding germplasm. The outputs of RegulaTomE will provide a framework of understanding as well as tools, in the form of genes, target loci and molecular markers, to support development of longer shelf-life, more nutritious and more flavorsome fleshy fruits in other horticultural crops.",0
1941790,23662,Functional human neural networks grown on 3D laser printed scaffolds,"Background: The last 10 years has seen a revolution in Biology and in Photonics Engineering. Namely, the development of methods to derive specific types of cells e.g. neurons from human induced pluripotent stem cells (iPSCs), and in photonics, the development of 2 Photon Polymerisation (3D laser printing), which allows microfabrication of substates with submicron resolution. In the brain, neurons function in defined 3D networks where the specific cellular and synaptic relationships are critical for effective function. To emulate human neuronal network function in culture, it is therefore, necessary to grow them in three dimensions.

Project: The aim of the project is to determine how 3D scaffold structure affects neuronal network architecture and function. This will involve 3D printing, growth of iPSC derived neurons and functional electrophysiological and calcium imaging of neuronal networks. The Student will also interact with the wider international membership of the recently awarded European FET Consortium, MESO-Brain, which comprises of Neuroscientists, Stem Cell Biologists, Physicists and Photonics experts.",0
752141,13671,External review of innovative security pairing protocol,"Westhawk has developed an approach that increases the security of peer-to-peer in-browser video and data connections (using WebRTC, for example for videocalls). Security (confidentiality and integrity of the connections) is a key advantage of the approach, but a thorough security validation is needed to ensure the security requirements are met. The innovation voucher will be used to allow this validation to take place so that it can be published in a reputable peer-reviewed publication, to establish the validity of the method.",0
2035790,3070,"Understanding reading comprehension in older adults identifying and examining stability, within and between, key components over time","Good reading comprehension is vital for effective and accurate sharing of information, and it is essential in modern society. Despite this, the most recent Skills for Life Survey revealed that almost 15% of adults in England lack sufficient ability to attain even the lowest grade in GCSE-level English assessments (BIS, 2011). Limitations in the capacity to fully comprehend written information can have significant consequences, complicating critical tasks such as understanding the instructions on medication bottles. Normal age-related changes in cognitive processes imply that older adults could be especially vulnerable to adverse changes in reading comprehension skills (Hannon &amp; Daneman, 2009). This is an important concern because the number of people aged 65+ is projected to increase globally by 383 million by 2030 (He, Goodkind &amp; Kowal, 2016). I propose a project to identify the cognitive resources underlying reading comprehension, and to investigate the stability of these components in older adults. The findings from this project will inform strategies to support effective reading comprehension across the lifespan",0
2238614,41511,Implicit Cognition and Personal Agency,"Recent studies in empirical psychology have revealed subtle ways in which our actions are influenced by implicit cognition - cognition that typically operates beyond conscious awareness and direct deliberative control. While philosophers such as Jules Holroyd and Michael Brownstein have attempted to provide models of implicit cognition, to explore its role in virtue and to establish what responsibility we bear for its influence on action, relatively little work has been done exploring how the influence of implicit cognition fits into the theory of action. That is the primary goal of my project: I aim to establish whether behaviour governed by implicit cognition should ever be considered an instance of human agency. In answering this question, I aim to explore the ramifications of the psychological findings for traditional conceptions of agency such as those defended by Donald Davidson and Christine Korsgaard. It may seem that such findings are not relevant for conceptions of agency; it has always been accepted that many aspects of action are unknown and not controlled deliberatively, though these aspects have been seen as beyond the scope of the study of a distinctively human kind of action. However, philosophers such as John Doris argue that the empirical evidence poses a threat to traditional conceptions that motivates redefining agency wholesale. Given how likely it appears that implicit cognition influences much of our action, it seems imperative to establish whether his scepticism is warranted and, if so, whether his response is successful, as I aim to do. 
 Two reasons why the influence of implicit cognition might seem irrelevant to conceptions of agency are that it often occurs without the agent's awareness and runs counter to her beliefs about how she should act, such as when an implicit bias causes an egalitarian to respond unfairly without her knowledge. Such behaviour is an unlikely candidate for action and much of the philosophical literature concerning implicit cognition focuses on examples of this kind. However, this focus on belief-discordant examples has caused cases in which implicit cognition helps an agent to act according to her beliefs to be overlooked. Where implicit cognition helps an agent act as she believes she ought, so that its influence is best explained by reference to her beliefs and values, there are grounds to say that what is done is done by her as a person in a sense that seems importantly distinct from other things that 'she' might unknowingly do merely as a body, perhaps due to a physical reflex. Whether this link to an agent's values is enough to make what is done an action deserves careful thought.
 The project will be interdisciplinary in nature, drawing in the work of psychologists and philosophers alike. It will attempt to establish more clearly whether implicit cognition is a tool used to achieve the feat of acting in a way thought to be distinctive of persons or whether it is simply a non-agential influence on behaviour. Accordingly, it will involve considering a range of relevant features of action such as alignment with the agent's values, deliberate control, knowledge of the action performed, and awareness of the causes of behaviour. Once the question of agency seems settled, the project may explore the closely related question of responsibility too, asking whether and when we are responsible for the influence of implicit cognition on action.",0
132095,16345,Affective Interaction Design of Child Toothbrush (AIDOT),"Tooth decay is the most prevalent childhood disease in the world even though and it is the most preventable health-related problem with just regular and proper toothbrushing. The 2013 Children窶冱 Dental Health Survey showed 46% of children in the UK develop teeth decay by the age of 15. Toothbrushing encouragement and education from early ages can build up good oral health habits in children and can improve public health. This project proposes an Affective Interaction Design of Toothbrush (AIDOT) which targets children in different age groups to improve their and their parents' experience of regular and effective toothbrushing. AIDOT project aims to design a smart toothbrush that interactively encourages children to correct their brushing habits and techniques through affective interfaces and gaming. Using 3D motion sensors and data fusion, the toothbrush detects its precise position and movements in mouth and connects to an app on the child's smartphone or tablet. The app launches age-specific games to interact with the user while brushing in real time. The toothbrush itself interacts with the child in forms of lights, colors and vibrations the same way an advanced game-console joystick would do. Pogolab Ltd. is lead company in this project. Pogolab has two PCT patent pending technology for toothbrush motion and location detection as well as toothbrush handle design. The company's expertise is user experience and industrial design. It was awarded startup award of year 2013 by Innovation RCA, an incubator funded by James Dyson Foundation. IOTICS is a partner in this project. IOTICS Ltd. is a startup in wearables technology and has experience in designing miniature electronic device for smart jewelry.",0
2282141,39985,The ability of microbial biofilms to modify the surface properties of nuclear cements,"Initial work will focus on the establishment and characterization of the cement test pieces. These test pieces with simulated cracks, will be cast in flow through biocells and the exposed cement surfaces will be initially characterized through SEM, EDX and CLSM. Background data on the ability of these surfaces to retard the transport of Ni, U and Th plus the complexing agent Iso-saccharinic acid will be determined under strict anaerobic conditions using simulated groundwaters. This work is enabled by the fact that SAS now have the ability to work with these radioelements. To increase the academic impact, the STFC Diamond XRD and XAFS facility will be used to characterize the speciation of the radioelements associated with these surfaces. Collaborators at the University of Leeds will assist in accessing the facility and the analysis of the resulting data.

Once the background data has been acquired, replicate cement biocells will be established which will be exposed to the alkaliphilic, biofilm forming communities that have been under investigation by the environmental microbiology team in recent years. These cells will be run until biofilms have been established and then exposed to the radioelements under investigation. The impact of the biofilms on radioelement retention will be determined initially through mass balancing, followed by more detailed surface characterization via SEM/EDX potentially followed by XRD and XAFS if sufficient retention of radioelements has occurred. CLSM will be used to characterize the structural aspects of the biofilm allowing the 3D structure to be determined and the relative positioning of key components such as proteins, lipids, carbohydrates and extracellular DNA identified. Comparison between flow cells with and without biofilms will allow a retention adjustment factor to be calculated which can then be factored into environmental transport calculation. Once the flow cells are fully characterized the associated microbial populations will be characterized. In order to optimize the impact of the research metagenomics/metatranscriptomic approaches will be applied to identify the key active metabolic pathways within these unique microbial systems.",0
2127247,18751,PhD Chemistry,PhD Chemistry- Summary to follow,0
MR/M025659/1,14955,Over-Hear: assessing functionality of hearing aids in complex listening environments,"The World Health Organization (WHO) estimates around 360 million people world-wide have a disabling hearing loss, with significant negative impact on the social and emotional health of individuals and their families, lost education and employment opportunities, and a substantial economic burden for deaf individuals and broader society. Currently, hearing aids are the most common form of therapeutic intervention for hearing loss. Nonetheless, even in high-income countries with established social- or insurance-based health care provision, the uptake and retention of hearing aids remains low; this is despite the lack of alternative treatments and therapies and the enormous personal and societal cost. Independent of differences in culture, economics of health-care provision or even whether or not someone has been provided with or purchased a hearing aid, a principle reason given for stopping using them (or not considering them in the first place) is the broadly held view that they provide little in terms of understanding speech in background noise. Since this is precisely the problem for which most hearing-impaired listeners seek help in the first place, it is unsurprising that this failure to deliver often leads to non-use of hearing aids. Several reasons likely contribute to disappointment with hearing aids, including unrealistic expectations of the devices' capabilities, intermittent use potentially compromising the extent to which the hearing brain adapts to the device, and the undeniable fact that hearing aids, whilst performing an adequate job in terms of amplifying sounds, do not make them very much easier to distinguish from each other; although hearing aids can provide the extra amplification of sounds that is lost when the inner ear is damaged, they cannot restore the frequency resolution (the ability to distinguish one sound from another) that accompanies the loss of sensitivity to quiet sounds. This is compounded by the fact that hearing aids are generally fitted with respect to increasing the audibility of pure tones (the pure-tone audiogram) with little or no regard to the natural listening environments in which most listeners need to perform. Although many putative strategies for enhancing listening in noise are implemented across a range of hearing aids, their rationale and their efficacy are only poorly understood, not least because they are inadequately assessed with respect to individual users' listening and communication strategies. We will establish a consortium of researchers, engineers and clinicians called 'Over-Hear' in order to understand and develop the best means of assessing how individual listeners utilise their hearing aids in complex listening environments. Through a series of Workshops, Over-Hear will seek to determine:- how best measures of listening performance can be assessed; how listeners behave in complex listening environments; the evidence needed to determine whether technological advances in hearing-aid processing are effective; the range of different performance levels in hearing-aid use by individual listeners. Our consortium will also conduct a Pilot Study in a specially designed arena that can recreate different sound and physical environments whilst simultaneously measuring behavioural (e.g. head movements towards or away from sound sources) and objective neural measures (e.g. brain activity that informs us as to how well hearing-aid users are listening and communicating). This might inform, for example, which selectable signal-processing strategies ('settings') a user employs, how this alters understanding of speech and communication strategies in complex listening environments, and could lead to the development of 'smart' hearing aids sensitive to users' listening intentions.",0
2317432,39255,The role of parents in reducing the transmission of infectious diseases in schools,"Certain infectious diseases, including flu and diarrhoea or
vomiting, spread readily among school children. To combat
this, Public Health England has produced recommendations
about the length of time children should be kept off school if
they are ill with different conditions. Unfortunately, evidence
suggests that these recommendations are often not
followed: one in six parents in England has admitted that
they would send their child to school even if they had
diarrhoea or vomiting. As far as we know, there has been no
academic research to understand why parents send sick
children to school, or what we can do to discourage this. In
this PhD, we will use interviews and focus groups with parents
to understand these issues better. We will also explore
current school policies and communication materials to see
what advice and messages parents are currently receiving.
We will then develop new advice for parents based on our
findings and also on previous studies about how to influence
other types of health-related behaviour. Our hope will be that
this new advice will increase the chances of parents keeping
their children out of school when sick. To test this, we will
take a group of 466 parents, and ask each parent to read
either our new material or existing messages about sickness
in school children. Each parent will only get one of the
messages, and we will decide which message each parent
receives completely at random. After reading it, they will
then be asked to imagine that their child wakes up tomorrow
with diarrhoea, and will be asked whether they would be likely
to send them to school or not. We hope that parents
receiving our new messages will be less likely to say that the
child will go to school.
The project will be a partnership between academic
psychologists at King's College London and public health
experts and Public Health England. If our new intervention is
successful, we hope that Public Health England will change
the advice that they provide to schools and parents based
on our findings, and fewer children are sent to school while ill as a result",0
BB/P00783X/1,33886,Understanding the mechanism by which tetraspanins regulate the 'molecular scissor' ADAM10,"The transmembrane metalloproteinase ADAM10 is a ubiquitously expressed 'molecular scissor' that cleaves the extracellular regions from its substrates, which include Notch, amyloid precursor protein and cadherins. ADAM10 can be regarded as a 'master regulator' of embryonic development. ADAM10 also impacts on human health via its role in diseases such as Alzheimer's, cancer, Staphylococcus aureus infection and inflammatory diseases including heart attack, stroke and asthma. As such, therapeutic targeting of ADAM10 has huge potential. However, realising this potential is currently impossible due to the toxicity that would result from targeting ADAM10 on every cell in the body. Our recent research demonstrates how we can solve this problem. We and others have recently identified six tetraspanin proteins, which we termed TspanC8s, which promote ADAM10 cleavage of specific substrates. Therefore future therapeutic targetting of specific TspanC8/ADAM10 complexes may be applicable to certain diseases, whilst minimising the toxic side effects of global ADAM10 targetting.

The aim of this project is to determine how one of the TspanC8s, Tspan15, specifically promotes ADAM10 cleavage of the N-cadherin adhesion molecule. N-cadherin acts as 'molecular velcro' and is essential for maintaining tissue architecture in the beating heart, and regulates neuronal synapse formation and cancer cell metastasis. We hypothesise that Tspan15 promotes cleavage of N-cadherin by regulating ADAM10 subcellular localisation and/or causing it to adopt a specific conformation.

To address this hypothesis, we will use cell line models that include our new Tspan15- and ADAM10-knockout CRISPR/Cas9 cells. The main objectives are as follows:

1) To discover how Tspan15 localises ADAM10 to N-cadherin.
We will use advanced fluorescent microscopy to determine the extent of Tspan15/ADAM10 localisation to N-cadherin, in comparison to other TspanC8/ADAM10 complexes. We will identify the intracellular trafficking proteins that promote Tspan15 localisation using proteomics and co-immunoprecipitation. We will demonstrate their importance by assessing ADAM10 cleavage of N-cadherin in their absence following knockdown, and in the presence of Tspan15 mutants that cannot bind to the trafficking proteins.

2) To determine whether Tspan15 induces a distinct ADAM10 conformation.
We will investigate ADAM10 conformation in complex with Tspan15 by flow cytometry using a panel of conformational ADAM10 monoclonal antibodies, and compare with the other five TspanC8/ADAM10 complexes. We will obtain structural information on the Tspan15/ADAM10 complex, again compared to the other TspanC8/ADAM10 complexes, using a novel membrane protein encapsulation method that we have developed for the purification of membrane proteins in their native state. Encapsulated TspanC8/ADAM10 structures will be determined by analytical ultracentrifugation, small-angle X-ray scattering, negative stain transmission electron microscopy and cryo-electron microscopy.

3) To investigate the functional effects of Tspan15 monoclonal antibodies.
We will determine how each of our 12 new Tspan15 monoclonal antibodies affects ADAM10 cleavage of N-cadherin using western blotting and an N-cadherin-dependent functional assay for cell migration.

The findings from this work will help us to understand how other TspanC8s regulate ADAM10 cleavage of other substrates, and allow us to assess for the first time how TspanC8 antibodies might act in a therapeutic setting.",0
511293,7327,Sheffield Hallam University and Westfield Health &amp; Wellbeing Limited,To develop a calibrated model to understand the impact of Health and Wellbeing Interventions on the individuals and companies who invest in them.,0
1645057,17401,Metabolic and molecular basis of the complex interaction between protein metabolism and insulin action in human skeletal muscle,"The ability of skeletal muscle glucose metabolism to respond adequately to insulin signalling is compromised (termed 'insulin resistance', IR) under conditions of increased dietary fat availability and this is thought to be a consequence of the intracellular accumulation of lipid within skeletal muscle. IR is a risk factor for the development of metabolic and cardiovascular disease and therefore an important modulator of metabolic health. As insulin signalling is also integral to skeletal muscle amino acid delivery and metabolism, it is likely that lipid-induced IR may also compromise the ability of skeletal muscle to adequately synthesise new protein in response to dietary amino acids (termed 'anabolic resistance', AR). Indeed, we have recently shown that elevating lipid availability in humans can induce skeletal muscle IR and AR in response to amino acid ingestion. However, it is not known which fatty acids are causative, or the underlying cellular mechanisms. 

The aim of this project is to elucidate the mechanisms that couple the accumulation of intracellular lipid species originating from different types of dietary fatty acids to the development of both IR and AR in human skeletal muscle. The proposed work will employ an integrated approach that will combine human based investigations with skeletal muscle cell based experiments. 

The objectives of the human based studies are to investigate the impact of manipulating circulating lipids in both lean and overweight healthy humans via dietary interventions on both skeletal muscle IR and AR. Primary cell cultures from human skeletal muscle will be used to elucidate the functional importance of proteins identified as key targets from the human experiments to establish the specific pathways by which different lipid species affect both IR and AR.",0
ST/S006567/1,34412,A new rotator for HiPERCAM on the GTC: design study,"HiPERCAM is a revolutionary new astronomical instrument that saw first light on the GTC, the world's largest optical/IR telescope, in February 2018. The instrument was funded by a 3.5Meuro ERC Advanced Grant awarded to me in January 2014, and was built by a consortium from the Universities of Sheffield, Warwick, Durham, the UKATC and IAC.

HiPERCAM is arguably the most powerful ground-based optical imager in the world. This is because of three unique characteristics: 1. HiPERCAM images in 5 wavebands simultaneously on its 5 CCD detectors, covering the entire optical spectrum from 300-1000 nm. It is therefore up to 5 times more efficient than other cameras. 2. HiPERCAM uses custom-built (for 1.0Meuro) low-noise, frame-transfer e2v CCDs that are cooled thermo-electrically to 183 K, thereby allowing both long-exposure, deep imaging of faint targets, as well as high-speed (over 1000 frames per second) imaging of rapidly varying targets. It is therefore much more versatile than other cameras. 3. HiPERCAM is mounted on the world's largest telescope, located at one of the world's best observing sites. It is therefore much more sensitive than other cameras.

The next few years will be witness to a revolution in our knowledge of the Universe with the advent of large survey facilities such as LSST, Gaia, TESS, PLATO, SKA, Euclid and LIGO/VIRGO. Many new variable and transient sources will be discovered by these facilities. Time-domain astrophysics is set to become a core activity, and detailed follow-up studies of the most interesting objects will be essential. HiPERCAM on the GTC has been designed to fulfill this role. Targets will include: LIGO/VIRGO gravitational-wave transients with localisations from smaller telescopes; supernovae; gamma-ray bursts; fast-radio bursts; broadband transmission &quot;spectroscopy&quot; of rocky exoplanets; occultations by dwarf planets in the Kuiper belt; accreting black-holes in binaries; testing quantum mechanics and general relativity by observing millisecond pulsar binaries; pre-imaging and simultaneous imaging of the proposed ultra-deep JWST Time-Domain Field (TDF), which is only visible to ground-based telescopes in the northern-hemisphere. These are just a few examples of the many science areas that HiPERCAM could have a major impact on in the years to come.

HiPERCAM is currently mounted on one of the two available Folded Cassegrain focii of the GTC. Unfortunately, from 2019, HiPERCAM will have to share this focus with two common-user GTC instruments: CanariCam (from Q1 2019) and MIRADAS (from Q4 2019/Q1 2020). There are two other Folded Cass focii available at the GTC, but neither have been commissioned, i.e. they do not currently have rotators, cable wraps and services, and both were originally assigned for use by (as yet unbuilt) engineering instruments to assist in calibration of the telescope. I recently proposed to the GTC Director, Dr. Romano Corradi, that there will be exciting new scientific opportunities available in time-domain astrophysics if we are able to mount
HiPERCAM permanently at one of these spare focii, thereby allowing us to respond immediately to transients discovered by survey facilities. Romano presented my proposal at the most recent GTC Steering Committee meeting, who responded very positively: &quot;The Committee acknowledge the unique capabilities that HiPERCAM provides in combination with the GTC, and is therefore happy to explore the possibility to mount the instrument
permanently in one of the free Folded Cass focii.&quot;

This grant will allow us to design a new rotator for HiPERCAM, hold a Preliminary Design review, submit a detailed technical feasibility report to the GTC board on the new rotator, and obtain reliable quotes for the new rotator. With all of the above complete, we will then be in a position to apply to STFC for additional funding to build and commission the rotator on the GTC.",0
102166,14204,CAR therapy for Multiple Myeloma,"Multiple Myeloma (MM) is a cancer of a type of white blood cell called a plasma cell. MM is a disease of older people. Patients with MM develop bone fractures, pain, infections and kidney failure due to this cancer. Although it can be controled for a period, MM is currently incurable. T-cells are the part of our immune system which directly kill infected cells. They can be easily taken from a blood sample and grown in the laboratory. Using genetic engineering tools, these T-cells can be 窶徨e-programmed窶・so that a patient窶冱 own T-cells recognize and kill cancer cells. This can be achieved by introducing a gene for an artificial protein called a chimeric antigen receptor, or CAR for short, into a patient窶冱 T-cells. While T-cells normally ignore cancer cells, with this modification they attack cancer cells with the same vigour and determination as they would naturally attack virus infections. Recent clinical data leave little doubt that CAR T-cell therapy will be game-changer in cancer therapy. We have developed a CAR which targets MM cells and with this proposal plan to test the effectiveness of a patient's own T-cells engineered with this CAR.",0
MR/R014086/1,19658,IMPC: Is Lrg1 an autocrine/paracrine regulator of thermogenesis in brown and beige adipose tissue? Implications for cardiometabolic disease.,"Background: Our bodies store excess energy as fat inside special cells, called white fat cells (that form white adipose tissue). But not all fat cells are the same; brown fat cells (brown adipose tissue) break down stored fat to generate heat during exposure to cold, while beige fat cells can switch between the two, either storing or burning fat.
It is thought that brown and beige fat cells have protective properties against obesity and type 2 diabetes, due to their fat burning activity. However, during aging and obesity the amount of brown and beige fat in our bodies decreases, while the amount of white fat increases. This may contribute to an increased risk of developing metabolic diseases such a type 2 diabetes. We do not yet fully understand why the amount of brown and beige fat decreases during obesity. Our experiments suggest that fat cells release a protein signal, known as Lrg1, which may enter the blood and decrease the fat burning ability of brown and beige fat cells. Lrg1 is increased in the blood of people with type 2 diabetes, and those who are obese. The concentration of Lrg1 in blood also increases with age. We don't yet know for certain whether Lrg1 decreases the fat burning ability of beige and brown fat in the body, or whether this contributes to accelerated development of type 2 diabetes. 

Research aims: This research in Dr Roberts' laboratory will determine whether &quot;turning off&quot; the gene for Lrg1 increases the amount of beige and brown fat cells, and their ability to burn fat. The research will also investigate whether switching off the Lrg1 gene protects against obesity and type 2 diabetes.

Potential benefit to society and people with diabetes: Type 2 diabetes is a worldwide healthcare challenge; with an estimated 422 million people thought to have type 2 diabetes globally. In the UK the NHS spends &pound;14 billion a year to treat diabetes. Understanding how obesity increases the risk of developing this disease, may lead to new treatments to taget the twin global epidemics of obesity and type 2 diabetes. By studying the role Lrg1 plays in regulating the fat burning capacity of beige and brown fat cells, this research hopes to identify whether Lrg1 is a potential new therapy target to protect against the loss of beige and brown fat and the onset of obesity and type 2 diabetes.",0
EP/P025374/1,32913,EARL: sdn EnAbled MeasuRement for alL,"Internet eXchange Points (IXPs) have become a critical element of the Internet, as they provide the physical locations where networks interconnect and exchange traffic. IXPs carry huge traffic volumes, reduce interconnection costs, and hence make national Internet access affordable. Despite the growth of these infrastructures, the rapid evolution of the Internet poses new challenges. 

Reacting as soon as possible to the highly dynamic Internet environment has always been the first priority for Network Operators. Unfortunately, state-of-the-art techniques are extremely limited. Networks use the Border Gateway Protocol (BGP) to inform each other of which destinations are reachable. Accordingly, network operators (ab)use BGP Traffic Engineering (TE) to tweak traffic paths. TE is a network-management tool allowing a network to adapt events ranging from a change in customer location to mitigating dramatically large traffic outbursts of a malicious Distributed Denial of Service (DDoS) attack. However, BGP-TE lacks programmability and dynamism: once BGP preferences are set up, they cannot react in real-time to network events. 

With a high-fidelity measurement-focused approach, a network could implement more sophisticated traffic management techniques. For example, any network connected through an IXP must implement ingress traffic filtering to avoid receiving undesirable traffic (e.g., DDoS attacks or resulting from misconfigurations). However, correctly controlling ingress filters is complex. Thus, most IXP customers unrealistically expect the organisations originating the traffic to manage any problem. TE limitations result from the inability of current Internet monitoring techniques to cope with the wide range of granularities of network events. While control plane related events (those concerned with the selection of paths/routes, such as BGP updates) happen at a time scale of minutes, data plane events (packet processing) occur at time-scales of micro-seconds. While control plane monitoring is relatively easy, data plane observability is poor, relies on expensive equipment, and does not scale. 

EARL addresses this imbalance between the ability to observe control and data plane, and the consequent limits on the detection and reaction to network events. EARL is a novel integration of monitoring mechanisms and reactive network management. EARL enables a prompt reaction to network events with its Software Defined Networking (SDN) approach. Because of the IXP's central role on the Internet and the critical nature at the national level, we believe that they are the ideal place to explore EARL's ideas. We will demonstrate how measurement-assisted network management permits new Internet-wide services and, enables the provision of services hitherto considered impossible or too costly to deploy. Our goal for the EARL project is to pioneer SDN enabled measurement-based network management to enhance the Internet infrastructure. This will lead to relevant tools and data for the larger researcher and practitioner communities. To this aim, we will create a new research instrument, EARLnet: an operational, research-centered, Autonomous System (AS) directly connected to our partners, providing a new and unique real-world environment for the real-time monitoring of network status and SDN-oriented research. EARLnet will serve also as a test-bed to develop and evaluate novel reactive network management solutions. 

The EARL project has the potential to revolutionise current Internet network management through new fine-grained and reactive TE policies. EARL will not only create new mechanisms, but also translate the blind, legacy BGP-based, TE into measurement-assisted SDN techniques. Furthermore, through our partner institution, the Cambridge Cloud Cybercrime Centre (CCCC), EARLnet will provide valuable data to a large community of researchers and practitioners.",0
2100087,26209,Building a robust Data Science toolset via Computational Rough Paths: Localised Regression based on the Signature Method,"The context of this project is that Rough Paths Theory provides a convenient and effective way to describe streamed data while dropping the noise generated throughout the data sampling process. It seems particularly valuable as a tool to be used in conjunction with the rapidly developing toolset provided by Data Science. It is particularly attractive when the underlying data is complex, multimodal and evolving but not stationary or regularly sampled. 
The primary benefit of the approach is that the transform provided by the Signature removes an infinite dimensional group of symmetries that would often cause profound difficulties for the learning process. The Signature Method represents a non-parametric way for extracting characteristic features from data. Thus, this approach allows to summarise information contained in the data by transforming it into a set of essential features and create a favourable and promising framework to perform Machine Learning tasks.
The applications of this methodology are widespread. One of the biggest and strongest banks is currently using this approach to re-think the pricing procedure of their derivatives portfolio as recently shown in (Arribas, 2018). The method has also been used in psychiatry to analyse self-reported mood and consequently separate diagnostic groups, as reported in (Arribas, Kate, Goodwin, &amp; Lyons, 2017). Furthermore, technology used in mobile phones to translate finger movements into Chinese characters has been developed using the Signature Method ((Zecheng, Zenghui, Lianwen, Ziyong, &amp; Shuye, 2016)).
My own expertise combines mathematical foundations with a strong ability to compute. My goal is to develop those initial strengths to further progress the effective use of Rough Paths Theory in Data Science. There are many problems where one would like to predict the outcome for an individual based on a large collection of histories of individuals. In many of these examples there is no natural metric of similarity. One of the advantages of this approach is that one can avoid the introduction of metrics prematurely. Therefore, I will start this project trying to build robust principle ways to perform Localised Regression using Signatures in moderate dimensions. If I can develop a robust mathematically principled approach, balanced with packages for scikit-learn and TensorFlow then this would be a great personal outcome.

This project falls within the EPSRC Mathematical sciences research area.",0
511593,45258,University of Leeds and Ilke Homes Limited,"To develop an innovative, optimised structural system utilising novel techniques to significantly improve the performance, safety and cost of current modular housing design.",0
752481,25331,Cactus Tongue,"Cactus Tongue is a stylish and versatile wall mount designed to store a bicycle by the crossbar, the handlebars or seat post. It is aimed at bike owners wishing to store their bike indoors or outdoors.",0
EP/M507969/1,32790,DTP - The University of Manchester,"Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes, see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.",0
BB/R506643/1,19307,Mechanisms determining oral microbial community composition,"Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes, see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.",0
1642216,27538,Revealing the hidden coding potential and dynamics of the mammalian transcriptome,"In recent years transcriptome sequencing (RNA Seq) has become a widely used technique in both fundamental and applied biological research. The Turner Lab at the world-class Babraham Institute studies the molecular processes that control development and function of lymphocytes. The lab uses the latest RNA Seq-based methods for exploring transcriptional regulation. This work contributes an important step towards a systems level understanding of immunity. The Turner Lab has partnered with Babraham-based Eagle Genomics Ltd., a leading bioinformatics cloud consultancy business, in an exciting PhD training opportunity due to begin in October 2014 (or potentially later in the 2014/15 academic year). 

The student will develop computational approaches to extract meaning from quantitatively and qualitatively different data sets relevant to gene expression. Additionally, the student will examine sequences of ribosome associated mRNAs for evidence of novel transcripts translated in lymphocytes. For the most part this data will be derived from RNA Seq but other data such as publically available measurements of proteins (proteomics) and metabolites (metabolomics) may also be used to provide supporting evidence. The project will involve the generation of new data by the student, as well as the use of pre-existing data (or data to be generated in parallel projects in the Turner lab or by collaborators) and publically available data. Thus the student will receive practical training in the growth and stimulation of primary lymphocytes and the generation of RNAseq libraries which provide information of RNA dynamics. 
The student will also participate in the iterative process of developing data analysis pipelines. In particular they would take approaches to modelling of experiments that integrate heterogeneous 'omics data which is a particular interest of the Eagle. Effective communication of results and analytical methods will be key to the success of this project and we propose to make use of publication formats that link standard manuscript publication with a database hosting all associated data, data analysis tools and cloud-computing resources. 
Applicants with a background in computer science and with an interest in how gene expression is regulated are particularly encouraged to apply.",0
ES/S00176X/1,26002,Discovering Individual and Social Preferences through Inverse Reinforcement Learning,"Organisations that provide services and create products often base their decisions on questionnaires and/or other explicit forms of communication with their user base (e.g. patients, customers, citizens). The aim of this information exchange between providers and users is to uncover the users' &quot;reward function&quot;, i.e. what users actually want from their interactions and what issues exist with the current product/service line-up. Explicit forms of information exchange can be cumbersome and expensive to design for organisations and are intrusive to the user. Furthermore, response bias is a well-known problem for survey based methods, particularly around sensitive topics, where respondents maybe unwilling to engage due to social or cultural concerns. Some practical solutions to response bias are provided by indirect questioning methods (item count and randomized response techniques). However, none of these solutions are practical for large scale and real time settings.
We postulate that ideally an organisation should try to elicit the reward function of its user base (i.e. what states are preferred by users) by using observational data generated from user activity. Inspired by recent literature in AI research, we propose a three-facet programme that aims to directly attack the problem of what users want by a) trying to infer the user reward function through the collection of behavioural data (e.g. website clicks, traffic behaviour, movie preferences); b) creating short, non-intrusive online questionnaires that will remove any uncertainties; and c) exploiting user preferences in order to improve service and product provision.
The proposed research aims to contribute to developing methods that can be embedded in artificial intelligence systems which must elicit and understand preferences by interacting with humans in order to adapt their behaviour and allow for a more natural experience and interaction.
Through this research we have four key objectives: (a) understand user preferences and develop methods to uncover and learn the reward function through data and behaviours; (b) develop interactive and conversational methods for eliciting responses and interactions from users that allow for a more natural user experience with automatic systems; (c) explore the social limitations of our approach (for instance, to what extend are personal rewards not dictated by individual preferences, but rather by social coercion?); and (d) investigate what steps can be taken to fully automate the procedure of provisioning new services and products through eliciting preferences via the methods developed under (a) and (b).
This Fellowship provides a unique opportunity to bring together artificial intelligence techniques and social science to tackle problems that are faced by a range of businesses and organisations in dealing with clients and customers and attempting to elicit preferences and needs through behaviours and interactions. We will be working closely with our industry partners in this project, British Telecom (BT) and the Essex County Council (ECC), to investigate the issues and challenges of eliciting and understanding preferences as being faced in their own contexts to inform and shape the programme of work.",0
MR/P022847/1,5523,The role of Cathepsin S in PAR-1 mediated lung inflammation - a new paradigm for neutrophilic inflammation,"During an infection the body normally responds by mounting an immune response. This generally involves the recruitment of white blood cells that play a role in removing the invading organism. A specific white blood cell, called the neutrophil, is pivotally involved in the process of removing bacteria from sites of infection including the lung. In some cases of disease, neutrophils arrive in significant numbers to the lung, and other organ sites, not as result of infection but as a result of a poorly-defined inflammatory process. When they arrive at the lung these neutrophils become involved in causing damage to the lung tissue. We have uncovered a new pathway by which neutrophils migrate to the lung involving the role of a protein called cathepsin S (CTSS). The identification of CTSS in this role has been uncovered by the use of specific inhibitors of CTSS but we now wish to confirm further the role of CTSS in neutrophil recruitment using novel genetically generated models in which key CTSS targets - called protease activated receptors (PARs) will be ablated thus allowing us to confirm the role of CTSS in neutrophil recruitment. We will also expand this project beyond simple mouse models to confirm a role for CTSS in neutrophil recruitment in unique porcine and human ex vivo lung perfusion (EVLP) models. The very clear application of this study is in the targeting of CTSS to regulate neutrophil recruitment in disease, particularly lung disease, although there is a potential role for this CTSS-mediated pathway in other disease processes including gastrointestinal and dermatological disorders. To this end, we have a very active collaboration with companies that are involved in the design and clinical testing of CTSS inhibitors including Virobay. Indeed, a lot of the preliminary data that we have generated for this project includes the use of the Virobay CTSS inhibitor. Future studies looking at the clinical evaluation of CTSS inhibitors in lung disease in collaboration with Virobay (or other Pharma developing clinical CTSS inhibitors) is a very real possibility as we are set-up to carry out such studies in Queen's Belfast as part of the UK Respiratory Translational Research Partnership.",0
2188482,45001,Broadband Spectral Interferometric Polarized Coherent anti-Stokes Raman Scattering - a non-linear approach to fast all-optical chemical fingerprinting,"Development in coherent anti-Stokes Raman spectroscopy (CARS) techniques has expanded greatly in the past two decades with research geared towards faster and more sensitive data acquisition, simplified experimental requirements and robust computational/optical methods to remove the associated non-resonant background (NRB) with CARS. Following on from research conducted by David Richards' group at KCL, this project aims to further expand the capabilities of the broadband CARS technique developed and patented by the group, spectral interferometric polarized CARS (SIPCARS), as well as work on broadband CARS in general. There are two main strands as to which this will be achieved; experimental studies and data analysis of hyperspectral CARS data.

The experimental strand will encompass both developments to the SIPCARS system and the usage of complex biological samples to characterise and demonstrate the validity and usefulness of SIPCARS as a means for obtaining rapid and accurate spectral data of biological specimen. 

The data analysis strand will primarily focus on analysing hyperspectral data obtained from SIPCARS measurements. Typically, analysis of hyperspectral data is carried out using clustering techniques. Essentially, the purpose of this strand in the research programme will be to provide tools to extract information from biological hyperspectral data, thus creating a fully comprehensive system capable of measuring and analysing hyperspectral Raman data of complex biological samples with rapid acquisition rates and a high level of accuracy.",0
1812657,15561,"Picturing the Antipodes: race, image and empire in 19C. Britain","This project is inspired by the British Museum's significant early pictorial collections of Australian Indigenous people. The research will focus on images produced c.1800-1860 - after the earliest British exploration and settlement of Australia, but before the granting of settler self-government - when ideas of race, civilization, humanity and colonization were in flux in Australia and across Britain's Empire. The project will move beyond traditional art history approaches to colonial Australia's visual heritage, to consider questions of production, circulation, collection, reproduction and display within colonial, imperial and Indigenous histories. As such it will encourage a consideration of how racialised and hierarchical ideas about Australia's Aboriginal peoples shaped British notions of empire, governance and civilization that continue to resonate for Indigenous people today. While the research will be based primarily on the study of pictorial images of Australian Indigenous peoples in the British Museum, other collections such as the Natural History Museum and British Library, hold relevant material that may be investigated. Consequently, the project should not only complicate our understanding of London's role as an imperial capital, but also create links between scattered collections of objects, images and documents in the U.K.",0
ES/S00744X/1,19765,Administrative Data Research Centres 2018,"There is great potential for understanding more about our society through better use of data that already exists and by linking different datasets together. Using existing data is not only efficient and cheaper than collecting new data, but it can also provide a powerful means to consider what action is needed to tackle a wide range of social issues, guiding the development, implementation and evaluation of government policies. This can be achieved in a way that ensures that the public have the maximum confidence that their data are being used appropriately and that the safeguards of these data meet the highest international standards.

The Administrative Data Research Centre (ARDC) in Northern Ireland (NI) comprises the two universities and NISRA, the local governmental statistics agency. Over the last five years, in collaboration with government bodies and the voluntary and community sectors, the widened access to administrative datasets in Northern Ireland, has enabled us to undertake a range of research projects that have informed government and public services. We have also greatly increased the number of researchers both in academia and government able to manage and analyse these large and complex datasets required to undertake this type of research. 

While our primary objective for the ADRC over the next 30 months will be to maintain the confidence of the different publics in the use of administrative data for research, our renewed focus will be to build on our work in fostering commitment from Government in NI and throughout the UK to an increased access to and use of administrative data. This will help us maximise the potential of administrative data as a rich resource for evidence-based policy making and evaluation. Our emphasis in this short period will be the rapid delivery of targeted, high impact research-related activities essential to data custodians. To do so, we will extend the use of administrative data that is available and accessible. Importantly, we will continue to strengthen the impact of our research portfolio through more focused knowledge exchange activities. In collaboration with our NISRA partners, we will engage with data custodians ensuring that we take into account their priorities in the policy process cycle and that our research activities in this period are focussed on the timely delivery towards NI Government objectives. 

We will also undertake a modest portfolio of world-class research projects at both NI and UK level that quickly demonstrates to respective data owners the utility and potential policy impact of using administrative data for research. Within NI, the ADRC and NISRA, will help develop Strategic Impact Programmes (SIP), prioritising the needs of the different Government departments and informing the NI Program for Government (PfG). Each of the SIPs will be accompanied by focused knowledge exchange packages co-designed and delivered by the data custodians. 

A major objective for the ADRC will be to demonstrate to Whitehall Departments the potential utility of their administrative data. We will therefore continue to develop large multipurpose research datasets under the 'Growing Old' Themed Partnership and undertake a series of research programmes addressing the Areas of Research Interest (ARI) that set out the most important research questions facing the collaborating UK Government Departments. We will also contribute to the development and delivery of the wider pan-UK research agenda arising from the Strategic Hub.",0
103270,4782,A high-throughput discovery-manufacturing platform for new pipelines of antimicrobial biologics.,"The advance of antimicrobial resistance (AMR) is relentless. A succession of WHO reports on AMR reveal that the problem is no longer a future or developing threat, but that it is already challenging our ability to treat common infections. To reverse this alarming trend, we need not just powerful compounds, but also powerful discovery and development paradigms. Novel antibiotics must have potent activity, but they must also serve as scaffolds for structural diversification for the sustainability of long-term functional efficacy. As with first generation antibiotics like penicillin, our goal should not just be to discover individual antibiotics but rather provide new antibiotic pipelines for a sustainable defence against AMR. This project will provide a discovery-manufacturing platform using state of the art equipment to accelerate the much-needed introduction of an exciting new class of potent antibiotics based on bacteriocins that rapidly kill bacteria, including drug-resistant Gram-negative pathogens and MRSA. The platform will deploy scalable systems for peptide antibiotic production and diversify their functional potential through rational design and discovery from novel samples, adapting their medicinal properties; thus providing a new pipeline of effective antibiotics.",0
MR/P028284/1,19995,Defining the function of histone ADP-ribosylation in DNA repair and genome integrity,"DNA is continually being exposed to a variety of agents that induce DNA damage resulting in tens-of-thousands of DNA lesions per cell every day. As such, an intricate set of pathways known as the DNA damage response (DDR) detect DNA damage when it occurs and activate mechanisms for its repair. These pathways are critical for our health and well-being and their dysfunction can lead to a variety of clinical symptoms including cancer, neurodegeneration, immune-deficiencies and premature ageing. Therefore, understanding how cells respond to and repair DNA damage will provide information about the underlying causes of these conditions and, importantly, how they can be treated. This strategy is exemplified by inhibition of ADP-ribosyltransferases (ARTs), a class of enzymes that detect DNA damage and attach ADP-ribose units onto proteins at damage sites to promote DNA repair. Inhibitors of these enzymes are currently being used successfully to treat ovarian cancer and have the potential to treat other pathologies associated with defects in the DDR. However, despite the importance of ART inhibitors in the clinic, our knowledge of how these enzymes regulate DNA repair is limited. Furthering this understanding will underpin refined strategies that exploit ART inhibitors to treat diseases associated with DDR dysfunction and provide a paradigm for how ARTs regulate other critical processes including cell growth and differentiation, gene expression and programmed cell death.

The proteins modified at DNA lesions by ARTs in response to DNA damage are particularly ill-defined and the basis of how this regulates the repair process is only poorly understood. This situation is epitomized by histones, the proteins that package DNA into the nucleus of the cell. These proteins are known targets for ARTs. However, the sites modified on histones in response to DNA damage and how this regulates DNA repair remains unknown. This lack of mechanistic insight is due, in part, to the absence of an appropriate experimental platform in which both ARTs and histone genes can be manipulated to directly test hypotheses of how modification of specific sites on histones by ARTs regulates DNA repair in a cellular context. We have established that these criteria are uniquely met in the model organism Dictyostelium, providing the opportunity to identify novel DNA repair factors and concepts in this system that will subsequently be applied to humans.

Our current work has developed an experimental pipeline in Dictyostelium to identify histone ADP-ribosylation sites in the cell and to genetically manipulate histone genes to block their modification. The aim of this research is to exploit this unique approach to test how these modifications regulate DNA repair. We will comprehensively catalogue the histones, and the amino acid residues in them, that are modified by ARTs in response to DNA damage. We will then exploit the genetic tractability of Dictyostelium to disrupt the specific histone ADP-ribosylation events identified to establish their importance in regulating DNA repair. This will provide a robust experimental platform to identify novel repair proteins that are recruited to ADP-ribosylated histones in Dictyostelium. Having identified these factors, we will subsequently characterize how the equivalent proteins regulate DNA repair in the humans. In addition to providing an increased understanding of how cells promote DNA repair to prevent mutagenesis, these studies will provide information to facilitate the design of specific therapeutic agents to target DNA repair pathways to treat a variety of diseases including cancer.",0
ES/S501712/1,10619,London Interdisciplinary Social Science DTP NPIF Placements 2018,"Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes, see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.",0
1645572,2346,Functional characterisation of Sam68 post-translational modifications,"The STAR (signal transduction and activation of RNA) family of proteins are RNA binding proteins of which the best characterised is Sam68, which is predominantly a nuclear protein. Sam68 has previously been shown to be involved in alternative splicing of specific transcripts and is a target for a number of post-translational modifications. Examples of these modifications include serine/threonine phosphorylation, arginine methylation, lysine acetylation and sumoylation and can have an effect on both structure and function. Within this project we aim to characterise specific modified residues with a focus on serine/threonine phosphorylation. This will be achieved by utilising NMR spectroscopy. Mutational studies will then allow us to study the effects of phosphorylation of target residues in a structural and functional way. 
Following on from the mapping of the modifications, we aim to perform NMR on cytoplasmic and nuclear extracts to examine similarities and differences in modifications in each subcellular location. We will use two types of nuclear extract; nuclear HeLa extract and nuclear extracts depleted of specific kinases. Additionally we aim to examine post-translational modifications in vivo on HeLa cells using NMR comparing between normal and cancerous cells, as overexpression of Sam68 is a characteristic of some types of colorectal and prostate cancers. From a functional perspective, we will aim to look at the effects of post-translational modifications on the splicing patterns of known Sam68 target genes by performing splicing assays. Finally we aim to address the effect of inhibiting enzymes that are responsible for the post-translational modifications of Sam68 within cytosolic and nuclear extracts. These inhibitors will be used in the splicing assays to examine changes in splicing patterns when specific modifications are inhibited.",0
2262853,36172,Multifluid simulations of embedded planets,"Planets form in discs of gas and dust around young stars. While the gas component has by far the most mass and is therefore dynamically more important, it is the dust component that is easier to observe. Ideally one would like to identify planets from their signature in the dust, but this is not straightforward since the dust interacts with the gas through a drag force. What is needed are simulations of embedded planets that take into account both gas and dust, so that we can make the link between the structures in the dust that are observed and the planet that is causing these structures. In this project the student will perform multifluid calculations of embedded planets and link these to recent observations.",0
2092930,18551,Application of Sum-of-squares of Polynomials Technique in Fluid Dynamics,"This PhD project will feature two primary objectives. Firstly, we aim to improve the UODESys toolbox. In
particular, we aim to improve the efficiency of the toolbox and obtain tighter bounds on the X term, which
appears in 2 and hence in the uncertain dynamical system. It is proposed to investigate different methods of
bounding the X term.
One of the main shortcomings of UODESys is that inefficient nested loops are used to implement certain
computations. We will replace nested loops with more efficient vectorised code wherever possible, in order to
speed up the derivation of the uncertain system.
The second primary objective of this research is to apply the SOS optimisation technique to specific fluid
flows. This will be done by first deriving a finite-dimensional (truncated) Galerkin approximation to the NSEs.
The finite Galerkin basis ui will be chosen based on physical considerations. Namely, the finite-dimensional
model should capture all the physical characteristics of the actual fluid flow. The resulting ODE system can
then be analysed. We will focus our efforts on determining the maximum Reynolds number for which a steady
solution of the ODE system is stable using a combination of Lyapunov stability theory and SOS optimisation,
thus enabling us to obtain a stability limit on the Reynolds number that is higher than the energy stability limit.
In addition, for various flows, we would like to derive rigorous bounds on flow characteristics in the turbulent
regime. If required, in both of these applications UODESys will be used to derive a reduced and uncertain ODE
system to reduce computational complexity.",0
1622607,10434,Discovery and characterisation of transiting exoplanets,The project will include work to discover new transiting exoplanets using data from the Next Generation Transit Survey (NGTS) and follow up observations on a wide range of national and international facilities. The project will also include characterisation of the atmospheres of the discovered exoplanets using optical/IR and X-ray telescopes,0
BB/M011615/1,19278,Ensembl genome portal for farm and companion animals,"Research on domesticated animals has important socio-economic impacts, including underpinning and accelerating improvements in the animal sector of agriculture, contributing to medical research by providing animal models, improving animal health and welfare and informing understanding of natural and wild animal populations. Knowledge of the genes that shape farm and companion animals is essential for such research.
The sequence of almost all genes (a draft genome sequence) has been determined for major farmed and companion animal species such as cattle, goats, sheep, pigs, chickens, ducks, turkeys, dogs and horses. Draft genome sequences are also available, or soon will be, for several important fish species, including cod, rainbow trout, salmon and tilapia. However, the strings of billions of bases (symbolised as four letters A, C, G, T) that constitute these genome sequences are not immediately useful to biological research scientists.
Annotating these draft genome sequences with features such as where the coding and regulatory parts of genes are located, and the bases which differ between individuals within a species (genetic variants) greatly enhances the value and utility of the genome sequence. Visualising the genome sequences complete with annotations in a freely accessible manner further improves the value of the information.
The web-mounted Ensembl genome browser, databases and associated annotation tools have been shown to be powerful and effective means of annotating the complex genomes of animal species including humans, mice and more recently farmed and companion animals.
This project is concerned with improving the quality of genome annotation for farmed and companion animal genomes. International consortia of scientists are using so-called next generation sequencing technologies, not only to sequence the genomes of more economically important species, but also the genomes of multiple individuals for each species of interest and to improve or finish the reference genome sequences for key species. These new sequencing technologies are also being used increasingly in assays, for example, of the extent of gene expression in different cells or under different conditions (transcriptomics) or of the state of the genome (epigenomics). Mapping the sequence read-outs from these assays back to the relevant genome sequence not only provides a genome-wide framework for analysis but also provides further information with which to annotate the genome sequence itself. Thus, there is a recurring need to refresh the genome sequence annotation for important animal species.
We will use the Ensembl system to annotate the genome sequences of key farmed and companion animal species. The resulting annotated genome sequences will be made freely available as resources mounted on the World Wide Web.
A high quality annotated reference genome sequence is a key source of information and critical bioinformatics resource for the effective prosecution of contemporary research in the biological sciences. This key information is valuable not only to academic researchers, but also to scientists working in industry, including those in the animal breeding, animal health and pharmaceutical sectors. However, the value and utility of such bioinformatics resources are critically dependent upon the currency of the resource. Thus, this project is concerned with delivering high quality up-to-date annotated reference genomes for key farmed and companion animal species to enable research on these economically or socially important animal species.",0
EP/R020523/1,14491,"GRAM - Gravity for Rivers, Agriculture and Mines","The coming gravity sensors based on Quantum Technologies (QT) have the potential to disrupt existing surveying practices through dramatically improved measurement sensitivities. GRAM is a collaboration between e2v, RSK, the Canal &amp; River Trust, the Coal Authority, Cranfield University and the University of Birmingham (UoB) to establish the Quantum Technology (QT) gravity sensor market opportunities against assessment of current geophysical technologies to determine soil compaction for precision agriculture, detection of water levels in disused mines and mineshafts and canal &amp; river embankment leak detection. GRAM will baseline the capabilities of existing sensor technologies in the sectors identified, provide technical specification and performance requirements to the manufacturers of prototype and commercial QT gravity sensors and establish a market pull from the end users of the information generated by the sensors. Moreover, it will provide a market sizing and market penetration assessment to determine the size of the potential markets, analyse the competitors and determine the cost brackets for each of the three applications together with expected survey methodologies.

Currently, geophysical sensors are commercially used in the three application areas, but they suffer either from localised in-situ installation (e.g. Earth Resistivity Tomography probes), thus not being able to cover large areas, depth penetration and resolution (e.g. Ground Penetrating Radar, Scintrex microgravity instrument) or contain a radioactive source (nuclear density gauges). This limits proactive asset management (earthworks), safe developments of brownfield sites and large infrastructure projects such as HS2 due to unforeseen ground conditions (mines/mineshafts) and increased food production due to poor soil health (precision agrculture). QT gravity sensors have the potential to provide information on water flow, water levels and soil compaction. GRAM will open up these new markets by: 1) Establishing the market potential for QT gravity sensors for leakages through earthworks, water level detection in mines/mineshafts and determination of soil compaction by benchmarking it against the most advanced state-of-the-art geophysical instrumentation currently used in these sectors; 2) Develop novel forward modelling and inversion techniques post-processing techniques to identify the signal of interest and demonstrate the potentil of QT sensors; 3) Undertake field trials to demonstrate the real-world capabilities and limitations of existing sensors to identify the operational space for QT sensors; 4) Assess the market of QT gravity instruments in these applications and 5) Develop sensor specifications for the three applications. 

GRAM will accelerate the commercialisation of QT gravity instruments in two ways: 1) ensuring that the sensor development and system engineering efforts produces instruments that are fit for purpose by providing sensor configuration and performance parameters with particular focus on time-lapse assessment and 2) increasing the marketplace for the sensors by engagement with a new client base not yet familiar with QT sensors, excellent dissemination activities, and practical field demonstrations.",0
2104607,31864,Quantifying community metabolomes within model freshwater ecosystems and their responses to pollutants,"The University of Birmingham (UoB) is an international leader in OMICS TECHNOLOGIES and SYSTEMS TOXICOLOGY, achieved by pooling its expertise and capacity in omics and bioinformatics with specialists in toxicology, systems biology and chemical regulation. Our mission statement commits to offering leadership in the development and application of omics- and bioinformatics-based solutions, enabling evidence-based chemical safety science to safeguard both human and environmental health. 

Current ECOLOGICAL RISK ASSESSMENT of chemicals relies on standardised OECD tests on typically three isolated plant and animal species. This lack of realism is widely recognised as a central failure of environmental legislation. QUANTITATIVE MODEL ECOSYSTEMS have the potential to revolutionise ecological risk assessment by enabling molecularly reproducible experiments on ecologies that &quot;develop&quot; along predictable trajectories. Characterising the extent to which those trajectories are perturbed by pollutants would provide fundamental new metrics of pollutant impacts on ecosystems. Furthermore, when coupled with discovery-driven OMICS technologies, quantitative model ecosystems could for the first time enable discovery of stress response MECHANISMS (and subsequently diagnostic markers of pollutant impacts) within realistic environments of interacting sediment microbes, algae, higher plants, invertebrates, etc. 

METABOLOMICS is a proven technology for discovering mechanisms of how organisms respond to stress. UoB is a world leader in the development and application of metabolomics to quantify pollutant impacts on isolated species, with a particular focus on aquatic organisms. Our recent NERC-funded work has for the first time utilised metabolomics to discover a toxicity pathway spanning two species across two trophic levels. Here we propose to partner with Thermo Fisher Scientific to: 

(1) establish and optimise novel sampling and non-targeted LC-MS metabolomics techniques to characterise community metabolomes within model freshwater ecosystems that comprise of many species, 

(2) examine the temporal stability of metabolic processes in these model systems, 

(3) quantify the impacts of pollutants on baseline community metabolism, and 

(4) disseminate via multiple channels including through our partnership with the European Commission's Joint Research Centre and through our membership of OECD Extended Advisory Group on Molecular Screening and Toxicogenomics.",0
EP/P009727/1,15750,Privacy-Protected Human Identification in Encrypted/Transformed Domains,"Biometrics has been widely utilized in the past two decades in many areas such as healthcare, banking, surveillance, and security control. Given the increased uptake of internet and mobile computing globally, many companies have been turning to biometric privacy and security to ensure secure communication. However, biometric verification over third-party or public network servers may be abusively exploited in an unauthorized way. To protect the privacy and improve the security, it has been advocated to carry out biometric verification in encrypted or transformed domains, where privacy and security can be more effectively guaranteed. 

The basic idea behind the project is that the biometrics in the irreversible encrypted/transformed domains contains exactly the same amount of information as its original one, and hence one can establish a pattern recognition methodology to determine/extract useful information from chaotic signals in encrypted/transformed domains. This First Grant Scheme project aims to investigate how to discover and evaluate the information from chaotic signals for discriminative power, and develop robust pattern recognition schemes for biometric/multi-biometric verification in encrypted/transformed domains. The proposed methods/schemes will be vigorously validated over typical wild face/speech/gait datasets, and two practical demo systems (biometric banking and pedestrian profiling) will be designed and tested in real world environments.

The project will focus on both theoretical understanding of chaotic information and application-specific exploitation of chaotic pattern recognition. Considering multiple data structures hidden beneath a set of given chaotic signals, I will develop a robust way to find out the underlying various data structures for data understanding, clustering and classification. On the other side, given a specific issue such as encrypted/transformed biometric verification, one need to examine the generic theoretic findings in this specific topic and develop a robust scheme for biometric human identification.

The work of this project is within the areas of signal processing, machine learning and pattern analysis. The research on encryted/transformed biometric verification has come from the practical new needs of the UK's emerging new businesses. The project will provide the understanding needed to allow the future development of robust biometric verification methods with novel applications.",0
509423,7349,London Metropolitan University and Ask Outlets Limited,To develop a forecasting solution which will help identify trends and facilitate optimum stock management.,0
2282009,45175,Ultrafast imaging of cell-nanobubble interactions for bone repair,"Bone fractures and their associated complications are a major societal problem that is set to get significantly worse as our population ages. Delayed bone healing and extended rehabilitation contribute to the 39 billion euros per year cost of bone injuries to the European economy. A proportion of bone fractures fail to heal appropriately with current clinical interventions, which include mechanical fixation or, more rarely, biomaterials and/or bioactive agents. New therapies are therefore urgently required. As yet, there is no clinically approved, systemic therapy for bone fracture. 
We are developing such an approach. In preliminary work, we have found that ultrasound-responsive, drug-loaded nanobubbles and nanodroplets accumulate at bone injury sites following systemic administration. These bubbles can be induced to oscillate and to release their drugs selectively under remote ultrasound stimulation. This means that temporally controlled drug delivery could be directed at specific phases of fracture healing.
Before this aim can be realised, however, it is necessary to understand more fully the dynamics of the bubble/droplet interaction with cells and tissues. This is necessary for determining a number of effects on cells and tissues, including: the rate of release of a compound in the vicinity of the cells, the mechanostimulatory effect of bubble movement and fluid streaming effects at the cell membrane, and effects on cell function through intracellular uptake, cavitation and oscillation. Ultrafast imaging will enable us to achieve this aim. 
In this project, the student will adapt a 5 million-frame/s ultrafast imaging system (Shimadzu HPV-X), which is currently funded under FP's EPSRC fellowship (see www.photodyn.org), for tracking bubble oscillations in the proximity to cells. Currently the imaging set-up is employed for capturing rapid deformations in biomaterials, but we believe can be conveniently adapted by coupling to an inverted microscope for ultrafast imaging of bubble/cell interactions. The student will develop methodologies for tracking in real-time the cavitation and oscillation of nanodroplets/microbubbles with high temporal resolution. The student will then explore the effect of bubbles oscillation in real-time on cells in proximity to bubbles. Both brightfield and fluorescence capabilities will be utilised to measure parameters including cell strain and strain rate, membrane fluidity and release and uptake of environmentally sensitive fluorophores.
The student will train with experts in stem cell biology, mechanobiology, ultrasonics and ultrafast imaging from established experts at UoS, and with a collaboration with the University of Oxford (biomedical ultrasonics, biotherapy and biopharmaceuticals laboratory). The project will closely dovetail with an EPSRC-funded grant (to DC and NE) and a EPSRC fellowship to FP. The project will have applications beyond the initial target of bone repair, including in fields such as antibiotic delivery to biofilms and drug delivery in cancer medicine.",0
ST/N005872/1,8851,New Applicant scheme in Theoretical Particle Physics.,"Lattice QCD calculations are now producing physical results with
errors at below the few percent level for some quantities. There
are some quantities that require so called disconnected pieces to be calculated, where
the dynamics between quarks are solely due to gluons. It is currently
a hot topic in lattice QCD to accurately compute physical quantities
that involve disconnected diagrams, unfortunately these are
computationally expensive. I propose to develop some novel algorithms
to compute these disconnected diagrams, which will be computationally cheaper,
and thus help reduce the error on physical quantities.",0
EP/P029426/1,31590,Open Lab Instrumentation,"Everyday gadgets contain an impressive range of technology; very high quality sensors, cameras, and microprocessors are now incredibly cheap - making it possible to build lab equipment very cheaply. Doing this would make a big difference in developing countries, as it enables better screening for diseases like malaria or TB, and makes it possible to study science in the lab as well as in theory. The biggest challenge with this approach is often mounting the different parts together: good quality mechanical mounts are very expensive. We will measure and develop micro-mechanical properties of printed plastic parts, and understand how the structure of the prints affects their strength and flexibility. This will allow us to improve the way parts are printed, and create stronger, better mechanisms using only low-cost plastic. Together with readily available parts, we will then design, build and test a number of optical lab instruments, including microscopes, spectrometers, and sample preparation equipment.

The 3D printers that are now found all over the world work by extruding plastic through a hot nozzle, and drawing shapes by moving the nozzle over a print bed. 3D objects can be made by stacking multiple layers on top of each other. This layer-by-layer approach means that the exact path taken by the nozzle as it prints the object strongly affects the mechanical properties of the part, and it is this effect that we particularly want to understand and control. Once we have fully understood the relationship between the path taken by the nozzle and the properties of the final part, we will be able to create much better toolpaths to make objects that are stronger, weaker, stiffer or more flexible - and to balance these properties as we need them in different parts of a design. 

This new printing process will allow us to create parts that move very precisely, which is a crucial part of building precision instruments such as microscopes, spectrometers, and more. These instruments can be produced anywhere with a printer - including in many of the least developed countries in the world. Our partners in Tanzania will pilot this, and work with local clinics, universities and schools to explore how these better, cheaper instruments can help improve education and healthcare.",0
2125385,34947,Learning diffusion MR from commercially available protocols: bringing advanced tractography into routine neurosurgical practice,"Accurate localization of diffusion magnetic resonance imaging (dMRI) tractography can aid surgical planning by identifying white matter (WM) tracts that should be preserved to avoid functional deficits. However, there are still shortcomings that limit optimal tractography in a clinical setting. Firstly, signal modeling depends on acquisition parameters including signal-to-noise ratio (SNR), signal magnitude (b-values), and the minimum number of diffusion-weighting gradients (b-vecs) for high-quality local fiber orientation modeling. However, acquisition time is limited, and commercial scanners may not provide robust state-of-the-art dMRI acquisitions. Secondly, fiber tracking methods have intrinsic unresolved challenges in how to distinguish between different complex fiber configurations within a voxel, where axons can cross, kiss, bend, or fan out. Thirdly, there is variability in the fiber tracking algorithms with regards to tracts locations that usually are not taken into account. Most of the state-of-the-art tractography approaches do not estimate the uncertainty of WM pathways, and post-processing user-guided filtering is often performed to eliminate spurious streamlines. In this Ph.D. project, I aim to develop an end-to-end approach to ensure optimal tractography for clinically acquired dMRI and thereby provide more accurate guidance during neurosurgery. I will do that by improving the ability to recover complex local fiber orientations from commercial dMRI acquisitions and providing a tract uncertainty measure for preoperative guidance using deep learning. To achieve this I will: 1) Develop a convolutional neural network (CNN) approach to improve commercial
dMRI model fitting; 2) Compute tractography uncertainty quantification, 3) Incorporate tractography specific features to improve model fitting and validate pipeline on patients with gliomas.",0
AH/P006019/1,28458,How do we ensure responsible lending and borrowing?,"Our FinCris 'responsible lending and borrowing' research on consumer credit for low-to-moderate income individuals, has been extremely timely. This proposal for impact and engagement is designed to create greater impact from the research than was unforeseen at the time of the original application due to unexpected regulatory reforms to consumer credit and welfare reforms, which have impacted on the consumer credit landscape and led to fast changing nature of the debates. 

We will work with lenders of affordable credit, specifically the UK Credit Union sector, ABCUL, ACE and Birmingham based Citysave Credit Union to develop innovative and creative strategies for improving the level of responsible lending through:
1. Workshops at UK Credit Union conferences - we will co-produce materials based on our research findings in order for them to understand and support responsible borrowing amongst their members for longer-term impact beyond the project. 
2. Supporting Credit Union staff and board member training in the challenges for responsible lending and borrowing within the broader credit landscape.
3. Facilitating knowledge exchange events on responsible lending and borrowing for key regulators, practitioners, and policymakers within responsible credit in the Australian and UK context to share experiences of consumer credit regulatory reform, and facilitating access to affordable credit for low to moderate income communities. 

This project is therefore extremely timely and relevant to challenge public debates on responsible lending and borrowing. The project will feed into these debates via the Credit Union network and key stakeholders within the lending and borrowing space, particularly policymakers and regulators which will make a significant impact upon credit union members and borrowers.",0
AH/N004299/1,20426,Suicide Voices: Neoliberal Globalisation and Workplace Trauma,"France, during the 2000s, experienced what the international media has described as an 'epidemic' of workplace suicides with unprecedented numbers of workers choosing to kill themselves in work or because of work. With a 70% increase in recorded cases since 2000, France today has the second highest rate of workplace suicides in the world after Japan. French workplace suicides are part of a rising international phenomenon with well-publicised cases in Germany, Spain, Australia, China and Japan. Recent French suicides have been marked by an intensified production of texts through which suicidal individuals have sought to describe for themselves the experiences that have pushed them to take their own lives. The purpose of the fellowship is to examine, through a close reading of testimonial material, what these 'suicide voices' can tell us about the lived conditions of human labour in the historical juncture of neoliberal globalisation. 
The fellowship undertakes an analysis of a corpus of testimonies linked to 82 suicide cases within three French companies during the period 2005 to 2015: telecommunications multinational, Orange; car manufacturer, Renault; and French postal services, La Poste. Each of these companies experienced an acute 'suicide wave' amongst its employees at a time of restructuring in response to the external economic imperatives linked to neoliberalism. The research examines an extensive corpus of letters, audio recordings, e-mails, press statements and legal documents written by suicidal individuals and intended for both private and public audiences. Whilst testimonies in a number of well-publicised cases have been published by the media, the full corpus of testimonial material has not yet been subject to academic scrutiny.
The fellowship examines suicide narratives as a unique testimonial mode that can shed light on subjective experiences of economics in the contemporary neoliberal and globalised workplace. The research locates suicide testimonies at a juncture between the everyday and the extreme. Whilst embedded in everyday life, these testimonies also reveal how the quotidian workplace can be transformed into a site of extreme human suffering. Why and how does work or conditions of work push some individuals to take their own lives? What are the social conditions to which these testimonies bear witness? Why is self-killing envisioned as a response to everyday experiences of work?
The fellowship aims to bring an arts and humanities perspective to bear on our understanding of a critical social and public health phenomenon by combining innovative theoretical and methodological insights from literature (testimony studies), social sciences scholarship and public health.
Three principal objectives are sought during the eighteen months of this fellowship. A first objective is to examine suicide narratives as a form of testimony that can transform personal trauma into public meaning and shed light on the conditions of labour in the contemporary historical juncture. The research aims to provide a critical alternative to 'top-down' theories of economics that often overlook experiential and quotidian dimensions of work. A second objective is to examine the historically-specific conditions of workplace suicides and ask why neoliberalism, as compared with earlier economic phases, has exacerbated suicidal tendencies in the workplace. A third objective is to consider the contemporary significance of suicide and ask whether workplace suicides constitute a new and radical mode of protest. To what extent do suicides stem from a failure of collective representation and a re-embodiment by the individual of grievances that might otherwise be given social expression? 
From the vantage point of the singular and extreme experiences narrated in suicide testimonies, the fellowship aims to investigate the human and social effects of neoliberal economics in the workplace within the contemporary historical juncture.",0
EP/N034368/1,11555,Antimicrobial filters for hospital air and water systems,"Most of the world's population is now living in cities and travelling more. As a result we are more likely to come into contact with infections that we would not have been exposed to just a few decades ago due to interactions with more people. The environment plays an important role in the transmission of some infections and it is possible to reduce the transmission of such disease by better filtration of water and air. Some filtration systems are currently used which physically stop pathogens such as bacteria. However these systems cannot stop virus particles, are expensive, require frequent maintenance and careful disposal. 

The aim of this project is to design one air and one water filter which will actively kill bacteria and viruses, thereby reducing their numbers in the environment. These filters will require less maintenance and be inexpensive to produce. During the project, we will first test the antimicrobial effect of a variety of nanoparticles. These will then be modified chemically so that they can be incorporated into materials that are suitable for water and air filtration. The filters containing the antimicrobial nanoparticles will be produced using a new EPSRC funded spinning technology developed at UCL. Once we have produced the antimicrobial filtration materials, we will test their ability to kill viruses in air and bacteria in water. We will test filters with different concentrations of antimicrobial nanoparticles and with different depths. We will also make sure that the filters are effective at flow rates that are used in the real world. 

The antimicrobial filters will be of most interest to the healthcare industry in the first instance, but they will also be relevant to busy public buildings (such as schools and care homes) and transport vehicles (such as airplanes). Furthermore, the filters will be capable of oxidising non-biological materials, like tar and pollution particulates and will improve air quality in a range of indoor environments. During the project we will be collaborating with industrial partners (including Pall Corporation, the world's biggest filtration company) and clinicians to ensure that we produce a viable product. At the end of the project, the technology will be validated and ready for scale-up production and we plan to apply for further funding for a collaborative project with industry in order to do this.",0
2296004,42934,ZrO2-corrosion-layers and their grain boundary networks,"Zr-alloys are used for nuclear fuel cladding in water-cooled reactors. These alloys corrode in contact with their local-environment, e.g. hot water and steam (F&eacute;ron 2012). Initially oxidation rapidly results in the formation of a zirconium oxide layer that reduces the oxidation rate. The migration of charged species in the oxide layer is largely controlled by the microstructure (Garner et al. 2015, 2017) and grain boundary network of the oxide layer (Gertsman et al. 1997).
Initially a non-equilibrium tetragonal phase close to the metal-oxide interface. However as the Oxide layer gains thickness the location of the reaction interface between metal and oxide are further from the surface. The compressive stress in the oxide layer decrease with distance from the metal/oxide interface to eventually be insufficient to stabilise the tetragonal phase. It transforms to monoclinic ZrO2, which is the stable phase at atmospheric pressure and temperature below 1500 K. 

In this challenging project, we aim at characterizing the behaviour of different grain boundary networks using state-of-the-art meso- to nano-scale characterisation techniques including transmission electron microscopy (TEM) and electron backscatter diffraction (EBSD) techniques. We will experimentally alter Zr-alloys and investigate how this affects the formation and microstructural properties of the resulting Zr-oxide layers. Eventually the experimental data will be used to explore the microstructures using different modelling approaches.

References:
F&eacute;ron, D. (2012) Preface. In Nuclear Corrosion Science and Engineering pp. xxvii-xxix. Elsevier.
Garner, A., Hu, J., Harte, A., Frankel, P., Grovenor, C., Lozano-Perez, S., and Preuss, M. (2015) The effect of Sn concentration on oxide texture and microstructure formation in zirconium alloys. Acta Materialia, 99, 259-272.
Garner, A., Frankel, P., Partezana, J., and Preuss, M. (2017) The effect of substrate texture and oxidation temperature on oxide texture develment in zirconium alloys. Journal of Nuclear Materials, 484, 347-356.
Gertsman, V.Y., Zhilyaev, A.P., and Szpunar, J.A. (1997) Grain boundary misorientation distributions in monoclinic zirconia. Modelling and Simulation in Materials Science and Engineering, 5, 35-52.",0
AH/S00193X/1,31597,Masculinity and the Ethics of Porosity in 'Post-AIDS' Gay Porn,"This project theorises gay &quot;pig&quot; masculinities and their visual mediation, which emerged in the last two decades in tandem with the introduction of antiretroviral therapies for the management and prevention of HIV infection. It does so through a close critical engagement with representations of &quot;pig&quot; masculinities in contemporary gay pornography.

&quot;Pig&quot; is a term used by some gay men to self-define themselves in terms of their own sexual practices, which they regard as transgressive, pushing the limits of the body and of its integrity through relentless condomless penetrations, stretching of the rectal sphincter, and exchanges of all kinds of bodily fluids (sperm, urine, saliva, etc). It is used in the names of hookup websites directed at gay men into fetish or &quot;extreme&quot; sex (e.g. NastyKinkPigs.com or AssPig.com) and often included, as a pig head or snout emoji, on usernames or profile text on gay hookup apps like Grindr, Scruff or Recon. It is also a term that, alongside &quot;bareback,&quot; has been appearing in increasing numbers of gay porn titles since the mid 1990s. What is interesting about gay &quot;pig&quot; masculinities are the ways in which they appear to be predicated on a transgression of the boundaries of the male body, a blurring of inside and outside, self and other, through the pursuit of relentless penetrations and exchanges of bodily fluids. Unlike hegemonic forms of Western masculinity, which have been shaped by a rejection of all things considered &quot;feminine,&quot; including penetrability, gay &quot;pigs&quot; appear to become more &quot;manly&quot; the more penetrated and open to foreign bodily fluids they are. 

The introduction of Highly-Active Antiretroviral Therapies (HAART) and viral load testing in 1996 made HIV infection a long-term chronic condition and led to a radical transformation in the lives, identities and sexual practices of gay men. Not only did HAART make HIV infection no longer progress to AIDS but it also makes HIV-positive individuals uninfectious. More recently, the confirmation of HAART's efficiency as Pre-Exposure Prophylaxis (PrEP) also means that those who are HIV-negative and having sex without condoms can prevent HIV infection by taking one pill a day. As a consequence, unprotected sex has been uncoupled from the spectre of AIDS and the number of gay men engaging in &quot;barebacking&quot;-that is, in intentional condomless anal sex-has risen exponentially, leading the practice to become mainstream. At the same time, bareback porn has also become the fastest growing genre of gay porn and, today, only a very small minority of studios continue to make visible use of condoms. 

It is in that context that gay &quot;pig&quot; masculinities have emerged and become visible in gay online platforms and pornography. This research project will lead to the first monograph and documentary feature film critically discussing &quot;pig&quot; masculinities and their sexual ethics at length. It builds on porn studies, masculinities studies and the posthumanities to theorise &quot;pig&quot; masculinities as &quot;porous&quot; masculinities that simultaneously reiterate and trouble hegemonic traits of Western masculinity, while pushing the limits of the body and opening themselves to new forms of sexual sociability and community formations. 

In so doing, the project will contribute to existing critical histories of sexuality, subjectivities, and their visual representations by examining a contemporary form of gay male self-identification, one that is emerging in &quot;post-AIDS&quot; contexts through a complex interplay of desire, sexual performance, biochemical technologies, and 21st-century visual media.",0
2260597,36886,Multilingual Modelling And Adaptation For Text-To-Speech Synthesis In Low-Resource Languages,"The production of high-quality text-to-speech synthesis systems has so far been limited to a small proportion of the world's languages by the need for large amounts of transcribed audio recordings and significant bases of linguistic analysis. One possible approach for reducing these costly requirements is to use information from one or more well-resourced languages as a starting point for training voices in languages where only small amounts of annotated data are available. For this to work, we may need flexible representations of speech which capture the commonalities across languages, yet are amenable to adaptation toward language-specific acoustic features. We will investigate the use of different input representations, for example decomposing individual sounds in phonemic transcriptions of input text into sets of phonological features, potentially allowing for more granular information sharing between similar but not identical pairs of phonemes across languages. We will also consider the structure of the learned acoustic representations, for example analysing the degree to which similar sounds across languages tend to cluster together in learned embeddings.",0
MC_PC_18026,45897,UKRI Industrial Strategy Challenge Fund UK BioBank Vanguard Project - Informatics,"UK Biobank and UKRI are taking advantage of the revolution in genetics analyses that makes large-scale sequencing of the human genome possible at an ever-quickening pace. With the ultimate goal to sequence all 500,000 UK Biobank participants, this investment as part of the Vanguard project will sequence 50,000 participants and help establish the world窶冱 most detailed whole genome database <U+2013> and further accelerate research into a wide range of diseases that cause disability and premature death in mid to later life.",0
2285827,46373,Use of Routinely Collected Health Data to Predict Sudden Death and Other Catastrophic Events,"Keywords: Sudden Death, Routinely Collected Health Data, Artificial Intelligence, Machine Learning, Precision Medicine

Background: The first presentation of about one third of cardiovascular disease is sudden death;about 50,000 cases per year in England or about 2,500 per year in the West of Scotland. Many others will present first with a myocardial infarction, stroke or heart failure and then die suddenly. The cause of sudden death is varied but many are likely to be due either to ischaemia or arrhythmias; aka sudden cardiac death (SCD). Presentation as a myocardial infarction, stroke or decompensated heart failure could be considered as a failed 'attempt' at SCD. Predicting such catastrophic events may help prevent them, either by applying existing medical guidelines more assiduously to those at risk or by helping design relevant clinical trials. However, the incidence of sudden death is poorly described, since it lacks a clear and unequivocal definition. Death certification provides one source of data but many sudden deaths are attributed to a specific disease based on medical opinion rather than evidence. Using routinely-collected data to create a new definition of sudden death by studying the evolution of the health record may provide very different perspectives on how to define and incidence rates. People who die at home or within hours of reaching hospital who had no prior severe medical history indicating imminent demise and where trauma or suicide is not the cause of death can be considered to have died suddenly. The West of Scotland SafeHaven provides access to routinely collected NHS data over the last 10 years (potentially ~20,000 sudden deaths) including electrocardiographic, imaging, laboratory and prescribing data from both primary and secondary care. This provides a rich source of data that can be interrogated to identify new patterns that predict the risk of sudden death and other catastrophic events. The size of this dataset makes it amenable to analysis with modern machine learning techniques. In particular, probabilistic clustering models that incorporate different data types can be used to subdivide instances of sudden death to help expose potential relationships. Search and natural language processing techniques on free text records can be used to extract structured data and to find similar patients (for use in modelling features). Supervised machine learning models, including deep neural networks, can be used to automatically learn features and build predictive models. Combinations of variables with high predictive ability can be extracted from these models to discover previously unknown relationships between factors. The diversity of the data across modalities (sensors, images, labs, codes, and text) allows for rich and complementary data models to be constructed. One particular modality may be subject to bias or noise (sensor or coding errors) that could be automatically corrected and de-noised based on large-scale data analysis across the population. For example, extraction of text from notes could be used to infer missing or incorrect codes or properties, such as prescription history or lifestyle factors. 

Aims: To describe the incidence of sudden death and other catastrophic events and, in a case-controlled study, to predict their occurrence to enable individual-patient targeted strategies for their prevention using AI, machine learning and information retrieval techniques. 

Training outcomes: Yola will receive basic training in clinical terminology, diagnosis, natural history &amp; treatment of relevant cardiovascular diseases to help put the data and strategy into context. She will also be trained in data-protection legislation, data-linkage, analysis, &amp; cleaning and receive hands-on training in modern machine learning techniques (eg. deep networks, text modelling, etc). As such, this PhD addresses two of the skills priorities highlighted by the MRC (quantitative &amp; interdisciplinary skills).",0
1766911,1223,Investigating ways to restore the aberrant inhibitory-excitatory synaptic imbalance in Alzheimer's disease,"Introduction:
Alzheimer's Disease (AD) is a debilitating disease, characterised by memory loss associated with neurodegeneration and loss of neuronal connections. Characteristic
markers are protein aggregates that disrupt healthy brain function: amyloid-beta (A beta) plaques and neurofibrillary tau tangles. Using a knock-in mouse model of AD, AppNL-F/NL-F, which exhibits similar disease progression to human AD, we experimentally observed an abnormal increase in the electric function of certain neurons in regions of the brain targeted by AD like the hippocampus and the entorhinal cortex. These are important for long-term memory formation, so any disturbance has negative consequences on the patient. This hyper electrical activity is present in cells that regulate the inhibitory-excitatory synaptic balance. Hence, early hyper-activity results in failure to modulate excitation, leading to chaotic brain circuits that impair brain function.

Aims and research plan:
We hypothesise that there is inhibitory-excitatory imbalance in the brain and predict that rectifying it pharmacologically will delay or halt AD symptoms. Calretinin-expressing (CR) interneurons are a category of interneurons that regulate the inhibitory drive of other interneurons, thus playing a role in the inhibitory-excitatory imbalance. Anatomical studies show that calretinin expression levels and density are not affected by AD (3) and preliminary results in the lab show they are functionally active in the disease model. Our objectives are to use immunostaining to quantify the number of CR cells in different brain regions in healthy and aged-matched AD animals, record their electrical activity and assess their response to certain pharmacological conditions. 

Pharmacological studies:
CR cells are activated by glutamate, an excitatory neurotransmitter, and produce gamma-Aminobutyric acid (GABA), an inhibitory neurotransmitter. Glutamic acid decarboxylase 67 (GAD67) is an enzyme that catalyses GABA formation from glutamate, hence to assess calretinin function we are also staining for GAD67. Preliminary results show that there is a difference in the density of calretinin cells in the APPNL-F/NL-F between the early and late stages of the disease in the hippocampus, which triggers the question- is there an increase in excitation facilitated by calretinin cells?

Identifying the receptors that CR cells use and investigating their function may help us determine how to modulate them. Studies show that alpha5 subunit containing GABA(A) receptors are preserved in AD so our objective is to identify whether CR cells use those receptors to activate their dis-inhibitory network. This is being done by staining for both calretinin and alpha5 and checking for co-localisation. 

I will also carry out behavioural work with two AD mouse models: APPNL-F/NL-F and APPNL-F-G/NL-F-G using an 8-arm radial maze. The mice will be treated with drugs that suppress GABA(A) alpha5 to verify whether that would help regulate the electrical imbalance. This will be followed with immunofluorescence assays and electrical recordings to assess the potential effects of the treatment on disease progression.

Concluding remark
To summarise, the project centres on understanding the excitatory-inhibitory synaptic imbalance in Alzheimer's Disease and finding ways to restore normal brain function in the hippocampus, with the hope that it will delay or halt disease symptoms. The focus will be on calretinin cells, which are one of the regulators of the inhibitory-excitatory balance in the brain. The methods employed will analyse the function and anatomy of the cells in distinct brain subregions, using a novel, more accurate, mouse model of Alzheimer's Disease.",0
BB/R009287/1,8264,"Neural mechanisms of long-range spatial vision: an investigation of perceptive, integrative and association fields across the lifespan","Incoming light is processed by retinal receptors. Light reflected from objects that are nearby each other will fall onto adjacent retinal locations, and will be fed to correspondingly located neurons in the visual cortex. In the visual cortex, units of different complexity will process this information further, ultimately giving rise to our everyday visual experience. The area of space on the retina to which a visual cortex unit responds is called a visual field. The concept of visual fields has played a crucial role in the study of visual perception since the pioneering studies of Hubel and Wiesel in the 1960s. Visual fields determine which information will be bound together and which will be individuated. Away from the centre of the retina, visual fields increase in size, but this size is flexible and, somewhat surprisingly, depends on the strength of the received signals (colour or brightness) as well as the presence or absence of nearby objects, which activate neighbouring neural units. There are also visual fields of different complexity: while neurons in the primary visual cortex simply integrate the amount of brightness or colour contrast that fall within their scope, neurons beyond it integrate or individuate more complex attributes of objects, e.g. orientation, to identify the object's shape. Therefore, visual fields determine information processing across space, especially processing of relatively long-range spatial information, which will be at some distance from each other once we move away from the centre of the retina. 

The aim of this project is to build a unitary framework that would encompass neural processing within visual fields of different complexity across the lifespan. Despite years of research, such a unitary framework is still lacking: while we know a lot about &quot;low-level&quot; processing of colour and luminance supported by neurons in the primary visual cortex, the intermediate stages of visual processing are more difficult to probe and distinct aspects of such &quot;mid-level&quot; vision are often studied separately. The uniqueness of our approach is that we will probe visual fields of different complexity, covering both &quot;low&quot; and &quot;mid-level&quot; vision, using the same paradigm. This paradigm is simple yet powerful: it relies on the same stimulus, consisting of multiple oriented elements (black and white gratings known as Gabor patches) that can form different letters, to probe visual fields of different complexity by simply changing the task that the participants are performing: a) detecting the presence or absence of a target element, b) judging its properties, or c) judging the identity of the whole letter. We will establish how visual fields process stimuli defined by brightness, colour, or both, thus integrating all types of contrast visible to the human eye. Finally, we will conduct our experiments on a large sample that consists of participants that are between 20 and 80 years of age. Our experiments will combine behavioural and neuroscientific techniques, using new, state-of-the-art electroencephalographic (EEG) techniques to ascertain which neural mechanisms underlie age-related changes in visual processing. We will determine the degree to which age-related deficits are driven by an increase in neural noise, and relate it to more basic changes in contrast sensitivity. Such analyses of age-related differences will offer an exciting window into the neural mechanisms that sustain information processing in human vision. In this way, this project will not only provide a basis for theoretical developments in visual perception, but will also considerably affect our understanding of the aging of sensory mechanisms. Such information can be used to improve the quality of life for the elderly.",0
BB/R013276/1,21600,Summer Skills School in Technologies for Drug Discovery,"Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes, see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.",0
MR/S000593/1,43979,MICA: Modulation of IL-33-dependent responses using parasite products,"This project will investigate how we can use proteins derived from a parasitic worm to either amplify or suppress &quot;IL-33&quot;, a protein used for communication within the immune system. IL-33 is released on damage to various barrier sites (lung, skin, gut), and can lead to either allergic or inflammatory responses, depending on the context. These responses can be beneficial, e.g. they can efficiently clear bacterial infections, or they can be detrimental, e.g. they can lead to the development of allergic or inflammatory damage such as in asthma or acute respiratory distress syndrome. Therefore being able to effectively &quot;tune&quot; the IL-33 pathway up or down would be a powerful technique for treating a wide range of diseases including asthma, eczema, fungal or bacterial infections, and acute respiratory distress syndrome. 

We have identified two proteins derived from a single parasitic worm (Heligmosomoides polygyrus) which act to suppress IL-33 responses; we have named these proteins HpARI and HpBARI. Suppression of IL-33 responses is advantageous to parasites, as it allows them to avoid triggering immune responses which could lead to their ejection or damage to their host. When we produced a mutant form of one of these IL-33-suppressive proteins, we found the mutant form had the surprising effect of amplifying (rather than suppressing) IL-33 responses due to stabilisation of the IL-33 molecule. Therefore we can use these proteins and mutants to either increase or decrease IL-33 responses and potentially treat a long list of diseases in which IL-33 has a causative, or curative, role.

This project will investigate the use of these proteins and their derivatives in mouse systems where IL-33 drives allergic responses (such as in asthma), damaging inflammatory responses (such as in acute lung injury or acute respiratory distress syndrome) or beneficial anti-bacterial responses (such as in pneumonia). 

We will translate findings from the mouse towards human responses by using genetically-engineered mice which express the human form of the IL-33 molecule, and stimulating human blood cells with human IL-33 in the lab, and testing whether our proteins affect the responses of these cells. 

Furthermore, we will engineer hybrid molecules, taking the active regions of our proteins, and combining them with proteins normally present in our blood. This will have the advantage that the resulting proteins will be largely ignored by the immune system as they look like one of the body's own proteins. This avoids a common problem (known as &quot;immunogenicity&quot;) of using foreign proteins as medicines, where the immune system rejects the protein, preventing it from carrying out its function. These engineered proteins will be further assessed for activity against IL-33 responses and for immunogenicity (the level of recognition by the immune system) in mouse and human tests, as described above.

In summary, this project will investigate and characterise new parasite-derived proteins which can suppress or amplify the immune response, with the potential to be used as new medicines or tools for research in a range of allergic, inflammatory and infectious diseases.",0
1990353,3718,Characterising and optimising the role of fine alpha laths in dual-phase titanium alloys,"Due to the high-performance requirements of the aerospace industry, relatively small improvements to the mechanical properties of titanium alloys can lead to significant gains in overall performance. Recent trials have suggested that fine alpha laths found in the transformed beta of dual-phase titanium alloys can significantly improve an alloys strength, without reducing ductility. The main objective of this project is to understand the role of these fine alpha laths on the mechanical properties of dual-phase titanium alloys and optimise alloy chemistry to maximise their benefits. 
 
This will be done through rigorous characterisation of both model and industrial alloy chemistries using the unique capabilities of the University of Glasgow's Kelvin Nanocharacterisation Centre (KNC). The student will use the KNC's new Plasma Focused Ion Beam Scanning Electron Microscopy (PFIB-SEM), capable of detailed 3-D characterisation of materials, and in-situ Transmission Electron Microscope (TEM) heating stage to study the effect of varying heat treatments on the kinetics of fine alpha lath formation and annihilation.

By developing a better understanding of the role of fine alpha laths on the mechanical performance of titanium alloys, this project has the potential to significantly improve the in-service performance of current titanium alloys and provide the underpinning knowledge to develop the next generation of high-performance titanium alloys.",0
EP/P008410/1,5220,AI Planning with Continuous Non-Linear Change,"Intelligent autonomous systems have a significant role to play in meeting the increasing needs of a growing modern society. These systems can take many forms. Autonomous robots can assist humans in performing tasks, work in manufacturing, and play an important role in cleaning up or exploring environments too hostile for humans. Autonomous large scale software systems can control our over-subscribed transport and power networks, allowing us to operate them as efficiently as possible to serve the growing population.

In order for an autonomous system to act intelligently and achieve its goals, it needs to be able to plan, that is decide what actions to take and when to take them: this is the problem of Artificial Intelligence (AI) planning. The major research goal for AI planning is to create systems that are domain-independent, that is they are not human-programmed to solve one specific problem; but rather are general purpose and capable of planning in scenarios encountered across a wide range of applications.

Decades of research has produced increasingly capable AI planners, and there have been successes in using these in a diverse range of applications, including the planning of global ocean liner movements and security penetration testing. There are, however, still major challenges to be met in creating systems that are scalable and expressive enough to form the core of the AI systems needed to meet future societal challenges. One major challenge, and the focus of this project, is equipping planners with the expressive capability to reason about a complex and dynamic world. Many interesting target problems, such as nuclear clean up or traffic control, require not only conventional reasoning based on facts that are true and false; but also reasoning about non-linear continuous dynamics: radiation exposure or traffic flow.

This project addresses the challenge of creating a planner capable of reasoning with non-linear continuous dynamics alongside all the existing state-of-the-art capabilities of the most expressive modern planners (time, deadlines, soft constraints and cost optimisation) without significantly compromising scalability. Such a system will be an invaluable asset in controlling the autonomous systems of the future.

The research challenges that need to be addressed to achieve this are significant, as present techniques for reasoning with these problems make compromises in one way or another. Some techniques are limited in scalability due to a requirement to 'discretise' time, splitting it into small chunks, and reasoning about whether to do something every fraction of a second. Others are incompatible with other expressive features; or rely on technologies that support only linear change. In this project we build on OPTIC, a planner that supports only linear change, due to its support of other expressive features and good potential for scalability. 

We will address the challenges of reasoning with non-linear change in a linear framework by reasoning with piecewise-linear approximations of the continuous change. The main challenges here are determining how to integrate reasoning about these with existing techniques for expressive reasoning; and generating sufficiently accurate approximations automatically. The finer we make the approximation, the more points we have to reason about and the harder it is to solve efficiently; yet approximations that are not fine enough will not permit us to solve the problem. 

Throughout the project, alongside development of the planner, we will focus on creating models of target problems, guided by our contacts with organisations in the relevant fields. These will allow us to ensure our work remains focussed on addressing the challenges that will most benefit application as well as providing us with benchmarks against which we can evaluate the project. Our target applications include nuclear clean up; medical dose scheduling and traffic flow management.",0
2145045,43369,Formation and evolution of Globular Clusters,"Currently, I am using the simulations from the First Billion years (FiBY) Project to look into the formation and evolution of Globular Clusters. I am using local universe observations of Globular Clusters to refine a set of criteria which can be used to identify them and proto-globulars in the simulations. Once candidates have been identified I then study their global and average properties in order to compare with current theories about their formation and evolution as well as finding properties that could be observed at high redshift. The future aim will be to look into the formation of Intermediate Mass Black Holes and to determine whether Globular Clusters could potentially host them.",0
MR/N010388/1,19716,Functional analysis of Epstein-Barr Virus genome variation in relation to cell growth and disease,"Most people are infected by Epstein-Barr virus (EBV) as young children, and carry the virus for their whole life with no ill effects, but the virus can cause several human diseases. Glandular fever occurs when people who were not infected as children first become infected with EBV as teenagers or adults. Also, several specific types of cancer are caused by EBV; together these cancers account for 1.5% of all human cancers worldwide. EBV may also play a role in multiple sclerosis. These diseases occur at quite different rates in different parts of the world and we suspect that the different EBV strains present in those parts of the world may be part of the reason for that. We therefore need to understand what variation is actually present in EBV strains and find out whether it makes a difference to function of the virus, in ways that might be relevant to the human diseases associated with EBV. 

We have recently published the first large scale DNA sequencing of EBV from different parts of the world, and from various EBV-cancers. This application will make use of this new information to understand how the variation in EBV sequence has an impact on EBV biology. In fact, we now know that most EBV research so far has used EBV lab strains that are poor representatives of the viruses that circulate in the human population. We shall therefore isolate - in a pure form suitable for research - a set of diverse EBV strains and assess their characteristics. The viruses will be tested by infection of human cells relevant to the diseases, both in the lab and in an animal model.

We shall also test two specific examples of the impact of virus diversity on biology and disease that have been highlighted by our preliminary work. First we shall investigate how two of the EBV genes (called EBNA2 and EBNA3) work together to determine the much greater ability of certain EBV strains to cause growth of white blood cells, likely relevant to some of the blood cancers associated with EBV. Second, we shall test whether specific differences we have identified in Chinese EBV may help to explain the very high incidence of EBV associated nasopharyngeal cancer that occurs in Hong Kong and nearby parts of China.",0
MC_EX_MR/R023549/1,35872,MRC AZ CLD 2018,"Bipolar disorder is a chronic and debilitating psychiatric disorder that with a lifetime prevalence of 1-3%. It has at a cost to the UK economy estimated to be in the region of &pound;2 to 5 billion per year, of which around &pound;350m are direct costs to the NHS with the remainder including social care, criminal justice services, informal care from family members and costs associated with lost employment. The gold-standard treatment for bipolar disorder is lithium, which is unique among the various treatment options available in that it not only has anti-manic and anti-depression properties but also reduces the risk of suicide in patients. However, the prescribing of lithium continues to decline due to the number of serious side effects that are unrelated to how it affects brain function. Most notably, lithium can cause death if blood concentrations reach only 2-3-fold higher than therapeutic concentrations. Consequently, lithium concentrations in the blood need continual monitoring and as a result lithium has been replaced as the first-line treatment of bipolar disorder by a variety of safer but less effective mood stabilising drugs.
There is clearly a need to identify drugs that retain the beneficial effects of lithium yet are devoid of the serious side effects. In this regard, there is considerable evidence to suggest that lithium exerts its beneficial effects in the brain by reducing the activity of a protein called inositol monophosphatase (IMPase). As a result, lithium dampens down the activity of nerve cells that are presumed to be more active than normal in bipolar disorder. In theory, a drug that only inhibits IMPase and is devoid of the multiple other effects that lithium possesses - and which are the responsible for lithium's side effects - should retain the remarkable beneficial effects of lithium yet be much safer. Such a drug has the potential to revolutionise the treatment of bipolar disorder and in doing so, not only reduce the financial and social costs but also assist patients in achieving normal, productive lives. Screening of the AstraZeneca's chemical library is a unique opportunity to start along the path of identifying such a potentially transformative drug.",0
EP/S02347X/1,39005,"'EPSRC and SFI Centre for Doctoral Training in Engineered Tissues for Discovery, Industry and Medicine","The lifETIME CDT will focus on the development of non-animal technologies (NATs) for use in drug development, toxicology and regenerative medicine.

The industrial life sciences sector accounts for 22% of all business R&amp;D spend and generates &pound;64B turnover within the UK with growth expected at 10% pa over the next decade. Analysis from multiple sources [1,2] have highlighted the limitations imposed on the sector by skills shortages, particularly in the engineering and physical sciences area.

Our success in attracting pay-in partners to invest in training of the skills to deliver next-generation drug development, toxicology and regenerative medicine (advanced therapeutic medicine product, ATMP) solutions in the form of NATs demonstrates UK need in this growth area. The CDT is timely as it is not just the science that needs to be developed, but the whole NAT ecosystem - science, manufacture, regulation, policy and communication. Thus, the CDT model of producing a connected community of skilled field leaders is required to facilitate UK economic growth in the sector.

Our stakeholder partners and industry club have agreed to help us deliver the training needed to achieve our goals. Their willingness, again, demonstrates the need for our graduates in the sector. This CDT's training will address all aspects of priority area 7 - 'Engineering for the Bioeconomy'. Specifically, we will: 

(1) Deliver training that is developed in collaboration with and is relevant to industry. 
- We align to the needs of the sector by working with our industrial partners from the biomaterials, cell manufacture, contract research organisation and Pharma sectors.

(2) Facilitate multidisciplinary engineering and physical sciences training to enable students to exploit the emerging opportunities.
- We build in multidisciplinarity through our supervisor pool who have backgrounds ranging from bioengineering, cell engineering, on-chip technology, physics, electronic engineering, -omic technoloies, life sciences, clinical sciences, regenerative medicine and manufacturing; the cohort community will share this multidisciplinarity. Each student will have a physical science, a biomedical science and a stakeholder supervisor, again reinforcing multidisciplinarity.

(3) Address key challenges associated with medicines manufacturing.
- We will address medicines manufacturing challenges through stakeholder involvement from Pharma and CROs active in drug screening including Astra Zeneca, Charles River Laboratories, Cyprotex, LGC, Nissan Chemical, Reprocell, Sygnature Discovery and Tianjin.

(4) Embed creative approaches to product scale-up and process development.
- We will embed these approaches through close working with partners including the Centre for Process Innovation, the Cell and Gene Therapy Catapult and industrial partners delivering NATs to the marketplace e.g. Cytochroma, InSphero and OxSyBio.

(5) Ensure students develop an understanding of responsible research and innovation (RRI), data issues, health economics, regulatory issues, and user-engagement strategies.
- To ensure students develop an understanding of RRI, data issues, economics, regulatory issues and user-engagement strategies we have developed our professional skills training with the Entrepreneur Business School to deliver economics and entrepreneurship, use of TERRAIN for RRI, links to NC3Rs, SNBTS and MHRA to help with regulation training and involvement of the stakeholder partners as a whole to help with user-engagement.

The statistics produced by Pharma, UKRI and industry, along with our stakeholder willingness to engage with the CDT provides ample proof of need in the sector for highly skilled graduates. Our training has been tailored to deliver these graduates and build an inclusive, cohesive community with well-developed science, professional and RRI skills.

[1] https://goo.gl/qNMTTD
[2] https://goo.gl/J9u9eQ",0
1802142,18832,"Candidate for CDA studentship on &quot;Instruments and their makers,&quot; material sent separately to CDA assessors","Candidate for CDA studentship on &quot;Instruments and their makers,&quot; material sent separately to CDA assessors",0
1952274,1384,An Investigation into testing the application level security of wireless access control,"Almost every large commercial workplace, educational institute, bank or government office uses wireless cards perform physical access control into their buildings. However, it is apparent that these electronic locks are not as secure as they appear to be. The ability to break into one of these places with little effort would be a major security breach. We will investigate issues in these systems and their implementations. We also introduce a tool which would model the implementation and produce a report of different issues in the implementation of the system.",0
1937604,5152,Dissecting calcium signalling pathways in basal land plants (MILLER_U17DTP1),"Plants need to respond to the environment in order to adapt and grow. Plants often modify the concentration of calcium ions in their cells in response to different environmental stimuli and stresses [1]. These changes in cellular calcium concentration trigger many downstream responses, including re-programming of gene expression. Calcium signalling pathways are therefore essential for plants to respond and adapt to environmental stimuli and stresses.
Higher plants such as the model plant Arabidopsis thaliana have extensive networks of proteins associated with calcium signalling pathways, and traditional genetic studies have identified mutants in components of these pathways. However, genetic redundancy is frequently observed and this has hindered further study of these signalling pathways. Recent genomic analyses have revealed that the gene families encoding components of calcium signalling pathways are considerably smaller in basal land plant species [2, 3]. The study of these pathways in basal land plants will therefore offer unique insights and understandings into calcium signalling pathways in higher plants, and may identify new potential targets that could be manipulated to improve stress tolerance in crop species.
This PhD project will undertake a multi-disciplinary approach combining plant genetics, molecular biology, bioinformatics and biochemistry to dissect calcium signalling pathways in basal land plants.

References:
1. Kudla, Batistic &amp; Hashimoto. Plant Cell 22:541-63 (2010)
2. Edel &amp; Kudla. Cell Calcium 57:231-46 (2015)
3. Hamel, Sheen &amp; S&eacute;guin. Trends Plant Sci 19: 79-89 (2014)",0
MR/P006493/1,13129,Recovery from vestibular dysfunction following Traumatic Brain Injury: A prospective behavioural and neuro-imaging study,"Traumatic Brain Injury (TBI) is the commonest cause of chronic disability in young adults. We found that 86% of acute TBI patients have problems with their balance. The problem of imbalance is important for this young working age group since previous studies have shown that following a mild TBI, at 6 months, 66% of TBI patients with balance problems will still be unemployed versus only 25% of those without balance dysfunction. A key step in treating TBI imbalance is to understand the underlying pathophysiology, however previous studies could not identify a clear-cut cause in 25% of TBI patients with chronic imbalance.

Our acute TBI data show that most patients have a type of imbalance that is typical for patients with a loss of function of the inner ear balance organ - the vestibular organ. When we tested acute TBI patients with normal inner ear function we still found the same type of vestibular gait impairment, implying that the problem lay with the brain's processing of the vestibular organ's signals. Whilst screening acute TBI patients we also observed that acute TBI patients appeared to lose the perception of vertigo (the sensation of bodily self-motion) despite overt vestibular activation (vestibular nystagmus, nausea and vomiting). This again implies a failure by the brain to adequately process the inner ear vestibular signals. Taken together, TBI impairs the brain processing of vestibular signals with a major impact upon balance function. But what is the mechanism underlying this impairment of vestibular processing?

Our previous work (Nigmatullina 2015) showed that vertigo perception is mediated by a cerebral cortical network. Congruent with this notion and using a test to quantify the vestibular perception of self-motion, we found that focal cortical damage from stroke did not affect vestibular perception of self-motion (Kaski 2015). In contrast, in our pilot data, we quantitatively show that acute TBI does indeed impair this vestibular perception of self-motion (which we call 'Vestibular Agnosia').

We thus hypothesise that TBI causes a disruption of a cerebral cortical network that processes vestibular signals important for perceiving our sense of bodily motion. We additionally hypothesise that impairment of this vestibular cortical network will also compromise balance, particularly in the dark, since excessive sway (normally indicated by vestibular signals of head motion) will not be detected, leading to falls.

Hence in our study we propose to:
(i) prospectively assess if our vestibular perceptual test (of vestibular agnosia) predicts functional outcome;
(ii) test our hypothesis that vestibular agnosia is a marker of brain network dysfunction; 
(iii) develop models linking pathophysiology and symptoms and hence enable us to explain why the persistence of symptoms post-TBI correlates poorly with TBI severity.

The output of this study will thus enable us to:
(i): predict which patients will be at risk of imbalance and falls post-TBI; 
(ii) objectively monitor the improvement in brain network dysfunction and hence provide an objective indicator of response to treatment;
(iii) provide a clinical framework to progress the research and treatment of TBI including sports concussion.",0
BB/P01898X/1,3346,PTBP proteins in T cell activation: Cellular and molecular mechanisms of action,"The adaptive immune system, which is comprised of cells called T- and B- lymphocytes, has evolved to provide protection against harmful microorganisms and parasites. These cells provide long-lasting memory of previous infections and harnessing their function is key for effective vaccination. T cells are not all the same and can divided into groups, or subsets, which have specialized functions. These include CD4+ T cells called T follicular helper cells (TFH) which help B cells make antibodies and CD8+ T cells that kill cells infected with viruses or other germs.

The importance of T cells has prompted many investigators to identify the genes that control their development, survival and function. One major class of genes that control T cell fate and function encode proteins that work at the level of gene transcription, the process by which genes are converted into messenger RNA. The importance of this layer of control is universally accepted and is exemplified by numerous studies using mouse genetics that identify the key genes involved. However, an additional layer of control is also important; this is called post-transcriptional regulation of gene expression and it can regulate how long messenger RNA sticks around for and the tempo at which the messenger RNA converts its message into protein.

When compared to transcriptional regulation, little is known about how post-transcriptional regulation controls the development and function of T cells. We have discovered that a class of genes encoding RNA binding proteins carry out important post-transcriptional roles in T cells. What is unknown is how they affect the biology of T cells. Our proposed research is based on unpublished data that identifies key RNA binding proteins (RBP) necessary for the proper development and function of T cells. 

To develop this research area we wish to understand, at the level of the whole organism, the redundant role of the RBPs in the function of T cells. We will study the phenotype of mutant mice using conditional gene targeting in T cells. These conditional systems will test for roles in development and maintenance of activated T cells. We will identify the directly bound targets of the RBP in both mouse T cells using assays of protein RNA interaction. We will investigate the mode of regulation of the targets.

The research is aimed at understanding a new mechanism that is necessary for T cell function and thus has implications for vaccine success and for autoimmunity-when T cells reacts against our own tissues. Importantly, we wish to understand how this novel mechanism interfaces with the mechanisms that we know most about -signaling and transcription.

This work is the key step towards elucidating a novel molecular mechanism of gene regulation in T cells. Appreciation of the importance and understanding the details of this mechanism has the potential to open up new possibilities for immunomodulation.",0
AH/P009654/1,17387,Enacting the Past: Stories from the Colony to the Tatras,"This project follows on from the work of the Heritage Legacies Project, the Bennachie Landscapes Project and work with All Our Stories community heritage projects across Scotland. It aims to widen the range of people engaged in learning about and contributing to the local heritage in north east Scotland, particularly those who have previously been excluded such as young Scottish Travellers and members of the Polish community. Returning to the site of the Colony settlement on the slopes of Bennachie, this project moves beyond a focus on material histories to include the performance and creation of stories, song and drama as ways of engaging with lived heritage.",0
NE/R011168/1,5531,The co-evolution of human hands and tool using behaviour,"When you talk to people about what makes humans different from other animals, one of the features that they will rapidly identify is the human hand. Indeed they are very likely to identify the 'opposable thumb' as a uniquely human characteristic. Whilst it can be argued that this is not strictly true, it is certainly the case that there are no other animals that have anything like the degree of precise control of their hands that humans have. We take for granted the fine movements of individual fingers that allow us to play the piano or tie our shoelaces, and these are activities that are impossible for non-humans to achieve. It is likely that the evolutionary history of our species is very closely linked to the evolutionary history of our hands and this is therefore an important area for scientific study. We currently know a great deal about how the shape of our hands has changed from those of closely related species but we actually know very little about how these shape changes are linked to how the hand functions. The story of our divergence from the common ancestor of chimpanzees and modern humans includes walking on our hindlimbs, the creation of stone tools, the increase in our intelligence, and living in extended social groups. The change in function of the human hand by losing its locomotor role and allowing its specialisation for manipulating and sensing the world, and extending its role in communication becomes a compelling narrative. In particular the idea that the evolution of our hands is closely linked to our adoption of increasingly sophisticated tools seems extremely plausible.

Thus the aim of this research project is to explore the changes in functional capabilities of the human hand and to use this information to evaluate the evolutionary history of the hand and its relationship to tool use and manufacture. To achieve this goal we need to collect information about how the individual parts of the hand are used in humans. This needs to be done in a controlled fashion so that we can make objective comparisons of the mechanical requirements of different actions that we can link to specific artifacts in the achaeological record. We therefore propose to collect movement and force information from humans whilst performing such a range of tasks. We will use a range of exciting new technologies developed for virtual reality and movie special effects where hand and finger movements can be recorded automatically using specially instrumented gloves and by attaching reflective markers to the fingers. In addition simply recording this information is insufficient to fully understand a mechanism as complex as a hand. We will also construct 3D computer simulations of these hand and arm movements using information from medical imaging and dissections. We will then use a variety of sophisticated mechanical engineering techniques to evaluate how the individual bones and muscles function within the hand. We also need to evaluate how human hand function has changed over time and this means that we need to investigate the hands of fossil primates as well as their living relatives. To do this we will create equivalent computer simulations for these extinct species reconstructed from the fossil bones. The computer models will allow us to predict the capabilities of these species and we will be able to directly evaluate the changes in locomotor, foraging and tool use capabilities of the hands of our closest ancestors over time.",0
EP/N025342/1,4283,Accurate blood pressure measurement,"The current clinical problem: raised arterial blood pressure (hypertension) is the third leading cause of death worldwide. Cardiovascular disease causes 17 million deaths per annum globally with complications arising from high blood pressure accounting for 9.4 million, split evenly between stroke and heart disease (World Health Organization, Global Status Report on non-communicable diseases 2014, &quot;Attaining the nine global non-communicable diseases targets; a shared responsibility&quot;). The WHO reported that 'Cardiovascular disease causes more than half of all deaths across the European Region'. The first important step in correctly diagnosing hypertension is in the accurate measurement of blood pressure (BP). This research project will result in an effective diagnostic device that will have the potential to displace all current devices on the market.

There is a worldwide need for accurate blood pressure measurement. The &quot;gold standard&quot; is the manual method, with an experienced clinician listening to the stethoscope Korotkoff sounds and viewing a cuff pressure scale. However, this is increasingly being underused because of the training needed and the time required for the measurement in busy clinics, and is almost never used for self measurement at home. The current undesirable move to replace manual by automated devices (they all unfortunately use the oscillometric technique) can result in radically different measurements on the same patient for different devices. Inaccurate measurement is such a problem that the UK Department of Health has had to issue several Warning Notices about current automated devices.

The aim of our research is to develop a novel technique for accurately and automatically measuring blood pressure. Our previous EPSRC research made observations that are now the basis of this proposed research, and were sufficiently novel to enable a patent application.

Working with our Industrial Partner will enable this research development to be taken to a marketable product available for hospital or home use.

The ultimate benefit will be for patients and clinicians who will be able to diagnose high blood pressure and monitor treatment more effectively than now. Since the technology is a radically new departure it will open up avenues for academic research in engineering and clinical medicine.",0
105034,34819,Use of bioimpedance and machine learning to predict transplant organ viability,"This project addresses a critical health problem of global significance - the shortage of organs for transplantation. For the better part of four decades, human organ supply has not kept pace with demand.

Currently only a small fraction of organs are retrieved from donation after circulatory death (DCD) even though this is the most common type of death. It is quoted that more than 60% of the hearts and lungs must be discarded annually.

New technologies are desperately required to expand the much needed pool of transplant organs.

We have identified a technology solution to assess and validate a patient's tissue (organ) viability and integrity.

Our approach is disruptive and will:

(1) afford quality organ harvesting;

(2) expand the pool of 'much-needed' organs among donation from circulatory death;

(3) reduce organ discard;

(4) reduce financial impact upon healthcare systems;

(5) enhance outcomes for recipient patients; and

(6) facilitate research in an area that can save tens of thousands of lives annually.",0
AH/P00606X/1,26791,Development Assistance and independent journalism in Africa and Latin America: A cross-national and multidisciplinary research network. (HN),"This project proposes an international and inter-disciplinary research network to explore the relationship between international development aid and local journalistic practice and training in Africa and Latin America. The network will allow researchers to examine the global power relations and geo-politics of foreign aid that since the end of the Second World War was substantially directed at disseminating a specific model of journalism practice and education aligned with the interests of donor nations. It will consider the extent to which the diffusion of a US/UK based model of journalism practice has been central to the 'modernisation' project in international development. This network project is linked to journalism practice, journalism education, and critical journalism studies in the context of the impact that foreign aid/development assistance has had in these regions and how this has affected the ability of these developing regions to foster a critical and independent media sector.
Given massive contemporary change in the global news media landscape, especially in regard to journalistic practice and the limited potential for genuinely independent 'watchdog' journalism, researchers and practitioners need to critically re-assess the relationship between external influences on journalism and local cultures and practices of journalism. This contribution to a deliberative assessment of the nature of public discourse in developing regions has the potential to open the public sphere to a greater variety of voices and aid the project of democratization. 
In this context, the critical scholarly approaches more commonly associated with arts and humanities research than with the more typically social scientific approaches to the analysis of journalism are particularly valuable. We propose to bring together a network of researchers who can provide critique grounded in critical political economy and postcolonial studies approaches to the historical and present contribution to the local journalism sector of international development aid in Latin America and Africa. The network will foster discussion and research concerning the use of international development aid and, broadly, structures of post-colonial dependency (Easterly 2006), to promote or inhibit specific models of journalism. 
We start from the assumption that the dissemination of the US/UK paradigm of journalism was central to international aid efforts since the late 1940s and has become the default model that aid programmes tend to foster and support. Such models have been problematized by the geo-politics of the Cold War and more recently by corporative agendas. Moreover, these models have not come into existence without their own contradictions, given the support that the US and other Western countries gave to dictatorships in developing countries in the context of Cold War efforts to contain the advance of the Soviet Union (this is particularly true of Latin America and Africa, the continental foci of this network). A further interest, therefore, is the question of how the end of the US-USSR confrontation re-shaped (or not) foreign aid towards journalism modernisation, diversification, and independence. 
Our network will initially link UK academic researchers with prominent journalism researchers and educators in two African countries and two South America countries, each of which receive UK Official Development Assistance. Each of these countries has diverse and vibrant media and civil society sectors with which our academic participants are well connected. These countries are Ghana, South Africa, Brazil, and Venezuela, but our participants are also leading experts on journalism in the broader regions around their countries and well placed to extend the network in their regions.",0
133420,2291,Algorithm Development for Respiratory Diagnostic Device,"This feasibility study project is to develop and evaluate concepts for software-based methods that improve respiratory diagnostic devices. Improvements are expected to the overall cost, usability, and access for the device. With a software-driven approach, personalised medicine approaches to diseases like asthma and COPD become possible. By helping to personalise treatment decisions, quality of life, patient outcomes, and overall costs to the health system will be improved.",0
2317339,37403,Improving Efficiency and Equity of Ambulance Services through Advanced Demand Modelling,"Demand for Ambulance Services in England has risen
dramatically over recent years, with growing pressure
anticipated for future years. The disparity between the
increasing demand and limited ambulance resources makes
the major challenge for maintaining a high-quality service. In
2017, NHS England undertook a significant national reform
called the Ambulance Response Programme (ARP), designed
to address efficiency and performance issues. It noted the
over-use of immediate dispatch decisions and the insufficient
allocation of resources to incidents. Key issues concerned:
the quality of care; its cost-effectiveness; and the equality of
provision across areas and population groups. Given such
situation, from 2017 to 2018, King's researchers have
worked with the London Ambulance Service (LAS) on an
ESRC-funded project - DASH, exploring how big data could
improve decision-making in ambulance response. The final
report suggested six new data initiatives, out of which, three
are strongly related to demand prediction.
In view of the growing pressures of NHS, and the necessity of
ambulance services to understand the needs of the
populations they serve, the proposed PhD project aims to
develop an advanced demand prediction model for
ambulance services taking LAS as a case study. The
research is to find the most correlated socioeconomic,
environmental, and spatiotemporal factors and to model
these factors as predictors of ambulance demand. The final
component of the PhD will develop the implications of the
model as Demand Management innovations, for future
testing.",0
753296,1040,An Advantage for Law Firms,"&quot;Clear gap in the market: develop a practice management software that can be easily tailored by the client. What is currently on the market does not offer much functionality, as providers have gone with 窶・et窶・systems.
The system we have identified to form the base does not currently meet the needs of the sector but provides a strong foundation. We are a firm operating in our target market, working with an IT expert to tailor this system to meet the needs of the sector without losing the 窶話espoke窶・aspect, we can develop a unique proposition in the marketplace with features
including:
<U+2022> Easily modifiable workflows
<U+2022> Data protection features &amp; secure document exchange
<U+2022> Client management
<U+2022> Accounting capabilities and prevention of fraud &amp; money laundering
<U+2022> Regulatory compliance runs throughout the system
The IT experts understand how the system works and we understand the market. Combined we make an enviable team &amp; have the knowledge to make this software package a great success.&quot;",0
1930689,30092,Optimal Railway Network Maintenance,"The UK railway comprises of 20,000 miles of track and over 40,000 bridges. Much of the infrastructure is aging and, in order to satisfy the future demand for passenger and freight transport, will experience increased traffic densities and loads. The maintenance of such systems, to ensure a safe and reliable service restricted by limited financial resources, is a significant challenge and needs to be carefully managed. Computer models are used to relate the future state of any asset (track, structures, signalling, electrification, communications etc) to the whole life costs when any maintenance strategy is adopted. To make best use of the financial resources available to maintain the railway network, decisions need to be made on a whole life, whole system basis. The assets feature dependencies between them such as common budgets, common possession time, common inspections and the ability to take advantage of opportunities where the condition of one asset provides the chance to carry out work on another. This produces large scales models and the objective of this project is to develop an optimisation framework to select the best maintenance and renewal strategies across the extensive asset base.
Through our Strategic Partnership with Network Rail, this project aims to develop an optimisation software to support the decision making to set the 'best' asset maintenance strategy.",0
1959126,7962,SSA: Investigating a role for the gut microbiota in stress axis dysfunction and anxiety behaviour in prenatally stressed rats,"Importance of the early life environment: The development and neuronal organisation of the fetal/neonatal brain is significantly influenced by the physiological status of the mother and the early environment1. Maternal stress exposure during pregnancy detrimentally 'programmes' the offspring's brain resulting in profound alterations in physiology and behaviour in later life. Using a social stress paradigm in rats we have shown that the principal neuroendocrine stress system, the hypothalamo-pituitary-adrenal (HPA) axis, is particularly sensitive to prenatal stress exposure: the adult offspring of stressed dams display markedly greater stress responses1. HPA axis dysfunction is involved in the neurobiology of a range of mood disorders, including anxiety and depression. Indeed, adult prenatally stressed offspring also exhibit heightened anxiety-like behaviour1. These changes in stress responsivity and anxiety-like behaviour have been linked with changes in the central expression of stress-related genes, however what mediates these changes in the offspring's brain is not known.
The gut microbiota influences stress responses and stress influences the gut microbiota: Bidirectional communication between the brain and the gut is well established; however recent studies have highlighted the importance of the gut microbiota in influencing stress responses and related behaviours2. For example, germ free mice (with no commensal microbiota) display reduced anxiety-like behaviour compared with conventionally-reared mice and this behaviour can be reversed by colonization of the gut with microbiota from control mice2. Similarly mice treated with probiotics display reduced anxiety-like behaviour and lower corticosterone responses to stress2. In contrast treatment of mice with subclinical doses of pathogenic bacteria results in increased anxiety-like behaviour and activation of the HPA axis2. Changes in anxiety behaviour and stress responsiveness induced by manipulating the gut microbiota are associated with altered expression of GABA receptors in the brain3. This is important given dysfunctional GABA signalling has been linked to anxiety and depression and the GABAA receptor is a target for some anxiolytic drugs. Importantly, stress also influences the composition of the gut microbiota e.g. repeated social stress exposure disrupts commensal microbial populations in adult mice. Moreover early life stress (via post-natal maternal separation) in rats results in increased stress reactivity and anxiety-like behaviour and is associated with long-term changes in the composition and diversity of the gut microbiota2. 
Commensal microbiota colonise the mammalian gut in early postnatal life, shortly after birth. The predominant source of microbes for the initial colonisation of the gut are the maternal microbiota. Studies using germ free mice have clearly demonstrated that the gut microbiota in early life is critical for the normal development of the HPA axis and appropriate stress responses in later life. Given that stress affects the gut microbiota, it is reasonable to hypothesise that social stress exposure during late pregnancy may alter the maternal microbiota and subsequently influence the composition/diversity of the gut microbiota of her offspring. Whether this may influence stress responsiveness and behaviour in the offspring is not known.
Project Aims: The overarching aim of this project is to establish whether alterations in the gut microbiota contributes to HPA axis dysfunction and anxiety-like behaviour in prenatally stressed (PNS) rats, whether there are any sex differences in the contribution of the gut microbiota and whether the adverse phenotypes in PNS rats can be reversed by manipulating the gut microbiota.",0
UKDRI-5009,36632,Reversing aggregates in neurodegeneration with the ubiquitin-proteasome system,"Balance is key to a healthy life. Cells balance synthesis of new proteins with removal of proteins whose functions are no longer required. Brain cells sometimes behave abnormally when obsolete proteins assemble together and disrupt normal biological functions. Such harmful agents formed from aggregated proteins have been implicated in neurodegeneration and dementia. While much research effort has focused on how these agents form, the reverse process of their removal is not well-understood. 窶榔roteasomes窶・are molecular machines responsible for removing proteins in cells, and their malfunction has been linked to both Alzheimer窶冱 and Parkinson窶冱 disease progression. In addition, many key components that crucially regulate the healthy state of the cells are also recycled by the proteasome. 

Our lab uses innovative techniques to understand how toxic agents are recycled at different neurodegenerative stages. We combine microscopy and biological approaches to look at how toxic agents are cleared inside patient-derived cells, and characterise the molecular mechanisms when the clearing functions are compromised in disease. We will also explore whether other aspects that perturb normal proteasome functions may have directly contributed to the progression of neurodegeneration. Ultimately, our research seeks to identify therapeutic points of intervention to reverse the processes that enable neurodegeneration to advance into the various stages of disease.",0
2266694,43431,Nanoscale bioelectronics for point-of-care diagnostics and wearable devices,"The uncovering of biomarkers holds great potential in the early detection of disease and physiological dysfunction, and miniaturized/portable sensing apparatuses can allow for continuous functionality in diagnostic or treatment. Low-cost processability and multipurpose analysis capability are among the most sought-out features that a device would need to possess to tackle the global Biosensor market. This project will combine expertise in conducting polymer synthesis with nanoscale device assembly and fabrication, to develop novel bioelectronic platforms for point-of-care diagnostics and wearable applications. It will build upon initial work on designing semiconducting polymers for bioelectronic applications and the fabrication of multiplexed sensing devices. As a proof of concept, the project will demonstrate real-time monitoring of multiple biomarkers on the same chip.",0
1722976,4322,Development of novel biocatalytic processes for the manufacturing of food flavours and fragrances.,"Foods and beverages contain, generally in trace amounts, a number of different volatile organic compounds (VOCs) possessing strong and powerful odours and contributing to both agreeable and disagreeable flavours and fragrances. Among VOCs, the volatile sulphur compounds (VSCs) contribute to the flavours of bread, wine, cheddar cheese, chocolate and tropical fruit. From a chemical point of view, VSCs can exist as chiral isomers and their olfactory perception may depend on their enantiomeric form. For example the (R)-enantiomer of 3-thio-1-hexanol has a tropical fruit aroma, while its (S)-enantiomer has a sulphurous and herbaceous smell. 

However, the chemical synthesis of chiral VSCs proves to be a challenge, and few synthetic approaches have been developed so far, with most requiring the use of polluting or expensive metal catalysts or rely on multi-step protection-deprotection sequences. It follows that a preeminent interest of food industries is the identification of new, sustainable and environmentally friendly approaches for the production of chiral VSCs.

This project aims to develop a sustainable biocatalytic approach aimed at the manufacturing of new VSCs as flavours and fragrances for foods in high enantiomeric excess through novel enzymatic methods that are more sustainable and efficient than the existing ones. Chiral sulphur compounds will be produced in the laboratory and biotransformed into the corresponding VSC with a range of enzymes. These biocatalysts will be further optimised in collaboration with the industrial partner, Prozomix Limited; a biotechnology company based in Northumberland with considerable experience in this area and existing diverse enzyme panels for immediate screening towards lead catalyst identification.

The olfactory properties of chiral VSCs will be explored by making use of existing contacts within food and flavour companies, such as Frutarom and Firmenich, and also by forging new relationships in this sector.",0
1783559,12495,Interaction of pore-forming toxins with cell plasma membrane: a biophysical approach,"Entamoeba histolytica is a protozoan parasite responsible for an estimated 100 000 deaths annually and is a major health problem in the developing countries. This parasite has strong cytolytic activity, which has been related to a class of pore-forming toxins, amoebapores, produced by this organism. Amoebapores (and more generally, pore-forming toxins) are capable of perforating the plasma membrane of target cells, thereby killing them. Although the cytotoxicity of amoebapores has been studied previously, there is little understanding of the biophysical processes associated with toxicity and the role of the lipid membrane physical properties. In the past few years, we have developed novel experimental methodologies to investigate the biophysics behind toxin activity, focusing on Clostridium perfringens a-toxin and the pore-forming toxins NetB and Pneumolysin. This project will investigate, using in vitro model systems, the biophysical factors determining cytolytic activity of amoebapores. Initially, we shall seek to establish the main lipid species responsible for recruitment of the toxin to the lipid membrane and its activation, using model membrane systems (Langmuir monolayers of lipids and bilayer lipid vesicles), as well as the effect of the toxin on the lipid organisation in the membranes. Then, we shall investigate the effect of biochemical and biophysical properties of the plasma membrane on the susceptibility of human red blood cells to amoebapores. The properties to be studied will be membrane elasticity, electrical properties and morphology, which are likely determinants of toxin activity. We will also modify the biochemical status of the membrane using oxidative stress, lipid scrambling and cell ageing in order to determine the role of cell surface biochemistry in modifying cell responses to toxins. There are some minor amino acid changes between amoebapores from Entamoeba species with different levels of virulence attributed to these differences but a mechanism explaining these differences in virulence is lacking. We shall study these amoebapores from different Entamoeba species using the above techniques as we expect these differences to affect membrane solubility. These studies will identify the factors responsible for cell lysis under the action of the toxin and likely suggest novel ways of increasing cell resistance to amoebapores.",0
2120298,33191,The People's Friend? Recovering Scottish Popular Magazine Culture,"This PhD project explores the rich and little-known archive of Scottish popular magazines, centred on the period between the founding of the People's Friend (1869) and WWII. Investigating how these magazines constructed a specifically Scottish sense of identity and culture, this PhD thesis will show their lasting influence and significance within wider British and international publishing contexts. Through this partnership, the student will also receive training in digitization practices, theories and techniques, and act as an adviser on the selection and implementation of digitization projects in relation to Scottish magazines. Besides reconsidering a vital aspect of Scotland's literary heritage, the PhD will also include a reflective final chapter on questions of 'recovery' and digitization, considering how this archive connects to reading communities today.",0
ST/T505894/1,40895,RAL Studentship on G3 Dark Matter at Imperial,"Doctoral Training Partnerships: a range of postgraduate training is funded by the Research Councils. For information on current funding routes, see the common terminology at www.rcuk.ac.uk/StudentshipTerminology. Training grants may be to one organisation or to a consortia of research organisations. This portal will show the lead organisation only.",0
ES/M006107/1,5794,Growing up on the Streets: building networks of knowledge exchange for delivering impact,"Street children are perhaps one of the most visible signs of poverty and marginalization in urban environments, yet their rights are often not realized. Furthermore, street children lack formal representation placing them outside the arena of policy development. Not only do they face multi-faceted problems but as a group they are difficult to define. This is both in terms of their relationship to the street and their status as both victims and perpetrators of crime; their complexity is key to their elusiveness. In addition, street children's independent status positions them outside the realms of child protection which places children under the care of adults, often resulting in limited or no access to services without adult representation. Therefore they have been replaced on the international policy agenda by other vulnerable groups whose human rights violations are much more easily pinned down, such as victims of sexual exploitation or violence, raising fundamental questions around how street children's rights and needs are defined and by whom? However, participatory research is now becoming recognized as one of the more successful ways in which children's voices are beginning to be heard and this can be utilised to offer advice for the inclusion of street children in decision-making and policy development.
The aim of this project is therefore to address the policy gap for street children through research knowledge exchange (KE). An academic-practitioner collaborative research project called Growing up on the Streets was established in 2012 collecting longitudinal data over a three year period with 198 street children from three diverse African cities: Harare, Zimbabwe; Accra, Ghana; and Bukavu, DRC. In addition an innovative participatory approach has been adopted whereby street children are actively engaged in undertaking their own research, under the mentorship of street worker project managers, to explore their capabilities on the streets. The findings from the research forms the evidence-base for this KE project which seeks to bridge the gap between current legislation and political attitudes, and street children's realities. The KE project has seven objectives fulfilled over four phases. Phase 1 develops street young people's participation in the research process from inception to policy development. This aims to include street children's views as a regular part of service provision. Phase 2 develops practitioner participation and capacity through the development of workshops that disseminate key messages from the research as well as through establishing a peer network, initially across Africa, for practitioners to discuss and share through an online forum. This network aims to develop capacity and share best practice for the better provision of services to street children. Phase 3 builds on the others for specifically targeting the policy gap. A series of workshops/events in Africa and the UK, inviting Government agencies, UN members and other key stakeholders aims to raise awareness of the research findings, develop policy recommendations and seek to translate them into concrete actions. Public engagement also forms a key strategy for raising awareness for street children's rights. Finally phase 4 includes a process of reflective evaluation during all other phases to ensure their effectiveness. 
The outcomes of the project seek to offer direct benefit: to street children, by involving them in data analysis and policy dialogue as well as creating NGO training for street children's inclusion in the research process from inception to policy development; to NGOs, by developing a network hub and face-to-face workshops for sharing best practice; and to policy stakeholders (Governments, Donors, International NGOs, UN agencies) through the translation of key messages from the research into policy recommendations with the potential to advocate for direct changes to national and international policy.",0
2253943,39721,Night Vision: Intersubjective possibilities in Dark Sky areas in the UK,"The global movement to protect dark skies from light pollution has grown rapidly in scale and reach in recent years, with the establishment of the Campaign for Dark Skies in 1990, leading to the accreditation of several 'Dark Sky Parks' around the UK. However, the movement's emphasis on preserving night sky visibility tends to reinforce the idea that dark landscapes themselves are landscapes of nothingness, merely 'viewing rooms' for the universal spectacle of the stars, a void in which individual bodies dissolve. 

When this assumption is extended to entire landscapes, it translates - literally - to black-box thinking, whereby structures and arrangements within darkened landscapes become unexaminable. This is problematic on a number of levels. It reinforces the hegemony of the 'objective' and self-effacing 'modest witness' of science, a largely white European male figure (Haraway, 1996). It perpetuates a persistent enlightenment-era association between light(ness), knowledge and goodness, which was used to justify the colonial project of 'bringing light to darkness'. And the conception of dark landscapes as 'blank space' dangerously resembles the seizure of land and violent attempted erasure of First Nations peoples under colonialism. Adding to a growing body of research that draws connections between colonialism, the enlightenment and environmental breakdown, this study will move towards a post-colonial understanding of Dark Sky Parks which also makes room for non-human viewpoints. After all, over half of all species are nocturnal. 

Currently, Dark Sky Park tourism that does engage with the dark ground (as well as the illuminated sky) may bear traces of prevailing colonialist and militaristic desires. Humans cannot 'see in the dark' without being dependent on night vision technologies, many of which which were developed in military contexts within which their purpose was to detect an invisible, dangerous and de-humanized 'other'. In fact, amateur night vision equipment is often marketed online as a means of hunting down UFOs or paranormal activity. How might nocturnal species, other bodies and impressions of movement, glimpsed at night in Dark Sky parks through the medium of these technologies, take on the perceived danger and otherness of the alien, paranormal or targeted enemy? And how might we develop new forms of night vision that overcome this militarization of vision, allowing viewers to observe their own participation in complex networks of humans, non-humans and devices? 

With Dark Sky parks at an important junction as they expand in number, this practice-based research project would be crucial in outlining forms of visual practice that recognize 'seeing' as an active exchange of viewpoints: a collaborative process involving technologies, humans and animals. It would consider certain instances of night vision to be examples of what Despret terms 'intersubjectivity': achievements at the intersection of human and non-human capabilities. According to Despret, capabilities are not innate, but can be extended and exchanged when they come into contact with one another. I will expand Despret's definition to include devices, experimenting with a range of recording technologies that interact in interesting ways with the subjectivities of humans and animals. Despret argues that uncertainty is an important prerequisite of intersubjective achievements, as it allows the goal of the interaction to be continuously renegotiated. Drawing insights from the practical challenge of recording encounters in darkness, I would explore the extent to which Dark Sky parks force human subjects out of the illusion of total clarity, and into terrain where understandings are murky, uncertain, and intersubjective.",0
105039,46413,RElease of Stains at Ultra Low Temperatures (RESULT),"&quot;The aim of this project is to develop non-fluorocarbon textile finishes which prevent oil and water-based staining and reduce the average laundry washing temperature required to remove grease and dirt from soiled clothing without encouraging the growth of bacterial odour.

The project brings together a multinational UK based, research focussed, global leader in sustainable chemicals, a large innovative UK based producer of textiles, one innovative SMEs and a leading UK university with a reputation for excellence in textile technology.&quot;",0
ST/P000584/1,4066,Astronomy at the Open University 2017-2020,"Our research programme, Astronomy at the Open University, covers the breadth of cosmic evolution, from dark energy to the birth of planets. We do this research by observation, laboratory experiments, simulations and modelling. We use purpose-designed laboratories and instruments, and instruments on telescopes and spacecraft to make our observations and measurements. Our group is based in the Department of Physical Sciences at the OU.

So what are we trying to find out? We have 8 separate projects, from exoplanets and stars to distant galaxies. We already know a lot about how the Solar System came about. The Sun and planets formed from a cloud of dust and gas about 4570 million years ago. The cloud collapsed to a spinning disk and dust and gas spiralled inwards. The core of the disk became hot, forming the Sun, while the leftover dust and gas formed the planets. Boulders gravitated together to make planets, but no-one knows how the dust grains became boulders. We are experimenting with colliding centimetre-sized particles in zero-gravity conditions to see if they stick together, to find the missing link in how planets form. We also look at processes that cause stars to change as they age. Only recently has it been recognised that so many stars are binary systems, where two or more stars are in close association and affect each others' motion. Such systems affect the way mass and energy is lost from a star, and how they are transferred into the interstellar medium. We will study how 'binarity' affects the behaviour of massive stars (&gt;20 times the mass of the Sun) and low mass stars (&lt; the mass of the Sun), and how star populations change as they age. Studying these effects is vital, because the environment of a star influences any planets that surround it. Many hundreds of planets have been discovered around other stars (exoplanets) and we are working to describe the range of properties of these planets, especially when they are located close to their central star. A star can even completely destroy a close-in exoplanet, which could be an important new source of dust in the nearby universe and even in distant galaxies in the early Universe. Also in the early Universe, we can use the way that galaxies warp space and time to learn about the dark matter that surrounds them, and the dark energy that drives them apart.

What else do we do? We build and test instruments for ground-based telescopes and for space missions, striving to make them smaller and lighter, and explore how they can be used on Earth for medical or security purposes. One of the most important benefits of our research is that it helps to train and inspire students: the next generation of scientists and engineers. We also enjoy telling as many people as possible about our work, and what we have learned from it about our origins.",0
1792166,5165,Use of 3D rendering and haptic robotics for improved delineation of cancerous tumours in medical imaging data,"The ability to efficiently render 3D information is critical to numerous applied applications, including remote telepresence, medical diagnosis, scientific visualisation, and industrial manufacturing. Despite this, people's ability to interact efficiently and explore such data has been greatly outpaced by the ease with which it can be captured. The primary problem is that, typically rich 3D data is explored in 2D using technology that was never designed for this purpose, i.e. a 2D computer screen and mouse. Visualising data in this way makes it difficult to perform tasks that people would find trivial in real life. Rendering in a single sensory modality (vision) also dramatically limits the amount of information which can be examined concurrently. A key example of this is in tumour delineation where clinicians have to identify the 3D volumetric boundary between cancerous and non-cancerous tissue from 3D scanning data (e.g. CT/PET/MRI), but do so by delineating visually in multiple flat 2D image slices. Delineation of cancer volumes is characterised by large inter-clinician variability and reducing this variability is seen as key to improving clinical outcomes (Steenbakkers et al. 2005, 2006). This studentship project will investigate how 3D rendering and haptic robotics can be used to detect and delineate the boundaries of imbedded objects with specific focus on improving tumour detection and the precision and accuracy of tumour delineation in medical imaging data.

Rendering imaging data in 3D has the benefit that users can interactively examine and explore the 3D volumetric imaging data in its true form, rather than indirectly via 2D slices explored on a flat monitor screen using a keyboard and mouse. In addition to this, multi-modal rendering has a number unique of benefits. First, humans are able to make much more precise estimates of the size and shape of objects when provided with multi-modal sensory information (Ernst and Banks 2002). Second, delineation is improved when data from multiple scanning techniques such as CT and PET is available (Steenbakkers et al. 2006). Currently, this relies on superimposing information from multiple techniques in the same modality (vision), resulting in the potential of each scan to obscure the other, or by comparing scanning data from different techniques across numerous imaging windows. Rendering different scans in different modalities offers a way to avoid both of these problems, whilst maintaining the benefits.

Consequently, 3D visual-haptic rendering has a number of unique benefits over traditional techniques, both in terms of decreasing perceptual variability, as well as concurrently examining complementary types of data more efficiently. This offers the potential to reduce inter-clinician variability and improve clinical outcomes. To assess this, we will compare visual-haptic rendering and traditional techniques in terms of (1) detecting and (2) accurately and precisely delineating the boundaries of (a) tumours and anatomical structures in scans from clinical patients and healthy individuals, and (b) simulations of objects that are embedded in a surrounding volume to mimic a tumour. Variability is a key evaluation criteria used in a clinical setting and is one of the key areas for improvement in tumour delineation (Steenbakkers et al. 2005, 2006), however, accuracy can only be estimated indirectly through clinical outcomes. In this project, by using simulated scenes with an objective ground truth, in addition to real scans, we will be able to measure precision and accuracy of delineation, providing an enhanced way in which to evaluate performance.",0
2016566,1363,Optimisation of mass spectrometry methodologies for continuous sampling of intra- and extracellular metabolomes from synthetic biology fermentations,"Studentship strategic priority area: Bioenergy and Industrial Biotechnology
Keywords: Metabolomics, Industrial Biotechnology, Big Data, Machine Learning, Fermentation

Abstract:
Lack of real-time process monitoring is a significant problem for the optimisation of fermentation used in synthetic biology-driven processes to produce high value compounds (e.g. plastic monomers, drugs and biologics) at industrial scale. Fermentation is complex with many extracellular and intracellular variables requiring optimisation for effective microbial growth/productivity. Stochastic effects resulting from cellular processes, if left untreated, can mean the difference between high product yields and bioprocess failure. Today, the monitoring of such impactful variables is, for the most part, done off-line with the potential for significant delay before an issue to be recognised and addressed. Real-time bioprocess monitoring could address this problem either by identifying markers of poor production (e.g. short chain fatty acids in anaerobic digesters) and/or allowing remediation of failing fermentations (e.g. by nutrient supplementation).

We believe that the application of high resolution mass spectrometry (MS) to the real-time monitoring of fermentation process conditions represents a significant technical improvement on current state-of-the art, and addresses key strategic priorities of the BBSRC: industrial biotechnology, synthetic biology and systems approaches to the biosciences. Furthermore, it would be of substantial benefit to Ingenza in helping enable their commercial customers realise their production costs targets for high value/low cost biobased chemical alternatives to today's petroleum derived products.

IBIOIC recently funded the RTMet project to optimise a TRL3/TRL4 system housed at Glasgow Polyomics for the real-time, high-resolution analysis of the medium from synthetic biology fermentations of succinate producing bacteria. The ambitious second part of the project is to prototype a system to lyse the cells themselves, so a profile of both intra- and extracellular metabolites can be obtained. This will allow greater potential for strain optimisation as key molecules may not be transported outside the cell. 

Additionally, data analysis for this project will be highly challenging. As a key component of the project, the student will develop an analytical pipeline capable to collating the hundreds to thousands of datapoints generated. This will be deployed as an interactive website, where the results of a fermentation run can be displayed in real time, highlighting metabolites that are changing in intensity through a run.

The key skills that the student will obtain during the project are advanced fermentation and microbiology skills to support the demanding fermentation components of the project; chromatography and mass spectrometry skills to enable effective data collection and optimise conditions to obtain the appropriate metabolites and software engineering skills to support effective data analysis. These will be supported by the IBIOIC PDRA, Dr Jeni Haggarty, an expert in biological mass spectrometry and microbiology and Dr Ronan Daly, project co-supervisor, an expert in machine learning and software engineering. In addition, the student will attend external training courses in entrepreneurship and business skills via IBIOIC, as well as metabolomics courses.",0
1802042,28484,Dislocation based modelling of engineering alloys,"The plastic deformation of metals and alloys is generally governed by the generation and motion of dislocations through the crystal lattice. Microstructural features such as grain boundaries, precipitates and inclusions impede the dislocation motion causing strengthening but often limiting ductility. Dislocations often accumulate in the vicinity of these microstructural features and their mutual interactions and reactions lead to further increased hardening and local hot spots in stress than can in turn lead to failure initiation. Understanding the behaviour of the dislocation ensemble is complex due to the many body interactions that take place. This project will continue development of discrete dislocation plasticity simulations with the particular aim of extending present capabilities from simple single phase, single crystal models to more complex geometries incorporating the grain boundaries and precipitates that are more representative of real engineering alloys. 
 
The project will involve assisting in the development of a 3D discrete dislocation plasticity code. This will require learning Matlab, C and CUDA for acceleration of the computation using parallelisation on graphics processing units. The student will also learn the finite element method (FEM), discrete dislocation dynamics (DDD) and how to couple these together so that FEM captures external boundary conditions while DDD captures the shorter range dislocation-dislocation interactions responsible for the material hardening. Training will be provided to the student in these areas although self-study will also be required. The main tasks are as follows:

1) Accelerating the code through parallelisation on graphics processing units 
2) Performing comparisons with available analytic results for simple well-defined sample and dislocation line geometries to check for errors
3) Debugging and development of the code to accurately simulate micromechanical testing
4) Simulating micro-cantilever single crystal bend tests and comparing the model prediction with measured load-displacement curves, the predicted elastic strain fields and lattice rotation fields with high resolution electron backscatter diffraction (HR-EBSD) measurements and the predicted dislocation structure with diffraction contrast observations in the transmission electron microscope (TEM), including 3D dislocation tomography results if available. 
5) Incorporating complex microstructure such as precipitates or grain boundaries. We will begin with simple building block configurations of single planar impenetrable grain boundaries in bi-crystals, tri-crystal geometries to investigate triple junctions, and quadruple points at the junction of four grains before moving on to larger groups of grains. We will also consider isolated precipitates and groups of precipitates incorporating them in different ways: as impenetrable to dislocations, as elastically different but penetrable, and with an initial misfit strain to the matrix lattice. This will require an elegant approach to incorporate the geometry. Different possibilities will be investigated such as the level set method. This will also require dislocation remeshing algorithm will also need to be developed to account for dislocations interacting with the geometry.

This project falls into the Engineering theme",0
1972728,31277,Applications of Large Cardinals to Constructive Set Theory,"The main aim of this project is to study the structure of the mathematical universe under variants of the standard axioms of ZFC (Zermelo-Fraenkel set theory with choice). In particular, how different the universe behaves under ZF on the one hand and the intuitionistic set theories IZF (Intuitionistic Zermelo-Fraenkel set theory) and CZF (Constructive Zermelo-Fraenkel set theory) on the other hand. In order to do this, the work will be split into two parts. The first is to explore the nature of large cardinal axioms in the classical setting without choice and how much the equivalences between certain definitions of large cardinals in ZFC break down when choice is dropped. The second, which concerns intuitionistic theories, will involve studying the notion of large sets. These are sets with properties analogous to the initial segment of the von Neumann hierarchy up to a large cardinal.
One of the many problems one encounters when working in a theory without choice is the difficulty in producing models of these theory. For example, assuming that there is a model of ZFC, the Lowenheim-Skolem Theorem gives a model of any cardinality. However it is known that that the statement ``Every infinite model in a language of cardinality K has an elementary submodel of cardinality K&quot; is equivalent to choice of length K. Therefore, when working with weak choice or no choice at all, it can be difficult to produce ``small&quot; models. Another result where we don't know whether choice is needed or not is the proof that in ZFC there is no non-trivial elementary embedding of the universe into itself.
Large sets in the intuitionistic context were first formally introduced in 1984 in a paper by H. Friedman and A. Scedrov. The purpose of this paper was to introduce the notions of inaccessible sets, Mahlo sets and sets that were the critical point of an elementary embedding of the universe into some transitive class model $M$ of IZF. The authors then go on to show that IZF plus the existence of some large set is equiconsistent to its classical counterpart. A more substantial study of large cardinals has been undertaken by P. Aczel and M. Rathjen and is contained within their draft of a book on Constructive Set Theory. This work is introduces the idea of a regular set which is an integral part of the definition of an inaccessible set. While both intuitionistic theories, inaccessible sets in CZF and fundamentally different from those in IZF. This is because, while in IZF the authors just wanted sets that were models of IZF (so were in fact closer to the definition of wordly cardinals), within CZF the authors wanted a set that had precisely those properties of in the classical case for inaccessible cardinals. The constructive formulation also allows for a second definition of what it means for a set to be inaccessible, giving a simple criterion of properties that the set must satisfy rather than solely asserting that the set satisfies every axiom of the theory.
The most in depth discussion of large sets in a constructive setting is given in Albert Ziegler's thesis, ``Sets in Constructive Set Theory&quot;. This work gives a rigorous formulation of constructive variants of many of the lower axioms in the large cardinal hierarchy. This culminates in an extensive review of two important aspects of the study of large sets; realisability and elementary embeddings. In particular, the results from this thesis show how differently large sets behave from their classical counterparts. Also, unlike in the classical case, the assumption that there are more large sets satisfying some property does not necessarily increasing the consistency strength of the theory. E.g., if it is consistent that there is one inaccessible then it is consistent that there are a proper class of them. Some of the many questions which will occupy the research for the thesisover the coming years are:
1. How do large cardinals differ without choice. E.g. what happens to the many equivalent formu",0
BB/N012496/1,22094,Development and Commercialisation of a Second Generation Rapid Diagnostic Test (RDT) for Human African Trypanosomiasis (HAT) and other Kinetoplastida,"The overall aim of this research is to complete the further development and commercialisation of new tests for the detection and diagnosis of the parasite Human African Trypanosomiasis (HAT or sleeping sickness), building upon and completing previously funded BBSRC applications. HAT threatens 43.4 million people in the sub-Saharan area of Africa, is the result of infection by parasites transmitted by the tsetse fly, and the development of new, more reliable and economic diagnostic biomarkers and assays is essential, particularly for surveillance and to curb transmission in the remaining moderate to high risk foci. Our approach is also amenable to the development of new diagnostic tests for the diagnosis, monitoring and surveillance of other diseases caused by parasite diseases. We will therefore also apply our technology to the development of new diagnostic tests for other diseases caused by Trypanosomes and Kinetoplastid diseases of commercial and social importance.",0
ST/P005969/1,3359,Lancaster EPP Capital bid 2016,"Particle physics experiments require substantial technical resources to do their research. We are requesting three items. The first concerns the fabrication of detectors that can measure the position of charged particles very precisely. To do this, the sensitive materials need to be divided into increasingly small areas, and then connected to other electronics to read out if they have been hit or not. Thsi requires a very precise form of 'solderer' called a wire bonder. The one we are requesting will allow us to make very precise detectors that can be used for particle physics, but also astronomy, medical applications, earth observations etc etc.
The second request is for computers and storage to allow the results from experiments to be analyzed, particularly interactively in a way that allows the human to assess the data by eye. The novel approach is to 'virtualize' the computers so different operating systems can be used by different people at the same time, without any real loss of performance. The data will be able to be read much faster.
The last item is for a computer controlled lathe. This can be programmed to produce large items quickly, accurately and reproducibly. While 3D printers are very fashionable, they cannot yet produce many of the mechanical items required for particle physics experiments and other activities. This will allow Lancaster to help build the next generation of particle physics experiments.",0
BB/R017220/1,29064,The role of SUR1 in synaptic and secretory vesicle function,"We're all familiar with the fact that machines are powered by electricity, but it's perhaps not so widely appreciated that the same is true for ourselves. Your ability to read and understand this page, to see and hear, to think and speak, and to move your arms and legs is due to the electrical events taking place in the nerve cells in your brain and the muscle cells in your limbs. And, in turn, that electrical activity is initiated and regulated by tiny protein pores embedded in the membranes of each one of your cells, known as ion channels.

Nerve cells are used to transmit electrical signals round the body. Within our brains, billions of nerve cells also engage in a constant electrical conversation, directing all our thoughts and actions. But nerve cells are not physically connected to one another and the electrical impulse cannot jump the gap between them. Instead a chemical messenger, known as a neurotransmitter, is used to send signals from one cells to another. Transmission takes place at specialised junctions called synapses, where the two nerve cells come close together and the gap between them is very tiny. At the synapse, the tip of the nerve cell is densely packed with small membrane-bound vesicles filled with neurotransmitter, and when an electrical impulse arrives at the nerve terminal it causes the vesicles to release their contents into the gap between the two cells. The neurotransmitter then diffuses across the gap and stimulates an electrical impulse in the next cell. 

A similar process takes place in gland cells, which release hormones into the blood stream. This process also involves the packaging of the hormone into tiny vesicles which then fuse with the surface membrane of the cell and empty their contents into the bloodstream when the gland cell is stimulated. The hormones then travel around the body in the blood to their target organs. 

The way in which nerves work, how they talk to one another at synapses, and the role of ion channels in this process is explained in The Spark of Life, a book for the general reader written by one of the applicants of this grant (Frances Ashcroft). 

This project is focused on the precise way in which the release of vesicles from nerve endings and gland cells is controlled. We are particularly interested in an ion channel known as KATP channel. It plays a very important role in the regulation of blood glucose levels because it controls the release of the hormone insulin from the beta-cells of the pancreas. It also is important in the nerve cells of the brain, and people with mutations in KATP channel genes not only get diabetes but may also have delayed development. Our preliminary data suggests that one of the proteins that makes up the KATP channel has a novel role in regulating vesicle function and release in both nerve and gland cells. Although we have known for some years that this protein (called SUR1) is present in the insulin secretory vesicles, we still don't fully understand what it does there. Recently, the mystery has deepened, as we discovered SUR1 is also present in vesicles at nerve endings in the brain. The aim of the grant is therefore to understand the role of SUR1 in both the synaptic and secretory vesicles. 

This question is of considerable scientific importance as it addresses a fundamental topic - how do cells communicate with one another? It is also of importance to the pharmaceutical industry because many clinically important drugs influence synaptic function and hormonal release. Elucidating the molecular pathways in which SUR1 is involved may lead to new targets for drug development. Finally, the methods that we propose to use are novel and will lead to the development of a new tool for scientists studying vesicle function. In addition, we are collaborating with a UK company to generate new applications for their microscopes.",0
2236030,38560,Secondary Toxicity Mechanisms of Insecticides and Their Metabolism in Pollinators,"Insecticides are one of the main stressors faced by pollinators, whose numbers are in global decline. Few studies have been undertaken to profile their secondary effects, that is responses not mediated through primary target interactions. S.cerevisiae, Baker's yeast, offers an ideal model for characterising secondary insecticide effects as its genome lacks their main molecular targets, whilst at the same time sharing fundamental cellular processes with other eukaryotes. Gene expression analysis will be conducted to reveal insecticide mediated responses in yeast for twelve insecticides, representing five classes. These results will be combined with existing, analogous expression studies in the bumblebee, B.terrestris, to identify homologous secondary responses. Gaining a holistic understanding of insecticide toxicity mechanisms is crucial for assessing their risk to pollinators. 
 The second part of this project will aim to map the enzymes responsible for insecticide metabolism in B.terrestris. Using S.cerevisiae based expression systems, cytochrome p450 enzyme (CYP) driven insecticide metabolism will be evaluated, with individual CYP substrate profiles determined. In turn, CYPs important to metabolism will become the basis for a phylogenetic comparison study, to assess the capability of insecticide metabolism in distantly related pollinator species. This presents the first step to predictive detoxification profiling.",0
EP/S011382/1,43389,Methods and Experiments for Novel Rotorcraft (MENtOR),"MENtOR is a result of the activities of the UK Vertical Lift Network (UKVLN). UKVLN is a network funded by ESPRC (EP/M018164/1) aiming to bring together the rotorcraft research community of the UK. MENtOR itself is aiming to develop and validate methods and tools that can be used for the design and analysis of the next-generation rotorcraft. The project is necessary because the conventional configuration of a vertical flying machine is changing from a helicopter with main and tail rotors to different configurations, the most complex of which is the tilt-rotor. This was recently recognised by Ormiston (R.A. Ormiston, 2016, Revitalising advanced rotorcraft research and the compound helicopter. The Aeronautical Journal, 120, pp 83-129) who performed a review on the future of vertical flying machines as part of his American Helicopter Society Nikolsky award and lecture.

In the UK, the tiltrotor configuration has been selected by the rotorcraft industry to be on the roadmap of the Technology Strategy Board for development, based on the AW 609 aircraft and the Clean-Sky 2 initiative. Recent progress with the AW609 highlights the relevance of the proposal and the challenge at hand to design safe and efficient vertical flight machines of such complexity, and the need for research to provide trained engineers with the necessary tools, data and understanding.

MENtoR is a combined effort that includes all researchers in the UK active in the rotorcraft filed. The development of high-fidelity design and simulation tools is a primary objective equal in importance to the validation of the tools using test data. To support this activity MENtOR capitalises on the investment of ATI (former UK Aerodynamics) on the manufacturing of a test rig suitable for wind tunnel experimentation and able to accommodate tilt-rotor configurations. This new facility is currently undergoing commissioning and MENtOR will be the first project to utilise it.

Finally, MENToR has as strong exploitation and dissemination arm that aims to maintain and enhance the position of the UK in the international rotorcraft scene and ensure that the UK industry is well-supported with trained staff, tools and fundamental research to embark in the design and development of this new breed of rotorcraft",0
ES/S001336/1,31120,Digital Technology-based New Business Model for Inclusive Development,"&quot;Leave no one behind&quot; has been a key objective of the recently agreed UN 2030 Sustainable Development Goals (SDGs). As the poor, in particular the youth and women, are often being marginalised and excluded from market participation due to unequal access to education, resources and information, empowering and including these segments into the main stream market and income creation activities turns out to be an important imperative to achieve SDGs and build an inclusive society. This is important as developing countries are witnessing an upsurge of young people in rather inadequate labour market. While emerging digital technologies can become both an equaliser and a disruptive factor in labour markets, they can empower both women and youth. The decreasing cost of digital technology should thus foster and support new exchange mechanisms that will generate new models of value creation (Amit and Zott, 2012) and will lead business organisations towards network based systems (Dafe &amp; Lewin, 1993; Dunbar &amp; Starbuck, 2006). Many new digital technology-based business models have already been developed. These developments not only create new drivers for economic growth, but also lead to upgrading of capabilities of small business owners. Such increased capabilities will in turn enhance the welfare of the poor (Sen, 1999). 
However, there are a number of gaps to fill in order for this potential to fully materialise. (1) Most of the research focuses on the evaluation of the impact of technology on development. Little is known about the business models that are needed to transform the benefits of technology into jobs, income and a driver for growth for the poor (Seelos &amp; Mair, 2007). (2) The existing studies mostly focus on e-trading businesses that sell products or services online, and normally require considerable initial capital investment to start the business. What type of new business model can help the poor to benefit from digital technology? This is an under-explored area for inclusive development. (3) Some research is available on how to use business models for digital innovations to support growth of new businesses and employment. How is it possible to design a business model to empower the poor who have no initial capital to benefit from technological progress is missing. What underlying institutional, regulatory and capability conditions are needed to ensure the success of such digital technology-based new business model? What role can the state and Multinational Enterprises (MNEs) play in this process? These questions will fill the significant gap and provide important policy and managerial implications.
Drawing on inter-disciplinary research from technology, development studies and responsible business studies, this project aims to fill in the gap in the literature with an Inclusive Digital Model (IDMODEL) that will particularly include deprived youth and women. In particular, it will:
1) Develop, test and finalise a digital technology-based new business model which enables poor people to start a business based on their skills and experiences, while requiring minimum capital investment. 
2) Evaluate the impact of this DT-based business model on jobs, income creation and capabilities building. 
3) Analyse the underlying regulatory and capability conditions that are needed to ensure its success and scale up, and the possibility to replicate in other developing countries.
4) Examine how the state, MNEs and civil society can collaborate for inclusive development.
The project will be supported by a multi-disciplinary team of researchers from the universities of Oxford and Birmingham, and collaborators in Bangladesh and China from both the private and public sectors. 
It will contribute to the literature by filling current gaps on technology, business model and inclusive development and its impact as well as producing novel datasets and robust empirical evidence to elaborate relevant policies for development.",0
EP/R033293/1,7477,PACE: Privacy-Aware Cloud Ecosystems,"With increasing take up of externally provisioned and managed services (from government, finance, entertainment), often hosted over Cloud computing infrastructure, there is a realisation that on-line electronic services can involve an interlinked range of providers. Gartner forecasts that cloud computing market will grow at a compound annual growth rate of 32% (2016-2019), with the potential for additional providers to emerge in the market place. Ofcom's &quot;Communication Market Report&quot; indicates total UK telecoms business revenue were 37.5bn in 2015, indicating significant contribution of mobile services to the UK economy. With the availability of additional mobile services and infrastructure, there is interest in new business models that can facilitate additional subscribers to make use of these services. However, from a user's perspective, trust in the use of these services remains limited, as highlighted in the Pew Research Centre report (&quot;The Fate of Online Trust in the Next Decade&quot;, August 2017), which surveyed 1,233 respondents - 24% of these respondents predicted that trust in on-line services is likely to diminish over time. The report revealed that although billions of people use &quot;cellphones&quot; and the internet now, many still do not use that connectivity for shopping, banking, and other important transactions due to limited trust in on-line providers. Some of the respondents surveyed indicated that the use of new technology (such as Blockchains) and regulatory compliance (and industry changes) will help increase trust in on-line services. 

As more people move online globally over the next decade, both opportunities and threats grow. It is now likely that due to the wide adoption of Cloud based provisioning, some of these mobile services will exist at the network edge. Consider, for instance, a coffee chain that initially provided Wifi services to customers, now working in collaboration with data centre providers to offer additional services to users (e.g. edge data storage, multimedia caching, etc). Such scenarios have been proposed by a number of organisations involved in Mobile Edge Computing (e.g. the European ETSI and the NIST &quot;Big Data&quot; Working Group). This project addresses security and privacy requirements of such environments, where multiple Cloud computing providers need to work collaboratively to offer services to a user. Users of these services only interact with a Web interface rather than the larger, distributed service ecosystem, and are often unfamiliar with the &quot;ecosystem&quot; of providers that are involved in offering them a particular capability. Their visibility beyond the first service provider is often missing, requiring them to &quot;trust&quot; the provider in handling and managing their data. This is a significant challenge, and according to a recent report from the Pew Research Centre, often deters the use of on-line services (especially for data providers which are new in the market place). 

They often entrust their data and identity without realising that the service provider may share their data with several back-end services (Cloud hosted analytics, advertisers). While this has been a problem in the past, it will be greatly exacerbated by the expansion of internet connected devices. In order to address this, the General Data Protection Regulation (GDPR) will be implemented to ensure that non-expert users can make informed decisions about their privacy and thereby give 'informed consent' to the use, sharing and re-purposing of their personal data. There are a number of challenges to facilitating this, both for individuals who need to provide consent and for data controllers who need to obtain it. As a means of addressing this, we propose a technological solution in the form of a mobile software &quot;container&quot; that will ensure that all access instances are securely logged. This will improve transparency, enable an audit trail of providers and facilitate greater trust between users and service providers.",0
BB/R00160X/1,13341,Exploiting the power of heterologous expression in plants to discover new virus structure.,"For a virus to be able to spread from one organism to another, it is absolutely essential that a protective protein (and sometimes membrane-containing) capsid is assembled to protect its genetic material (genome) from the harsh external environment. Typically, the protein capsid is formed from one (or a few) type of coat protein that assembles to form a highly symmetric container into which the genome is packaged. These capsids are characteristic of the virus: each virus has a particular size, shape and configuration that uniquely identifies it. A large number of 3D structures have been determined for virus capsids, and these structures have helped revolutionise research into viruses. Structural information enables a myriad of experiments, including the design of mutant versions of the viruses to help understand their basic biology, informing the design of new molecules that have antiviral properties and are thus potential anti-viral medicines, and helping to validate the design and efficacy of new vaccines. However, despite these enormous strides, large holes exist in our structural understanding of the viruses in nature. A great many different types of viruses, including viruses that are devastating pathogens of crops around the world, and a thus are a major source of food insecurity in the developing world, currently have no structures. In part this is because many viruses, especially those that are extremely toxic to plants, are exquisitely difficult to propagate in the amounts required for structural studies. 
 
We are now in a position to remedy this problem. Using cryo-electron microscopy, a technique in structural biology that is now capable of generating structures for viruses at atomic resolution using relatively small amounts of virus (at the University of Leeds), and new capabilities to express virus proteins in plants (at the John Innes Centre in Norwich), we have shown that virus-like particles that are identical to the authentic virus can be produced, and their 3D structures can be relatively rapidly determined. We will now use these techniques to fill in some of the gaps in our structural knowledge of viruses present in Nature. We will start with the Luteoviridae, a family of viruses that infect plants, and are commercially important pathogens of cereals and potatoes. We have already determined a preliminary structure for one: potato leaf roll virus, showing that our approach is highly likely to yield rapid results. We will improve our existing structure and solve the structure of other important family members, before beginning to work on more challenging viruses (with more complicated capsids). These will include a large number of different families of plant viruses, which again include important pathogens that devastate food and commercial crops across the developing world (e.g. rice tungro spherical virus, that is implicated in rice crop losses of &gt;$1.5 billion p.a.). They will also include human pathogens.

Clearly a greater understanding of the structure that viruses assemble to protect their genomes, and of processes essential for virus spread would be of huge significance to our ability to combat the diseases these viruses cause. Such understanding might help to develop virus particles that can act vaccines, or as vehicles for the delivery of molcules to cells for a variety of medical applications. As a routine part of our work, we will generate a novel protein-based binding reagent that can specifically recognise the virus in question. These molecules, called 'Adhirons' are functionally analogous to antibodies, and will be an invaluable resource for researchers interested in the virus in question, potentially allowing for example the rapid diagnosis of infection in a simple, in-field testing device, or the purification of small amounts of authentic virus from infected tissues for future research. The knowledge gained from these studies would therefore also aid applications in biotechnology.",0
MR/P007694/1,4490,USE OF LOW-DOSE IL-2 TO EXPAND ENDOGENOUS REGULATORY T CELLS AND ACHIEVE TRANSPLANTATION TOLERANCE,"A population of immune cells, called regulatory T cells or Tregs, have been shown in experimental animal models to regulate the immune system and to play a central role in preventing organ rejection and in controlling autoimmune and inflammatory diseases. In animal models of transplantation, Tregs are key to induce immunological tolerance, a situation in which the transplanted organ is indefinitely accepted in the absence of anti-rejection medication. The use of IL-2 at low doses has been shown to selectively and safely increase the number of Tregs in humans, but whether this can be used to induce tolerance in transplanted patients has never been investigated. Liver transplantation is an optimal clinical setting to do so, given that there are evidences indicating that transplantation tolerance can spontaneously occur in these patients (albeit only many years after transplantation), and that liver transplantation is the only solid organ transplantation setting in which it is safe to investigate the development of tolerance by intentionally discontinuing all anti-rejection medications. 

Our hypothesis is that administration of a short course of low-dose IL-2 will transiently expand the number of Tregs and allow for the permanent discontinuation of anti-rejection medication. In the current project we propose to conduct a clinical study in which liver transplant recipients who have a very low probability of achieving tolerance spontaneously will receive daily injections of IL-2 during the period of time when their anti-rejection medication is gradually withdrawn. Patients will be carefully studied to investigate the following:

1) Whether IL-2 is efficacious in expanding the number of Tregs in liver transplant patients. 
2) Whether the expansion of Tregs in the circulation and/or the liver facilitates the successful discontinuation of anti-rejection medication.
3) What are the effects of an increased number of Tregs in the immune system of a transplanted patient. 

Ultimately, the project will serve to clarify whether donor-specific Tregs are essential to establish transplantation tolerance, and the extent to which low-dose IL-2 is an effective strategy to promote this phenomenon. This will have implications for a number of other inflammatory diseases, and will open the door to future clinical trials in which low-dose IL-2 could used in combination with other tolerance-promoting medications.",0
105703,35609,Project Zeus: Thermal Management of High-Powered Satellite Payloads,"This project is helping OrbAstro address a key problem throttling the growth of the nano-satellite (1-10kg), micro-satellite (10-100kg), and small-satellite (100-500kg) sectors. This project will allow the company to develop an elegant solution for the power electronics and thermal management systems required to enable high-powered payloads to operate on satellites of this scale. This is relevant to applications such as space-based Internet, telecommunications, distributed sensors for Earth monitoring/science, and synthetic aperture radar clusters.",0
752074,32705,TentoIDs as an anti-counterfeit device,"Tento Technologies is investgating the feasibility of using its patented technology, based on visual cryptography, to provide protection from counterfeiting in industries such as pharmaceuticals, cosmetics and entertainment.",0
EP/R015104/1,24127,Fourier analytic techniques in geometry and analysis,"A powerful discovery of Joseph Fourier in the early 1800s was that certain functions could be written as an infinite sum of simple 'wave-like functions'. Such a decomposition is now known as a Fourier series, and has had wide-ranging applications across mathematics and wider science, for example in signal processing and in solving complicated differential equations. The Fourier transform describes how quickly the Fourier series converges, i.e. the decay rate of the amplitudes of the waves in the decomposition as frequency increases. One way of viewing this is that the faster the Fourier transform decays, the more wave-like the function was to begin with. Thus, some geometric information about the original object is captured by Fourier decay. This research project considers the Fourier transform of measures (mass distributions), which are analogous to functions. It is well known that the Fourier transform of a measure encodes a lot of information about its geometric structure, for example concerning its dimension, curvature properties, and arithmetic resonances. We investigate the Fourier transform, and the geometric information it encodes, in several challenging contexts. For example, we consider how it is affected when the original measure is distorted under standard geometric operations, such as projecting a measure in 2 dimensional space onto lines. Similar questions about the Hausdorff dimension of sets and measures are at the heart of geometric measure theory and we will establish Fourier analytic analogues of classical results in this direction. We also consider the Fourier transform in probabilistic settings. Brownian motion is a fundamental random process - first observed as the seemingly random path a grain of pollen follows when suspended in water - and is our archetypal example. We will consider the Fourier transform of natural (random) measures associated with Brownian motion and related processes. Finally, we will consider dynamically invariant measures, where we will use transfer operators and other tools from the thermodynamic formalism to analyse the Fourier decay.",0
2325761,38821,Investigating the water and volatile inventory of unequilibrated ordinary chondrites,"Liquid water is one of the vital ingredients that allowed the emergence of life in the Solar System. Therefore, understanding the origin(s) of Solar System water is an active area of Solar System science research. Water is ubiquitous in the Solar System, and is present in most of the planets and their satellites, as well as asteroids and comets. The volatile-rich carbonaceous chondrite meteorites are thought to constitute some of the most primitive Solar System objects, and have thus been the focus of most of the studies on water in the early Solar System. On the other hand, the volatile inventory of ordinary chondrite meteorites has received much less attention, despite the fact that these meteorites, which represent the large majority of samples in our meteorite collections, probably sample asteroid-types that played an important role during formation of terrestrial planets. The goal of this project is to fill this important knowledge gap by constraining the volatile budget of unequilibrated ordinary chondrites.

We will investigate the water and volatile inventory of around 15-20 unequilibrated ordinary chondrite meteorites using a combination of petrological, geochemical and spectroscopic techniques. The mineralogy of the samples will be examined using XRD analysis, infrared spectroscopy and electron beam techniques. The abundance and isotopic composition of water and other volatile species (e.g., N, S, and Cl) will be determined in selected samples using transmission infrared spectroscopy and secondary ion mass spectrometry. This original dataset obtained on water and volatiles in ordinary chondrite meteorites will eventually permit testing of our existing models for the origin and processing of water and volatiles in the early Solar System.",0
ES/N003756/1,16277,Bringing wellbeing to community,"There is more and more evidence on what determines people's wellbeing (how they experience their lives), and what activities can increase people's wellbeing. The UK's Office for National Statistics began in 2011 to conduct the largest national annual survey in the world on wellbeing. Potentially, this and other wellbeing evidence could have a profound effect on how policy-makers and funders make decisions, and how frontline workers and community organisations deliver activities and services. Many, including the Prime Minister David Cameron, have expressed a serious commitment to the idea of using this evidence in the policy process. However, to date, wellbeing evidence has not been used extensively in this way.
The What Works Centre for Wellbeing is about accelerating the process of getting wellbeing evidence used. It seeks to connect wellbeing evidence to those who could use it. The focus of our evidence programme is communities. This means we are focusing on how the things that happen where we live determine our wellbeing. For example, whether people have access to parks, whether they have a say in local decisions, and whether people trust one another in an area. We will also look at the interactions between these things, for example whether access to parks has any influence on trust.
This is what we will do:
1. An in-depth consultation process where people working in a range of organisations including local authorities, central government, charities, and housing associations, as well as people involved in small community groups, have the opportunity to discuss what would be useful for them to know about wellbeing. We will run events, get feedback electronically, and carry out interviews. We'll compare what people want to know with what we know already.
2. Identify a few key questions based on the consultation, and gather all the relevant evidence related to them. This will come from a range of different fields of study such as economics, psychology and geography, and including academic research as well as evaluations carried out by community organisations. 
3. Review that evidence so that those who could use it can easily determine which findings are more robust, and which less so, and draw conclusions about the best options for increasing wellbeing.
4. Carry out analysis on new wellbeing survey data to understand why certain parts of the UK have higher or lower wellbeing.
5. Ensure all this evidence is published in formats that are easily understandable by a wide range of people, from policy makers to the general public. 
6. Build closer links between researchers and people who could use that research - through events, networking, and on-going communication.
7. Provide training and tools for community organisations and local authorities to understand how they can use wellbeing in their day-to-day work, including how they can evaluate their activities using wellbeing surveys.
8. Develop a better understanding of what people mean when they talk about 'community wellbeing'.
9. Respond to questions about wellbeing evidence as they come in.
10. Develop new questions for researchers to explore in future research.
We are a team of five universities and five civil society organisations. We bring together a wide range of skills and knowledge areas, and have strong networks with the people who could use wellbeing evidence. We are committed to working together as a team, playing to our many strengths, and learning from our different perspectives. We will listen to the wide range of people we engage during the project, and will be sensitive to the real-world challenges of policy and on-the-ground community work. We will be systematic and transparent with evidence, ensuring our own methods our robust, but recognising that all kinds of evidence can be of value if treated appropriately. And we will be ambitious, seeing Wellbeing What Works as a genuine opportunity to help improve the lives of people across the UK.",0
EP/S00033X/1,4504,Voigt waves in bianisotropic materials,"Voigt-wave propagation represents an unusual form of electromagnetic plane-wave propagation that is supported by certain anisotropic dielectric materials. It may be distinguished from the usual form of plane-wave propagation, as encountered in standard textbooks on electromagnetics and optics, on the basis of rate of amplitude decay. That is, the decay of Voigt waves exhibits a linear dependency on propagation distance whereas in the usual case of plane-wave propagation there is exponential decay with propagation distance. Bianisotropic materials offer much greater scope for Voigt-wave propagation than do anisotropic materials, because of the intrinsic coupling between electric and magnetic fields and the much larger constitutive parameter space that is associated with bianisotropic materials. Conditions for Voigt-wave propagation will be derived for certain types of physically-realizable bianisotropic materials. These bianisotropic materials will take the form of engineered materials that arise from the homogenization of relatively simple component materials that may not themselves support Voigt-wave propagation. Furthermore, the prospects of controlling the directions in which Voigt waves propagate by means of an applied DC electric field will be investigated for certain bianisotropic materials arising from electro-optic component materials. The prospects of harnessing Voigt waves in bianisotropic materials for optical sensing application will also be investigated. In addition, the prospects of realizing Voigt waves which exhibit a linear gain in amplitude with propagation distance will be investigated for certain bianisotropic materials arising from active component materials.",0
2127169,8541,"Defining the relationship between rheumatoid arthritis, comorbidity, and adverse health-related outcomes: A precision medicine approach.","Studentship strategic priority area:E-Health Informatics Research
Keywords: Multimorbidity; cohorts; rheumatoid arthritis; outcomes

Rheumatoid arthritis (RA) is a chronic systemic inflammatory disease affecting 1% of the adult population. Therapeutic advances have improved RA prognosis but it is increasingly recognised that comorbidities may shorten life span and quality of life. Depression, asthma, and cardiovascular disorders are common comorbidities and cardiovascular disease is a leading cause of death. This proposal aims to use a precision medicine approach to delineate the relationship between RA, comorbidity, and adverse outcomes. 
Key research questions are:
1. What is known about predictors of mortality and adverse health-related outcomes among people with RA and comorbidity? 
2. How do demographic, lifestyle factors, morbidity measures, and routine clinical blood tests mediate the relationship between individuals with RA and adverse health-related outcomes (death, cancer, hospitalisation and cardiac events)?
3. Is it possible to develop a predictive algorithm to identify individuals with RA and comorbidity at high risk of adverse outcome?
The student will undertake a systematic literature review and interrogate several large well-defined research cohorts (UK Biobank; Scottish Early RA (SERA) cohort, Swedish Arthritis cohorts in Karolinska Institute). The intended outcome would be improved risk stratification for adverse health outcomes in people with RA, which in turn can potentially lead to improvement in the clinical management of RA.

This PhD project, under the guidance of an experienced and multidisciplinary supervisory team, will provide the student with a solid grounding in systematic review, population health, and data science approaches, including in silico-type modelling approaches. The student will receive specific training and develop competencies in epidemiology and statistical analysis using complex and innovative methods. Generic research and communication skills will also be developed. The student would visit and be hosted by Professor Johan Askling in Karolinska Institute for a few months to undertake a component of the analysis. 

This project aligns with MRC's research priority theme of &quot;living a long and healthy life&quot;, particularly in relation to the impact of lifestyles on health, and mission to produce skilled researchers. This project will involve experts from rheumatology, epidemiology and primary care research backgrounds with expertise in the areas being studied.",0
EP/N020715/1,27099,Realising a solid state photomultiplier and infrared detectors through bismide containing semiconductors,"Semiconductors are commonly used in imaging sensors and solar cells, as they can directly convert light into an electrical current. The highest band of electron energies that are fully occupied is known as the valence band while the lowest unfilled energy band is the conduction band. The energy difference between the conduction and valence bands is known as the bandgap. When electrons from the valence band are excited into the conduction band by absorbing light with energy equals to or greater than the bandgap, the change of charges induces an electrical current. Consequently the bandgap is the most important parameter in the design of semiconductor photodetectors. While visible wavelength photodetectors are widely available, detectors for infrared wavelengths are significantly less mature and more costly. Progress in infrared detectors has been hindered by the limited choice of bandgaps currently available. In this work we will introduce a novel approach, by incorporating Bismuth (Bi) atoms into existing semiconductors such as InAs and InGaAs, to achieve a wide range of bandgap energies to detect infrared signals across a correspondingly wide wavelength range. Achieving this will lead to a new range of infrared detectors that can have transformative impact on applications including night vision imaging, medical diagnostic sensors, environmental monitors and for accurate temperature measurements in manufacturing processes. 
 
We will also exploit Bi-alloys to engineer a noiseless charge amplification process in photodiodes known as avalanche photodiodes (APDs). When an electron leaves the valence band a vacant state (a hole) is created. Therefore an electron and a hole are created as a pair of charges in semiconductors. Properties of the conduction and valence bands will determine how electrons and holes gain energy from an applied electric field. In materials such as InAs, electrons gain energy at a much faster rate and travel at higher velocity too, when a voltage is applied. Therefore InAs is an excellent material for high speed electronic devices and also for providing internal signal amplification in APDs. When designed appropriately, the energetic electrons in InAs APD ensure that the amplification process, known as impact ionisation, is coherent so that negligible amplification noise is generated. In this work we will incorporate Bi into InAs to alter the valence band such that only electrons will gain significant energy from the electric field. This ability to suppress energetic holes will allow us to design very high gain APD across a wide range of electric field while concomitantly suppressing the noise associated with impact ionisation. By carefully controlling the fraction of Ga and Bi atoms, we will also develop a range of InGaAsBi APDs suitable for detecting a wide range of infrared wavelengths. 
 
The proposed research to introduce a new class of Bi-containing infrared detectors and APDs, will be carried out by a carefully assembled team of world leading researchers from Universities of Sheffield and Surrey, in collaboration with the Tyndall National Institute, as well as partners from LAND Instruments, Laser Components and the UK Quantum Technology Hubs in Enhanced Quantum Imaging. Our work will start with a focus on formulating growth conditions (such as temperature and atomic fluxes) to obtain high quality InGaAsBi crystals. Following an intensive crystal growth programme, we will develop procedures to fabricate the grown InGaAsBi semiconductors into devices for a wide range of measurements to extract key material parameters. A model that accurately describes the bandstructure of InGaAsBi will be developed so that we can use them to design high performance infrared detectors and APDs. These newly engineered devices will be evaluated with our industrial partners for applications ranging from temperature measurements in manufacturing to novel imaging techniques using quantum properties of light.",0
104932,35893,Improving the stated calibration accuracy of Valeport instrumentation to improve International competitiveness.,"&quot;We need to improve the uncertainties associated with thermometer calibrations at Valeport, which will in turn allow us to offer more accurate temperature measurements in the field. Additionally, this will also result in improved accuracies of associated sensors which also fundamentally rely on Temperature measurement, such as Conductivity (Salinity) and Sound Speed.

The specific problem that we have with seeking to improve our Temperature measurement capabilities is that despite already investing in state of the art equipment in our calibration laboratories, we are unable to further narrow down the accuracy specifications of our products. To put this in context, we are currently able to confidently specify that our products will measure Temperature with an accuracy of &plusmn;0.01K. However, our international competitors (USA and Canada in particular) claim accuracies of the order of &plusmn;0.001K, an order of magnitude better.

Worldwide, this market for science grade CTD products (Conductivity, Temperature, Depth) amounts to several tens of millions of pounds, and given the limited number of competitors, we believe that it is entirely reasonable to expect to poach a minimum market share of 10% from our overseas competitors. In monetary terms, this would represent a minimum increase in export turnover of well over &pound;2m per annum.

Having discussed the problem with our partner NPL, we believe that our greatest sources of error are generated by the instability of the raw temperature sensor and the instability and resolution of our existing interface circuit board.

The project will deliver us the understanding to develop our temperature measurement to provide an improved accuracy by an order of magnitude. We will also benefit from the ability to support our accuracy claims by working with NPL.&quot;",0
2110575,28351,Using Non-Covalent Catalysis to Influence Regioselectivity and Enantioselectivity,"Palladium catalysis has become established one of the leading tools in the development of new catalytic methods over the last 50 years. Several leading types of cross-coupling reactions using palladium were awarded the Nobel Prize for Chemistry in 2010. We have recently developed a method using ligand-substrate non-covalent interactions that enables site-selective cross-coupling of molecules bearing remote halides (J. Am. Chem. Soc. 2018 doi: 10.1021/jacs.8b08686). This employed sulfonylated Buchwald-type ligands such as sSPhos, which is commercially available: the sulfonate group acted as the point of contact with the substrate. This project will explore this concept more widely in a variety of other palladium-catalysed reactions that feature regioselectivity or enantioselectivity choices and demonstrate that non-covalent catalysis can be a general approach to tackling some of these outstanding challenges.",0
2033238,18969,Understanding the phase separation of multicomponent organic solar cell heterojunction blends,"The project investigates the molecular and bulk parameters responsible for the morphology of thin films comprised of two or more components. Detailed studies of crystallisation, thermal properties, solubility and other parameters are used to elucidate thin film morphology.",0
ES/N008146/1,26022,Re-imagining professionalism: towards co-production,"The aim of this seminar series is to develop ideas on how to encourage and develop co-production in mental health. Co-production involves mental health service users being able to make decisions about their own treatment and care as equal partners alongside professionals. This application is timely because there is currently a strong policy emphasis encouraging the greater involvement of service users and carers in making decisions about the care they receive. It is widely recognised that new ways of working with service users (a new approach to professionalism) are needed in mental health care. 
This seminar series was developed jointly by a research team which includes service users, carers, and people working in charitable/voluntary organisations, and in public and governmental organisations. Academics in the research team are from diverse disciplinary backgrounds: mental health nursing, philosophy, political science, psychiatry, social work and sociology. 
The seminar series will bring people together from different stakeholder groups in order to develop ideas about new ways of working in mental health which are based on the principle of co-production. This will involve considering current practices, policies, approaches in different organisations, as well as education and training in mental health. Crucially, mental health service users and their family carers will fully participate in this process. We use the term 'professional' in a new way. A professional can (for us) belong to any occupational group. What makes someone professional is, in our view, their sense of commitment - not their occupational status. Importantly, we believe that service users and family carers should be considered professionals in this context because they are 'experts in experience'. Our speakers and participants include some people who are in positions where they can shape practice, education and policy. We believe though that it is important that all the participants have equal status. The idea is that sharing ideas across groups will be enable us to work out how professionalism in mental health can be based on co-production. 
In healthcare a growing importance is being placed on respecting different people's values. This is known as Values Based Practice (VBP). But the problem is that VBP overlooks problems of power - that is the reality that some people's values and perspectives are more powerful and influential than other people's. This is why this seminar series will encourage people to think about co-production by considering some of the key ideas associated with 'democratic professionalism' (DP). DP is based on the idea that it is important that the voices of 'lay' people, particularly marginalised people, should be regarded as highly relevant when it comes to shaping professional practice and values. Another principle of DP is that professionals should be assessed according to the extent to which they support the involvement and enablement of people they work with, such as service users. In other words, professionalism should involve sharing power with others, not exercising power over them. We believe that our seminar series will contribute to the development of professional practice and values which are suited to the 21st century. 
Each seminar will focus on a particular topic: the first two seminars set the scene with a focus on co-production and democratic professionalism and on people's lived experience of co-production. The seminars which follow consider how changes to practice, policy and education in mental health could be implemented to develop a new form of professionalism based on co-production.
We will make the video-recordings of the seminar series available on our website and we will have a blog to continue the discussions and conversations which take place in the seminars. All the groups represented at the seminars will contribute to future practical and research initiatives.",0
1891294,10026,The cognitive and neural substrates of inhibition of speech,"The ability to stop the execution of speech actions is essential for effective interaction. For instance, few things are as irritating as having a conversation with someone who keeps interrupting. However, we do not understand which neural mechanisms allow us to stop speaking. Yet, the neural organisation of inhibition is relatively well understood for hand actions, but poorly understood for speech. Inhibition of hand actions has been investigated using cognitive neuroscience methods: functional Magnetic Resonance Imaging (fMRI) and Transcranial Magnetic Stimulation (TMS). No studies have examined speech inhibition with fMRI and only a handful of TMS studies have examined neural underpinnings of inhibition of speech. The proposed work will address these issues in one fMRI experiment and two TMS experiments. The project will use TMS to record Motor Evoked Potentials (MEPs) while participants perform an inhibition task. The fMRI experiment will examine how brain areas outside M1 exert inhibitory influence on M1 using a sophisticated TMS design. A single TMS pulse to an area of primary motor cortex (M1) causes the associated muscle to contract, resulting in an MEP. The two TMS experiments will map out patterns of inhibition in M1 during speech inhibition and examine the role of areas outside M1. In sum, this project provides an innovative opportunity to examine speech production by applying techniques and paradigms traditionally used to study inhibition of manual actions to inhibition of speech actions.",0
2124598,15592,Assessment of role of RANKL and its inhibition on muscle mass and function,Assessment of role of RANKL and its inhibition on muscle mass and function,0
700548,4393,Industrial Scale Continuous Plug Flow Reactor with Improved Heat Transfer and Mixing Control,"Crystallisation has traditionally been operated as a batch process, but problems with
consistent product specification arise e.g. size distribution, correct polymorphic form &amp;
morphology. Consequently it has been identified that continuous flow crystallisation can
improve manufacture and offer several benefits including energy and capital cost savings;
leading to many flow reactors being sold for laboratory use. However due to the vulnerability
of crystallisation, its implementation at an industrial scale has been restricted. Autichem have
noted this gap in the market and have devised a continuous plug flow reactor that combines
CSTR and tubular technology to improve heat transfer and mixing control.",0
MR/S016066/1,35733,Exploring the Universe with radio and optical galaxy surveys,"During the last two decades we have entered a &quot;golden era&quot; of cosmology. Using satellites and ground based telescopes we have gathered high quality data from the very early Universe, essentially from light emitted right after the Big Bang explosion, as well as from the late Universe, through the light emitted from stars and galaxies.

However, a big part of our Universe's history and volume remains unexplored. A way to attack this challenge is by observing the light emitted from the neutral hydrogen (HI) that filled the Universe for a long time after the Big Bang and before the first galaxies were formed. After that time HI resides within galaxies, so we can also use it as a novel way to study the late Universe. This is my main area of research; it is exciting because it opens a new observational window into the Universe and can push the boundaries of our understanding of astrophysics and cosmology.

In the next few years, HI surveys of exquisite sensitivity will be performed using radio telescopes, and part of the proposed research is working on new techniques in order to maximise their science output. I have pioneered a new observational method that does not require the -difficult and expensive- detection of individual galaxies but maps the entire HI flux coming from many galaxies together in large 3D pixels (across the sky and along time). I aim to use this technique to provide a 3D map of the Universe using HI intensity mapping data from the MeerKAT and SKA arrays. MeerKAT is a radio telescope located in Karoo, South Africa, and it is a pathfinder for the Square Kilometre Array (SKA), which is going to be the largest radio telescope in the world.

My main goal is to build a complete pipeline for the cosmological analysis of the HI intensity mapping signal from instruments like MeerKAT and the SKA. This pipeline will also account for the possibility of powerful synergies between HI and traditional optical galaxy surveys, by including cross-correlations data analysis tools. This is useful in order to obtain measurements that are free of systematic contaminations that often plague individual surveys (but drop out when combining them), and therefore more robust. I aim to perform the first ever measurements of HI and cosmological parameters in the radio wavelength using the intensity mapping technique, exploit multi-wavelength synergies, and revolutionarise our understanding of galaxy evolution and dark energy. 

I am also working on two of the largest and best optical galaxy surveys of the next decade, the Euclid satellite mission and the ground-based Large Synoptic Survey telescope, whose main goals are to measure dark energy and understand the initial conditions of the Universe. In Euclid, I am working on various projects including building the software tools that are going to be used for the analysis of the data as soon as they become available. I am also working on the very challenging task of modelling the way galaxies cluster on small scales, in order to extract useful information for cosmology. I am also using tailored simulations to assess how well Euclid will measure the largest cosmological scales in order to characterise the initial conditions of the Universe. In both Euclid and LSST, I am working on synergies with radio experiments. My goal is to find innovative ways to optimally combine optical and radio surveys, in order to maximise their joint scientific output. 

Another exciting part of working with these surveys is the huge amount of data that are going to be available. For example, the Phase 1 of the SKA is expected to generate 300 petabytes of data products every year. My research includes developing modernised and innovative data processing and analysis pipelines, which is required for the success of these amazing surveys.",0
1939680,20896,Modelling ultrafast molecular photo switches,"Molecular switches form the basis of human vision. The retinal molecule in the rhodopsin complex absorbs visible light which leads to photo isomerisation. From experiments with ultrafast laser pulses, this process is known to be extremely fast, with photoproduct formation within 200 fs (1 fs is ten to the power minus 15 seconds). A combination of laser experiments and theory are used to study how the motion of the atoms in the retinal molecules happen after absorbing light. Retinal is an example of an ultrafast photo switch that operates in a highly complex environment.

With the recent development of X-ray free electron lasers, new experiments on the motion of molecules after absorbing light become possible, which will lead to a more detailed understanding of such photo switches.

The goal of this project is to develop theoretical treatments of photo switches in a complex environment, where interactions with the solvent or the molecules surrounding the photo switch lead to strong damping. The objective is to create such a theory, and then apply it to molecular photo switches to produce simulation results that can be compared with experiment. The essential ingredient of the model is strong damping in combination with quantum mechanics. Quantum effects are important because of the nature of the light excitation. The complex environment of the photo switch molecule leads to damping of its motion, and also to effects such as decoherence.

The basic understanding and modelling tools that will result from this project will be needed to interpret and complement experimental studies on photo switches. They can be used to design such molecules for applications. These could be used in future fast electronics, or in molecular machines. This research project fits well in the EPSRC research area 'Computational and theoretical chemistry'.",0
1640667,3136,Thea Musgrave,The music of Thea Musgrave: an analysis based on the archival sources,0
MR/P014844/1,1866,Verbal Autopsy with Participatory Action Research (VAPAR): expanding the knowledge base through partnerships for action on health equity,"Health systems can be considered as the products of human relationships: between patients and health workers, managers and policy makers, communities and governments. As a whole, these relationships establish norms of who is eligible for care and what can be expected from the health system. In poor countries where health services are weak and under-funded, care that is unaffordable and unavailable can become socially normal. Communities and health workers have substantial knowledge of these norms and interactions and how health policy is 'brought alive' through them. Their voices are often overlooked in the routine design and delivery of services however. 

The project will address this situation by institutionalising processes to: (1) strengthen systems to record and report on deaths, their causes and circumstances; (2) enable the voices of people excluded from access to health systems on their needs and priorities for action, and; (3) act on this information with health workers, managers, planners and policy makers. The process will collect data, analyse, plan and act, and demonstrate an ability to bring about change in partnership with those for whom the situations are most directly relevant. Practical research that is understood and 'owned' by end users in an action-oriented process will strengthen relationships between patients, health workers and policy makers to support and sustain positive change. 

The research builds on development work providing actionable health information for poor and rural groups in South Africa. Rural villages in South Africa represent many settings in the region, with deeply entrenched poverty, inequality, avoidable illness, and weak health systems where many deaths go undocumented and uncounted. The development work has adapted Verbal Autopsy, a method used in many poor countries to establish the causes of death for people who die without a doctor present. The research has introduced a system to record new information in Verbal Autopsy on factors such as transport and hospital admissions. In developing countries these processes can play a critical role in survival, and documenting them provides important information for health service provision.

The development work has also tapped into local knowledge on long standing health problems by building partnerships with communities. Using Participatory Action Research, we have developed understandings of the social issues affecting health, and how these affect people's interactions with care. Participatory Action Research provides a route to involve those in the greatest need in health services. This can empower disadvantaged groups to have more of a say in health systems, in turn strengthening people's abilities to protect and promote their health. We have worked with the health authority throughout, considering what the data are telling us, and how changes can be implemented to respond to the issues identified.

The project will extend the development work into an ongoing system of collaborative problem solving, taking data to those who organise and provide services, and working at different levels to understand and enable what is required for change. The work will strengthen existing partnerships with communities, policy makers and planners, and develop new relationships with health workers and clinic managers to act on the evidence towards shared goals. The research will embed a partnerships culture to generate and use information on the realities of health workers and patients to improve care, strengthening access to the health system, achieving improved outcomes and fostering equity in health.

The work has been done with a research centre in South Africa established for over 20 years. A team of researchers and policy makers from universities and health authorities in developing and developed countries who have shaped health research and policy in Africa for over 25 years have come together to lead the five year programme.",0
BB/N019997/1,9352,Ubiquitylation within and beyond the DNA damage response,"As we age our cells become increasingly sensitive to accumulating damage in their genetic makeup, which is formed by a complex molecule called DNA. DNA damage happens frequently, for instance through radiation, sunlight, chemicals in tobacco smoke, and even from the oxygen in the air we breathe. A rise in DNA damage is linked to some of the most severe and common problems that prevent us from healthy ageing. This includes cancer and diseases of the brain, such as loss of mental abilities. In fact, certain permanent DNA changes that affect the ability of cells to repair DNA damage, can lead to an early onset of these diseases and to premature ageing itself. With the global population ageing, the burden of age-related disorders will steadily increase. It is therefore of urgent importance that we understand better how cells prevent DNA damage. This could lead to ways to prevent these disorders and thus, contribute to healthy ageing across the lifespan.

To prevent permanent DNA damage, cells have found many different ways to repair the damaged DNA. Hundreds of proteins -the workhorses of the cell- need to quickly change their behaviour in highly organised ways, an amazing feat that is far from being properly understood. While cells can make use of an elaborate toolkit for this, the following way is especially fascinating: a little protein, known as ubiquitin, is attached to other proteins. Ubiquitin can be attached in different ways, as a single ubiquitin or as poly-ubiquitin chains made up of many ubiquitins glued together in different ways. The process of ubiquitin attachment is called ubiquitylation. The ubiquitylated proteins are recognised by other proteins, which trigger the final change in the behaviour of the ubiquitylated protein. Ubiquitylation relies on several enzyme groups, including ones known as E2s. I have recently found that several E2s play fundamental roles in repairing DNA damage. Through using novel techniques that I have been key in developing, one of the major aims of the proposal is to better understand how precisely different E2s accomplish DNA repair. This could highlight their potential as drug targets, meaning that they could be changed by a medicine to give a desirable effect. Such an effect could for instance be towards treating age-related diseases such as cancer. Moreover, my recent findings suggest that many more proteins recognise and translate ubiquitylated proteins than is currently expected. Another key aim of the proposal is therefore to analyse these ubiquitin binding proteins. By doing so the proposed work will transform our understanding of how different ubiquitylations change the behaviour of proteins in defined organised ways. These discoveries could be attractive to the commercial sector, as they have potential to be developed into general ubiquitin research tools. Since ubiquitylation is involved in almost every aspect of cell biology, the proposed work is likely to have a wide impact regarding this.

Taken together, the proposed research will increase our fundamental knowledge of how ubiquitylation regulates the DNA damage response and associated processes. This is crucial to maintaining DNA integrity. Given the significance of the DNA damage response for preventing various age-related disorders, the work may pave the way for the development of new medicines contributing to healthy ageing throughout life.",0
133687,2954,Applying AI to storytelling - bringing computational research into creative industries,"&quot;Charisma.AI is an interactive media platform that allows writers to create interactive stories and characters that audiences can talk to and immerse themselves in.

This project is an exciting fusion of creative writing and artificial intelligence to help writers create new forms of dynamic, interactive stories. It specifically aims to understand what the impact of artificially-intelligent memory is on storytelling and narrative structure, and how to transfer the resulting research into industry.

The project is being developed by To Play For, a pioneer in interactive storytelling, and a cross-disciplinary team at King's College London covering digital humanities, culture and software engineering. Together these two teams will undertake the research and development required to interrogate the complexity of memory as a concept in interactive storytelling and the impact that this can have on the story experience. The partnership will leverage To Play For's interactive storytelling technology, Charisma.AI, as a research tool and commercialisation platform.

This major new innovation will open up opportunities for creative industries across all media who are interested in harnessing the power of machine learning and artificial intelligence for their craft in writing stories. It will act as both a tutorial and an accelerator for new creative processes, opening up new publishing opportunities, jobs and revenue streams, keeping the UK at the forefront of established and newly emerging creative industries.&quot;",0
EP/P001483/1,5829,A Focused Ion Beam Microscopy Facility for Advanced Materials Analysis,"Ion beam preparation and the ability to use it for precision lithography has made it one of the most interesting and useful tools in materials science. It is key to the preparation of high quality site-specific specimens for transmission electron microscopy and scanning transmission electron microscopy and its versatility as a nanoscale scalpel makes it an essential tool for nanostructuring shapes and designs that are often difficult or impossible to realise otherwise. Building upon our long track record in focused ion beam preparation and expertise in materials characterisation we will commission a 3rd generation focused ion beam instrument. This design replaces the gallium beam used in the 1st and 2nd generation instruments with a noble gas beam for milling. The use of noble gas beams has major advantages over gallium in reducing chemical reactions, implantation and surface damage. In consequence we will be able to extract the greatest possible information from advanced high-resolution electron microscopy by reducing artefacts and ambiguities when preparing cross sections and lift outs. Moreover, with the 3rd generation machine our ability to define features lithographically will benefit from a significant improvement in definition. This will allow us to create and study functional nanostructures in a greater range of material systems than currently possible. The addition of this state of the art tool to the Kelvin Nanocharacterisation Centre at Glasgow will add value to numerous projects and collaborations at the University of Glasgow, across Scotland and throughout the north of the UK, a noble gas FIB that is optimised for the liftout of high quality TEM/STEM specimens will be of especial national importance as the first instrument of its kind funded by the EPSRC anywhere in the UK. Access mechanisms will be put in place to allow users from across the UK to use this facility, as detailed elsewhere. We will track the significant industrial impact this instrument will have, including with existing industrial partners on advanced materials development, as well as in collaboration with the instrument suppliers to further develop usage modes and protocols with a clear benefit to future users of such technology. This will also benefit the training of a future generation of scientists and technologists through its explicit linkage to two Centres for Doctoral Training.",0
1946984,11742,A molecular approach to understanding membrane permeation,"The permeation of charged organic molecules through membranes is not fully understood. Of particular importance is permeation through membranes that have a voltage maintained across them. For example, the membrane potential across the plasma membrane of animal cells is 30-60 mV, while those across mitochondrial inner membranes and plant cells are two- to three-fold higher. Of critical importance to the effect of permeation is whether an ion crosses a membrane alone or with its counterion because an ion that crosses alone may accumulate on one side of the membrane in accordance with Nernst equation and may carry a current. We will explore the factors governing the barrier to ion translocation in studies that encompass synthesis of different types of organic ions, testing with black lipid membrane experiments, computational studies, and applications to drug delivery, to devices and sensors.",0
MR/N007999/1,27352,Ensuring test evaluation research is applicable in practice: investigating the effects of routine data on the validity of test accuracy meta-analyses,"Diagnosis is a difficult process. A patient who presents to their doctor ill will often undergo a process which involves being asked questions, observed, examined and perhaps even having blood or imaging 'tests'. Each question asked or observation made is either a diagnostic test in its own right or part of one and is a necessary part of arriving at a diagnosis.

But some tests are better than others and importantly probably no test is 100% accurate. Sometimes a test result may suggest a patient has normal health when they actually have disease or have disease when they have normal health. This happens to all tests and diagnostic test accuracy research is aimed at evaluating how often this happens, in other words, determining how accurate tests are.

Essentially when a clinician decides upon a diagnosis they are consciously or otherwise invoking a probabilistic process where multiple tests are combined and the patient's diagnosis should be the one most probable given the combination of all the test results. However, for this process to be truly beneficial to the patient the clinician needs to know the accuracy of each of these tests and how likely the patient has disease before the diagnostic process has even started.

This is where the difficulty lies for those who practise evidence-based medicine. Although the accuracy of many tests has been estimated by research studies, for individual tests the accuracy may vary significantly between studies. This variation may depend on who is applying the test, how it is being applied, which patient it is being applied to and most significantly of all, how the accuracy was measured in the study. When there are several studies there are methods which allow us to combine their results. These methods may also help determine the real reasons why the test's accuracy varies. However, in general, the studies report insufficient data of sufficient quality to enable such analyses to be either possible or comprehensive. 
 
Furthermore, from previous work, we have been able to demonstrate that in some cases the test accuracy reported by a study may be virtually impossible in some patient settings. This creates a problem for the doctor. How do they know which estimate of a test's accuracy to use if it varies greatly between studies and risks being nearly impossible for their own practice?

We have already begun to develop methods which make it possible to determine whether results from a test study are likely to accurately represent a doctor's practice in general. This would mean that a doctor could confidently apply the research to their own practice without reservation. However, sometimes the research is not reflective of the different clinical settings seen in practice and a more specific solution is required. This may be done by collecting routine data from the doctor's own setting and using it to determine a feasible range of values for the test's accuracy. This method, in its current form, is used to exclude the studies 'least likely' to derive a plausible estimate of a test's accuracy for the doctor in their own practice.

At the moment both methods are in development but potentially could be implemented into the real-world and used to improve diagnosis. There are clear patient benefits to improving diagnostic performance including reducing the number of patients treated unnecessarily and increasing the number treated appropriately. One of the aims of this research is to pilot integrating this method into General Practice to help diagnose infection. This could also help reduce the potential for antibiotic resistance by reducing the number of antibiotics prescribed inappropriately.

However, before this is done the methods need to be fully investigated to determine their utility and limitations. It may be that other approaches afford greater patient benefit, and an evaluation of these with the methods already described, will be the focus of the proposed research.",0
753477,20150,Cyber Expert,An internal and external data breach test of our systems to ensure that we protect client information both now and into the future.,0
511023,9841,University of Huddersfield and Craftsman Tools Ltd,To embed a systems engineering approach to the automated manufacture of innovative static tool-holding.,0
MR/M00841X/1,394,Improving the presurgical evaluation of patients with refractory focal epilepsy using advanced neuroimaging techniques,"Epilepsy is a common neurological condition affecting around 1% of the population (600,000 people in the UK). Frequent seizures carry risk of injury and death and significant psychosocial consequences, affecting relationships, employment and the ability to drive. There are over 20 medications to treat epilepsy, but a third of people with epilepsy continue to have seizures despite medication.

Surgical treatment of epilepsy in which the abnormal part of the brain is removed is an effective technique to cure or improve seizures suitable for some people with epilepsy. The National Hospital for Neurology and Neurosurgery, with the Epilepsy Society and UCL Institute of Neurology, is the largest centre in the UK undertaking epilepsy surgery (100 operations a year) and has an internationally known research programme to improve the identification of patients for surgery and understand and improve the outcomes.

In order for a person to be suitable for surgery, it is necessary to confirm that seizures are arising from one part of the brain and that it is safe to remove this part. This requires many tests including MRI brain scans. Despite advances in technology, around 30% of people with seizures arising from one part of the brain have completely normal MRI scans. Further investigation with other types of scan is expensive, may involve radiation exposure and is not available in most places, unlike MRI. If imaging cannot identify the source of seizures, recording wires may be placed directly onto the brain surface. This is available in only a few places, is invasive, very expensive and carries some risk.

In my previous research, presented and published internationally, I developed MRI techniques to improve the safety of surgery and understand its effects on the brain. I showed preliminary results in which new MRI techniques could identify the source of seizures in patients with normal MRI scans.

In the first part of this project, I will assess several new MRI techniques to determine which are helpful in identifying the source of seizures in people with severe epilepsy and normal standard scans. I will use new ways of acquiring MRI scans and will work with colleagues in the UCL Centre for Medical Image Computing, with whom I have worked for the last 5 years, and the Montreal Neurological Institute to develop new ways to analyze the scans by computer to detect subtle abnormalities not seen by the human eye.

These developments will enable a larger proportion of people with epilepsy to undergo surgery and be cured or significantly improved from epilepsy. MRI may replace some more expensive and less readily available scans. This will simplify and shorten the investigation pathway so surgery can take place more quickly. Since MRI is widely available at all epilepsy surgery centres, the new techniques can be introduced elsewhere to improve assessment and treatment for people with epilepsy. Understanding of these techniques can also be applied to other conditions such as dementia and stroke.

In the second part, I will build on my prior work using MRI to make surgery safer. I used a special type of MRI scan to identify connections in the brain important for vision and displayed these connections to the surgeon when they were operating so they could treat epilepsy without damaging vision and thus allow people to return to driving. At present, there are many limitations with this and analysis takes a long time. I will improve the technique to give more detailed and accurate images of the brain more quickly. The results and software will be made freely available to allow other centres to adopt the technique.

Overall more people will be identified as suitable for surgical treatment, more quickly and at lower cost using techniques that are applicable to all epilepsy surgery centres rather than just at highly specialised units. A greater understanding of these new MRI techniques will allow them to be used in many other conditions.",0
1940174,28186,Compiler and Architectural Support for Ultra-Fine-Grained Parallelism,"The main idea is to split an application into tiny fragments of code, where each performs a small fraction of the computation of the original program. In the extreme, each fragment would load a value from memory, perform simple computation, then store back. These fragments are then scheduled dynamically onto a sea of low-power processors, based on data flow through the program. The aim is to achieve significant application speedups through parallel execution of the code.
The technique would be achieved by analysing an application during compilation to determine its data dependences. A transformation pass would create the tiny code fragments, then link them together based on their data dependences. At runtime, a pool of ready fragments would be maintained (those with all dependences satisfied), that could be scheduled on any of the low-power processors. Once a fragment had finished execution, it would check its dependent fragments and place any into the pool that had no more unexecuted dependences. There are several challenges to address in order to achieve a functioning and high-performing prototype system. The main challenge is in splitting up an application into code fragments. The optimal size of each fragment needs to be determined, and its composition in terms of the types of instruction it contains. For example, should there be a maximum of only one store in each fragment, are multiple loads a good idea, should some code be duplicated in different fragments? Then, linking the fragments together requires the definition of a binary format and sufficient dependence analysis of the original program so as to keep the number of dependents as low as possible.
At runtime, the main challenge is in an efficient implementation of the pool of ready fragments. The pool could be a global data structure, or local to each processor, or hierarchical. It needs to support fast access. A method needs to be created to dispatch fragments into the pool efficiently, and pop them off again. To schedule fragments, each processor needs to decide whether to take the oldest ready fragment, or one that involves the least data transfer, or one that satisfies some other metric, such as number of dependents. This will be influenced, to an extent, by the implementation of the ready pool.",0
MR/M020134/1,2146,A dynamic insight into the interaction of Chlamydia trachomatis with host cells,"Infection by the bacteria Chlamydia trachomatis, or chlamydia, imparts a large burden on society, particularly amongst young adults. It contributes significantly to the prevalence of sexually transmitted diseases and is a key cause of infertility and preventable blindness. Unlike many other types of bacteria, chlamydia cannot replicate outside of a cell. It is obligated to enter a cell in order to reproduce. As a result, it has evolved the ability to manipulate the environment of the host cell to keep the cell alive for the appropriate length of time; because if the host cell dies too quickly, the chlamydia will also die. In order to develop strategies to tackle this major public health problem, we will need to have a better understanding of what happens to the host cell and to the chlamydia during the infection process. Thus we will use a powerful new technique, which will allow us to accurately determine what happens to host cell and chlamydia proteins, as well as how they interact with each other, over the course of the infectious life cycle. In addition, we want to identify whether the chlamydia prevents the body's immune system or defence mechanisms working properly We think that the chlamydia may influence the types of proteins on the surface of the cell, and change the way the immune system cells react to an infection, so that the bacteria can persist. In order to study this, we will compare the proteins on the cell surface before and after infection. Both these approaches will help us better understand how chlamydia successfully enters cells, replicates and manipulates its environment. This knowledge is critical if we are to devise strategies to prevent humans succumbing to the infection and most importantly, the irreversible damage to the body that results in blindness and infertility.",0
EP/P012442/1,30101,A Novel Deep Raman Spectroscopy Platform for Non-Invasive In-Vivo Diagnosis of Breast Cancer,"Recently, we have pioneered a portfolio of revolutionary optical technologies in the area of laser spectroscopy, namely deep Raman spectroscopy, for non-invasive molecular probing of biological tissue. The developments have the potential of making a step-change in many fields of medicine including cancer diagnosis. The techniques comprise spatially offset Raman spectroscopy (SORS) and Transmission Raman (both patented by the applicants). The methods are described in detail in a tutorial review: http://pubs.rsc.org/en/content/articlelanding/2016/cs/c5cs00466g. There is an urgent clinical need for early objective diagnosis and prediction of likely treatment outcomes for many types of subsurface cancers. This is not addressed by existing technologies. There are numerous steps along the cancer clinical pathway where real-time, in vivo, molecular specific disease analysis would have a major impact. This would significantly reduce needle biopsy, in around 80% of those recalled following mammographic screening this step is unnecessarily - ie leading to the diagnosis of benign lesions. Our novel approach would allow for more accurate and immediate diagnosis in conjunction with mammography at first presentation by improving screening or surveillance techniques, leading to earlier diagnosis and better treatment outcomes. Secondly it would allow surgical margin assessment and treatment monitoring in real-time and thirdly identification of metastatic invasion in the lymphatic system during routine surgery. There are numerous other areas where a rapid molecular analysis of a tissue sample in the clinic or theatre environment would allow improved clinical decision-making, for example when pre- operatively staging the disease and particularly when non-invasively monitoring tumour response during chemo/radiotherapy. Clearly these approaches would be beneficial to the patient by reducing cancer recurrence rates; but also by minimising the numbers of invasive procedures required, thus reducing costs and patient anxiety.
Raman spectroscopy is a highly molecular-specific method, which itself has proven to be a useful tool in early epithelial cancer diagnostics, although in its conventional form it has been restricted to sampling the tissue surface of much less than 1 mm deep. The new technology unlocks unique access to tissue abnormalities of up to several cm's deep, i.e. at depths one to two orders of magnitude higher than those previously possible with Raman.

Following on from our previous project, where we were able to demonstrate conceptually a ~100x improvement in signal recovery compared to our early feasibility work, we are now able to rapidly develop a platform for real-clinical tools using this approach. We propose to make major breakthroughs in this area and advance diagnostics particularly focussed on breast cancer and lymph node metastasis initially as focused case studies and then potentially applied to prostate cancers (outside the scope of this proposal). This will be explored as a joint cross-disciplinary research venture between Profs Stone and Matousek, the two key researchers in this area. We now seek funding to progress this work in a timely manner by developing a novel medical diagnostic platform of major societal impact. We propose to bring together key players from multidisciplinary areas covering physical sciences, spectroscopy, radiology, cancer diagnostic and therapeutic surgery, and histopathology to exploit all of the relevant skills and develop a critical mass of expertise to tackle these challenging issues.",0
1925887,7436,Exploring discourses of smart citizenship in the Oxford Smart City Partnership,"Responding to the ESRC strategic priority of 'ways of being in a digital age' the research will be embedded in emergent literatures on smart cities, big data and citizenship. Smart cities emerge through varying partnerships, stakeholders and trajectories that affect how the 'smart citizen' is constructed. Similarly to Greenfield's (2006) assertion that 'everyware' technology &quot;will appear differently in different places: that is, there is and will be no one continuum of adoption&quot; (p.167), there is not one model for existing nor purpose-built smart cities. A 'top-down' model could suggest an organised strategy between key stakeholders for the end benefit of the smart citizen. Critiqued as a 'high tech' variation of urban entrepreneurialism, Hollands (2015) sees private firm-led smart cities as a 'corporate smart city' where it can &quot;only be effectively delivered through a corporate vision of smartness, in conjunction with an entrepreneurial form of urban governance and a large compliant and accommodating citizenry&quot; (p.62). This raises the potential for conflict as &quot;what if some smart initiative which started out as publicly funded and with social inclusion as a goal, become overtaken by private sector concerns whose goal becomes purely profit-making?&quot; (Hollands, 2008, p.306). The corporate smart city could also be seen as providing the &quot;supporting infrastructure for business activity and growth stimulating new forms of entrepreneurship&quot; (p.2). However, this means the 'smart citizen' could exist within a highly hierarchal strategy with limited involvement in the delivery of the smart city. A 'bottom-up' or community model could be seen as producing the smart city with the smart citizen, rather than of the smart citizen. An example of this is exemplified by the Face Your World project - a 3D simulation environment software where young people in a neighbourhood community in Amsterdam collaboratively designed a city park by uploading images and ideas online for debate amongst each other (De Lange &amp; De Waal, 2013). Through the agency of software, this crowd sourced plan persuaded the local government to abandon their initial plans for the park in preference of its alternative.
Responding to the lack of in-depth empirical case studies (Kitchin, 2015) the research will focus on smart city initiatives taking place in the city of Oxford. This is coordinated by the Oxford Strategic Partnership (OSP) - a set of collaborative organisations across the public sector (such as the city council, the NHS, the police), business (e.g. Unipart), academia (University of Oxford, Oxford Brookes University) and voluntary and community organisations (such as the Oxfordshire Community and Voluntary Action) with the core of its pledge to build on existing 'smart' initiatives and technologies with &quot;rigorous citizen engagement&quot; (Smart Oxford Project Board, 2015, p.18). Examining policy documents and online content from these core actors will provide the theoretical discursive framing embodying meanings of 'smart' and 'smart citizenship' within this strategy. Additionally, attending public meetings from Oxford City Council and Oxfordshire County Council or talks such as those hosted by either university will provide insight to discourses of smart citizenship. Together this will also enable comparative analyses between the academic literature and other smart cities.
Three or more case studies will then be developed in order to explore the diversity of smart citizenship across the projects categorised by Smart Oxford; mobility, energy, sustainability, robotics, innovation. As the OSP will build on current projects (Figure 1, 2015) it may be possible that additional initiatives of interest may emerge while later refining the research design.",0
509555,8010,University of the West of England Bristol and Denby Holdings Limited,To apply pioneering academic research to underglazed tissue printing production to embed an innovative process combining digital technology and traditional craft skills.,0
509702,24667,Kingston University Higher Education and Cubic Defence UK Limted,"To develop a novel, marketable solution capable of guaranteeing seamless, dynamic and reliable wireless communication over multiple communications bearers.",0
753270,25163,Innovative Methods To Deliver Community Mediation Services,Development of a system to help companies and communities grow by jointly addressing creative and social challenges using innovation and mediation.,0
BB/S00033X/1,13500,Delineating the roles of GPR55 in cellular metabolism and energy homeostasis,"The G-protein coupled receptor (GPCR) superfamily play crucial roles in cell communication. As such, they mediate the effects of circulating hormones and other biologically active molecules across the blood-facing membranes of cells to regulate diverse cell/tissue processes including, for example, sensory perception, metabolism and satiety. Given their involvement in neurological disorders, inflammatory and metabolic diseases, diabetes and cardiac dysfunction they represent the largest and most successful class of &quot;druggable&quot; targets in the human body. However, despite the immense current interest in GPCR biology, the function of numerous members of this family remain poorly understood, but which may well represent important therapeutic targets for treatment of major public health issues, such as obesity, diabetes and cardiovascular disease. 

This project aims to explore links between a lipid sensing GPCR, called GPR55, and processes influencing adiposity, inflammation, cardiac function and response to insulin within key metabolic tissues, such as white fat, liver, skeletal muscle and heart. These tissues are major targets for insulin in the body and represent the principal sites where sugar (glucose) and fat are stored and metabolised in response to the hormone. GPR55 is stimulated by a circulating lipid called LPI, which we find improves the response of these metabolic tissues to insulin and also helps lower inflammatory drive in cells derived from them. Crucially, this LPI-mediated response is lost if cells are co-treated with a GPR55 inhibitor. Strikingly, we have discovered that animals deficient in this lipid sensor exhibit reduced tissue responsiveness to insulin, impaired metabolic capacity and a decline in cardiac performance. Metabolic capacity is crucially dependent upon mitochondria; structures within cells representing the cell's &quot;energy generator&quot;. Significantly, animals lacking GPR55 show changes in mitochondrial biology consistent with a reduced ability to &quot;burn&quot; fat. In line with this, we find animals lacking GPR55 develop obesity and that inhibiting the receptor in cultured adipocytes (fat cells) induces proteins that help make more fat, which would augment the process of obesity. Precisely how GPR55 links to the molecular regulation of the above processes is currently unclear. 

The studies described in this application will utilise cells in culture from rodent and human origin as well as mouse tissues for laboratory-based analysis to help dissect out the role GPR55 plays not only with respect to insulin action and inflammation, but in control of tissue adiposity (fatness) and cardiac function. The project will also explore whether GPR55 activation helps mitigate the increase in fat gain, the loss in tissue sensitivity to insulin and cardiac dysfunction in mice fed a high fat calorie diet. Tissues taken from animals at the end of such studies will be processed for biochemical analysis and state-of-the-art whole cell/tissue protein profiling - an approach that will identify which proteins become up- or down-regulated in tissues of mice lacking GPR55 or in cells in which GPR55 has been activated/inhibited with selective drugs. This methodology will generate a wealth of information, potentially unveiling novel proteins that connect with GPR55 to regulate how insulin works or fat is stored or &quot;burnt&quot;. Importantly, the large scale protein profiling may flag-up proteins that have not previously been linked to GPR55, but which may be central to the work of researchers in other fields thus providing an invaluable data resource to the scientific community. 
 
Collectively, our pilot studies indicate GPR55 may function as a novel metabolic regulator within tissues and suggest that understanding how it regulates insulin action, lipid metabolism and cardiac function may offer new pharmacological opportunities for treatment of metabolic disorders associated with conditions such as obesity and type II diabetes.",0
BB/R003068/1,11336,Junctional multiprotein signaling complexes in sensory neurons,"In order to perceive and evaluate the environment mammals are equipped with peripheral nerves (peripheral somatosensory system). These nerves run through our body and collect information about rigidity, warmth and chemical composition of the surrounding milieu and also about our own body's integrity. These nerves are equipped with various molecular sensors that respond to specific external stimuli, transforming these into the uniform electrical impulses ('action potentials') that are then sent to the brain for interpretation. Single somatosensory nerve often expresses a variety of different sensors or sensory mechanisms that respond to distinct stimuli, yet the output signals produced by a nerve are very similar. A major conundrum in the field is how different types of signals are specifically interpreted by a single sensory nerve cells; the main aim of this proposal is to shed light on this question. 

Based on the wealth of preliminary data and published work from our group and others we hypothesize that one mechanism for such intracellular signal specificity lies in the assembly of different intracellular signaling mechanisms into distinct, physically associated protein complexes. Such physical separation of one signaling machinery from another allows them to use common signaling events and messenger molecules without 'mixing up' the meaning of the message. We will focus on one such multiprotein complex which is responsible for body's detection of tissue inflammation (i.e. inflammatory pain). We have already established that there are intricate multiprotein signaling complexes in some sensory nerves that bring together receptors for chemical mediators of inflammation and some signaling proteins that are targeted by these receptors. However, hardly anything is known about the overall constitution of these complexes, functional arrangements of their components, relationships with other signalling mechanisms, whether these complexes are dynamic or static or whether these can be manipulated for therapeutic benefits. Our project aims to answer these intriguing questions. We have three specific aims: 1) to reveal molecular composition of the inflammatory multiprotein signaling complexes in sensory nerves; 2) to elucidate functional significance of these complexes; 3) to develop strategies for manipulations with complex integrity for scientific and therapeutic purposes. 

We developed a comprehensive and multidisciplinary approach in which fidelity, specificity and localization of neuronal communication mechanisms will be elucidated in their complexity. This approach combines cutting-edge methods such as Nobel Prize winning super-resolution microscopy, proteomics, molecular and structural biology approaches and in vivo studies. We are confident that this research will bring our understanding of mammalian sensory systems and, particularly, of inflammatory pain mechanisms, to a new level of insight. Importantly, our findings may shape new approaches for analgesic drug development and pain management.",0
1983536,3388,XRD/Material Science,The research project aims to investigate the application of novel x-ray characterisation techniques for rapid assessment diagnostics in a number of contemporary manufacturing processes.,0
ST/R006105/1,23487,"STFC - Swansea University / TWI Regional B4I Pilot Centre, Wales.","This goal of this proposal is to create a beamline-bridging industry-focussed centre for Wales. A beamline bridge is an activity (supported by local specialist facilities and expertise) that supports (bridges) access to STFC's national level scientific facilities and in particular (but not limited to) the ISIS neutron and Diamond light source beamlines (hence the name). Wales has a higher proportion of manufacturing based jobs than the rest of the UK and has clusters of large numbers of businesses of varying size from anchor companies to SMEs in a variety of sectors from metallurgy and green energy, to health solutions and semiconductor fabrication. However, this region does not access STFC facilities at the same level as similar businesses based in the South and East of England. This activity aims to address this disparity by First: Informing local industry of the capabilities of the local and national facilities and inviting expressions of interest, Second: Aiding in design of experimentation and completing proof of concept studies locally and Third: Supporting access to STFC facilities including post-acquisition data analysis and interpretation. 

The proposed centre will be built on existing facilities and expertise based at both The Welding Institute - South Wales (TWI) and Swansea University's (SU) Advanced Imaging of Materials (AIM) Facility. Together these facilities represent a critical mass of characterisation capability and expertise un-paralleled in the region. However, significant experience serving both local industry and academic partners has highlighted the limitations in capability even of these advanced techniques that can only be addressed at national level facilities, such as those provided by STFC. It is these facilities and this knowledge and experience that TWI and AIM will draw on to support local businesses on their pathway to the beamlines. The centre will employ business development officers (BIBOs) that will initially be seconded to STFC and then return to the region to utilise the contacts and expertise they have acquired to engage local industry, assess levels of interest and support them from proof concept to data analysis. Local industry will be engaged first and foremost via TWIs and SU's own industry engagement mechanisms (representing hundreds of companies in the region). However, BIBOs will publicise the centre's activities at relevant industry conferences and strategic partners EEF (The Manufacturers Organisation -who have a network of 25,000 companies) will broaden engagement significantly.

The centre will be closely aligned to Innovation Wales, Welsh Government's (WG) Smart Specialisation implementation plan with WG as a partner in the centre. The centre will interact with representatives of key clusters identified in this strategy such as the SPECIFIC IKC and the compound semiconductor cluster. Expected direct impacts of the activities include: Increased utilisation of state-of-the-art characterisation facilities with Wales, Increased and improved industrial research and development activity, Increase in pan-supply chain, inter-industrial and industry-academic research activity and critically, Improved utilisation of STFC facilities from within Wales. However, it is also expected that these direct benefits will cascade into indirect impact such as: increased job creation, increased economic output (and GVA) in Wales and contributions to UK technological and environmental targets.",0
753101,1344,Alphakinetic,A web based client portal for highly sensitive investment data to allow fund managers to publish reports to their clients.,0
MR/P008801/1,11484,Viral and cellular regulation of T-cell amino acid metabolism,"Approximately 100 years since it was first transmitted to humans, the Human Immunodeficiency Virus (HIV) now infects almost 40 million people worldwide, and causes more than 1 million AIDS-related deaths every year. It is therefore critical to understand how HIV has been able to replicate and spread, and why HIV infection causes AIDS. &quot;Proteomics&quot; is the large-scale study of &quot;proteins&quot;, the critical building blocks of living cells and organisms. During my PhD, I used proteomics to measure changes in the number and quantity of proteins at the surface of cells infected with HIV, and found that &gt;100 proteins were specifically depleted by the virus. Proteins are themselves made up of long chains of &quot;amino acids&quot;, and many of the proteins I found to be depleted by HIV are involved in transporting amino acids into cells. These amino acid &quot;transporters&quot; are relatively understudied, and may be attractive candidates for new therapies. I therefore wish to understand why amino acid transporters are targeted by HIV, and the importance of these transporters for &quot;T-cells&quot;, the main cells of the immune system infected by HIV and progressively destroyed in patients with AIDS.

Amongst the HIV targets I identified were proteins called SNAT1 and SERINC3/5. I discovered that SNAT1 transports an amino acid called alanine into cells, and that an abundant supply of alanine is essential for normal T-cell function. Likewise, SERINC proteins are thought to incorporate an amino acid called serine into cell &quot;membranes&quot;, which surround cells and separate their interiors into compartments. In the first part of my project, I therefore wish to determine why alanine is important for T-cells, and investigate the role of SERINC3/5 in T-cell serine incorporation. &quot;Metabolism&quot; refers to the chemical reactions which take place in living cells and organisms, and a number of these reactions involve amino acids. In other settings, changes in T-cell metabolism are known to be important in regulating T-cell function. In the second part of my project, I therefore wish to investigate in more general terms which metabolic reactions are altered in HIV-infected cells, and understand how these changes benefit the virus. Finally, in the third part of my project, I wish to combine my skills in proteomics with a new technology called &quot;CRISPR&quot; to identify amino acid transporters and metabolic reactions which are critical for normal T-cell function, even in the absence of HIV infection. Taken together, these data will be a valuable resource for other researchers in the field and will, I hope, lead to the development of new treatments for patients targeting amino acid transporters in T-cells.",0
EP/P019323/1,12107,Next-generation test methods for nonlinear structures,"Many physical systems, whether engineered or natural, undergo sudden changes in behaviour as a physical parameter changes. Examples include the onset of wheel shimmy (&quot;tank-slapping&quot;) in motorbikes, where the front wheel starts to oscillate violently at a critical speed, and aero-elastic flutter in aeroplanes, where an aerofoil starts to vibrate and deform at a critical wind speed. Control-based continuation (CBC) is a method for investigating these types of nonlinear dynamics and bifurcations directly in physical experiments without the need for first deriving a mathematical description of the system. This proposal seeks to advance CBC to the point where it can become a general-purpose tool for use by structural engineers (and in the longer term, wider ranging use by industrialists and applied scientists). Specifically, two aspects of CBC are addressed in this proposal. Firstly, the robustness to noise; any physical system is subject to disturbances (noise), some to higher degrees than others, and CBC must be capable of dealing with these disturbances. Secondly, the scalability to multiple degrees of freedom; physical structures and systems are not necessarily simple and may have many interacting components, CBC must scale well to large structures.",0
2297062,44883,Growing Pains: How do the first galaxies grow?,"My project will aim to use state-of-the-art high-resolution cosmological simulations of the formation of the first galaxies and stars to study the formation and growth of the first galaxies. The simulated data will be used to make predictions and comparisons to available observational data. I will use data from the First Billion Years Simulation, one of the largest simulation of its kind to date. I also have access to a dedicated computing cluster to run additional simulations exploring different physical models.",0
EP/N006895/1,2606,Non-classical paramagnetic susceptibility and anisotropy in lanthanide coordination complexes: a combined experimental and theoretical study,"Rare earth elements are used widely in society and industry in the 21st century. Even your mobile phone contains up to 9 different rare earth elements, harnessing their unique magnetic and optical properties. Advances in the application of these properties requires that we understand better the physicochemical origins of their behaviour. A key part of this process is to develop new theories that test our understanding, and guide us in the design of new chemical applications. 

Of particular importance is the magnetic behaviour of the rare earth elements in their chemical compounds, and the ramifications of the directional dependence of the 'paramagnetism' that arises from unpaired electron density. This behaviour has important consequences not only in the design of new magnetic materials, but also in their use in magnetic resonance imaging (MRI) where they have been used since 1988 as contrast agents to assist in clinical diagnosis of disease. For example, paramagnetic lanthanide coordination complexes are being created as proton chemical shift magnetic resonance probes, in a radical change in imaging technology that directly relates to the importance of imaging technologies in healthcare. 

This multidisciplinary project brings together three teams of scientists with complementary expertise in Durham, Manchester and Southampton to develop and test new theoretical and computational approaches that will promote a better understanding of the magnetic properties of new series of rare earth chemical compounds that are directly relevant to their application in magnetism and their scope for use in MRI.",0
EP/R000441/1,31925,The Calcium-Air Battery,"Energy storage in the form of rechargeable batteries is becoming increasingly important for a range of applications and devices including transportation and grid reserves. Alkaline earth metal-oxygen batteries using the earth abundant metals, such as calcium as the anode and calcium cations as the charge carrier present a low cost and easily raw material resourced high energy storage battery system. They offer much greater energy storage a than present day batteries, such as lithium ion, in addition to their abundance worldwide. In order to achieve progress in the field of calcium based batteries and their subsequent development, mechanistic understanding of the cell chemistry and the required materials, and cell structure, needs to be understood. To evaluated the feasibility of a battery system based upon calcium within the project we will construct Lab-scale test cells that will be tested under an oxygen atmosphere.",0
NE/M015742/1,26380,DISENTANGLING THE MECHANISMS OF ECOLOGICAL SPECIATION IN SYMPATRIC PALM SPECIES,"How species originate and diverge from their progenitor is one of the key questions in biology. Divergence resulting from geographical isolation is a well-known driving force of speciation, but in theory populations could also diverge into separate species in the absence of geographical isolation, a mechanism generally referred to as speciation with gene flow. Documented cases with very high initial gene flow remain rare. Savolainen et al. provided compelling evidence for in situ speciation in a case study of two species of palm in the genus Howea, H. forsteriana and H. belmoreana, strictly endemic to the minute Lord Howe Island (LHI) in the Tasman Sea. Although this case study is viewed by many as probably one of the most convincing examples of sympatric speciation to date, it has still been hotly debated. Speciation in the face of high gene flow would occur most readily when ecological traits under divergent selection (e.g. soil preference or foraging behaviour) and traits associated with assortative mating (e.g. flowering time or body size) are correlated genetically. The two Howea palm species have distinct peaks of flowering time and have contrasting distributions related to substrate preferences: H. belmoreana is restricted to the older volcanic rocks, whereas H. forsteriana grows predominantly on calcareous soils but also on volcanic soils in disturbed sites. Given these features, a scenario for ecological speciation has been proposed. However, although ecological speciation is thought to be a major generator of biodiversity, the genetic basis behind this process is still poorly understood. Here, building on our previous research, we will determine the mechanisms of reproductive isolation in the evolution of sympatric Howea palms and identify the genes underlying speciation.",0
MR/R015031/1,29227,Holistic Approach Towards Unravelling Antibiotic Resistance in East Africa,"The potential harm that increasing levels of antibacterial resistance (ABR) will have on human health is vast, as a consequence the effects of this will be felt across society and at the economic level. It is predicted that by 2050, 10 million lives per year and a cumulative 100 trillion US Dollars of economic output may be lost worldwide. In order to address this looming problem a co-ordinated global response is required to try and halt the rise of ABR. Efforts are underway to tackle the rise in resistance, however agenda-setting is dominated by High Income Countries (HICs) and may not reflect priorities or needs of Low and Middle Income Countries (LMICs), where the levels of resistance and also the types of disease caused by bacteria may be different.

One of the most vulnerable regions to the increase in antibiotic resistance is Africa where, in comparison to other regions of the world, the burden of infectious diseases is highest. The economic, cultural and ethnic diversity of Africa mean that the problems surrounding ABR across African countries are likely be distinct from other regions of the world, and therefore require regional solutions and approaches. For example, the availability of antibiotics can be patchy, and the routes of access to antibiotics are variable (including traditional healers, public and private medical practitioners and over-the-counter antibiotic access). Social, cultural and lifestyle drivers of ABR in Africa also have specific features - closer communal living in cities with variable water/sanitation, and closer animal husbandry in rural communities. 

This project aims to address ABR in Africa and fill the gaps in knowledge. The research will target three main areas that comprise the problem: the bacteria that are antibiotic resistance and cause disease; the amount of antibiotics that are used to treat disease; and the behaviour of humans that governs how antibiotics are used and supplied. The three elements incorporate epidemiological, economic, cultural and societal factors that interact and contribute to the problem. 

Bringing together research covering these 3 elements will provide a holistic view of ABR in East Africa. The project will establish a surveillance network across Uganda, Kenya and Tanzania that is comprised of sentinel sites that monitors and characterized the ABR bacteria that cause disease at that location, maps the use of antibiotics in the sentinel hospitals and the surrounding communities, and captures the behaviour and attitudes of humans that is responsible for their use in these setting. The project also recognises antibiotics are not exclusively used for human medicine, therefore our surveillance will also cover the use of antibiotics in veterinary medicine in the linked communities to provide a 'One Health' view. Using a multidisciplinary approach, encompassing, microbiology, genomics, epidemiology, statistics, social sciences and geography, we will seek to explore and describe the relationships between the elements, and identify the drivers of ABR.

Using this knowledge, we will identify interventions, such as public health and infection control measures and legislation changes, that can be made to control ABR at national and regional level. At the global level, the output of this project will add to the worldwide picture of ABR. This information will also be of value to global development agencies such as the WHO and FAO, to direct funding into effective interventions critical to the region.",0
2266595,38273,A Defence of the Cognitive Value of Contemporary Avant-Garde Art,"My project will critically examine the cognitive value of contemporary avant-garde art. This project seeks
to answer two questions:
1. Why is 'avant-garde' an appropriate concept to capture certain critical practices of contemporary art
for art history and philosophy?

2. How can contemporary philosophy, particularly epistemology, help to explain the cognitive ambitions
of contemporary avant-garde art?
Certain practices which have reached maturation after 1989 have sought to expand the formal
boundaries of art in order to challenge viewers to shift their thinking about the world they inhabit. In this
way, they have ambitions that are continuous with those art historians demarcate as 'avant-garde'.
Current philosophy of art struggles to account for this work. Philosophical tools must be developed to
offer better analyses.
The novel answer that I propose is to focus on how these practices seek and succeed in shifting our
epistemic standing in the world by contributing to our understanding. This is exemplified by how these
works guide our imagining, and reveal marginalised epistemic positions. Grasping the cognitive value of
contemporary avant-garde art will help to bring advanced philosophical work into connection with
advanced art practice.",0
BB/S009329/1,1432,Reverse engineering cell competition using automated microscopy and recurrent neural networks,"The aim of this project is to use state-of-the-art machine learning (ML), automated time-lapse microscopy, and proteomics to understand cell competition. Cell competition is a phenomenon that results in the elimination of less fit cells from a tissue - a critical process in development, homeostasis and disease. The viability of loser cells depends strongly on context: when they are cultured alone, they thrive, but when in a mixed population, they are eliminated by cells with greater fitness. In development, competition acts as a quality control mechanism and also participates in pattern formation. In ageing, competition may eliminate senescent cells from tissues to prevent age-related pathologies. In stem cell niches, competition may determine which cells differentiate and which remain pluripotent. 

A number of mechanisms of cell competition have been identified to date involving either biochemical competition (for example through competition for pro-survival growth factors) or mechanical competition (for example a fast growing clone compresses cells in a slow growing clone, which results in cell extrusion for the now denser slow growing clone).While competition was initially thought to take place only at the interface between cell lineages, the discovery of mechanical competition revealed that this is not necessarily the case and that extrusion may take place several cell diameters away from this interface.

To date, the vast majority of studies have examined the biochemical mechanisms of competition in single cells and competition at the population level, however it is becoming increasingly clear that the topology of the tissue plays a central role in determining the outcome of competition. Despite this, cell competition remains poorly understood -- we do not know the interaction &quot;rules&quot; that determine each cell's fate. This is largely because most studies only quantify whole population shifts for very few time points and for few cells. 

One major obstacle to understanding how population shifts occur as a result of single cell behaviours is that it requires thousands of cells to be tracked over hundreds of time points. To address this challenge, we recently built the first deep learning and automated single-cell microscopy system to analyse cell competition. We used deep convolutional neural networks to analyse the cell cycle state of millions of single cells in mechanical competition, including cell division and death.

In this project, we will use the full scope of the information contained in our time-lapse data to determine the physical and topological parameters that govern cell competition. We will develop a deep learning approach to extract time-dependent features of a single-cell's environment that predicts its fate in biochemical and mechanical competition. We will use the ML model to determine what physical and topological features govern cell competition. We will combine ML and proteomics to identify proteins involved in the commitment pathway, determine their hierarchy in the signalling cascade, and identify convergent pathways.",0
2271319,40289,Student is currently enrolled on the Taught Masters part of the 1+3 course and will decide on the PhD project details in September 2020,"Core modules to be taken during MSc year are as follows:
MA930 - Data Analysis and Machine learning
MA933 - Stochastic Modelling and Random Processes
MA934 - Numerical algorithms and optimisation
MA999 - Fundamentals of Mathematical Modelling
MA931 - MSc Project
MA932 - MSC Research Study Groups",0
EP/R021252/1,28344,Fast and Flexible Imaging of Excitable Tissues,"Optical microscopy is an essential tool in biology. However, biomedical researchers are limited in the types of problems they can address with the imaging tools available in the vast majority of laboratories. Our understanding of the way in which complex tissues such as the heart and brain function is confined by the capabilities of commercially available light microscopes. Specifically, the limited speed with which cells and other features of interest can be imaged within a three-dimensional volume restricts our understanding of the electrical communication between networks of cells which occur on a broad range of time scales. Acquiring image data from the entire tissue volume is slow and leads to a secondary problem of processing the vast quantities of data to isolate those cells and networks of interest. These technical constraints limit the range of behaviour that can be observed in both healthy and diseased tissue. 

This project will for the first time give researchers the ability to efficiently capture user-defined features of interest within a three-dimensional tissue volume. Light sheet microscopy sends a pencil of light into the sample and rapidly sweeps this back and forth to create a sheet of light. A detection lens then focuses on this sheet of light to relay the specimen image back to the science camera. However, by scanning the focus of the detection lens in concert with tilting the sheet of light, it is possible to image the specimen over a wide range of angles without the need to adjust the position of the camera or the detection lens. Previously, to capture two cells within a specimen that are located at different depths, the microscope would capture many images covering the range of depths between the two objects. Much of this information would not be useful. By using a tilted illumination plane, it is possible to capture both cells in a single image. This has several benefits: (i) the data required to see both cells is much smaller and easier to manage (ii) the data does not need to be processed in a computer before being able to see both cells clearly (iii) because the cells can be captured in a single image, they can be observed at much greater speed. This last point is particularly useful when trying to measure electrical communication between two cells, which can happen in just a few milliseconds. 

Observing short time scale communication between heart and brain cells is crucial in furthering our understanding of how disease develops and progresses. By providing flexibility in the way microscopes capture images it will provide a new window into the normal behaviour of these excitable tissues and thereby provide clues as to how to limit or stop disease progression through medical intervention.",0
1924625,22238,Citizens of the world as Citizens of Nowhere? Students' Narratives of National Belonging in an Economically Elite Transnational Educational Space,"This proposal seeks to understand young men and women's sense of national belonging, when their school and it's members are part of various 'elite' groupings within a transnational space. Doing so loactes these subjectives within and beyond national clas structures and borders, extending scholarship that has examined how national fields of power shape meaning-making processes.",0
2275088,43893,Enhancing the Sustainability of Aluminium Production and Products,"This project is associated with the EPSRC LightForm programme grant (http://lightform.org.uk/), led by the University of Manchester, in collaboration with Cambridge University and Imperial College. The overall goals of LightForm are to develop the enabling science to embed materials engineering into manufacturing practice, driving improved performance and sustainability in applications of Al, Mg and Ti alloys.
This DTP-funded project is in collaboration with Norsk Hydro (Norway and UK), who are providing a CASE top-up. As the Al industry strives for an increasingly circular economy, there is an urgent need to address the implications of impurity build-up on the formability, microstructure and final properties of wrought alloys. The objectives of this project are: (a) targetted experimental and modelling work on the sensitivity of key process steps to specific impurities, e.g. extrudability, sheet formability and age hardening of 6000 series alloys containing increased levels of Mn; (b) exploration of the potential for &quot;alloy compensation&quot;, i.e. further alloying additions that counteract the detrimental effects of higher impurity levels in wrought Al alloys.",0
MR/N015355/1,26385,Early life DNA methylation patterns linking intra-uterine events to adverse cardiometabolic outcomes,"Complex diseases are typically caused by a mixture of genetic, environmental and epigenetic effects. A number of prenatal risk factors, including intra-uterine growth restriction (IUGR) and gestational diabetes mellitus (GDM), have been shown to determine signatures in the blood methylome. However, most studies on this topic fall short are underpowered, or fail to take genetic effects into account to investigate causality. Birth cohorts with multiple tissue samples and deep phenotyping offer an opportunity to investigate the interplay of genetics, epigenetics and the environment affecting foetal and child growth. Moreover, my project aims to specifically determine which changes in DNA methylation are causal to subsequent disease states by combining genetic and epigenetic data in Mendelian Randomization experiments. The discovered results can then be used to develop biological tools to detect children at risk stratify risk groups and develop prevention strategies. 
 
The work I propose to undertake follows on from my recent research in cross-sectional epigenome-wide association studies (EWAS) for T2D and obesity In adults (Wahl*, Drong* et al. under review). However, I have found previously that most of the strongest signals of methylations associations display a reverse causal relationship. I am thus interested to investigate the influence of early-life events, such as foetal growth and gestational diabetes (GDM) on patterns of DNA methylation. To achieve this, I aim to employ quantitative skills to develop robust methodology to take into effect confounding effects from experimental confounders (mixture of foetal/maternal tissues), maternal/paternal genotypes and to develop a robust, reusable pipeline for Mendelian Randomization in birth cohorts. Ultimately, I aim to link epigenetic markers both identified for GDM and IUGR with future health outcomes, and develop biomarkers for the effects. 
 
Firstly, I aim to apply my analysis methodology to utilise the rich data sets curated by the proposed research sponsors to detect associations of DNA methylation with a number of phenotypes. I will perform a large scale EWAS case/control studies for GDM. Secondly, I will lead for the analysis of epigenetic data from biological samples for IGUR in the INTERBIO-21 study. This includes development of the experimental designs for large-scale epigenome-wide association scans. Lastly, I will be utilizing genetic variants as instrumental variables in two-step Mendelian Randomization to determine whether epigenetic markers are in causal pathways linking intra-uterine events to the child's phenotypes. Thus I will apply an informed approach about causality to separately detect genetic associations to avoid bias and will be able to detect maternal genetic and epigenetic confounding. 
 
This will allow me to be in a unique position by extending the scope of simple cross-sectional EWAS to include not only causal analysis, but also a robust characterisation with respect to biological and technical confounders. 
By focussing my hypothesis on causal pathways, my work can filter out reverse-causal confounders facilitate personalised prevention and novel drug target discovery. If successful, my research will provide accurate tools to guide childhood interventions through early biomarkers of the intrauterine environment.",0
ES/M01147X/1,26603,"The Analysis of Non-stationary Time Series in Economics and Finance: Co-integration, Trend Breaks, and Mixed Frequency Data","Macroeconomic and financial time series are typically non-stationary (or unstable), in that their means, variances and autocovariances evolve over time, such that standard multivariate time series models can only be validly applied to the changes in these variables. Such models, however, contain no information about any long run relationships between the series, as are often predicted by economic or finance theory. A solution is provided by co-integration analysis which recognises that certain combinations of the variables are stationary (stable). A key example is term structure data, where it is often found that while individual interest rates appear to be unstable, the spreads between the rates appear stable.

Practical co-integration analysis is complicated by the fact that economies periodically undergo episodes of structural change, such as stock market crashes or changes in government regime/policy. Empirical evidence suggests that these episodes often manifest themselves in the form of multiple changes in the underlying deterministic trend component of the variables and/or changes in the volatility of the unanticipated random shocks. Extant co-integration tests can result in misleading inference regarding the presence or otherwise of long run relationships between the variables when these forms of structural change are present. This will typically result in misspecified econometric models with poor forecasting ability. It is therefore important to develop new co-integration tests which can deliver reliable inference in such environments. Doing so constitutes the first part of this project and will involve the development of a new simulation-based (bootstrap) procedure.

In light of the recent financial crisis, attention has increasingly focused on understanding the interactions between the macroeconomy and the financial sector. To do so effectively, econometric methods are needed that are capable of handling the mismatch between the frequencies at which data on the financial sector (eg exchange rates, stock prices) and the macroeconomy (eg GDP) become available, and this constitutes the second part of the project. While financial data can be observed at very high frequencies, macroeconomic data are typically available only monthly at best. The vast majority of methods for modelling multivariate time series assume a common sampling frequency; this typically entails discarding information in the high frequency data by converting it to the lowest frequency. However, high frequency financial data contains information that can affect the future time path of the low frequency data, and its utilisation can enable policymakers to act promptly prior to the macroeconomic data becoming available. For example, a financial crisis can be observed long before its effects on GDP are observed, but the ability to predict what those effects might be, using an econometric model capable of dealing with mixed frequency data, can be an important aid to policy making. Methods to allow for structural changes when dealing with mixed frequency data will also be considered.

The theoretical development, to be conducted using large sample econometric theory, will exploit the expertise and experience of the applicants. Taylor has already examined the behaviour of non-constant volatility on co-integration tests which do not allow for structural change in the trend. Chambers has recently developed methods of combining mixed frequency data that preserve the underlying relationships between the series and has also analysed co-integrated systems under temporal aggregation. This project will build on these foundations.

The practical relevance of the theoretical results will be explored using simulation experiments. We will also provide clear guidance to empirical researchers, through worked examples on key international datasets, and make freely available computer programs, to facilitate the implementation of the new techniques.",0
ST/N003217/1,14225,Neutrino Scattering R&amp;D for CP Violation Searches,"The predominance of matter over antimatter in the universe points directly to the existence of some currently hidden laws of physics which are different for matter and anti-matter. One focus of the search for these new laws is the recently-discovered phenomenon of neutrino oscillations. Searching for these new laws of physics will require comparing the oscillations of neutrinos and anti-neutrinos. In neutrino oscillation, the internal quantum mechanical properties of neutrinos---specifically the mass and the flavour---interfere with each other. This allows a neutrino created as one flavour to be observed as another flavour. In the next generation of neutrino experiments, we will compare muon neutrino to electron neutrino oscillation to noun antineutrino to electron antineutrino oscillation. Doing so is the best way to explore charge-parity (CP) symmetry, which stipulates that antimatter should behave just like matter if viewed through a mirror and upside down. CP violation in neutrinos would manifest itself as antineutrinos oscillating differently than neutrinos, and if this happens it is a strong clue as to the origins of the matter/antimatter imbalance in the Universe today.

Neutrino oscillation measurements depend on accurate knowledge of neutrino interactions with the target nuclei used in neutrino detectors. This R&amp;D is dedicated to developing a new type of neutrino detectors based on high pressure gas. This will allow us to look at neutrino-nucleus interactions in more detail than ever before, and will give us much more accuracy on neutrino oscillation measurements.",0
EP/P031250/1,19521,MechAscan - A novel on line mechanical assessment tool for manufacturing engineered tissues in regenerative medicine and drug discovery.,"The proportion of people around the world aged over 60 years is growing faster than any other age group, as a result of longer life expectancy. This population ageing can be seen as a success story for public health policies and for socioeconomic development, but it places a challenge on medicine and, within the UK, the NHS to maximize the health and functional capacity of older people. Regenerative Medicine is one potential solution for this longer life and healthy lifestyle, providing cell based therapies which can replace damaged or diseased tissues. Growing replacement tissues is bringing exciting novel solutions which now require new manufacturing methods and processes to enable the translation to the clinic. Bioreactors are mechanical devices that provide controlled growth environments for engineered tissues and mimic the physical forces cells and tissues experience in the body. Monitoring the maturation of tissue implants during culture, and prior to implantation into the patient, is important for defining optimum manufacturing criteria and for their clinical success. Key properties that tissue engineered implants must display include strength and durability. To infer material properties from imaging, new non-destructive, three-dimensional imaging techniques are needed, that can be used to provide accurate results efficiently at both the manufacturing site and the clinic. In this proposal, our partners have linked the imaging technique, optical coherence elastography, with a hydrostatic pressure bioreactor to create a novel imaging solution, MechAscan, which allows real-time mechanical characterisation and simultaneous physical stimulation of engineered tissue implants. MechAscan will provide a clear advantage over currently available traditional mechanical testing approaches and elastography techniques, which require direct contact of the mechanical load with the sample and are destructive. Additionally, MechAscan can be used for real-time monitoring of mechanical properties as the construct is grown in culture in a sterile growth environment. Our aim is to develop a novel technology platform allowing real-time and non-destructive monitoring of tissue engineered products in a sterile growth environment to avoid construct to construct variation during manufacturing and allow the translation of regenerative medicine constructs with known properties into the clinic. To facilitate uptake in use of the technology and translation to the clinic, we propose to fully test and validate the MechAscan technology in an interdisciplinary approach combining bioreactor technology, biomaterials science, physics and mathematics.",0
EP/P007910/1,1595,A Spatio-chromatic colour appearance model for retargeting high dynamic range image appearance across viewing conditions,"This project will investigate human perception in the context of novel high dynamic range display technologies. Specifically, it will devise and validate a new model of spatial colour vision that will support detailed analysis and prediction of how content on new displays will be perceived. Such a model can then be used to automatically process images so that their appearance is preserved when presented in a significantly different manner: at different brightness levels (display dimming), at different contrast (tone-mapping, ambient light compensation), under different viewing conditions (dark cinema vs. bright living room). The model will also be able to take into account potential individual differences in observer sensitivity and implement the effect of age-related changes in the visual system.

To build such a model, a large dataset of colour appearance data will be collected from both existing sources and from new measurements. A new method will be devised and used to take new measurements only to fill in the &quot;gaps&quot; in the dataset, where information is the sparsest. The new appearance model will be created by simultaneously training and testing a large collection of candidate models, which will be tested for overfitting using information criteria. The candidate models will further help to identify the gaps in the existing dataset and will thus direct collection of new data. 

The model will be tested in novel applications, such as adjustment of image appearance depending on the user's visual performance (age adaptive rendering), and adjustment for display brightness, contrast and ambient illumination (display adaptive rendering).",0
1889071,9460,"Students in London: Universities, Knowledge Economy and the Urban Experience","London is frequently conceptualised and marketed as a 'global hub' of knowledge and creative industries (Lucci and Harrison, 2011; Togni, 2015); a status heavily reliant on higher education institutions (Olsen and Peters, 2007). Proponents of 'creative city' policy and ideology have positioned universities as key components of a strong urban economy, due to the 'super creative core' of individuals they attract (Florida, 2003: 5). Further, universities are increasingly considered to be central tenants of regional or national 'knowledge economies' (Goddard, 1999). It is clear that certain institutions recognise this, and fully embrace their role as 'creative powerhouses' (Goldsmiths, 2016). London, a city widely advertised for its 'cultural pre-eminence' (Mayor of London, 2014), largely dominates the internationalised higher education sector in the UK. University College London recruited more international students than any other UK Higher Education Institution in 2014-15 (UKCISA, 2016), and six of the UK's top twenty universities with most international students are based in London. Moreover, four London institutions grace the QS World Rankings' top fifty universities (QS, 2016). London is a key component of its universities' marketing strategies, who utilise concepts such as 'creativity' and 'the knowledge economy' to promise an exceptional student experience in the city. However, students' experiences of London appear to contradict these portrayals. Only one London-based university (the Royal Veterinary College) features in the top fifty Times Higher Education's 'Student Experience survey'. These results are based on '21 key provisions' (QS, 2016), many of which relate to the institution's local area. London is portrayed as a creative destination brimming with possibility and knowledge: how do students' experiences of London correlate with or contradict these messages?
This proposal approaches the question of students' experience in London from three perspectives: it critically engages with how and why universities and other bodies utilise specific terminology or concepts to represent London; it explores the impact this has on students, and it will produce recommendations which assist institutions and related stakeholders to support and enrich students' experiences. The following are indicative research questions:
1. In what ways is London represented as a cultural, creative or knowledge destination by universities and other actors engaged in the higher education sector?
2. How and to what extent do these portrayals of London as a centre of creativity and knowledge influence students' perceptions and expectations of London universities? 
3. How can universities and associated stakeholders support and enrich students' experience of London?",0
752374,13743,Healthinnova - Physiotherapy Innovation,"&quot;The idea is around using modern video games to aid in physiotherapy and rehabilitation of young people. For children and young people recovering from a physical
injury, rehabilitation involves regular, repetitive exercises which are often considered boring or painful. The lack of motivation results in the inability to follow the regimen and subsequently, longer recovery periods. The intention is to evaluate modern technologies and whether the 'gamification' of therapy, using easy to use, easy to procure games on digital
media.&quot;",0
NE/S012877/1,45840,Geodynamics and Tectonics Plate Analysis based on Distributed Optical Fibre Acoustic Sensor,"Megathrust earthquakes have long occurred repeatedly in Japan. Since 2011, an oceanic observation networks constituted by point sensors connected by optical fibres have been developed to monitor seismotectonic activities in this region. In this project we expand the seismometer capabilities by using the optical fibre network itself as a distributed seismometer providing thousands of high resolution seismic measurements aimed at clarifying the source of the very low frequency earthquakes based in the accretionary wedge between the Philippine Sea Plate and the Eurasian continent, which were discovered by the DONET stations in 2015.
After initial tesing in JAMSTEC own fiber optic cables off Toyohashi, Aichi, Japan and Hatsushima, Shizuoka, Japan, a portable unit will be manufactured and will be taken on the research vessel R/V Shinsei-maru to be connected to the 10 km fibre optic extension cables via a fibre optic cable of the shipboard remotely operated vehicle. The novel distributed seismometer will be tested in the DONET stations to produce a 3D map of seismic activity along the Nankai through and investigate possible links links with the structure of the subducting plate interface.",0
132678,6611,Evaluation of the technical &amp; commercial viability of developing an accelerated MERS vaccine,"Anglo Biopharma Ltd, a UK based british biotech startup, will assess both the commercial and technical potential of a Middle Eastern Respiratory Syndrome (MERS) vaccine. An evaluation of the commercial viability of a novel MERS vaccine towards MERS will be performed. MERS is a disease described by the director of the World Health Organisation (WHO) as a &quot;a threat to the entire world&quot;. Anglo Biopharma in colllaboration with the University of Reading will assess the potential of University's baculovirus platform's potential to generate novel vaccine antigen candidates.",0
2093560,20904,The Development and Use of Elastic Resonators and Optogenetics to Study Locomotion in Small Soft-bodied Animals,"Terrestrial animals with hydrostatic skeletons solve complex motor problems by orchestrating how their soft bodies compress and deform in order to interact with the substrate. Previous studies have made progress in understanding how these animals perform this action flexibly over a wide variety of substrates by researching large animals such as Manduca sexta caterpillars. However, progress has been limited by the insufficient tools to simultaneously record the animal's behaviour from a neuromuscular, behavioural and actuation through forces perspective with high spatiotemporal resolution. Recently, a technique, elastic resonator stress interference microscopy (ERISM), was developed in order to allow for the imaging of migratory forces on a cellular level using the interference of light in a deformable elastic cavity. This technique uses an elastomer between two gold mirrors, the length of which determines the resonant light wavelengths within this cavity. As cells produce forces the cavity deforms, thereby decreasing the overall length, thereby shifting the local resonant wavelengths. Thus, for each given cavity length, the pushing and pulling forces on the substrate can be determined by examining this shift in local resonance. Until recently, this technique did not have the requisite time resolution for resolving beyond the 0.5 Hz region, however, this technique was developed to make use of fewer wavelengths in order to allow for imaging of forces within the 10 Hz timeframe - although this technique is still limited to recording cellular forces. This project aims to develop ERISM to allow for recording forces from small animals by making use of an elastomer with a greater elasticity modulus (20-60 kPa) and to combine it with epifluorescence microscopy to allow for simultaneous force measurement and fluorescence activity measurement. Developing this technique will allow us to observe the forces produced by soft bodied animals. One such animal, Drosophila melanogaster larvae, has a history of almost unrivalled genetic control through use of the Gal-4 UAS system. This animal will allow us to study the simultaneous contraction of muscles via genetic tools such as expressing fluorescent proteins in each of its muscles or by expressing genetically encoded calcium indicators (GECIs) directly in its nervous system to observe neuromuscular activity. This genetic tractability also allows us to express ionophores directly in the specific cells within the nervous system - allowing for optogenetic control of specific aspects of the animal's locomotor behaviour. These larvae also grow within an interesting scale, growing from the size of the largest of cells to the size of the smallest of animals over the course of mere days. This means they have to solve both micro and macro domain problems using the same body. Thus, this study aims to develop two-wavelength ERISM to allow for the utilisation of the full genetic toolkit of Drosophila melanogaster and will be important in understanding both ordinary locomotor behaviour of soft-bodied animals, but also may offer insights into the behavioural phenotypes of Drosophila melanogaster disease models - allowing for a dynamic study of impaired neuromuscular actuation found in Parkinson's models.",0
AH/N007573/1,12595,Editing Aphra Behn in the Digital Age (E-ABIDA),"Through systematically integrating digital and established methods, E-ABIDA will produce and disseminate a new, comprehensive edition of Aphra Behn (1640-89), one of the most important English Restoration writers, and one of the most significant women writers in any age or nation. Celebrated by Virginia Woolf as the first Englishwoman to earn her living by her pen, Behn was a leading dramatist, a pioneering author of prose fiction, a skilled poet, an influential literary editor, and a successful translator of poetry, fiction, and philosophical and scientific prose. Her diverse writings address such matters as the challenges facing women writers; colonialism and slavery; the cultural legacy of the classical world; scientific innovation; politics; and sexuality (on which she wrote with a frankness unmatched by any woman of her time). She sustained a 20-year career in the competitive London theatre, worked with leading writers such as Rochester and Dryden, and was published by eminent booksellers including Tonson. Few other writers of any period match these remarkable achievements across multiple genres, or were as well connected in the cultural institutions of their time. Her importance is recognised both by The National Archives (TNA) and The National Theatre (NT), who will work with E-ABIDA to mount a public exhibition about her work as a spy, and to stage one of her plays.

E-ABIDA will integrate digital and standard editorial methods so as to facilitate the swift production of a new Behn Complete Writings for publication by CUP. This will be both print and electronic (with the latter available in both old- and modern-spelling). Generously annotated, it will be accessible to both specialist and general readers; print-on-demand, modern-spelling selections will be available, enhancing its attractions to teachers and theatre companies. The edition will be based on a complete re-evaluation of Behn's literary canon, which includes several texts of contested attribution. The existing standard edition (ed. Todd, 1992-6) was produced with limited means and predates modern digital resources; pioneering in its day, it is lightly annotated, and inadequate to 21st-century needs.

A key dimension of the project is its integration of standard and digital methods, facilitated through a digital workspace. In Phase 1, the software on this platform will facilitate collaboration between contributing editors (CEs) by alerting them when other editors are working on cognate problems. It will also enable the General Editors (GEs) to oversee progress on the various works. In Phase 2, a public-facing website will be added, including: a searchable dataset of Behn's works; materials showing how scholarly editions are made; virtual representations of Behn's connections with theatres, printshops, coffee-houses, and other institutions. Study Packs for schools and workbench tools will be made available as a resource for other editorial projects.

To produce a global Behn edition for the 21st century requires a collaborative team of international, interdisciplinary scholars. E-ABIDA brings together exactly that, with CEs from Britain, France, Austria, North America and Australia. The PI, Co-Is, and RA1, based at two universities, have complementary research interests in literature and language, theatre and book history, and digital humanities. They span the career stages from PDRA to professor, and have worked together since 2013 to build partnerships with TNA and NT and to plan the edition's methods. Behn's works not only span a wide range of genres and subjects but also - given their engagement with New World exploration and exploitation, the relationship of literature with science, cultural difference and dialogue, and translation - have a strong worldwide appeal and present-day resonance. E-ABIDA will ensure this global recognition.",0
BB/R020027/1,22345,Sustainable interventions for an emerging livestock disease problem in Tanzania,"This project has been developed in response to concerns of livestock-keeping communities who have reported major mortality losses in sheep and goats due to an emerging disease problem, known locally as Ormilo. Our preliminary studies support a growing consensus that Ormilo is the disease cerebral coenurosis, a fatal, neurological disease of sheep and goats caused by a tapeworm infection (Taenia multiceps). Sheep and goats are infected by ingesting the parasite eggs shed in the faeces of dogs (the definitive host), with clinical disease occurring when the parasite larvae migrate to the brain and form cysts. Dogs are in turn infected when they consume the brains of affected sheep and goats. 

Current levels of coenurosis appear to be unprecedented and a cause of major concern among the poorest livestock-keeping families, particularly pastoralists who are increasingly dependent on sheep and goats for livelihoods and food security. Ormilo is now ranked as the highest priority disease in most pastoral communities of northern Tanzania. Several factors may be contributing to the current upsurge in cases including a shift to keeping of small ruminants in preference to cattle, a rapid increase in dog populations, and the practice of livestock-owners of feeding dogs the brains of affected animals.

This project aims to develop simple, sustainable interventions that can be adopted easily by livestock-keepers and dog-owners to prevent infection and reduce the burden of disease. The project will focus on two interventions: (a) developing and disseminating culturally-approrpriate information to livestock-keepers on the life cycle of the parasite, and the importance of not feeding brain tissue to dogs (with burning a simple alternative); (b) anthelminthic treatment of dogs with praziquantel every three months. An important additional benefit of de-worming dogs would be the effective control of Echinococcus granulosus, the cause of human hydatid disease (cystic echinococcus), a potentially fatal disease which is known to be an important but neglected human health problem in pastoral communities of East Africa. With a similar life-cycle involving dogs and small ruminants, hydatid disease may also be increasing, but cases will not become apparent for several years. An effective intervention in dogs at this stage could avert a major future human health problem.

The final output of the proposed project will be a business development plan, which charts a subsequent course of remedial Ormilo intervention. The plan will depend to a large extent on whether Ormilo is a localised or widespread/regional animal health issue and the willingness of farmers to pay for praziquantel treatment of dogs. Market research to better understand the scale of the Ormilo problem and demand for interventions will involve analysis of detailed Ormilo prevalence data being generated through other on-going studies, household econometric and wilingness-to-pay studies, as well as stakeholder workshops. Further work will involve development of materials for dissemination to livestock-keeping communities and training courses for NGOs and animal health professions. By working with project partners with experience of developing solutions for livestock interventions (GALVmed), we will explore both NGO-based delivery strategies and market-led approaches through which animal health supply chains could be developed for delivery of praziquantel to a large population of livestock-keepers, potentially extending to countries in the East African region (eg. Kenya and Ethiopia).",0
2009354,17023,Computer Vision and Machine Learning for Digital Pathology,"This project aims to develop and validate algorithms and software that can be used to efficiently extract useful information from histopathology images now produced in very large quantities by hospital pathology departments. Microscopic examination of very thin sections of stained tissue by expert histopathologists is used in diagnosis, treatment selection, and in research to help further our understanding of diseases such as cancers. However, there is an ever-growing need for automated methods for quantitative analysis of images of these tissue sections so that the information they contain can be extracted and mined at scale, and ultimately used to improve diagnosis and treatment. The student will develop and apply deep learning and computer vision algorithms to automatically detect and segment structures of interest in histology images so that they can be quantified in a reproducible and high-throughput way. The student will benefit from inhouse
software and algorithms developed in our previous related research, e.g., in breast tumour segmentation [1], gland segmentation in colon cancer [2], and discrimination of dysplastic changes in colorectal polyps [3].
This is an interdisciplinary collaboration between Computer Vision &amp; Image Processing (CVIP) in the School of Science &amp; Engineering, and Pathology at Ninewells Hospital and Medical School. The PhD student will benefit from access to both technical and clinical expertise. The CVIP research group has considerable experience developing novel methods for biomedical image analysis applications and has won several recent international contests in this area. Our graduated PhDs find work in other prime academic research groups (e.g. UCL, Edinburgh, Toronto) and companies (e.g. Toyota, Toshiba, OPTOS plc).",0
104703,34785,Automated football action event detection,"The automated football action event detection technology will help to improve access, at all tiers of football, to data needed for player performance analysis and talent identification. Advances in computer vision, motion detection and cloud computing will enable this technology to bring greater access to performance data for football clubs, football academies and national football governing bodies. This will be achieved by overcoming the existing challenges include the reliance on the labour-intensive process of obtaining football data due to manual logging of match actions; accuracy, consistency and comparability in the data due to human judgements, and the inability to accurately detect the body pose of players from a single camera angle.",0
EP/N023668/1,26640,QuantifyTBI: A Machine Learning Approach to Automatic Segmentation and Quantification of Lesions in Traumatic Brain Injury Imaging,"Traumatic brain injury (TBI) has been characterised as the most complex disease in the most complex organ of our body. TBI is defined as a pathological change in brain function caused by strong external force, commonly induced by falls, assaults, car traffic accidents, sport injuries, or the blast of an explosion in military combat. TBI has been estimated to affect over 6.8 million people per year worldwide and is the leading cause of disability and death of young adults in developed countries. The high number of incidences puts a major socio-economical burden on public health. A recent estimate of the total costs of TBI in Europe, excluding non-hospitalised patients, produces a figure of 33 billion Euros. The biggest cost, of course, is paid by the millions of patients and their families, who live for years with long-term consequences of TBI. Medical imaging combined with advanced computational methods have the potential to improve TBI care by supporting the critical tasks of early diagnosis, prognosis, and treatment. Imaging has been established as the primary tool for visual, non-invasive assessment of TBI both in critical care, and short- and long-term follow-up. However, the current use of imaging for TBI assessment is limited to manual, qualitative and often subjective inspection of the images. This motivates the main objective of this project which is the development of software tools that enable the automatic extraction of clinically useful information to improve care for patients with TBI.

The project QuantifyTBI explores computational methods, in particular machine learning approaches, to analyse and quantify brain scans of patients with TBI. Specific algorithms and software tools are developed that allow doctors to more objectively and accurately assess the severity of head injuries and monitor the progression during treatment. The main focus is to develop software that allows to automatically derive quantitative measures about TBI lesions from the patient's brain scans. Such measures include the number of lesions, the type of lesions, their size, the location, and the ratio of affected brain tissue. An accurate and comprehensive image-based quantification is essential for developing personalised treatment strategies, supporting diagnosis and monitoring disease progression. It also helps to better understand TBI from a clinical perspective, and will eventually lead to better treatment and improved outcome of TBI patients.",0
105721,42931,ProDrive - Advancing the Safety and Security of Vehicle Fleets,"This project fully addresses the IUK scope for a Smart project by providing an significant improvement to a market security need, which will lead to more resilience, secure and smarter e-commerce delivery through the use of modern sensors, and connected vehicles.

Protrack have a commercially active tracking system with a strong customer base. This project seeks to develop and add new functionality to address a costly industry need among delivery fleet operators. The system will make use of the existing infrastructure used by telematics systems in terms of the connectivity between vehicle and the management team at base. The product will support the one of the main benefits of telematics systems which is to combat the risk of theft. The solution proposed will use innovative techniques to achieve increased security and improve the efficiency and effectiveness of fleet operators internationally. In addition, there are important benefits for the community in terms of reducing environmental pollution. Overall the project will deliver a new and much sought after product to the international transport fleet market.",0
2193131,46492,Plasticity of visual information processing and the consequences of neurodevelopmental disorders,"The ultimate goal of much neuroscience research is to link the responses of individual neurons or populations of neurons with perceptual capabilities and behavioural outcomes. Recent advances in functional brain imaging at the cellular and subcellular levels are now allowing us to approach this goal in an unprecedented manner. In this project we will apply two-photon imaging of calcium signals to examine fundamental questions of how higher cortical areas are wired during development and how this process goes awry in neurodevelopmental and neuropsychiatric disorders.
First we will examine how an early defect of vision in one eye affects higher visual function in the long term. In humans, such an early developmental disadvantage of one eye relative to the other causes a condition known as &quot;lazy eye&quot;. Most of the research into the underlying mechanisms has focused on the primary visual cortex (V1), despite the well-recognised fact that the extent of abnormalities in V1 cannot account for the much greater deficits in visual performance. The cutting-edge techniques in use in our lab will enable the student to investigate visual stimulus-evoked activity in higher visual areas of mice while these are carrying out visual discrimination tasks.
We will extend this work to examine more broadly how developmental deficits in neuronal connectivity formation might result in abnormal propagation of information through cortical circuits. Specifically we will use similar techniques to examine the flow of information through cortical circuits in a genetic model of autism spectrum disorders and of schizophrenia. Although these mouse models are well understood at the electrophysiological level little is known about how the mutations translate into sensory abnormalities. In this project two-photon imaging will be complemented with in vivo electrophysiological recordings in order to analyse synaptic connectivity. The aim of this project is to identify specific cellular mechanisms by which developmental or genetic defects translate into visual or neurological condition.",0
2267146,41408,Josephson tunnelling into a thin film spin-triplet superconductor,"The superconductor Sr2RuO4 is widely believed to be almost unique in that it may be one where the Cooper pairs form into a spin S=1 triplet state, making it a solid-state analogue of the spin-triplet superfluid He-3[1]. Among possible S=1 pairing states there are several possibilities, of which the Lz=+/-1 chiral states are generally the most likely [1,2], although others have also been proposed recently [3]. Until now experiments on this material have almost exclusively concentrated on bulk crystals. However, in recent months three groups around the world have finally succeeded in growing thin films which become superconducting [4,5,6]. The thin films provide a new way to manipulate Tc, and indeed Tc has been shown to increase significantly if the films are grown on substrates which expand the a-b lattice constants by a few percent, effectively acting like a negative uniaxial strain in both directions. 

The possibilities of manipulating thin film geometry also provides a wide range of new opportunities for experiments which directly probe the Cooper pair state via Josephson tunnelling. In particular, there has been no previous system in which the Josephson effect could be directly used to probe the spin state of a Cooper pair. Some preliminary theoretical work has been done in this direction in highly simplified models [7], but this now needs to be refined by more realistic calculations with realistic band structures and pairing states. During the visit in 2018 of Prof Annett to the MPI for Solid State Research in Stuttgart the need of such calculations became clear following discussions between Prof Annett and Dr D Manske [7] and his group of postdocs and students at the MPI as well as their experimental partners in Tokyo [4]. In Bristol we have a well developed model of the bulk material, which includes a realistic band structure and a multi-band S=1 pairing state, with and without the effects of spin-orbit coupling. This model has already been shown to produce accurate physical predictions for bulk thermodynamic and transport properties as well as intrinsic optical and magnetic effects such as the Kerr effect and orbital moment associated with the chiral nature of the pairing state [8]. However this model has not yet been applied to the theory of tunnelling into thin film samples of the type now open to experiments. The goal of the PhD project will be to update the theoretical model for the new band structure present in expanded lattice thin films, and then to consider tunnelling in various scenarios, eg in junctions of Sr2RuO4 to Sr2RuO4, or junctions with other materials, such as the cubic SrRuO3 or Mott insulating Ca2RuO4 or other materials which are lattice compatible with the thin films of interest and therefore candidates for future experiments. A range of theoretical tools will be used for this work, including ab initio band structure calculation, self-consistent calculations of the gap, and then tight binding solutions of the Bogoliubov de Gennes equations to describe the tunnelling current. The novel feature of the tunnelling current calculations will be to discover whether it consists of both a charge and spin supercurrent components, hence possibly providing a new and direct way of measuring the Cooper pair spin. The project is also related to, but separate from, an ongoing EPSRC funded project, which has recently been extended until summer 2020.",0
2370242,43376,Experimental measurement of turbulence in the divertor volume of MAST-U,"Turbulence in the scrape-off layer is complex with multiple regions displaying differing characteristics, yet understanding turbulent transport in the scrape-off layer remains a critical step towards a predictive capability for future fusion devices. Understanding cross-field transport inside the divertor volume has been historically neglected, however it strongly impacts conditions at the divertor surface which is a critical interface for the operation of a fusion reactor. This project will provide a deep and systematic experimental analysis of cross-field transport in the divertor volume of MAST-U using a specialised probe diagnostic.
 MAST-Upgrade will be installed with a new divertor reciprocating probe in 2019/2020 and comparisons of turbulence measurements made on this probe with upstream will provide unique insight into turbulence in the super-X chamber. Recording power spectra, correlation lengths, fluctuation amplitudes and other such measurements at high time resolution will provide detailed characterization of the turbulence in the divertor of MAST-U. The current set of probe heads available to MAST-Upgrade are not optimized for turbulent measurements beyond single point time-series. Whilst each probe can make measurements of the ion-saturation current, only the Mach probe can be used for measurements of density and temperature (via its triple probe arrangements) at high time resolution, but these measurements are made at discrete length scales that exceed turbulent correlation lengths. The Ball-pen probe can measure the plasma potential directly, but again the arrangement of the probe tips on the probe head prevents a more detailed measurement of the internal structure of fluctuations. This project will develop a new probe head for the MAST-U RP systems, interchangeable between midplane and divertor. The probe head will be designed using a synthetic diagnostic to optimize the positioning and type of probes used, and will use both Langmuir and Ball-pen probes to provide measurements of electron density and temperature, alongside detailed measurements of turbulent correlation length scales and internal fluctuation structure at high time resolution. The synthetic diagnostic will be applied to STORM simulations to test novel measurement techniques exploiting the new probe head, in preparation of analysis of data from MAST-Upgrade. The new probe head will be installed on both the midplane and divertor RP systems to provide a comprehensive analysis of the characteristics of turbulence both upstream and downstream. This analysis will provide deep insight into the level of turbulent transport present in the divertor both in absolute terms, and relative to the upstream SOL, radially across the SOL and PFR region.
The aim is to run the experiments using newly designed Langmuir probe in the second MAST-U campaign, late 2020",0
1911023,346,The regulation of development in the antibiotic-producing bacteria Streptomyces (BUTTNER_J17DTP),"Streptomycetes are filamentous bacteria that grow by tip extension and branching to form a vegetative mycelium. Nutrient depletion triggers a developmental program that leads to the formation of specialized reproductive structures called aerial hyphae, which ultimately give rise to long chains of spores. This program is genetically and temporally coordinated with the production of numerous commercially important antibiotics (Streptomycetes account for $40 billion of revenue annually in the pharmaceutical industry worldwide). The transition from vegetative growth to the formation of aerial hyphae is controlled by a regulatory switch consisting of a sigma factor, BldN, and its cognate anti-sigma, RsbN, a transmembrane protein. After BldN is expressed, it is held inactive by RsbN, which sequesters it to the membrane, until an unknown signal triggers Regulated Intramembrane Proteolysis (RIP) of RsbN and release of BldN into the cytoplasm. The goals of this project are to identify the signal that triggers release of BldN and to characterize the proteolytic process that inactivates RsbN.

Bibb, M.J., Domonkos, &Aacute;., Chandra, G., and Buttner, M.J. (2012) Expression of the chaplin and rodlin hydrophobic sheath proteins in Streptomyces venezuelae is controlled by BldN and a cognate anti-sigma factor, RsbN. Mol. Microbiol. 84:1033-1049.

Bush, M.J., Tschowri, N., Schlimpert, S., Fl&auml;rdh, K., and Buttner, M.J. (2015) c-di-GMP signalling and the regulation of developmental transitions in streptomycetes. Nature Rev. Microbiol. 13:749-760.

Tschowri, N., Schumacher, M.A., Schlimpert, S., Chinnam, N.B., Findlay, K.C., Brennan, R.G., and Buttner, M.J. (2014) Tetrameric c-di-GMP mediates effective transcription factor dimerization to control Streptomyces development. Cell 158:1136-1147.",0
ES/N006860/1,1638,Title: Anarchy as constitutional principle: Constitutionalising in anarchist politics,"Just as state power is being championed as a solution to the weakness of international organisations, the legitimacy and power of the institution of the nation state is being widely contested too. Campaigns for devolution and independence, claims for cultural, linguistic and regional autonomy, as well as disengagement from the EU and political parties in general, invite a reconsideration of the statist paradigm at the heart of modern politics. These constitutional issues are exacerbated by the crisis of capitalism and the inequalities it generates.

Anarchism is routinely dismissed in these debates: the association of anarchy with chaos and the carnivalesque travelling circus is deeply embedded in popular consciousness. Our research will transform this perception and make a concrete contribution to constitutional debates in the UK, EU and beyond. We investigate what anarchists understand by anarchy and show how their ideas establish novel benchmarks for thinking about constitutionalism. We use this analysis to rethink the status of anarchy in politics, extending insights from International Relations (IR) theory where the potential virtues of anarchy have been acknowledged, to political theory, where they have not. We deploy the idea of anarchy positively, as a model for self-government and we challenge the way that chaos is read into anarchy by its theorisation as the absence of constitutionalised order. 

The project examines the constitutions governing three national and international groups: Occupy Wall Street, the Industrial Workers of the World and the Cowley Club co-operative. Working with these groups, we hope to understand how anarchists constitutionalise and whether they are successful in realising their goals - an important first step for analysing the distinctiveness of anarchist practices more broadly. Our key question is: What constitutional principles and practices does a commitment to anarchy generate?

The work that republican political theorists have done to re-define freedom as a principle of non-domination provides a new space to integrate anarchist perspectives in mainstream politics and consider the value of its perspectives. Their idea is that being free is not just about having rights to do things, but about being protected from the arbitrary introduction of policies that disregard our interests: the introduction of a Poll Tax, for example. They believe that freedom from arbitrary rule provides the best foundation for thinking about constitutional principles in the domestic and global realm. But in deciding what constitutes arbitrary rule, republicans regulate within the state and capitalism. This is a bit like defining 'music' by the conventions developed by classical composers: jazz, rock and reggae all suffer by this standard. Anarchists also adopt an idea of freedom as non-domination but argue that these institutions structure arbitrary domination unjustly and they seek to challenge the privileges that result from them by using a commitment to anarchy to organise their associations. 

In the study of IR, the potential for anarchism to help us re-think politics in new ways has been highlighted by recent attempts to use studies of stateless tribal groups to questions our assumptions about the chaos and violence of a world without states. These writers claim that there is no reason to think that a life without the state would be 'nasty, brutish and short', as Hobbes put it. These discussions chime with work in public policy, where research shows the benefits of self-organising networks over centralised hierarchical management. Our project contributes to debates in these areas by helping us see how anarchist politics works in practice. By reconsidering the anti-anarchist assumptions at the heart of modern politics, this research will open up a critical and radical vein of thought, contributing to the ESRC's commitment to think through the foundations of a vibrant and fair society.",0
1798923,32732,Algorithms for one-dimensional bin packing problems with ordering implications,"One-dimensional bin packing is one of the most fundamental and widely-studied problems in operational research. In this project we focus on various extensions to this problem where, unlike the original problem, the ordering of items within each bin is of critical importance.

Two examples of practical situations can occur can be found in the publications [1] and [2] below. This project is specifically concerned with designing efficient (and perhaps exact) algorithms for special cases of these problems, extending on the research documented in [1] and [2].

1.Goulimis, C., 2004. Viewpoint: Minimum score separation - an open combinatorial problem associated with the cutting stock problem. Journal of the Operational Research Society 55, 1367-1368.
2.Lewis, R., X. Song, K. Dowsland, and J. Thompson (2011) 'An Investigation into two Bin Packing Problems with Ordering and Orientation Implications'.European Journal of Operational Research, vol. 213, pp. 52-65.",0
509138,27454,The University of Nottingham and Krow communications Limited,"To explore and develop data driven innovation across the business offering, to increase retained clients.",0
EP/S003657/2,43723,"Mirror symmetry, quantum curves and integrable systems","The subject of the proposed research lies at the frontier between pure mathematics (geometry) and mathematics motivated by physics, especially high energy particle physics. 

One basic motivation of this proposal is given by two fundamental classes of problems in mathematics: the enumeration and classification of geometric spaces. These type of questions hark back to Greek antiquity to form one of the most venerable branches of mathematics since classical times: enumerative geometry, that is, the count of the number of solutions of geometric problems. Whilst very classical, these questions have often eluded an answer through standard methods; however, since the early nineties, the introduction to the realm of algebraic geometry of a wide range of sophisticated curve counting theories (such as Gromov-Witten theory), inspired by the physics of quantum gauge and string theories, has revolutionised the field by providing the long-awaited solutions to an immense range of enumerative-geometric problems. 

Besides its intrinsic interest for geometers, this close relation to modern theoretical high energy physics has sparked a paradigm shift across the subject, blending new physically motivated insights in geometry with an immense toolkit of powerful computational schemes; this has revealed an intricate web of highly sophisticated algebraic structures underlying Gromov-Witten theory and its allied enumerative theories. This is typically encoded into rich number-theoretic properties of the generating functions of Gromov-Witten counts; and sometimes it can be characterised in terms of a hidden infinite-dimensional group of symmetries given by the flows of a classical integrable hierarchy: a very special non-linear partial differential equation possessing infinitely many commuting conserved currents. 

These discoveries have had a transformative impact in all fields concerned, in geometry, mathematical physics, and the theory of integrable systems, and they have provided a shared source of insights for very different communities of pure mathematicians and mathematical physicists. Furthermore, the last decade has witnessed a range of dramatic advances which have revolutionised methods and perspectives of the field, and have opened up important avenues of investigation. 

These new directions are the subject of this project. The central tenet of the proposed research is the identification of novel, powerful, and truly cross-disciplinary methods stemming from recent work of the applicant to solve four central problems in a burgeoning area of theoretical science: these include the explanation of the interplay between higher genus Gromov-Witten invariants, the theory of modular forms, and the theory of integrable systems; a constructive proof of a recently proposed and surprising connection between analysis (spectral theory) and geometry (mirror symmetry); a proof of the strongest version of a long-standing conjecture relating the invariants of a class of real four-dimensional spaces related by surgery-type operations (the &quot;quantum McKay correspondence&quot;) in full generality; and the study of the asymptotic properties of curve counts in a large class of four-dimensional spaces (complex surfaces).",0
ST/K005014/2,10672,Surveying black holes and neutron stars with gravitational waves,"Black holes and neutron stars are some of the strangest objects in our universe, formed in the supernova explosions at the end of the lives of the most massive stars. Neutron stars contain the mass of the Sun compressed into a sphere only a few tens of kilometres across; so dense that atoms can no longer exist, so the entire star consists of neutrons packed together by gravity. Black holes are thought to be more massive still, and so dense that not even light can escape from beyond their event horizons. These fascinating objects are a physicist's dream laboratory: a place where all our theories are pushed to their limits and beyond. Understanding how they are formed can also shed light on the evolution of the stars that they came from.
When two of these objects are found in a binary system, their small size allow them to orbit each other in a few hours or less.
According to Einstein's general theory of relativity these systems have so much matter in such a small space that they distort the space-time around them, whipping up gravitational waves that extract energy from the orbit and change the dimensions of everything they pass through. Luckily, by the time they reach us at Earth, these gravitational waves are so weak that the changes in length are equivalent to changing the distance between the Sun and Saturn by one hair's width, far too small to notice. Eventually so much energy is extracted that the objects orbit each other hundreds of times a second before they finally collide, releasing a huge amount of energy that can produce the brightest explosions in the universe if a neutron star is involved, but are completely invisible if only black holes are. Invisible that is, except to gravitational wave observatories, which are designed to measure the distortion of space-time produced by these events throughout the universe. The second generation of these observatories, called Advanced LIGO and Advanced Virgo, will come online in 2015 and start to make detections of binary collisions soon afterwards. By precisely measuring the distortions produced as a gravitational wave passes by, it will be possible to measure the nature of the binary system that produced it, even when no electromagnetic signal can be seen. Gravitational waves form in effect an entirely new spectrum with which we can observe the universe, opening up new avenues for discovery.
The hunt for these gravitational waves is an incredibly exciting field of science. It pushes the limits of what is technologically possible in every part of its design. Knowing that we will soon be observing black holes and neutron stars fuels the curiosity that drives this global effort forward. We are about to open up a new tool that will allow us to observe space-time itself, and will eventually lead to a better understanding of the nature and evolution of the universe.",0
720671,893,Development of a new heat resistant lighting system for use in consumer ovens,"The detrimental effect that temperature has on electronics has so far restricted the design and
integration of innovative LED lighting into consumer and industrial applications that require
high temperatures, resulting in inefficient, ineffective incandescent light bulbs still being used
for these applications. These inefficient bulbs have already been banned from general sale in
the EU under Regulation 244/2009 and increasingly restricted to a small list of specialist
applications. As the EU continues its legislative drive to remove all incandescent and halogen
bulbs from circulation by 2016, there is a real need to develop and supply the market with a
viable LED alternative.
Trumeter Technologies Ltd are a leading designer, developer and manufacturer of innovative
lighting, measurement and sensory technology. Having created significant advancements in
LED technology in the automotive industry, Trumeter believe there is significant cross-over
potential for their lighting technology in the consumer products market, developingthe next
generation of LED lighting for home appliances.Trumeter intend to develop a low-energy, low
failure rate LED lighting system capable of operating in and illuminating ovens which are
heated to temperatures in excess of240&ordm;C. The detrimental effect of temperature on electronics
and LED窶冱 has so far restricted the integration of innovative LED technology in household
appliances, preventing the environmental, control and luminosity benefits of the technology
being realised.
If successful the project will result in the first, high volume, low energy LED lighting system
able to function and illuminating environments of 240&ordm;C heat or more. Implementation of the
technology will initially focus on consumer oven, before other applications and markets are
explored. The project will help ensure that Trumeter and the UK remains at the forefront of
lighting technology and to the wider benefit to the UK household appliance manufacturing
community.",1
511104,7187,University of St Andrews &amp; RD Graphene Limited,To investigate the physical and chemical properties of graphene to support the development of energy generation and storage systems.,1
1834852,7247,Investigating Corrosion Using a High Speed AFM,"There are significant safety and economic incentives to prevent the failure of structural
components in the nuclear industry[1]. Stainless steels are widely utilised in the nuclear
industry due to their amicable mechanical properties, however, they remain susceptible to
corrosion. Corrosion can be affected by a number of different factors and as such is
considered a highly complex process that is under much ongoing research[1]. Conjoint
corrosion and stressing of a metal or alloy, such as stainless steel, can result in stress
corrosion cracking (SCC)[2]. SCC results in significant degradation of component structural
strength whilst being difficult to identify in early stages, thus, SCC is often undetected prior
to failure[1]. The unpredictable nature of SCC calls for considerable research in the
mechanisms under which SCC and other forms of destructive corrosion occur, in steels and
other engineering alloys[2].
To investigate the processes by which corrosion occurs it is required that the sample is
imaged in controlled environments[3]. The field of atomic force microscopy (AFM) has
allowed for high-resolution imaging of structures and the measuring mechanical properties
at nanometre scales in varying gaseous, liquid and vacuum environments[4]. AFM has a
multitude of applications in materials, surface and biological sciences, and is considered one
of the most versatile and significant tools in nanoscience.
Significant effort to increase the imaging rate in recent years has allowed for dynamic
nanoscale events to be observed directly in real time[3]. The applications for high-speed
AFM (HS-AFM) are still relatively new and unexplored, and advances in HS-AFM
technology are ongoing. HS-AFM is a valuable tool for studying solid-liquid interfaces and
so has the potential for use in corrosion studies as it offers the opportunity to observe
dynamic nanoscale structures within in vivo conditions[3].
Laferrere et al. have previously demonstrated the use of the Bristol contact mode HS-AFM
to image nanoscale corrosion events, with parallel electrochemical control[3]. This work
demonstrated the ability of HS-AFM to image steels clearly in liquid environments and the
potential for new insights into corrosion at nanoscales[3]. The main aims of this PhD are to:
- Investigate the conditions that may lead to corrosion and SCC initiation, and to observe
and measure changes to the sample as corrosion takes place in real time using HS-AFM.
- Demonstrate the capability and potential of HS-AFM for applications in material and 
corrosion science.

References:
[1] R. Cottis et al., Shreir's Corrosion. Elsevier Science, 2009.
[2] R. Cottis, National Physical Laboratory, Teddington, 2000. 1
[3] O. Payton et al., Nanotechnology, vol. 23, no. 20, p. 205704, 2012.
[4] H.-S. Liao et al., Rev. of Scientific Instruments, vol. 84, no. 10, p. 103709, 2013.",1
EP/N020669/1,12857,Accurate free energy calculations for biomolecular catalysis of electron transfer,"Long- and short-range electron transfer (ET) between proteins is vital for all living systems, and plays an essential role in photosynthesis and bio-assimilation. ET is a central process for the transfer and storage of solar energy in advanced materials as well. Our understanding of the corresponding biological electron transport can inspire new approaches for developing and advancing energy efficient technologies. However, robust, accurate, and predictive underlying theoretical and computational models are still needed to determine structure, energetics and kinetics of ET processes in materials and biological systems. 

We introduced a new analysis method, DHAM, which can be used to calculate rates and free energies from biased or unbiased simulation trajectories (Rosta and Hummer, JCTC 2015). The DHAM method is a generalisation of the current state-of-the-art weighted histogram analysis method (WHAM), which is widely used to obtain accurate free energies from biased molecular simulations. We showed that WHAM-computed free energies can exhibit significant errors, e.g. when analysing simulations under weak bias - a problem overcome by using DHAM. Our method is designed to determine a global Markov chain based on a maximum likelihood approach to analyse multiple simulation trajectories. We construct the Markov transition matrix along a discretized reaction coordinate, and obtain the corresponding stationary distribution to determine the free energy profile. Importantly, our formalism provides kinetic information of biased simulations. By building on this approach, my main aim is to develop a new method to study electron transfer.

As a first application, we will study the catalytic reaction of FNR, a central enzyme in the final step of the photosynthetic electron transfer processes using the energy of light to store high-energy electrons in the form of chemical bonds in NADPH. Our novel computational methods will provide accurate free energies as well as kinetic information about the dynamics of the photosynthetic systems. Importantly, it will allow us to understand the underlying mechanism, including the elusive coupled proton transfer steps that occur together with the electron transfer reactions in FNR.",1
2287637,39908,"Deep, dark and dynamic: Converted-wave seismology to explore the physical properties of Antarctic glacier ice","Quantitative seismic analysis holds the key to establishing the mechanical properties of glaciers - the very properties which are required to accurately parameterise predictive models of glacier dynamics.

Global sea levels are predicted to rise by ~1 m over the next 100 years, but such estimates are uncertain. To improve model predictions, a comprehensive description of all aspects of the glacier system is required, motivating the development of novel survey techniques.

Seismic surveys are a powerful means of accessing the deep, dynamic underbelly of an ice mass. Hitherto, most seismic surveys considered only the P-wave component of the wavefield, and converted-wave seismology has been largely overlooked. Converted-waves could, however, offer an untapped resource of interpretative insight.
 
This project explores the scope of converted-wave seismology to quantify fundamental glaciological properties - potentially spanning basal hydrology, ice temperature and flow fabrics. Test data will be acquired during the project on Norway's Hardangerjokulen ice cap with existing datasets provided, by the British Antarctic Survey and the Thwaites Glacier TIME project, at two priority Antarctic sites.

The successful development of converted-wave methodologies will broaden the glaciological seismic toolbox, providing novel insight at sites of international research interest.",1
103895,36967,"Adaptable Design for Low cost, Efficiently Reconfigurable Offshore Wind LIDAR","This project seeks to reduce the costs of offshore wind by targeting the wind monitoring infrastructure used at multiple stages of wind energy projects. By developing a factory adaptable laser wind sensor design the costs of such remote sensor systems can be reduced - by using a modular approach to the subsystem design, maintenance and down time costs can be reduced. The outputs from this project will include field demonstrators of different wind profilers set up for different applications. These wind profilers are based on LIDAR - (LIght Detection And Ranging) and the project brings together wind LIDAR developers, optical product designers, ruggedised optical instrumentation engineers as well as the wind industry end user. The project will make use of wind energy test sites in the UK and also in Germany - where a parallel project - looking at wind LIDAR vertical profiling and validation methods is being set up.",1
2199243,38533,Next-generation ammonia adsorption heat pump cycles and technology 1=Energy 2=Energy Efficiency,"in reducing the CO2 emissions associated with domestic heating. One ammonia - water absorption technology is commercialised, with good GUE (Gas Utilisation Efficiency, heat out/gross calorific value of gas in of c. 1.4) but high capital cost. An ammonia - carbon adsorption cycle is under development, offering reduced GUE of 1.2 but affordable capital cost. 
Two possibilities exist to improve the adsorption cycle GUE without a major increase in capital cost. One is a development of the carbon ammonia technology employing either multiple adsorbers with improved heat recovery and the other using chemical adsorbents, generally halide salts embedded in a graphite matrix and used in resorption cycles. Both have been the subject of preliminary work at Warwick.
The research programme will first undertake sufficient analysis and modelling to decide which of either the active carbon or metal halide adsorbent types has the greater potential for eventual commercial adoption. The carbon adsorbent can certainly achieve a GUE of 1.4 at the expense of some extra complexity. The metal salt route is lower Technology Readiness Level but in theory could offer a GUE of 1.5 in a two-salt cycle and 2.0 in a three-salt cycle.
The challenges presented by the two technologies are somewhat different. The carbon adsorbent is well characterised and understood. The difficulties are in construction of a carbon ammonia adsorber with low thermal mass, good heat and mass transfer and low cost; this has already been the subject of many years' effort. A multiple bed with advanced heat recovery introduces further complexities in design and simulation. 
The adsorbers in a metal salt system are very different in that the salts are contained within a conductive (non-adsorbing) graphite matrix which improves conductivity. The resorption cycles also have the benefits of fewer components. However, the chemical reactions that take place are much more problematic with reaction rates very difficult to predict. Where the active carbon in the carbon-ammonia machines is always in chemical equilibrium and operation is heat transfer limited, within metal salt - ammonia systems there is never equilibrium and operational performance depends on the poorly understood reaction rate dynamics.
Having made a choice between the two competing technologies (expected by Month 9) the research will enter a detailed design and simulation phase in which proposed adsorber designs are evaluated at 'unit-cell' level using the Large Temperature Jump (LTJ) technique already established at Warwick. With the validation of the adsorber design, construction of a proof of concept machine (3-10 kW output) will commence and simulation of control strategies begun. The POC machine will be tested first in the ThermExS laboratory, purpose-built under an EPSRC capital grant for the easy evaluation of novel thermodynamic systems. It consists of four computer-controlled thermal baths, valve and pump assemblies that act as heat sources and sinks from -10 to 180 C and powers from 7 to 30 kW.
This level of testing, electrically heated and within the laboratory is sufficient to prove the chosen cycle/adsorbents and result in new knowledge worthy of a PhD. However, it is quite probable that by this time there will be newly funded projects at Warwick that will enable the work to go further, perhaps integrating with a gas burner in a stand-alone system.",1
2271936,41028,Effects of Radiation Damage on ALM produced components,"Additive Layer Manufactured (ALM) components are currently being developed for use in a range of industries, and variants of ALM have been investigated since the 1980s. The development of next generation nuclear reactor technologies combined with the increasing use of novel manufacturing methods is therefore a key area for exploration. An essential criterion for materials/components used within nuclear reactors is the requirement to withstand radiation induced damage within the core. Consequentialy for ALM to be used more frequently in nuclear engineering, how such radiation induced damage impacts material properties is key to both the long-term stability of the component, as well as the acceptance of ALM within the nuclear industry. This PhD will fabricate and examine ALM produced samples for changes induced by radiation damage, how they impact properties and how they recover from damage.",1
1645860,5245,"Evaluation of the relative importance to carbon sequestration and nutrient cycling of root exudation, and turnover of roots and mycorrhizas","Maintaining soil function and carbon storage represent key objectives in sustainable agriculture. Most C, N and P is returned to soil via exudation from live roots, and turnover of dead roots and their associated symbionts. Consequently, both the rate at which C fixed by plants is returned to the atmosphere as CO2 and the rate at which nutrients are recycled to plant-available forms are tightly coupled. However, quantitative separation of the three most important below-ground fluxes of C and nutrients (root exudation and root and mycorrhizal turnover) remains largely unachieved. This is due both to limited understanding of the fate of the range of C, N and P compounds and their polymers (e.g. protein, nucleic acids, cellulose, lignin and chitin) delivered to soil, and to a lack of suitable techniques to measure rates of delivery. Consequently, poor knowledge of these fluxes is a major impediment to understanding and modelling the storage of atmospheric C in soils and the factors controlling nutrient cycling. 
We propose to utilise recent technological advances to determine: (1) The relative quantities and types of C, N and P delivered to the soil in turnover of roots and mycorrhizas in temperate permanent grassland. (2) The rate and route of utilisation by soil microbes of the various forms of C delivered to the soil by these processes and how this controls the delivery of C back to the atmosphere as CO2. (3) How synchronous with mineralisation of plant C to CO2 is the return of N and P to plant-available forms. (4) How estimates of root and mycorrhizal turnover measured by state-of-the-art techniques compare with those from more traditional approaches.",1
ES/N013638/1,19055,EVI-MED - Constructing an evidence base of contemporary Mediterranean migrations,"&quot;EVI-MED - Constructing an evidence base of contemporary Mediterranean migrations&quot; seeks to conduct urgent data collection and essential analysis on the Mediterranean migration crisis and to make these swiftly and publicly available to policymakers, practitioners, migrant community support organisations, and the research community. 

EVI-MED will provide insights into the major humanitarian, social, economic and political implications for the principal countries of arrival - above all Italy and Greece - as well as Malta which is a central pillar of the search and rescue effort. The project is also relevant to other potential countries of reception and settlement in Europe, including the United Kingdom. This will be achieved through a diversity of research methods, including:

A) The collection and standardization of a broad range of secondary data on migration, including statistics provided by search and rescue organisations and national and European bodies which will be integrated with data-sets made available by international NGOs, to create a synthetic database on migration trends and characteristics of flows.

B) A survey of individual migrants - with at least 750 participants across Sicily, Greece and Malta - providing insight into profiles, routes, experiences and migration plans. This survey data will be complemented by 45 in-depth interviews focusing on migrant life-histories, decision making and use of networks.

C) A systematic mapping of the 'reception systems' in Sicily, Greece and Malta, identifying governmental and non-governmental actors involved in the identification, management, reception, integration and potential return of migrants who make the journey across the Mediterranean.

D) Overall analysis of the migration and reception situation, derived from the above data-sets and integrated with further interviews with experts and practitioners, the contribution of international advisors, and the evidence emerging from the existing literature and other research and ongoing research activities. 

The project benefits from close collaboration with a number of well-established specialist organisations, including the Greek Council for Refugees, the Migrant Offshore Aid Station (MOAS), Migrant Report, Borderline Sicily, People for Change Foundation Malta and with expert knowledge of countries of origin provided by the Regional Mixed Migration Secretariat (RMMS), a project of the Danish Refugee Council working in the Horn of Africa and Middle East. 

EVI-MED's wide-ranging engagement platform capitalises on the network of collaborations and partnerships established with Middlesex's Mediterranean Observatory on Migration Protection and Asylum (MOMPA) - a joint initiative of Middlesex University London and Middlesex University Malta.

The project outputs - including data-sets, policy briefs, academic articles, situation reports, interactive maps - will be made available through the project website, in order to advertise them as widely as possible through EVI-MED's 'engagement platform', networks and social media provided by partners and collaborating organisations. Other outputs include conferences, knowledge exchange events, consultations and briefings with national and European policymakers.",1
AH/P005438/1,9370,"Local Community Experiences of and Responses to Conflict-Induced Displacement from Syria: Views from Lebanon, Jordan and Turkey","The UN has described the Syrian conflict as &quot;the most dramatic humanitarian crisis that we have ever faced&quot;. By August 2015, 1,114,000 refugees had fled Syria to seek safety in Lebanon, 630,000 had fled to Jordan and 1,939,000 to Turkey. Local communities, civil society groups and faith-based organisations in these countries are some of the most important actors responding to the refugee influx from Syria, filling major gaps which exist even when major aid programmes have been implemented by international agencies such as the UN. These civil society responses have included Lebanese, Jordanian and Turkish citizens providing food and shelter to refugees, local faith leaders offering spiritual support to people displaced by the Syrian conflict, and social and material support provided by protracted refugees who were already living in Lebanon, Jordan and Turkey before the outbreak of the Syrian conflict.

All of these initiatives are clearly significant, but little is known about how and why local communities offer assistance to refugees. This project aims to enhance our knowledge by carefully examining a range of responses developed by the members of nine local communities in Lebanon, Jordan and Turkey, asking questions such as What has motivated these responses? and Who has benefited and who has been excluded from these responses? Another important question is How are these local responses perceived by 'traditional' humanitarian aid providers, including governmental Ministries, international humanitarian aid agencies, and UN agencies? 

It is important to examine the different implications of local community responses to displacement for different reasons. For instance, although little evidence exists, the UN and traditional Northern donors are increasingly supporting 'local' responses to conflict because this is a way of sharing the 'burden' of providing aid and services to millions of refugees. At the same time, however, academic, political and policy observers express concerns that local responses may be motivated by political, ideological and faith-based priorities, rather than adhering to the international humanitarian principles of neutrality, universality and impartiality upheld by organisations such as the International Committee of the Red Cross. Detailed research is therefore urgently needed to ensure that local initiatives are neither prematurely celebrated nor unduly demonised.

This research aims to improve our understanding of the challenges and opportunities that arise in local responses to displacement, both for refugees from Syria and for the members of the communities that are hosting them. A team of local researchers will spend 6 months in Lebanon, Jordan and Turkey carefully observing how the members of 9 local communities have responded to the arrival of refugees from Syria. They will interview a total of 270 local community members and 270 refugees, asking them about their experiences of providing or receiving local assistance; refugees and community members will also share their views through a number of participatory research workshops and creative writing workshops in Lebanon, Jordan and Turkey. 150 people who work with local, national and international organisations (including UN agencies) will also be interviewed, to examine their views of local responses to refugees from Syria. Doing this will help us identify whether there is national and international support for local community responses for refugees, or if national and international organisations believe that local responses should not be encouraged or allowed. 

The project will use this research to develop recommendations for civil society groups, aid groups, governmental ministries and international organisations. These recommendations will provide suggestions on how local, national and international organisations can best work together to support the needs and human rights of people affected by conflict.",1
BB/R019819/1,19911,Genomics-led improvement of biotic and abiotic stress tolerance in mustard rape for economic and environmental sustainability,"The proposed research is a Newton-Bhabha development programme. The overall aim is to transfer and optimize UK expertise in genomics, which is the scientific approach involving analysis in parallel of the complete set of genes of an organism, for improvement of both economic and environmental sustainability of mustard rape (Brassica juncea) in India. 

The crop characteristics (traits) that are the focus of the research were defined by the Indian partners in the proposal as the most important challenges faced by the crop in India. There are tolerances to the range of environmental challenges (stresses): diseases and infestations from fungi (causing white rust, stem rot, black spot), viruses (Turnip mosaic virus), pests (aphids and butterflies) and root parasites (broomrape) and conditions of high temperatures, drought and salinity. Of particular importance is that multiple stresses are often encountered simultaneously and interactions and trade-offs between tolerance mechanisms can be expected, necessitating an integrated approach across this broad range of challenges. Included in a broad correlation analysis between the traits will be an assessment of associations with variation in classes of chemicals produced by the plants that are recognised as playing roles in tolerance to environmental stresses. To enable this programme to be undertaken thoroughly and successfully, we have assembled a consortium comprising 39 co-applicant scientists representing 17 institutions. 

The approach is to establish a toolkit of technologies to help understand the basis of naturally-occurring tolerances and to enable future work to enhance them. These include the establishment of a platform enabling the association of trait variation in panels of genetically diverse mustard rape varieties with variation of both gene sequences and gene activity (expression) to enable the development of molecular markers to accelerate breeding and identify candidate causative genes for further investigation. Non-GM approaches for improvement beyond the range of existing natural variation will be established for mustard rape, including modernised resources for the traditional approaches of radiation breeding and wide crossing with related species, and the emerging technology of genome editing.

Underpinning the programme is the experience gained in developing the Brassica juncea genomic platform currently used by the University of York and University of Delhi South Campus as part of their current Crop Genomics and Technologies (CGAT) project &quot;Broadening the genetic diversity underpinning seed quality and yield related traits in mustard rape and oilseed rape&quot; will be updated to incorporate emerging genome sequences from B. juncea and its progenitor species. The platform will be used to support the trait-focussed activities of the consortium, modelled on the University of York-led &quot;BBSRC Renewable Industrial Products from rapeseed (RIPR) programme&quot;. A particular feature will be the highly integrated nature of the research with expertise contributed by world-leaders in the respective components being shared. UK expertise will be transferred to partners in India for application in mustard rape. The benefits of scientific understanding and ability to improve traits in mustard rape accrue primarily to the Indian members of the consortium. However, they will also be of use for improving the corresponding traits in oilseed rape for cultivation in the UK.",1
ST/P003281/1,2150,Integrating remote sensing and ground-based spectral analysis to investigate biodiversity of archaeological sites in Amazonia,"There is growing evidence and awareness that human impacts on ecosystems and biodiversity are leading to significant implications for sustainability. Amazonia is a critically important biome in terms of: potential impacts of development (e.g. deforestation), sustainability of indigenous peoples and their livelihood, and sustainability of biodiversity and ecosystem services with global impact. Modern land uses such as urbanization, intensive agriculture or extensive conversion to pasture is already showing devastating effects on Amazonian biodiversity. Until recently, the Amazon was considered to be pristine forest, barely occupied by people in the past. Researchers have now come to agree that at least the riverine areas of the basin were densely occupied While there is keen awareness of contemporary anthropic effects, Amazonia is in fact a laboratory for investigation of long-term impacts of anthropic influence. Emerging technologies will shed light on ancient human footprints on biodiversity which in turn will help us to better understand current and future anthropic impacts and potentially develop mitigation strategies which will inform national and global efforts towards biodiversity conservation and sustainability.

The overarching objective of this project is to implement and demonstrate a novel approach to investigation of anthropic impacts on biodiversity in the Amazonian rainforest. This will be achieved by developing a multidisciplinary team that includes remote sensing expertise, archaeologists, and plant biodiversity expertise. Our plan is to demonstrate the usefulness and power of integrating ground-based spectral analysis of vegetation (NIR - near infrared spectroscopy) with aerial survey data using NIR to develop a method for analysing local biodiversity that is scalable to much larger areas by remote sensing. This will enable analysis of the impact of past human activity on biodiversity, and it will also enable investigation of that human footprint across a larger landscape. The programme of work includes a UK inception workshop, a Brazilian workshop, and a field demonstration project. 

This project has grown out of scientific networks established under STFC/NERC Global Challenges Network on Bioinformatics and Environmental Omics. Networking activities through these programmes have also established an interface with the &quot;Terra Preta de Indio Network&quot; (TPInet: http://tpinet.org).

The purpose of the present STFC Futures proposal is to consolidate a potential research network involving EOS and integrating across strengths at STFC RAL-Space (remote sensing), St Andrews (plant diversity and conservation), RBG Kew (plant diversity and conservation, remote sensing), Cardiff (TPINet)., and USP, Brazil (archaeology) to develop advanced remote sensing technologies for investigation of long-term anthropic impacts on Amazonian ecosystems.",1
2002942,32406,Assessment of Crack Arrest Behaviour in Modern Structural Steels,"Fracture mechanics based Fitness-For-Service (FFS) assessment of engineering structures is normally based upon the failure criterion, which is the initiation of crack extension by brittle fracture or ductile tearing at specified temperatures. The philosophy behind crack arrest is that if a crack initiates in a region of high stress or local embrittlement, it will be arrested in the surrounding material to prevent failure of the entire structure. The basic, simple idea for ensuring crack arrest is that the materials must have sufficient crack arrest toughness to ensure that fast propagating cracks, initiated in regions of low toughness and/or high stress, are arrested after they emerge from the critical zone. Obviously, during the design stage of ships, pipelines and some specific pressure vessels, analysis of crack arrest is of vital importance. The effect of temperature is another factor that needs to be taken into account in the course of the assessment of crack arrest or during design against crack arrest. The main aim of this project is to derive empirical models, which can be used to define crack arrest toughness from small test specimens (i.e. Charpy tests). It is also proposed to investigate and quantify the differences between the crack initiation and arrest toughness of two types of steels and explain the differences based on material microstructure. Finite Element modelling techniques will also be incorporated to understand crack arrest behaviour by analysing crack tip conditions in relation to a particular microstructure under specified loading condition.",1
NE/R000026/1,31374,NSFGEO-NERC: Two-phase dynamics of temperate ice,"Discharge of ice from the Antarctic Ice Sheet is dominated by ice-stream flow, but there is no consensus as to what controls the onset and geometry of ice streams or their evolution. Diverse observations clearly indicate the importance of water in affecting flow resistance, both within the icestream margins and at the bed. However, ice-stream models do not yet account for the necessary feedbacks among temperature, water content, and ice deformation to resolve and interrogate these processes. Specific observations highlight processes and knowledge gaps: (i) the basal hydrology of ice streams is responsible for low basal shear stresses that focus stress and strain at ice-stream margins; (ii) strain heating within ice-stream shear margins raises the temperature of the ice to the pressure melting point, causing internal dissipative melting and helping to control the distribution of temperate ice; (iii) interstitial water in ice-stream margins may significantly soften the ice, with poorly known dynamical consequences; (iv) the dependence of ice rheology on water content is itself poorly constrained; (v) the multiphase dynamics of temperate ice, including permeability and drainage rates within ice sheets, are not known; (vi) routing of meltwater to and at the bed is a primary control on ice speed. Without models that address these processes, predictions of the ice sheet's mass balance and sea-level contribution will inevitably be speculative, with incomplete physical grounding.

This study will target the dynamics of temperate ice, with the overarching goal of determining its effect on ice streaming. The project will have two components that reinforce each other: laboratory experiments in which an existing rotary device at Iowa State University will be used to study the effect of water content on the rheology and permeability of temperate ice; and development at Oxford University of a two-phase, thermo-mechanical theory for temperate ice flow-with water production, storage, and routing-that will serve at the basis for fully dynamic and multidimensional models of ice-stream motion. Results of the experiments will guide the constitutive rules and parameter ranges considered in the theory, and application of elements of the theory will improve interpretations of the experimental results. The theory and resultant models will predict the coupled distributions of temperate ice, water, stress, deformation, and basal slip that control the evolution of ice-stream speed and geometry.",1
132721,757,African off-grid solar power and mobile connectivity,"Ubuntu Power is a socially driven business focused on providing affordable solar power and unrestricted

Internet to off-grid communities in Sub Saharan Africa, starting with Kenya.

Our mission is to kick-start a virtuous cycle of economic growth in underserved communities by providing them

with two of the most pivotal and empowering services: Clean and affordable electricity and greater access to

information",1
1643131,28197,Structure and function of microbial communities at the soil atmosphere interface,"The top few millimetres of soil forms a microbiotic layer, known as the Biological Soil Crust (BSC), that consists of unique communities of bryophytes, algae, cyanobacteria, microfungi and bacteria. At the soil surface the BSC is exposed to exclusive conditions, which gives it a distinct soil chemistry and community structure in comparison to bulk soil. These properties allow it to play irreplaceable roles in nitrogen and carbon fixation, water infiltration, sediment production, protection from soil erosion and breakdown of pesticides, which are all of great agricultural and environmental importance. However, previous studies, which often focus on arid soils, have suggested that the ability for the BSC to perform these roles often depends on the community structure, which has been proven to differ greatly both temporally and spatially. Consequently, the diversity, composition and dynamics of the microbiology at the soil surface layer remains poorly understood, and the nature of different microbial communities contribution to key functions is unresolved, especially in an agricultural context in temperate soils.

In this project, next generation sequencing methods will be used to understand the environmental factors that determine composition and functioning of the BSC in agricultural fields in temperate soils. Using landscape sampling approaches, the roles of geographical distance, local environment and seasonable variables that determine composition of the soil surface community will be resolved. Molecular approaches will be used to characterize the microbial community organisation and its ecological function. These approaches will include DNA and RNA extraction and purification, PCR, nucleic acid sequencing using next generation platforms and bioinformatics analysis. Lastly, the way in which community composition affects the degradation of pesticides will be investigated to identify relationships between soil surface community composition and ecosystem function.",1
132510,34105,Rapid polymer to metal joints: RapidPM,"Legislation is driving major changes in the way that certain industries designs and manufactures its products to make them more environmentally friendly and less polluting. In automotive, emissions controls are challenging designers to produce ever lighter vehicles, which has driven them to consider incorporating less dense materials such as polymer composites. In electronics, WEEE Legislation has driven designers to use materials, which are inherently recyclable as well as allowing them design freedom to reduce costs and increase functionality. This has led to a shift towards 3D packaging and the use of thermoplastic encapsulants. RapidPM will develop technology to enable structures comprising fundamentally different material types to be assembled rapidly, consistently and using low cost technology. The basic approach is to use a thermoplastic coating which is deposited onto the surface of one component, usually a metal such as aluminium alloy or copper, and bond this by welding onto the other component which could typically be a thermoplastic or a thermoplastic composite. In this way, designers of structures for the electronics and automotive industries can use the flexibility afforded by advanced thermoplastic processing technologies, the properties of the thermoplastic in use, and the inherent recyclability which thermoplastics bring by remelting. The project will generate results of mechanical test of joints, environmental tests, and techno-economic assessment against conventional adhesive bonding and mechanical fastening techniques.",1
NE/P00637X/1,25652,"The Changing Arctic Ocean Seafloor (ChAOS) - how changing sea ice conditions impact biological communities, biogeochemical processes and ecosystems","ChAOS will quantify the effect of changing sea ice cover on organic matter quality, benthic biodiversity, biological transformations of carbon and nutrient pools, and resulting ecosystem function at the Arctic Ocean seafloor. We will achieve this by determining the amount, source, and bioavailability of organic matter (OM) and associated nutrients exported to the Arctic seafloor; its consumption, transformation, and cycling through the benthic food chain; and its eventual burial or recycling back into the water column. We will study these coupled biological and biogeochemical processes by combining (i) a detailed study of representative Arctic shelf sea habitats that intersect the ice edge, with (ii) broad-scale in situ validation studies and shipboard experiments, (iii) manipulative laboratory experiments that will identify causal relationships and mechanisms, (iv) analyses of highly spatially and temporally resolved data obtained by the Canadian, Norwegian and German Arctic programmes to establish generality, and (v) we will integrate new understanding of controls and effects on biodiversity, biogeochemical pathways and nutrient cycles into modelling approaches to explore how changes in Arctic sea ice alter ecosystems at regional scales. 
We will focus on parts of the Arctic Ocean where drastic changes in sea ice cover are the main environmental control, e.g., the Barents Sea. Common fieldwork campaigns will form the core of our research activity. Although our preferred focal region is a N-S transect along 30 degree East in the Barents Sea where ice expansion and retreat are well known and safely accessible, we will also use additional cruises to locations that share similar sediment and water conditions in Norway, retrieving key species for extended laboratory experiments that consider future environmental forcing. Importantly, the design of our campaign is not site specific, allowing our approach to be applied in other areas that share similar regional characteristics. This flexibility maximizes the scope for coordinated activities between all programme consortia (pelagic or benthic) should other areas of the Arctic shelf be preferable once all responses to the Announcement of Opportunity have been evaluated. 
In support of our field campaign, and informed by the analysis of field samples and data obtained by our international partners (in Norway, Canada, USA, Italy, Poland and Germany), we will conduct a range of well-constrained laboratory experiments, exposing incubated natural sediment to environmental conditions that are most likely to vary in response to the changing sea ice cover, and analysing the response of biology and biogeochemistry to these induced changes in present versus future environments (e.g., ocean acidification, warming). We will use existing complementary data sets provided by international project partners to achieve a wider spatial and temporal coverage of different parts of the Arctic Ocean. The unique combination of expertise (microbiologists, geochemists, ecologists, modellers) and facilities across eight leading UK research institutions will allow us to make new links between the quantity and quality of exported OM as a food source for benthic ecosystems, the response of the biodiversity and ecosystem functioning across the full spectrum of benthic organisms, and the effects on the partitioning of carbon and nutrients between recycled and buried pools. To link the benthic sub-system to the Arctic Ocean as a whole, we will establish close links with complementary projects studying biogeochemical processes in the water column, benthic environment (and their interactions) and across the land-ocean transition. This will provide the combined data sets and process understanding, as well as novel, numerically efficient upscaling tools, required to develop predictive models (e.g., MEDUSA) that allow for a quantitative inclusion seafloor into environmental predictions of the changing Arctic Ocean",1
EP/S001581/1,7361,Auto-Fungan: Automating the continuous anaerobic digestion of wheat straw by co-cultures of fungi and methanogens,"Wheat straw (WS) is an energy-rich, relatively inexpensive source of biomass that can be converted to biogas fuel during anaerobic digestion (AD) by microbes living in the absence of oxygen. WS is a particularly good candidate for conversion to clean energy and other useful products in industrial bioprocessing because it is a globally abundant agricultural residue and is commonly viewed as a waste product. However, challenges are associated with using WS as a feed resource for fuel production because the chemical structure is abundant in lignocellulose. Lignocellulose, a mixture of biomass polymers, is highly resistant to enzymatic breakdown (or hydrolysis) by the majority of well-characterised microbial species. Hydrolysis is an essential step that is required to derive small enough sugars from WS, for uptake by microbial cells. During conventional AD of WS, the speed of hydrolysis often limits the rate of biogas fuel production and this heavily influences the overall bioreactor size. Therefore, AD plants tend to be very large in order to allow for the time required for bioconversion of WS and this can increase capital and operational costs.

Typically, industrial AD is reliant on undefined microbial communities. The hydrolysis stage can take weeks and is performed by a consortium of bacteria dominated by species of Clostridium. Several of these species can deconstruct WS into simple sugars that they ferment to provide for their metabolism. Products of clostridial fermentation include H2, CO2 and acetic acid. These chemicals become the substrates for a second group of microbes, the methanogenic Archaea, which convert them to methane fuel. The biological process of lignocellulose conversion in AD is analogous to microbial activity in the rumen of mammalian herbivores (e.g. cattle and sheep). However, lignocellulose in the rumen is converted over a much shorter time period that lasts for several days (as opposed to several weeks in industrial AD). One explanation for this discrepancy stems from the fact that anaerobic fungi native to the rumen are able to perform hydrolysis much more efficiently and effectively than clostridial bacteria. However, in comparison to clostridia, relatively little is known about the anaerobic fungi. Furthermore, no information is available concerning their growth and activity with co-culturing methanogens in continuously-fed fermentation systems. Almost all previous investigations on the anaerobic fungi have used culture volumes (typically less than 100 ml) and batch-culture methodologies that are not comparable with industrial AD, nor with the growth conditions prevalent in the rumen. In particular, information is unavailable about the ability of anaerobic fungi to survive in continuously fed bioreactors. This is due to the absence of a low-cost, lab-scale bioreactor, capable of continuously feeding particulate lignocellulose material while maintaining the aseptic, anaerobic conditions that are necessary for fungus-methanogen co-culture survival.

Initially, this project aims to meet a requirement for the development of an automated lab-scale bioreactor system that is capable of continuously feeding WS to anaerobic fungus-methanogen co-cultures under aseptic conditions. The newly developed system will be used to study microbial growth in a continuous culture system analogous to their native habitat. Additionally, biomethane production will be compared between fungus-methanogen co-cultures and conventional AD consortia (dominated by clostridial species and their associate methanogens). If the fungus-methanogen co-culture can significantly outperform conventional AD, this new knowledge will facilitate the production of smaller digesters that can handle significant throughput of lignocellulose material. This will ease the cost of anaerobic digesters for decentralised production of clean energy in rural communities that exist in close proximity to cereal crop growers.",1
102253,1920,Hybrid Electric Push-Back Tractor,"HElP-BT: Hybrid Electric Push-Back Tractor
HElP-BT is a series hybrid, aircraft push-back tractor with a downsized diesel engine and an electric driveline with a state of the art control system and energy storage device. The project brings together companies providing market leading innovation and a global sales reach along with a leading academic institution to deliver new product in the off-highway market.
Douglas Equipment are the OEM, vehicle integrator and route to market, ensuring that the airline and airport functional and legislative requirements are met. Hyperdrive are responsible for the hybrid powertrain design, manufacturing the energy store and developing the control system. Birmingham University will carry out simulation work to size the hybrid sub-systems and optimise their control. 
A prototype vehicle will be built to demonstrate the system and prove it's reduced emissions and lower running costs to Douglas Equipment's worldwide customer base.",1
1959133,12859,Predicting Pit-to-Crack Transition by Using Peridynamics,"Environmentally assisted cracking (EAC) is considered as the primary cause of failure of metallic structures and components with environmental and, occasionally, catastrophic consequences. Stress-corrosion cracking (SCC) is one of the main types of EAC mechanisms. It can be defined as the progressive failure of the material due to the presence of non-cyclic tensile stress and the exposure to a corrosive environment. In some cases, the tensile stress necessary to trigger the phenomenon can be as low as 5% of the yield stress. Due to the substantial number of SCC critical environment-material combinations, a wide range of systems related to different industries are affected by this phenomenon such as pipelines, nuclear power systems, aerospace and marine vehicles, boilers, cooling water systems, and oil and gas drilling and production systems. When inspection and maintenance of structures is inherently challenging, the damage tolerance approach is not feasible. This means that a deterministic model is necessary to improve the safety and reduce the cost of over-conservative designs. Pitting corrosion is often the precursor of SCC. Despite the availability of advanced computing resources and software, predicting SCC and pitting corrosion propagation poses many challenges. The formation of corrosion pits occurs preferentially in areas where the tensile residual stresses are highest. Also, residual stresses exist at different length scales. Moreover, it is widely recognized that SCC damage is affected by metallurgical (e.g. chemical composition, material micro-structure, micro-chemistry) and environmental variables (e.g. temperature, electrode potential, PH, dissolved chemical species) which play a role at different length scales. Simulation of pitting corrosion involves a moving electrode-electrolyte boundary (interface) across which the concentrations of ions and their gradients are discontinuous (sharp-interface assumption). The construction of solutions to non-linear second-order partial differential equations associated with electro-diffusive transport in the electrolyte domain and with propagating interfaces present formidable challenges for both sharp interface approaches and diffuse interface approaches. One of the major computational challenges with sharp-interface models is that the standard finite element method cannot capture the interfacial discontinuities within a finite element and would necessitate remeshing when the interface morphology changes, which is unavoidable. Methods such as arbitrary Eulerian-Lagrangian, meshfree/meshless, or moving mesh for evolving sharp interfaces can be tedious and/or computationally expensive, especially, when Neumann and Dirichlet boundary conditions are prescribed on the interface. Due to the aforementioned reasons, a new multi-scale and multi-physics numerical methodology will be developed by using peridynamics for modeling of pit nucleation, pit growth, transition from pit to crack, short SCC crack growth and long SCC crack growth. Peridynamic framework will enable the coupling of electrochemical-mass transport problem with corrosion front movement while introducing a characteristic length-scale. Furthermore, it will consider not only the diffusion of ions due to concentration gradients but also electro-migration of dissolved ionic species in the aqueous solution environment within the pit and the rate of depletion or production of ions due to chemical reactions for investigating corrosion. The electro-diffusion of ions will be modeled based on dilute solution theory using the Nernst-Planck equations along with the assumption of local electro-neutrality. The proposed approach will enable simultaneous analyses at different length scales within the same numerical framework. Completion of the proposed project will lead to computational and analytical tools that will help in designing against SCC and pitting corrosion in marine structures.",1
2145109,17769,Biodegradable batteries for biomedical engineering,"The overall aim of the project is to develop a novel biodegradable energy storage device with controllable degradation characteristics. The project will be based on a pre-existing concept developed by Wallace et al. and will be broken down into 5 objectives corresponding to the major components of the device, namely:
1. Anode
2. Separator
3. Electrolyte
4. Cathode
5. Encapsulant

The project will employ a combination of lab based synthesis and characterisation with state-of-the-art atomistic simulation.",1
2115994,16707,Hybrid Nanomaterials for Energy Storage,"Single-walled carbon nanotubes (SWNT) exhibit exceptional conductivity and have a very high surface area, making them excellent candidates for next generation battery and supercapacitor materials. Their hollow tubular morphology enables effective encapsulation and protection of the redox-active guests, such as metal or metal oxide nanoclusters (NC), facilitating rapid charge-discharge cycles and protecting NC during the process, both of which are key challenges in the development of new energy storage materials and devices. In this project you will design, prepare and characterise redox-active hybrid nanocarbon materials using advanced chemical nanoscience methods and explore their electrochemical properties using electroanalytical methods.",1
NE/N006852/1,18598,Linking biotic attack with tree mortality &amp; canopy condition in droughted tropical rainforest,"We propose an international network to explore this key knowledge gap in understanding the effects of pests and pathogens in accelerating tropical rainforest tree mortality during drought. The project will deliver an integrated and focused anlaysis, using expertise in plant physiology, forest ecology and microbial and insect ecology. It will also make use of the unique leverage of the world's only long-term drought experiment network in tropical forests. We will use field-based workshops at two current tropical forest drought experiments, in Australia and Brazil, to bring together experts in plant function, the effects of pest and pathogen ('biotic') attack on woody tissue, and vegetation modelling. New ground-based and remotely-sensed measurements will be examined to test for relationships between measures of biotic attack and metrics of plant function during experimental drought. We will compare responses in different tree size classes, tree species groups, and at the level of the forest ecosystem (large experimental plot treatment). 

The outcome will be new insights into the causes of tropical rainforest tree death from drought, in relation to plant physiology and insect or microbial attack. This insight will be delivered in the form of new data, new scientfic articles and information that can be used by vegetation modellers to predict the effects of drought on tropical forests in the future.

The group of experts built using these funds will form a pre-eminent multi-disciplinary consortium in the subject area, capable of advancing the subject into the future for the benefit of the science, interested environmental policy makers and university educators.",1
NE/M008584/1,10805,Groundwater Futures in Sub-Saharan Africa,"Groundwater Futures in Sub-Saharan Africa (GroFutures) will develop the scientific evidence and inclusive groundwater management processes by which groundwater resources can be used sustainably for poverty alleviation in Sub-Saharan Africa (SSA). It will improve understanding of the volume and renewability of groundwater in SSA, and develop robust models and tools to forecast available groundwater resources under changing climate, land-use and demand scenarios, including expansion of arable land under irrigation. GroFutures will examine current groundwater governance processes and identify pathways toward more sustainable and equitable use of groundwater resources that are reconciled to projections of changing demand and resource availability. It will assemble an international consortium of scientists with an unmatched track record of groundwater research and stakeholder engagement in SSA that both leverages substantial additional investment (&pound;461,000) and engages with research and development communities across Anglophone and Francophone Africa. GroFutures will also establish a Network of African Groundwater Observatories that representing the primary groundwater environments and development governance challenges in SSA that features a new dataset of 25 records of groundwater-level observations that are 2 to 6 decades duration from across SSA enabling the most rigorous analysis of the relationships among climate, land-use and groundwater recharge that has ever been conducted in the tropics. Dedicated basin observatories will be constructed that will enable very detailed monitoring of the physical process by which groundwater is replenished and application of a new method for quantifying the volume of groundwater in African aquifers thereby overcoming fundamental limitations in present knowledge of groundwater in SSA. GroFutures will also employ an innovative and participatory approach to the management of groundwater which will enable for explicit consideration ofthe views of poor people in making decisions over the allocation and development of groundwater resources.",1
NE/N017471/1,19288,D-Risk: an innovative decision-support tool for improving drought risk and abstraction management for UK irrigated agribusinesses,"Irrigation is an essential component of crop production to meet supermarket and retailer demands for premium quality produce when rainfall is insufficient. Under drought conditions, the ability to provide sufficient irrigation can be constrained by abstraction licence conditions, with consequent important impacts on crop yield and quality and farm revenue. As part of the abstraction reform process, the Environment Agency (EA) are proposing to change the conditions of agricultural time-limited licences (TLLs) as they are due for renewal. These conditions would reduce the amount of water licenced for abstraction in order to meet objectives set by the Water Framework Directive (WFD). This will represent a major business water risk to the soft fruit, field vegetable, salads and potato growing businesses in regions that are dependent on direct abstraction. It is vital for irrigated farmers to understand the implications of these changes to their abstraction licences, to their risk management and to the competitiveness and economic viability of their businesses. Recent work at Cranfield has shown that the total net benefits of irrigation in England in a 'design' dry year are around &pound;219 million, demonstrating the substantial business risk that a lack of irrigation water can pose to farmers. 
 
Although the EA originally planned to take immediate action, it has agreed to delay its implementation until 2018. This provides a valuable opportunity to support businesses in understanding the repercussions of the proposed reforms for the future drought risk management of their farming enterprises. However, there are currently no tools available to support irrigated farming businesses to do this. 

Given the economic importance of irrigation to many farm businesses, we propose to use insights gained from recent and ongoing research within the NERC-funded HistoricDroughts (NE/L010070/1) and MaRIUS (NE/L010186/1) projects to help farm businesses understand the consequences ofthe proposed licence changes to their business in the context of drought risk management. In particular, using a combination of farm data, pre-existing modelling tools that relate crop type to irrigation need and historical re-constructed weather data covering the whole of the twentieth century from these projects, we will work with our key Project Partners to develop an innovative web-based tool (provisionally named D-Risk) that will allow irrigated agribusinesses to evaluate:
1) How the proposed abstraction licence reforms will affect their licensed volumes upon renewal, post 2018;
2) How the reduced licensed volumes will impact on current farm business plans through changing attitudes to drought risk, based on the balance between licensed volumes and irrigation need under historical weather;
3) How best to adapt their farm business plans to achieve an acceptable future level of drought and water resource risk;

The project will involve a small but highly active consortium of project partners in the Cam and Ely Ouse catchment in Anglian region where the licence renewal changes will first be implemented by the EA. Their engagement is explicit throughout each of the work packages and their input is integral to the project. Case Studies describing how the D-Risk web-based tool was used to revise our Project Partners' business planning to improve their drought risk management will be used, in conjunction with workshops co-organised with the National Farmers Union and UK Irrigation Association, to promote the use of the D-Risk tool to the &gt;3500 irrigated agribusinesses with TLLs outside Anglian region that will subsequently be affected once the roll out of the EA procedure commences, thereby contributing to the economic competiveness of the UK food supply chain.",1
103586,19956,&quot;Eco-Net&quot; Remote Boiler Management System,"&quot;Eco-Net&quot; is a digital innovation for the domestic heating market to connect the control electronics in gas boilers directly to the cloud, allowing them to be monitored, controlled and calibrated remotely. Eco-Net will add significant value to consumers, reduce servicing costs, and allow manufacturers to differentiate their products. It will reduce household gas bills and the carbon footprint from domestic space and water heating. Eco-Net modules provide a low-cost direct connection between the boiler electronics and a secure cloud-hosted app platform that will allow different data access and control features to consumers, to housing associations and service providers, and to manufacurers of HVAC equipment.",1
EP/N017870/1,9427,Glass-Ceramic Wasteforms for High Level Wastes from Advanced Nuclear Fuel Reprocessing,"A key barrier to maturation and exploitation of glass-ceramic technology, for immobilisation of high activity waste from nuclear fuel recycle, is the gap in fundamental understanding of the molecular-scale mechanisms of phase separation and crystallization, that lead to the development of the desired phase assemblage and microstructure. These characteristics determine the long-term performance behaviour of the glass-ceramic wasteform in a geological disposal facility. The demand for increased waste loading per package, to minimise onward storage, management and disposal costs, results in a tendency towards liquid-liquid phase separation and (uncontrolled) crystallization of complex metal oxide phases. The grand challenge, to be addressed in this project, is in predictably achieving the targeted phase assemblage and microstructure, requiring a detailed understanding of the transformation process as a function of both cooling rate and melt chemistry. Controlling this phase separation and crystallization process is critical to preventing the formation of a non-durable crystal, glass, or crystal-glass interface. This understanding is of paramount importance for radioactive waste management programs in the UK, USA, and elsewhere, which seek to exploit glass-ceramic technology or, conversely, optimize conventional borosilicate glasses to improve the solubility of key fission products and actinides. 
This research program is a joint collaborative enterprise between leading researchers from the US and UK who, collectively, bring mutually complementary and compatible skills, capabilities, and interests required to achieve a paradigm shift in the fundamental understanding of relevant phase separation and crystallization mechanisms in glass ceramics for radioactive waste immobilisation.",1
2282634,45832,"Low-Impact development, self-governance and enclosure: planning's difficult relationship with rural sustainability","Rural issues remain overlooked in planning debates about sustainable futures - other than as a site for preservation, food production, recreation or urban overspill. However, in the context of climate change, food insecurity and climate change the purpose of the rural in a sustainable future remains poorly defined. How planning deals with structural issues such as these depends upon how planning - as a tool which is suited to incremental change - forecloses on radical sustainable futures in rural environments.
A specific gap in the literature is around the meaning and implication of those who aim to live beyond the system - by not having planning permission - in a radically sustainable way. The low impact development movement broadly rejects mainstream attitudes towards carbon reliance, industrialised agriculture and private property. However, planning has way of understanding this which leads to significant obstacles in gaining and retaining planning permission for low impact sites. 
The broad themes explored will be planning's treatment of rural areas and historical geographies of rural land and property. Discourses in planning focus on the urban as a driver of growth. Consequently, the rural is treated both as an environment to preserved in its natural state. Viewed in this way the rural is the urban's other: where the urban is designed and anthropocentric the rural is natural and pristine. From this I will investigate how the rural is perceived and why certain practices and forms of development are not seen as legitimate. This will be situated in the context of the process of enclosure. The context of enclosure is important, as it is a historical process which has shaped the countryside by through restricting public access through the establishment of private property on previously common land. Relatedly, the process and establishment of private property has led to a perceptive difference in what the countryside is for and the bounds of legitimate activity and development. Furthermore, the radical groups which challenged enclosure and advocated for a return of the commons - such as the Diggers - are strong influences for ideology behind low impact development.
The question the research will seek to answer is 'What are the consequences of the existing planning order on non-conforming users who follow radically sustainable lifestyles?' To do this I will collect qualitative data about why research participants don't engage with planning and how avoiding detection affects day-to-day activities. Drawing on Forde's description of planning having a &quot;preservationist rationality&quot; I would like to research how this permeates into determining the bounds of acceptability for rural activity both within and beyond planning. Furthermore, I would to explore the aesthetic element of these bounds and how they are policed. A specific focus on non-conforming users and planning in rural areas fills a gap in literature and will provide further scholarship regarding low impact development.",0
NE/M00256X/1,29374,Evolution of phenotypic plasticity in an emerging pathogen,"There is growing concern that the evolution of more virulent and more resistant pathogens in response to our overuse of antibiotics will soon lead to a global crisis. Advances in evolutionary medicine have advocated that the key to developing effective alternatives to antibiotics relies on an improved understanding of how pathogens behave and evolve, in particular in response to host defences. For example, nothing is known about the ability of bacteria to facultatively adjust their behaviour (replication rates) in real time in response to different levels of host resistance, or the consequences of this for disease transmission. Such ability would radically change our understanding of host-pathogen interactions. In particular, because the rate at which pathogens replicate has repercussions for their virulence (i.e., how much damage they do to a host), one prediction is that this facultative behaviour will actually reduce the speed at which virulence evolves, with obvious implications for antibiotics programs in humans, livestock and wildlife. 
Here we provide the first investigation of the causes and consequences of facultative replication rates in pathogens by using a particularly well-documented, emerging infectious outbreak of the bacterium Mycoplasma gallisepticum (Mg), which recently jumped from poultry into a wild North American songbird, the House finch. This outbreak was particularly severe, leading to the death of hundreds of millions of finches, although host resistance became widespread within just 10 years. The environmental changes experienced by the bacteria upon colonisation of the novel finch host, and subsequently during the spread of resistance, represent the typical ingredients that should theoretically give rise to behavioural flexibility, termed plasticity. We use novel infection experiments of wild-caught house finches, combined with cutting-edge molecular techniques, to test how the ability to plastically adjust replication rates evolved in Mg over the course of the finch epizootic and to identify the environmental cue and genetic basis of this plasticity. 
This system allows a rare investigation of the evolution of plasticity in natural populations for two reasons. First, we have access to a comprehensive collection of Mg strains sampled at epizootic outbreak and subsequently during the spread of host resistance. It is therefore possible to conduct experimental infections using these different strains of Mg to measure differences in plasticity among strains and to test how plasticity evolves in the wild. Second, we can use antibiotics, vaccines and immune-suppressants to experimentally manipulate the level of resistance of wild-caught finches and thereby recreate the environmental conditions experienced by Mg over the course of the epizootic. Specifically, we will answer the following four questions. (1) Is pathogen plasticity in response to host resistance beneficial for the pathogen in that it allows the pathogen to infect more secondary hosts before it is cleared by the immune system? (2) How does plasticity evolve following colonisation of a novel host and, subsequently, in response to the spread of host resistance? This question will allow us to test whether an abrupt change in the environment (i.e., colonisation of a new host) and/or whether gradual environmental changes (i.e., spread of host resistance) drive the evolution of pathogen plasticity. (3) What is the environmental cue used by bacteria to elicit phenotypic plasticity? Bacteria are known to sense molecules secreted by other bacteria in the environment. Whether they use signals of bacterial density or of bacterial stress to assess the quality of their environment, however, is unknown. (4) What is the genetic basis of plasticity? This question will be determined using the very latest genetic sequencing technology by identifying genes and processes underlying difference in plasticity between different strains of Mg.",0
NE/N012364/1,28839,Pan-participatory Assessment and Governance of Earthquake Risks in the Ordos Area (PAGER-O),"The Ordos region has a population of about 80 million, of whom approximately half live within large cities, which have grown rapidly and recently around the nuclei of much smaller cities that are known to have been destroyed by earthquakes in the historical past. The remainder of the population is rural, and live in highly vulnerable buildings. The region has suffered three of the most deadly earthquakes in recorded history; the 1556 Huaxian earthquake was responsible for the deaths of over 800,000 people, and other historical earthquakes are known to have killed over 100,000 people. This project aims to make a significant improvement in the assessment of seismic hazard in the region, and is particularly timely because the study area covers the most populous part of the Chinese end of the Silk Road Economic Belt, a planned investment of hundreds of billions of dollars that will transform communications, transport and trade across Eurasia. 

This population is particularly vulnerable because there are two fundamental gaps in earthquake-risk reduction in Mainland China First, there is a gap between scientific understanding of the risks and hazards, and the knowledge that communities need in order to design effective practices of governance. The second gap is between the top-down and bottom-up approaches to the governance of disaster risk reduction (DRR).
 
This project brings together teams from the China Earthquake Administration (CEA), the Overseas Development Institute (ODI), and the Universities of Oxford and Cambridge to carry out research and practical action to bridge these gaps. Our work will be rooted in the two-thousand-year historical record of earthquakes in the region, which allows us to investigate a suite of methods for bridging these gaps. In this work, we shall collaborate closely with researchers, policymakers and operational agencies at local, provincial, national and international level, and shall work with them to integrate local (bottom-up) and national (top-down) approaches to earthquake DRR.

We shall use tools of modern tectonic geology to estimate probable sizes of the historical earthquakes of the region. Then we shall calculate ground shaking if such an earthquake were to recur. We shall make loss estimates using both the CEA's database of vulnerability and that of the US Geological Survey's PAGER (Prompt Assessment of Global Earthquakes for Response) project. These estimates will form the basis of engagement between the scientist and policy makers at the county scale and upwards, where legislation and practice are top-down.

At the same time, working in partnership with local communities, village, town, and county officials, and staff of local NGOs, we shall explore the social roots of earthquake disaster risk by focussed studies on small sites within the region. We shall partner with Geohazards International (GHI) to produce a detailed scenario based on a historical earthquake. Such scenarios have been shown to stimulate communities to generate their own mitigation strategies for earthquake risk, and we shall use this technique as the basis for developing, testing, and evaluating participatory approaches to assessing earthquake vulnerability and risk from the bottom up in China. Finally, with the provincial and national partners we shall explore routes to link these with top-down laws regulations and procedures to establish improved, long-term, earthquake disaster risk reduction.",0
NE/P014313/1,119,A Bayesian Belief network to operationalize the concepts of Soil Quality and Health,"'Soil Quality' and 'Soil Health' are general terms for indicators that are associated with 'Soil Security'. None of these terms within quotation marks is easy to define, however. Neither are they easy to quantify rigorously in a way that avoids dispute. Nonetheless all three terms have traction with policy makers and with land managers and regulators. Indicators provide benchmarks for ranking different places or practices and deciding where to deploy effort to bring about change as effectively and economically as possible and they provide a means to assess afterwards whether or not and to what extent this change has actually been brought about.

As a result, indicators of this kind are attractive to stakeholders. Indicators often rely on expert opinion for their derivation, but experts differ. Even apparently objective biophysical measurements are subject to error and worse, the soil itself varies from place to place and even time to time. It is not clear how to eliminate bias or how to weight the different kinds of information - opinion and measurement.
There is therefore scope for developing a rigorous, scientific approach to SQH that incorporates expert-derived opinion alongside physically-based measurements in our understanding of Soil Quality and Health (SQH) in a scientific manner.

Bayesian Belief Networks are graph-based, directional networks that can incorporate probability distributions of these various kinds of data. Essentially the directedness leads from multiple pieces of data to a conclusion - in our case a rating of SQH. The network is self-learning in that any additional soils and data for which quality assessments are available will re-inforce the pathways that decide the quality rating. In use, SQH ratings for additional soils that contain even partial data can still be obtained if the net defaults to mean values where data is missing.

To accommodate the various functions and scales needed to operationalise SQH, will require a set of Bayesian Belief Networks that considers the interactions of soil properties with SQH but also the impact of environmental change and land use and management on soil quality. There a numerous advantages to using BBNs: they can consider and integrate biological, economic and sociological factors and have effectively been use to determine the consequence of land-management decisions in land use decision behaviour. Bayesian modelling methods are a rigorous framework in which a complete characterization of the coupling and variability of soil quality is based on physical laws, empirical relationships but can easily incorporate expert knowledge formally and other kinds of soft data.",0
1953556,40542,Global change ecology and the biogeography of human infectious diseases,"Infectious diseases threaten individual wellbeing, are a major public health burden, can impact economies and, as most recently seen with the west African Ebola outbreak, can have profound international consequences in places far removed from their origins. Infectious diseases can also threaten agricultural systems and wild plant and animal biodiversity. Understanding what factors drive the emergence and shape the global distributions of infectious diseases is thus of considerable public health, economic and conservation importance. 

In this project, the student will adapt, apply and further develop 'biogeographic' methods/theory drawn from ecology, geography and biodiversity science (including invasion biology, macroecology, community ecology, bioinformatics) to help characterize the factors that define the global distributions of infectious diseases (pathogeography), with a view to informing disease emergence/spread risk assessments and biosecurity strategy via cataloguing and forecasting shifts in disease risk in a rapidly changing world. 

In previous work, we have developed a simple pathogeographic framework to shed light on the underlying barriers to human infectious disease dispersal at regional and global scales, reveal what traits allow some infectious diseases to overcome these barriers to spread or become pandemics, and decompose the risk factors that link global environmental change to the emergence and spread of human infectious diseases more broadly. Potential applications of this work range from outbreak investigation, pathogen discovery and surveillance, biosecurity risk assessments, disease risk forecasting and design of management interventions. 

The student will have the opportunity to build directly on prior work in which we have developed a conceptual framework for pathogeographic analysis, compiled a number of datasets relevant to analyzing the observed and potential distributions of a large number of clinically relevant human infectious diseases, particularly zoonoses, and conducted preliminary risk assessments for the changing basis of disease risks with a focus on Europe. Extensions of this work could incorporate specific interests of the candidate, such as applications to wildlife or plant pathogens, or integration of novel data types or methods such as genomics or the use of big data. We thus encourage candidates from diverse backgrounds and a broad range of experience / expertise to apply.",0
NE/N006496/1,940,Development and application of eDNA tools to assess the structure and function of coastal sea ecosystems (MARINe-DNA),"Summary

SeA-DNA: Development and application of eDNA tools to assess the structure and function of coastal sea ecosystems.

This NERC highlight topic focuses on the use of eDNA as a new tool for 21st century ecology. Environmental DNA (eDNA) is defined in the call as 'free DNA present outside of any organism'. The aim of the call is to address the current knowledge gaps in the application of eDNA approaches to help understand community biodiversity and dynamics of ecosystem functioning. 

We will conduct a proof-of-concept investigation at Station L4, an exemplar coastal ocean ecosystem, and natural laboratory, in the English Channel off Plymouth, UK. Starting with a hydrodynamic model to spatially and temporally define the ecosystem (how large is the natural laboratory?) the project will then be split into three experimental phases: 

1) eDNA methodological validation (developing the tools);

2) 18-month temporal pelagic survey (testing the tools); and

3) Comprehensive data analysis and model assimilation (did the tools work, what did they tell us, and are they useful?)

Using a wide range of expertise from 4 different institutions (PML, MBA, NOC, and U.Exeter), we will investigate a spatially defined region, from estuarine to coastal, benthic to pelagic; and at a range of temporal resolutions building on NERC National Capability sampling regimes and biosensor deployment. E-metagenetic and e-metagenomic data (individual genes to whole genomes) will be used to answer cross-cutting science questions utilising current physicochemical and biological information collected in parallel at this important coastal site. 

Results from this project will provide a methodological template for the use of eDNA and remote eDNA biosensors in aquatic ecosystems. Downstream data will significantly advance our understanding of persistence of eDNA, and its potential impact on informing models of ecosystem functioning. 

Products of this research will have wider implications for the use of this tool on fisheries assessments, fish pathogen detection, conservation biology, environmental risk management (e.g. toxic algae blooms, human pathogens, ballast water regulations), with the wider aim of supporting biodiversity and nature's services through NERC's strategic pillar of &quot;Managing environmental change&quot;.",0
1650505,14838,Linking biochemistry and genetics in celery to taste and flavour perceived by consumers: developing a more acceptable product.,"Celery characteristics
Celery Apium graveolens var. secalinum is popular as a fresh product due to its characteristic flavour and texture. It was originally adapted to marshy conditions, hence its tendency to produce hollow stems and petioles. Domestication of the crop has resulted in the selection of more edible varieties with reduced bitter and strong flavours. Celery is a good source of Vitamins C, K, sodium, and potassium in the diet (USDA, 2012) and has a strong protective effect against colorectal cancer (Jinfu et al., 1991). It is rich in flavonoids and phenolics (Lin et al., 2007); oxidation of the latter causes postharvest browning of cut surfaces. Key flavour compounds in celery are phthalides, and to a lesser degree the terpenes. Van Wassenhove et al (1990) found 33 compounds using GCMS that were present in all four varieties of blanching celery tested. 

The aim of the project is to develop breeding lines and associated molecular markers that can give rise to a celery variety with improved postharvest performance and flavour attributes. 

Project plan.
A L Tozer Ltd have 52 lines in total available to the project. We will select 30 lines that cover the diversity and grow them in controlled environment at Reading. We will determine flavour profiles of volatile compounds e.g. terpenes and phthalides using GCMS and non-volatile compounds such as phenolics and sugars using LCMS. From these data we will select 6 extreme lines = Milestone 1 (month 9).
We will conduct sensory panels to evaluate the selected extreme lines, thus validating the biochemistry against human perception = Milestone 2 (month 12).
We will start to generate mapping populations based on linked parents that represent the breadth of biochemistry and flavour perceptions. If the first crosses are made in year 1 we should be at F2 generation by year 3 = Milestone 3 (month 30). 
The six extreme lines will be grown in Spain and the UK in year 2, thus testing the impact of different environments, soil types and seasons on the biochemical and sensory properties of the selections. This work will enable evaluation of the environmental impact on celery flavour = Milestone 3 (month 24).
In year three the project will examine changes in flavour and biochemistry at different plant development/field holding times, thus providing information on which lines are likely to impart seasonal and sensory stability = Milestone 4 (month 36). Consumer panels will be used to assess liking (or otherwise) of the parental celery lines.
Transcriptome sequencing of the parental generations will be used to assemble a celery genome. SNPs will be scored in the F2 population and a working map will be produced = Milestone 5 (month 40)
In year 4 the project will collaborate with G's to process celery from the parental lines and in the F2 generation of the mapping population through their commercial processing line. Postharvest quality (firmness, weight loss, browning, stem hollowing) and flavour biochemistry will be analysed and used as traits that can be mapped = Milestone 6 (month 45). These traits will give broad QTL, and possible association with transcriptome based markers that Tozer can refine and take forward beyond the life of this PhD. Even if transcriptome based markers cannot be found the project will still provide strong associations between biochemistry and desirable flavour profile, such that development of new lines based on metabolite profile will be possible.",0
2113283,44375,The Railways and the Making of Upland Britain: The Lifecycle of an Envirotechnical Regime,"Railways have played an integral role in the production of Britain's upland landscapes. They were the keystone of a envirotechnical regime and important agents of social, cultural and environmental change, proving vital to processes of industrialisation and settlement. Their subsequent dismantling and re-use - and sometimes revival - make their long afterlives important vectors for processes of post-industrial transformation. This history has yet to be written. This project will seek to redress this historical elision and will help the NRM establish a stronger narrative about the crucial role railways have played in the production of some of the UK's most valued landscapes.",0
EP/R010919/1,13342,Perspective Media: Personalised Video Storytelling for Data Engagement,"An unprecedented amount of data exists about our lives, environments and the people we share them with. The devices (e.g. phones, smart thermostats and even cars) and organisations (e.g. councils, supermarkets) we interact with on a daily basis, record and store ever more information about things we do and care about. By empowering large numbers of people to access and interpret this data, we can transform the way we understand and make decisions about key aspects of our lives (e.g. health and energy use) and have a greater say in how we are treated by the government and other groups. 

We can access an increasing amount of this data by downloading it from our devices or other places like our local council's website. However, being able to get data does not necessarily mean we are able to understand it. Interpreting raw data files requires special software and techniques that most of us are not trained to use. Websites and apps that let us access and browse data in more accessible forms like graphs and infographics can help many people, but still are not right for everyone. Some people do not have the educational background needed to understand these forms of presentation, and others struggle to interpret what the facts and trends they show mean in the context of their lives. Equally importantly, many of us will not find seeking out and browsing data displayed in these ways an enjoyable and enriching way to spend our time - and might miss out on benefits of understanding our data as a result.

This project will pioneer a new way for presenting data to the public that a large and diverse section of the population will be able to, and equally crucially, want to use. We propose that this can be achieved by creating personalised video stories that tell us how our data relates to our lives and the people around us. We call this new form Perspective Media. Imagine a documentary about climate change that uses a personalised narrative structure and graphics based on data from your smart meter to show specific and achievable ways to improve your carbon footprint. Building on the skilled craft of video storytelling (e.g. from TV) to present a personalised perspective on data will allow us to provide an easier route for many people to understand how large and complex data sources relate to their lives. Basing our approach on a highly popular media format like video, with a diverse range of genres, will mean that large numbers of people from different backgrounds will enjoy using it to engage with their data.

Current ways of making video content assume that stories are fixed and linear, with the same information shown to everyone in the same order. Perspective Media, on the other hand, will show each viewer a personalised story about their data. For this reason, new ways of telling video stories that respond to data will need to be developed. These new approaches will, in turn, require new tools and technologies for creating content and delivering it to viewers. The aim of this research is to lay the foundations for these developments by: 1) investigating a range of techniques for presenting data in personalised video story form; 2) analysing the processes and tools that are currently used to make video stories to see how they need to be changed and extended; and 3) exploring how users experience video stories that are personalised to their data, and whether they truly offer a more inclusive and enjoyable way for people to engage with data.

We will achieve this aim by bringing together people with expertise in media production and data analytics with technology designers, to create prototypes of personalised video stories based on data. By analysing these prototypes, and how they are made and received by audiences, we will inform future research into production tools and technologies for Perspective Media and encourage the growth of a community of people in the media industry who create it.",0
NE/R014922/1,6592,Innovative monitoring of offshore methane and hydrocarbons with miniature sensors and autonomy,"Autonomous Underwater Vehicles (AUVs) can be loaded with chemical sensors and sent on missions to conduct high-resolution surveys in the deep sea. They are of interest to the oil and gas industry, as, if fitted with the right sensors, they can be used to help monitor subsea pipelines for leaks and also pinpoint new hydrocarbon reserves under the seafloor by measuring the chemical composition (e.g. the dissolved methane concentration) of the waters above. However, AUVs are prohibitively expensive for routine monitoring and exploration, and often require a large and expensive ship to be present on the surface. A new innovation in AUV technology is the microsub. These miniature AUVs can cost about 2% of the price of a traditional large AUV and are small enough to be launched from a small inflatable boat or the shoreline. They can reach complex areas (shallow waters and reefs) that larger AUVs cannot get to, and can operate in large swarms to efficiently survey a large area. The main drawback of microsubs is that they have limited onboard space and power, meaning that many sensor systems cannot be carried. This means the measurements performed by microsubs are very basic. No methane sensors are currently available that can be deployed on microsubs. At the National Oceanography Centre in Southampton, we have developed a new miniaturised methane sensor that could be deployed on microsubs. In this project, we will adapt this sensor to be deployed on ecoSUB, a microsub developed at the NOC in partnership with Planet Ocean. We will work with BP to test the ecoSUB equipped with the methane sensor on demonstration missions, and help BP to change the way in which they perform leak detection and exploration. Detecting leaks early using microsubs will help BP reduce the cost and environmental impact of subsea pipeline leaks. More efficient exploration will reduce the cost environmental impact of searching for new oil and gas reserves.",0
2366363,43294,The macroevolutionary drivers of bird diversification,"The diversity of phenotypic traits observed in the natural world is extensive, driven by pressures ranging from natural selection that drives adaptation to ecological niches, to social and sexual selection that determines which individuals have access to resources and mating opportunities. The relative roles of each of these broad drivers, and specific pressures within, is still a highly contested topic, and whilst this has been addressed in empirical experiments and comparative studies, a coherent theory for explaining broad-scale phenotypic evolution is still lacking for many traits. 

To address the issue, this project aims to integrate global datasets of traits, environmental niches and phylogenies for all birds (&gt;10,000 species), combined with newly proposed phylogenetic models, to help shed light on the relative roles of broad selection pressures. Birds are an ideal group for this project because they are relatively well studied, with extensive knowledge of ecological and evolutionary traits. This is further supplemented with additional unpublished data, overall contributing to a near-complete estimation of the variation in many traits, including foraging strategies, adaptive morphology, plumage dichromatism and song; there is also the opportunity to add to this data through literature reviews, museum visits and digital sound archives. 

The initial stage of the project is a six-month training program, comprised of taught modules in evolutionary ecology and statistics, and a three-month project. The aim of this project is to investigate the drivers that shape the evolution of sexual dichromatism in bird plumage. This question was first addressed in a debate between Wallace and Darwin, who believed differences were a result of natural or sexual selection. There have been various attempts at explanations throughout the literature through experiments and reviews, including natural selection on females for cryptic colours, sexual selection on brightly coloured males, and social selection on females that engage in territorial behaviour. This project aims to resolve the relative input of these pressures by assessing the evolution of dichromatism across the whole clade of birds.

Completing this initial study into dichromatism will build a foundation of experience in conducting phylogenetic analyses, a more in-depth understanding of some of the main evolutionary drivers in birds, and a knowledge of the dataset, which can then be applied to other areas of evolutionary theory. This may include, amongst others, continuing research into selection pressures on females, studying the evolution of song behaviours, or studying how human-mediated changes affect the evolutionary stability of traits crucial for ecosystem services, such as beak shape. Another interest is the incorporation of phylogenetic models of birds into range maps, with the intention of assessing the rate of niche evolution, which could be crucial in assessing the future effect of climate change. Through exploring these avenues early on, potential areas of evolutionary ecology will be highlighted that are of interest, leading to more extensive research and subsequent chapters of the thesis.",0
NE/P019269/1,7699,Does developmental plasticity influence speciation?,"Life is a journey. As we grow older, we change. Sometimes we respond in the spur of the moment. Occasionally, an event has long-lasting consequences in spite of any change in circumstance and shapes our outlook far into the future.

This future flexibility, or a lack thereof, also applies to the traits like size and weight that influence our daily risk of death and our reproductive success. Some of these traits retain flexibility throughout life, whereas others can only change in a fixed early window. As humans, we are far more likely to shift weight gain trajectories before six months of age than when older. 

Any ability to flexibly adjust traits can boost survival chances in new or changing environments, but also provides the means to innovate and so express new combinations of traits. Flexibility as a means of innovation might promote the divergence of ancestral organisms into new species, but also might not because such flexibility would mean that species can already deal with whatever circumstances they encounter, which would in turn remove the pressure for any innovation to become hardwired into their DNA.

The long timescales over which this hardwiring plays out complicates collection of data. We don't know whether future flexibility or a lack of it is more likely to catalyse change into new species. In this project, we will contribute this increasingly requested data and therefore provide the first evidence if a lifetime of flexibility, or a stubborn refusal to change, influences the emergence of new species. 

Planktonic foraminifera are single-celled organisms that live in vast numbers in all the world's oceans. While chemical analysis of their fossil remains has generated a remarkably continuous record of past climate change, each individual also retains a complete record of its size and shape at each stage along its journey through life. 

These growth stages can be revealed by state-of-the-art imaging technology, which has sparked a digital revolution in how biologists study life on Earth. To study evolution, we need to study differences among lots of individuals. We need to know how and why these differences change through time. This need to measure lots of individuals means that the current practise of a person pointing and clicking on a computer screen to identify distinct parts is too slow. Computer programmes that provide a faster, more repeatable and less biased way of identifying and analysing such parts are now available, completing the toolkit needed to build big databases.

By bringing together lessons from diverse scientific disciplines, we propose to use the same fossil specimens to collate records of an individual's journey through life and the environment it experienced every step of the way, both of which were changing from day-to-day, millions of years ago.

While the fossil record of planktonic foraminifera provides the necessary timespan and abundance, new computer programmes and imaging technology complete the toolkit jigsaw to investigate for the first time if certain parts of an individual's journey through life are more influential than others in determining the eventual evolutionary destinations of its species. 

Our unique, direct link between organism and environment lets us study the dynamic journey through life in the static death of the fossil record. The fundamental limitation to the current ways we study how new species emerge is the lack of repeated samples through time to follow the genesis of novel lifeforms, and explicitly targeting this limitation using state-of-the-art approaches from multiple scientific disciplines means we will deliver a breakthrough in attempts to answer one of the most fundamental of all biological questions: how do differences among individuals make differences among species?",0
AH/M008142/1,8094,Conferencing the International: a cultural and historical geography of the origins of internationalism (1919-1939),"One of the largely forgotten legacies of the First World War was the belief that peace would result from connections between and across national borders, the fault lines of the war itself. After the centenaries of the War have concluded, we will argue that we should remember how hopes for peace were tied to hopes for connections across the earth; that is, for &quot;the international&quot;.

Forging these connections and new worlds required new sites of interaction, meeting, learning and friendship making. These sites were the international &quot;conferences&quot; of the interwar period, the places in which internationalism was forged and politically debated, emerging through conversation, disagreement, dance, song, taste, and laughter. Through piecing together the records of these meetings, we will provide a rich history of the spaces through which the international was created and challenged, and in which it floundered.

Existing literature has shown that conferences had grown in popularity towards the end of the 19th century, connected to wider showcases such as world fairs and universal exhibitions (35 between 1900-1910) and to the explicitly internationalist claims of the socialist and communist left. But there is a dearth of research into modern international conferences that emerged specifically to take advantage of the opportunities the post-war world offered for peace. For some, peace was the stability of pre-existing colonial empires; for others, peace was &quot;not-war&quot;; while to others, peace required the destruction of the pre-war political landscape. 

We will examine three sets of conferences that demonstrate these visions of peace and their forms of internationalism that were emerging through and in tension with specific nations (Britain, France and the USA): the Round Table conferences on the future of India in the British Empire (Legg), the International Studies conferences of the League of Nations's ICIC (Heffernan), and the Pan-African Congresses (Hodder). Each of these conferences provided a public commentary on the changes brought by the war and the prospects of a new international order which it was seen to make possible. It was the secret negotiations before and during World War I which exposed the urgent need for public political meetings, to which people would travel from around the globe; these meeting spaces are what international conferences provided.
 
We know very little about the internal spaces of these conferences. Internationalism wasn't centrally organised; it took place through specific, brief meetings of overlapping groups in particular locations. As a result, the archives of modern internationalism is fragmented and dispersed. This project will re-assemble and re-interpret these archives through an analysis of the infrastructures, materials and performances of the inter-war international conference: where people stayed; how their days were planned; how clothing and manners facilitated or hindered certain meetings; what they discussed, and how. 

One hundred years after the First World War it is often claimed that modern digital technology and instantaneous communication will render the practice of conferencing obsolete. Yet our globalised world is still shaped by G20 meetings, Climate Change Summits and World Economic Forums, embedding locations like Davos and Kyoto in the international geographical imagination. This project will historically situate and explain how conferencing in our contemporary period remains as important as ever. We will communicate our research through a co-authored monograph and an edited volume resulting from a major international conference and exhibition at the Royal Geographical Society on international conferencing at the end of the award, as well as with smaller workshops that will bring together academics, conferencing professionals, and community groups with interests in the global cast that these meetings assembled.",0
NE/R017565/1,19045,Impact of hydraulic fracturing in the overburden of shale resource plays: Process-based evaluation (SHAPE-UK),"Summary

In recent years, the UK has made significant progress in establishing renewable sources of energy. Solar, wind, biomass and hydro have seen a steady rise in use over the past decade, having gone from providing less than 5% of our electricity in 2004 to nearly 25% in 2016 (DBEIS, 'DUKES' - chapter 6, 2017). Nevertheless, natural gas will continue to be an important fuel in a transition to a carbon neutral supply of electricity. Furthermore, natural gas currently heats roughly 80% of our homes in the UK, and provides an important industrial feedstock. As North Sea gas reserves decline, the UK has in a decade gone from a position of self-sufficiency to importing over 50% of its natural gas. Therefore, for reasons of energy security, affordability and environmental impact, it is desirable to increase domestic gas supplies until we reach a point where carbon neutral energy sources are better established (e.g., nuclear). 

Shale gas and shale oil has transformed the World's energy market, contributing to the reduction of world oil prices and the USA becoming self-sufficient in both gas and oil. Furthermore, CO2 emissions in the USA are back to levels last seen in the early 1990s, because electricity generation has moved from coal- to gas-fired power stations. However, the move to shale gas has not been without controversy. Shale gas resources normally require hydraulic fracture stimulation - or fracking - in order to achieve production at economic rates. This technique is contentious due to public fears over a range of issues, including ground water contamination, induced seismicity, atmospheric emissions and ground subsidence. 

In November 2017 the UK will see its first shale gas stimulation in over 6 years, which will occur in the Vale of Pickering, North Yorkshire. The UK has a strict regulatory framework for shale gas exploitation, which requires close monitoring of any fluid leakage, fracture growth and induced seismicity associated with fracking. To achieve this requires a detailed understanding of local geology, and robust means of sensing fluid movement and stress changes before, during and after stimulation (e.g., geophysical monitoring). SHAPE-UK is a project that will establish a series of best practice recommendations for monitoring and mitigating fluid leakage into the overlying sediments and close to boreholes. To accomplish this, it is crucial that we understand the mechanical processes occurring in the subsurface, which are dependent on the composition of the rock, the chemistry of the fluids, and the structures they encounter (e.g., faults). Through a linked series of work packages that integrate geology, geophysics, geochemistry, petroleum engineering and geomechanics, we will be able to address fundamental scientific questions about the mechanisms for leakage, and how the leaking fluids might affect the sub-surface environment. 

A team of leading experts from a range of disciplines at 6 institutions has been assembled to address 'coupled processes from the reservoir to the surface' - Challenge 3 of the NERC call for proposals in the strategic programme area of Unconventional Hydrocarbons in the UK Energy System. We will exploit newly acquired data from the UK Geoenergy Observatory near Thornton in Cheshire. We are also very fortunate to have access to seismic, borehole and geologic data from a new shale gas development in North Yorkshire and a dataset from a mature shale gas resource in Western Canada. Our project partners include regulatory bodies who monitor ground water and seismicity during shale gas operations. The team has access to several comprehensive datasets and are thus in a very strong position to answer fundamental science questions associated with shale gas stimulation, which will provide a firm foundation for an effective regulatory policy. We expect this project to be a role model study for future developments in the UK and internationally.",0
104281,6680,Novel Ozone Based Sterilizer for Medical Device and Life Sciences,"&quot;The current grant will allow Anacail Ltd to validate a product concept by building a proof of principle machine which can sterilize single use medical devices, and simultaneously pack them in a sealed primary pack, at point of manufacture.

The market need for such a device is the common requirement across all medical and healthcare devices for sterility. Traditional techniques such as radiation or ethylene oxide are either damaging to materials, or can leave toxic residues on devices. The increasing sophistication of modern medical and healthcare devices in terms of advanced materials and surface treatments and the integration of electronics and optics, exacerbates these drawbacks.

Furthermore, the use of hazardous or toxic chemical presents a significant health and environmental risk as these materials must be stored and disposed of in a safe and responsible manner.

Anacail has developed a technology which is based on ozone, a naturally occurring allotrope of oxygen, which, once the sterilization is complete, decays back into native oxygen. This renders the technology environmentally benign and relatively safe to handle as there are no toxic chemicals for storage transport or disposal.

Ozone is already recognised as a sterilant by regulatory authorities such as the FDA (https://www.fda.gov/downloads/MedicalDevices/.../ucm109897.pdf) which can remove significant hurdles to its adoption.

Ozone has not been more widely adopted as a sterilant because of two key drawbacks: When used as a conventional chamber based steriliser, its is relatively slow acting compared with alternatives, and it historically uses pure oxygen as a feedstock gas, which creates significant flammability issues.

Anacail has recently patented a non hazardous gas composition which only contains 21% oxygen, yet can provide high ozone concentrations. This removes the flammability issues which in turn allows Anacail to inject this gas into a bag, which is then sealed. The bag contents are sterilized, and then the ozone in the bag decays back to oxygen, leaving no residues.

The benefit to society for this technology is to reduce the incidence of healthcare acquired infections, provide increased safety in terms of reduced use of hazardous chemicals or radioactive sources, and reduce environmental impact associated with use, storage and disposal of hazardous chemicals.

Once developed, the technology can be adapted for application in healthcare and hospital environments, opening up a second market and directly addressing healthcare acquired infections.&quot;",0
BBS/E/B/000C0424,2232,Transgenerational epigenetic inheritance: mechanisms and consequences for metabolism and ageing,"Epigenetic changes that occur during the lifetime of an individual are generally not inherited by the next generation, as this could subvert epigenetic reprogramming events needed to reinstate totipotency. Yet, some genomic elements remain incompletely reprogrammed, and may thus represent a key genomic vehicle for transgenerational epigenetic inheritance47. Transgenerational inheritance requires that the germline remembers exposure to environmental changes and allows for these to be inherited to the next generation(s). Nutritional stress can mediate transgenerational memory through histone marks and small RNA pathways in invertebrates and DNA methylation changes in mice48,49. As observed in many studies, the inheritance mediated by epigenetic modifications reverts back to wild-type after one or a few generations. However, some epigenetic changes can lead to more permanent genome rearrangements, when coupled to genomic instability. For example, nutritional stress can lead to instability of high copy number ribosomal DNA (rDNA), resulting in copy number variation (CNV) at rDNA loci. There are many key aspects that remain unresolved in the field and this Objective tackles two essential questions: firstly, what are the mechanisms by which epigenetic reprogramming normally returns cells to a na&iuml;ve and totipotent stage and could these mechanisms thereby mediate transgenerational inheritance upon experimental manipulation. Secondly, can, and if so how could, stressors such as age and nutrition contribute to inheritance by modifying CNV through gametes with consequences for metabolism and ageing in subsequent generations.",0
AH/S012303/1,43451,Red River: Listening to a Polluted River,"The Red River in West Cornwall has been described as the most 'unnatural' or 'modified' river in the UK. No part of its 7.5mile length has been untouched by the effects of the Cornish tin-mining industry. Although little more than a stream, the river has played an important role in the industrial revolution in Cornwall and the development of hard-rock mining around the world. This significance has been recognised by the designation of the area through which it flows as a UNESCO World Heritage Site. It continues to be a source of innovation by necessitating the development of new techniques to reduce pollution from the heavy-metal laden mine water that feed into its course. 

Despite these contaminants, the Red River contains a genetically-unique population of brown trout that has evolved to survive its toxic environment. These fish are as much artefacts of the industrial revolution as Cornish engine-houses. In a poem they may operate, along with the river itself, as multi-dimensional metonyms for our complex interaction with the environment. This combination of natural, industrial and post-industrial history makes the Red River a rich subject for an eco-poetic and critical exploration of the human/nature interrelationship. The fellowship will test the ability of creative writing as 'practice-as-research' to create knew knowledge that reveals the complexity of this interrelationship through combining critical textual research, fieldwork, poetic composition and socially-engaged research practices.

There is a growing understanding that we need to confront the mess we're making of our environment. Beach cleans, environmental activism, media campaigns and legislation have drawn attention to the impact our addiction to plastic has had on the world's oceans and rivers. Through working with local communities and partners the fellowship will offer poetry as a gathering place for the social meaning generated by individuals and communities involved in changing their environment. The project will address both visible and invisible pollution connected with the Red River, and visible and invisible feelings about the wider landscape; it will address the conspicuous history of EU-funded signboards, as well as the invisible and ephemeral histories of those who live along its contaminated banks. Set alongside more celebrated rivers like the Dart and the Severn, the Red River may come to operate as an exemplary 'shadow site' counterpointing, through the complex human/nature interaction it embodies, ideas of the wild, sublime and picturesque.

The catchment area for this practice-as-research investigation will be mapped through research into archaeological reports, SSSI statements, historical documents, the literature of rivers, eco-poetics, acoustic ecology, visits to local community groups and schools, interviews with subject experts in aquatic ecology and mining, field-walking and river surveying. It will borrow the ecological concept of the 'ecotone', or meeting place of biomes, as a conceptual instrument for both reading the marginal environments of the Red River and as a metaphor for the way texts shape and are altered by close observation of ecological objects. The fellowship will result in a book length poem, a sound installation, and a scholarly article derived from the knowledge generated through practice-as-research. Findings will be presented at conferences, literary events, in art galleries and heritage sites. The fellowship will demonstrate leadership in developing new methodologies for socially-engaged research and conducting trans-disciplinary arts/science collaborations. These findings will be shared at discipline-specific conferences and online. It will co-produce educational materials for schools and curate a 'Parliament of Waste' event bringing together local people, politicians, artists and experts to debate the environmental impact of pollution and waste on health and wellbeing.",0
1917097,5337,Exploring skin-age limits on the production of vitamin D in vivo,"It is well known that the secosteroid hormone called vitamin D is essential for musculoskeletal health, but it is now apparent that many cells have receptors for vitamin D and its metabolites, and the vitamin has been associated with a range of other health benefits, leading to widespread calls for the vitamin D status of the population to be improved. Since modern diets generally contain little vitamin D the main source is exposure to sunlight, when UV radiation acts on the precursor 7-dehydrocholesterol (7DHC) in skin cells. The levels of precursor vitamin D are understood to decline with age, but it is not clear whether vitamin D synthesis in aged skin is 7DHC limited, or whether it is lack of sun exposure that leads to concern over low vitamin D status in the older population. Understanding the limits to vitamin D synthesis in an aging population will enable targeted advice on maintaining an adequate status at a life stage when retaining a strong musculoskeletal system is vital, as are the other benefits associated with vitamin D.
The aim of the project is to identify, at a cellular level, the age-related ability to synthesise vitamin D in the skin on exposure to sunlight, through availability of the precursor 7-dehydrocholesterol (7DHC) and its UV-conversion. The project will involve a comparative study involving human volunteers in 2 age groups, young and aged adults. Skin (precursor 7DHC) and blood (vitamin D and 25-hydroxyvitamin D, the measure of vitamin D status) will be taken before and after controlled doses of simulated sunlight. Tandem mass spectrometry is the technique to be used for analysing all samples and the extraction procedures to prepare samples from tissue will be refined during the project to enable increased sensitivity from the analysis for the small skin biopsy samples.
The results will be set in context against previous and on-going studies that have assessed the year-round vitamin D status in several population groups of different ages. It will identify whether vitamin D synthesis in the skin of the elderly is 7DHC limited, in which case alternative interventions must be considered in achieving all the health benefits of a good vitamin D status, or whether small changes in lifestyle might lead to such improvements through exposure to UV radiation, as assessed in our previous work based on a detailed UK climatology.
This project supports technological development and strengthens the skills base in multidisciplinary research and in vivo skills. The analysis of vitamin D related molecules from tissue samples is under development and extraction techniques from tissue will be further refined (increasing sensitivity of analysis to pmols) and demonstrated during this project. The project has three discipline strands, physics/radiation, dermatology/human volunteers, and laboratory analysis, providing the student with a range of complementary skills, the vocabulary and understanding to translate between the disciplines, and the vision to combine them.",0
NE/P005349/1,9369,Aquaculture Directed Knowledge Exchange Fellowship,"With the global population expected to rise to 9.6 billion by 2050, there is increasing pressure for aquaculture to meet the rising demand, while maintaining sustainability and food security standards. While European aquaculture has been struggling to maintain competitiveness, at a UK level research investment has dropped considerably, until the recent joint BBSRC-NERC initiative. Prior funding has largely focused on salmonids and shellfish, mainly spanning the areas of disease or environmental impact, often focusing on Scotland but not fully covering the breadth of strategic needs of the sector. Furthermore, there is often a decoupling between basic research funded by research councils and industrially applied research. Moreover, the impact of basic research has been further limited by inadequate mechanisms for knowledge exchange between academia and industry. This KEF will build the know-how for effective information exchange and research translation by connecting the actors within the aquaculture value chain. The fellow will work closely with research and industry, to identify knowledge needs, promote collaborations, disseminate BBRSC-NERC funded research and improve public perception of aquaculture.
A key deliverable and enabling tool will be an innovative and intuitive web-based, user-friendly visual database that maps the UK aquaculture sector, thereby connecting stakeholders and their areas of activity and interest. Further, the Fellow will create and publish 'Research Profiles', on department/institute specific research track records, and 'Company Profiles', on company's key activities and research interests. Another key activity will be the development of an 'International research network map', based on academia's connections with international partners so contacts are easily identified. These tools will provide the industry with information on potential partners, which can answer its R&amp;D needs and will also foster the development of networks to access to EU funding schemes and international expertise.
The Fellow will advance the development of the UK aquaculture network, by meeting and developing contacts with industry, trade/advisory bodies and academia, and will bring stakeholders together through innovative ways in a sector-wide conference 'Connecting UK Aquaculture'. The fellow will organise an industry-focused workshop 'UK Aquaculture: key knowledge needs and gaps' and develop a strategy document on aquaculture research and investment priorities from a stakeholder's perspective, to inform and engage funders and policymakers.
This KEF will support the dissemination of BBSRC-NERC research through 'Research Bulletins' to industry and the creation and public dissemination of a series of videos explaining BBSRC-NERC research '@UKAquacultureResearchExplained'. The third pillar of the fellowship is assessing the public attitudes and perception of aquaculture and the development of recommendations to enhance public appreciation, which will be disseminated to funders, policymakers and industry. UK aquaculture best practices and success stories will be promoted through press releases, media engagement, social media, and an interactive web-presence. A series of digital materials for education and outreach in aquaculture will be created and widely disseminated to schools throughout the UK. 
By these combined approaches, the Fellow will promote collaboration opportunities between industry and academia, while facilitating informed governance and research funding, supporting the uptake of research by businesses and improving public perception of aquaculture. The impact of the activities started during this programme will extend post-fellowship, supporting the sector's competitiveness and internationalisation through an increased focus on innovation and industry-relevant research, enhanced synergy between industry and academia, and towards the sustainable development of UK aquaculture.",0
BB/P00556X/1,29107,Exploiting the immune system to tackle emerging filamentous diseases in tomato,"The world's population is expected to increase by 1.6 billion in the next 40 years, which challenges humanity to increase food production by 70%. Despite current control measures, weeds, pests and pathogens claim up to 40% of our major crop yields after use of effective control. Filamentous pathogens (e.g. mildews, molds and late blight) are exceptionally problematic to control as their evolutionary capacity makes them highly proficient on overcoming the resistance offered by genes or chemical pesticides. In the past century, there has been an increasing number of virulent emerging pathogenic fungi. Agricultural systems are extremely vulnerable to emergence and epidemics of filamentous disease due to food mobility and climate change. Moreover, crop cultivation under controlled environment, even when it provides advantages in terms of increased production, it represents a clear disadvantage in controlling the spread of filamentous diseases. Current methods of control depend largely on the use of fungicides, which are under strict European regulation due to its toxicity to human health and the environment. Therefore, it is urgent to develop alternative strategies to control diseases. 
Plants are equipped to defend themselves against harmful microbes through constitutive and inducible defence strategies. Alternatively, plants have evolved the capacity to prepare their immune system to respond faster and stronger against attackers. This so-called priming of defence can be triggered by a variety of signals that warn of an upcoming attack, including treatments with priming agents such as b-amino butyric acid (BABA). BABA has been shown to provide protection against a wide spectrum of filamentous diseases. The reason for this outstanding performance is due to its priming activity at different defence signalling pathways that are used by plants to fight diseases with different lifestyles. BABA has been shown to be effective in inducing resistance against a broad-spectrum of diseases in crops such as tomato. Filamentous pathogens are particularly problematic in this crop as they are responsible for yield loses pre- and post-harvest. Therefore, emerging filamentous diseases are a serious threat to the tomato market.
Tomato is a model plant for research in Solanaceae as its genome has been sequenced and crosses with their wild relatives allow the study of the genetics behind different processes. However, only one study in Arabidopsis has investigated genetic variation in the induced resistance response. This project will investigate genetic variation in induced resistance trigger by BABA in tomato with the overarching aim to identify advantageous traits which could potentially maximise the inducible resistance capacity of commercial varieties. 
To achieve this aim, I will test BABA-induced resistance against the devastating pathogen Phytophthora infestans (late blight) in a Recombinant Inbred Line (RIL) population from the cross between a commercial tomato cultivar, and an accession of the wild relative. Induced resistance quantification will be done by using a sophisticated phenotyping scanner that can image and analyse different disease parameters in a high-throughput manner. The induced resistance traits (IR-traits) will be identified by sequencing of the significant quantitative trait loci (QTLs) and the molecular mechanisms behind the response will be investigated. The last part of the project will test the hypothesis that multi-directional resistance as a result of the IR-traits offers effective protection against newly identified strains of filamentous pathogens with a high risk of emergence, such as strains of late blight or Fusarium wilt (caused by the multi-host pathogen Fusarium oxysporum). 
The results coming from this work will identify the genetic traits to exploit the tomato immune system for enhanced defence against a broad-spectrum of diseases, including emerging pathogens that can have a huge devastation potential.",0
NE/R007152/1,32609,Marine Scotland - Marine Acoustics Placement,"With the ultimate aim to minimise the impacts of rising noise pollution from human activities on the marine environment and the species inhabiting these waters, this placement aims to examine opportunities for the development of a long-term, coordinated, passive acoustic monitoring programme in Scottish waters. Knowledge and skills regarding analysis and reporting of ambient noise levels from broadband data, analysis of acoustic recordings for marine mammal presence, and approaches suitable for measuring sound detection by fish and invertebrates, will be transferred to MSS, so this can be integrated into environmental impact assessments and conservation measures. 
There has been growing concerns about the impacts of increasing human-made sounds on marine mammals, which rely on sounds for most aspects of their lives. Studies have demonstrated direct and indirect effects, including behavioural (e.g. area avoidance, changes in behavioural budgets, changes of vocalisations), physical (e.g. temporary and permanent hearing loss, stress) as well as lethal impacts related to anthropogenic sounds such as military sonar, seismic surveys, shipping and marine construction work.
Various EU and world-wide regulations have been transposed into national legislation to protect marine mammals in UK waters, and new coastal and offshore activities and developments are tested against these conservation commitments. This requires sufficient knowledge about the spatio-temporal presence and natural behaviour of populations and their population trends (and hence conservation status). Long-term passive acoustic monitoring has been used extensively to collect baseline data on marine mammal occurrence. Additionally, policymakers are beginning to develop management approaches to assess and mitigate noise risks to the marine environment through legislative frameworks, but are constraint by lack of data on current and historic noise levels. As such, information about typical and site-specific underwater noise levels is needed to explore how these might change in response to anthropogenic activities. This highlights the need for the establishment of large-scale and long-term acoustic monitoring programmes for underwater noise and marine mammal assessments.
Within Scotland, MSS is responsible for the licensing of coastal and marine developments and projects need to demonstrate that they do not have adverse impacts on local marine mammal populations. The development of several of the required impact assessment protocols have improved significantly in the last decade, in part due to increased site-specific cetacean data, and technological advances and modelling approaches. The framework for background noise assessments, however, is currently still in it's infancy, and the integration of particle motion to specifically assess noise impacts on fish and many invertebrates has not been fully developed and implemented yet. This data gap needs to be addressed if acoustic habitats are to be managed effectively for these species.
The work proposed will develop a future-proof strategy for a collaborative, coordinated passive acoustic monitoring network throughout Scottish waters. The project will identify suitable approaches for analysing and presenting background noise statistics and trends, in line with EU requirements. Acoustic data collected from existing Scottish monitoring projects will be used to train MSS staff in the appropriate analyses to establish presence of vocalising marine mammals and obtain and present ambient noise level statistics. The latter will provide baseline measurements against which to measure future noise pollution trends, and will offer evidence to assess the efficacy of management measures.",0
NE/N001672/1,19144,Effects of artificial light on multi-trophic population dynamics,"Daily, lunar and seasonal cycles of natural light have been key forms of environmental variation across the Earth's surface since the first emergence of life, and have driven the development of biological phenomena from the molecule to the ecosystem. These natural patterns have, however, over the last 100 years come to be greatly disrupted through the introduction of artificial light into the nighttime environment. This derives from a diversity of sources, including street lighting, advertising lighting, architectural lighting, security lighting, domestic lighting and vehicle lighting. Indeed, artificial nighttime lighting is already estimated to be experienced directly and indirectly (through skyglow - scattering by molecules or aerosols in the atmosphere of artificial nighttime light that is emitted or reflected upwards) by nearly 20% of the global land area, and to be growing at about 6% per year. The extent of the problem is evidenced by frequently reproduced satellite and astronaut acquired nighttime images of the Earth.

The introduction of artificial light into the nighttime environment has doubtless provided significant and substantial benefits to humankind. But, given that biological systems are fundamentally shaped by light, there have inevitably been a wide array of environmental impacts. Studies have particularly focussed on the effects on individual organisms, and have highlighted consequences of artificial nighttime light for physiology, foraging, daily movements, migratory behaviour, reproductive behaviour, and mortality. Whilst population level effects are predicted to follow, these remain poorly understood. Moreover, it is unknown how these change with the intensity and the spectrum of artificial nighttime light. This means that it is difficult to make the best possible recommendations as to how artificial nighttime lighting (e.g. street lighting) might be modified to optimise the trade-off between human benefits and environmental costs. This is particularly significant at a time of large scale and rapid introduction of new lighting technology and use of 'smart illumination'; many street and other lighting systems are moving to 'whiter' lights, commonly using light-emitting diodes (LEDs), and central management systems are increasingly enabling more flexible approaches to the implementation of public lighting. 

In this project we will determine the impact of artificial light at night of different intensity and spectrum on population dynamics, using an established aphid-parasitoid-hyperparasitoid experimental study system.",0
BB/N007492/1,24457,A new drug discovery pipeline for animal African trypanosomiasis,"A disproportionate burden of the world's infectious diseases (both human and veterinary) fall upon the African continent. Among the most devastating of the infectious agents of animals are the trypanosomes that cause Animal African Trypanosomosis (AAT). Transmitted primarily by tsetse and other biting flies, the disease is present in 40 African countries and affects nearly all domestic animals. The overall economic losses attributable to AAT are estimated at $4.75 billion per annum. These are losses borne principally by those who can least afford them: small-scale subsistence farmers and rural communities in AAT-affected areas of large parts of sub-Saharan Africa who rely on livestock for their livelihoods. Current AAT control tools rely extensively on trypanocidal drugs for the treatment of infected animals and for prophylaxis of infection. The drugs are widely available but were developed over 50 years ago and have significant limitations in terms of safety and increasingly lack efficacy against emergent drug-resistant trypanosomes.

Over ten million km2 of Africa are infested by tsetse flies and thus affected by AAT; this represents a substantial portion of Africa's fertile and watered land. Within this area, millions of small-scale livestock keepers rely on an estimated 55 million cattle and 70 million sheep and goats for their livelihoods and food security. These regions are under sustained and increasing pressure to produce more food for growing populations, increasing per capita consumption of meat and dairy products, climate change and desertification all combine to require increased agricultural output within the potentially productive areas of sub-Saharan Africa. Losses arising from AAT are both direct (e.g. estimated annual death of 3 million cattle) and indirect as a result of productivity losses (e.g. benefits of up to $7,000 per km2 from removing AAT). The net effect is a significant constraint on growth and development of the dairy and beef sectors, as well as sheep and goat rearing in the regions affected. Trypanocidal drugs are the mainstay in the control of AAT because of the absence of realistic prospects for vaccines. Vector control has had limited success and showed poor sustainability, the more so in areas where non-tsetse fly transmission is important (e.g. parts of Africa, but particularly in the Far East and South America too).
The Global Alliance for Livestock Veterinary Medicine (GALVmed) was founded to help channel global efforts into amelioration of the burden placed upon the world's food security brought about by various infectious diseases. With substantial funding from the UK Department for International Development and the Bill and Melinda Gates Foundation, GALVmed has become the primary agency involved in efforts to bring new drugs forward to treat AAT.

In this proposal, experts at the Universities of Glasgow and Strathclyde, and the Roslin Institute of the University of Edinburgh, are coming together to develop a new class of compounds that has been shown to have profound efficacy against the causative agents of AAT, both in vitro and in rodent models of the disease. Chemical structures of those compounds optimised for trypanocidal activity in cattle will be developed with the intention of taking them into clinical development. We will additionally develop new culture systems for the relevant parasite species - a crucial step for rapid and routine screening of our candidate drugs but also large sets of unrelated compounds (chemical libraries), with minimal need for tests in animals. We will also use state of the art biological and computational methods to learn about the internal functioning of the causative parasites, in order to understand how this new class of compound works. This part of the project will also provide key information to allow other classes of compounds to be brought forward, giving an important input to a long-term pipeline of new drugs to treat AAT.",0
2301415,46336,Selection and evolution of coat colour in a wild mammal,"This project offers the opportunity to study evolutionary genetics as part of the Soay sheep project, one of the most data-rich long-term studies of any vertebrate in the world. There will be opportunities to visit and work on St Kilda, a UNESCO world heritage site.

Understanding how genetic and phenotypic variation changes in response to environmental conditions remains one of the great challenges in evolutionary biology. Ten years ago we published a paper in Science (Gratten et al. 2008) showing how allelic variation at the TYRP1 gene underlying a coat colour polymorphism in a wild Soay sheep population has been under natural selection, and how variation at TYRP1 has been maintained. In the following decade, the environment on St Kilda has changed, the population size has increased, and demographic models (conducted by co-supervisor DZC) predict a dramatic change in allele frequency dynamics.

Here the student will combine evolutionary genomics tools (SNP genetic profiling), state-of-the-art demographic modelling and ecological data to study how Soay sheep coat colour evolutionary dynamics have changed in the last decade. The findings will shed further light on the evolution and maintenance of genetic variation, and will provide a framework with which to robustly test demographic predictive models. Testing how gene frequencies change in response to real-time environmental change is not often possible in wild vertebrate populations, but the short generation time (males and females can breed at age 6 months) and long-term data set make the St Kilda Soay sheep population an exception. Since our previous publication several thousand sheep have been born and monitored throughout their lifetimes. Advances in genomics tools mean that SNP genotype data (at ~500,000 loci) are available for nearly all of them. There are very few, if any, comparable opportunities to study evolutionary dynamics of fitness loci in the natural environment.",0
EP/R045127/1,24294,The Internet of Food Things,"The &quot;Internet of Food Things&quot; will create an interdisciplinary network that defragments and expands the UK's food digital economy. Food and drink is the largest manufacturing sector of the UK economy. The food supply chain from farm to consumer generates &pound;108bn GVA per year and employs 3.9m people. In addition, food has highly significant social and environmental impacts. Obesity alone, including downstream health impacts such as diabetes, heart disease etc, costs the UK economy &pound;49bn per annum. There are still c. 1,000,000 cases of food poisoning per year costing &pound;1.5bn p.a.. Food generates up to 30% of the UK's road freight, but 10MT of food, generating 20MTCO2e of GHG emissions, are wasted each year. 

Digital technology has the potential to transform the food chain, for example, opportunities (that map onto the EPSRC DE Network strategy) include but are not limited to;
- New business models via distributed ledger technology (DLT) to underpin the traceability of food. The recent Holmes report identified food as one of the key seven UK industry sectors most likely to benefit from DLTs.
- The creation of a &quot;data trust&quot; for the food sector to underpin data sharing, trust and interoperability within complex supply chains. 
- Wide scale application of the internet of things (IoT) for the service community, for example, the use of IoT by domestic users (refrigerators, cooking devices etc) to improve health outcomes and reduce waste. 
- The development of new digital labelling protocols that assist with consumer use of food as well as supply chain optimisation, 
- The use of novel digital technologies (e.g. artificial intelligence) to reduce food waste by optimising whole supply chains from manufacturer to consumer.

Hitherto these opportunities have not or are only partially realised. There is an urgent need to defragment the digitally inspired academic community and connect it to food industry practitioners.

Although the digital focus is in within EPSRC's remitIoT, blockchain, data trusts, interoperability issues), we will multiply impact by including interdisciplinary contributions from food science and technology practitioners, policy makers, engineers, management specialists and colleagues in social and behavioural sciences. The network will include academia, industry and consumer interests. The industry interest covers the whole food and digital innovation chain including food manufacturers (e.g. Food and Drink Federation, EPSRC Food CIM), IoT and digital specialists (Siemens and IMS Evolve), the HVM Catapult and regulators such as the Food Standards Agency and GS1 the international agency that sets data standards (bar codes) for retail. Consumers will be represented through out, but the inclusion of food retailers within the consortium provides access to unrivalled data sets demonstrating behaviours.

The DE network will facilitate a number of key actions, including a marketing, social media and work shop / conference campaign that yields a large scale (up to 500 persons) network who have mutual interests within the food digital domain. We will host one main conference per year and in addition 3 facilitated workshops p.a. to deep dive key questions within the food domain. We will fund a range of pilot studies (&pound;350K applied) and detailed reviews to underpin horizon scanning. All the research challenges will be co created with industry. We expect that the network will facilitate onward research funding and catalyse interest in the food digital economy. In addition to network activities, we will deliver a comprehensive pathway to impact that engages professional practitioners as well as the general public and schools.",0
2112605,5480,Barriers to building community resilience to the impacts of climate change,"The Intergovernmental Panel on Climate Change Fifth Assessment Report demonstrates with growing confidence that climate change is going to have increasing negative impacts on communities around the world (IPCC, 2014). Over the next century, extreme weather, flooding, forest fires and droughts will cause disruption and devastation at an increasing frequency. Governments and community leaders are under huge pressure to protect their citizens and infrastructure from increasingly severe events, which can overwhelm the local capacity to respond and recover. Many communities in vulnerable regions are already facing limits in their capacity to adapt, and as climate change accelerates, more communities will begin to approach these limits (Dow et al, 2013). More research needs to be conducted into what happens on both a national and local scale when adaptive capacities are met, and how this can be avoided. The potential consequences could be devastating, with the risk of conflict, mass forced migration and financial collapse possible scenarios. As climate disruptive events increase in frequency and severity, communities will become even more reliant on local governance structures for relief and recovery. Whilst it is vital that governments increase resources to meet this need. If citizens are better prepared for disruptions, this should reduce some of the reliance and pressure on central recovery efforts. This is recognised across research into disaster preparedness (WHO, 2007) (FEMA, 2011), however much of the research focuses on specific events, such as earthquakes or flooding, whereas it could be argued that building overall resilience to any disruption would hold more value to communities. 
The economic cost of natural disasters is also increasing, reaching $1.5 trillion in the decade 2003-2013 . Not only do these increasing costs affect governments at a country level, but also at a local, community level. Individual citizens will also share the burden of the economic costs, as businesses and homes are disrupted and damaged, and livelihoods temporarily or permanently destroyed. 

The design of the research will be purposeful and interpretive- engaging specific community populations who have experienced climate-related impacts and disruptions to gather insight into that experience. Discovering what challenges and barriers they faced in building personal resilience will help achieve the overall projects aims and objectives - to understand what barriers are in place to prevent ground-level resilience, whether it be knowledge and information, finance or time resources, or psychological barriers (e.g. they are safe, &quot;it'll never happen&quot;, &quot;the [technological adaptation e.g. levees] will protect us&quot;).",1
NE/P014208/1,16476,Resilience of below-ground fungal communities: a mechanistic and trait-based approach,"Soil provides a home to a large number of soil organisms and provides a number of services that are underpinning human health. These include storage of carbon and nutrients, which is critical for production of food and contributes to minimising the impact of Global Warming, the provision of antibiotics often derived from soil fungi, to provide and filter water and regulate hydrological cycles. There is however increasing concern that soils are in decline and may not be able to fulfil these services to the same extent if not managed sustainably. The problem we are facing is that we currently have little understanding of how soils respond to change, how this will impact on the microbial community and how this in turn will affect services mediated by microbial life.

Our project will tackle this problem by developing for the first time a theoretical framework that links soil properties, such as the complex geometry of pores within which microbes live, with biodiversity and ecosystem functioning. We will do so by demonstrating interactions and feedbacks for soil borne fungi. 

Fungi can influence nearly every process that occurs in soil. There are up to 1.5 million different species of fungi, and they can form between 55 and 89% of the biomass of microbial life in soils. They are characterised by a mycelial growth form that enables them to spread through soil pores over large distances exploring the soil environment for C whilst avoiding competitors. As they interact with the environment and competing species a complex community emerges that delivers services to mankind, such as C decomposition or sequestration. It is generally believed that the diversity of a community makes soils resilient to changes and allows it to deliver services over a wide range of environmental conditions such as wetness, drought, temperature changes, but also various management strategies including organic amendments and tillage operations. This is because various competing species fulfil similar roles and can induce feedbacks that mediate perturbations to the system.

It is therefore important that we understand how these interactions shape these communities, how they respond to perturbations and what risks they are under to be no longer capable of adapting to change. To be able to answer those questions we need to have a fundamental understanding that is currently lacking.

The project will develop such a fundamental framework that will address these questions and identify what key soil properties and fungal traits make a soil more or less resilient and indicate what management options can be put in place to manage soils to be more resilient towards physical changes, such as induced by tillage operations, or wetness and drought cycles, which are envisaged to increase in extreme due to climate change. The mathematical approach followed in this proposal will be able to explore situations beyond what is experimentally tractable and can therefore identify limits beyond which soils are at risk of losing the ability to resist consequences of environmental perturbations.

The questions addressed are at the heart of the soil security programme which seeks to address how soils function and how this functioning can be sustainably managed to enable soils to resist or adapt to perturbations such as those imposed by soil management or environmental change.",1
ES/T00312X/1,42891,"Caribbean Cyclone Cartography: Mapping histories, narratives and futures of hurricane 'resilience' in a changing climate.","When category-5 Hurricane Maria made landfall in Dominica (Eastern Caribbean, population 71,293) on 18th September 2017 - killing 31 people, disappearing 37 people, damaging 90% of buildings and costing an estimated US$ 1.3 billion/226% of GDP - this environmentally and economically vulnerable Small Island Developing State was left in chaos, without national planning measures to ensure a clear course to recovery. Thus, besides limited humanitarian aid, Dominicans survived Maria by improvising meals from stockpiled food, assembling work crews to clear debris, telling cathartic stories to ease stress and using remittances to rebuild homes. They survived, through social modes of resilience.

Months later, the government vowed to make Dominica -the most mountainous island in the region with perhaps the greatest number of environmental hazards per square mile - the 'first climate resilient nation on earth', launching the Climate Resilience Execution Agency of Dominica (CREAD) and a 'National Resilience Development Strategy' (aligned to the UN 2030 Sustainable Development and Sendai agendas) to 'climate proof' the island's housing, infrastructure, energy and tourism sectors. Yet, despite this macroscale 'resilience turn', very little is known about the micro - individual, household and community level - adaptations that enabled Dominicans to survive Maria, Erika (2015) and earlier storms. Nor is there a critical high-level conversation what this ubiquitous term, 'resilience', means to everyday Dominicans - notably marginalized groups (Dominican youth, female farmers, indigenous people and displaced communities).

Towards creating a more inclusive understanding of cyclone preparation, response and recovery, the CCC project will develop collaborative methodologies that explore lived understandings of what 'building back better' might mean in local terms. This multi-disciplinary approach to such 'vernacular resiliencies' is intended to complement and critically enhance the CREAD agenda, holistically mapping survivor-led recoveries - past, present and future. But why mapping? We believe maps do not simply represent the world; they guide our experience of it. 

We will investigate and visually map cyclone resilience 'from below' by using the following research methods:

- Oral, archival and architectural enquiry into hurricane histories.
- Contemporary community-led digital storytelling and ethnography of life and livelihoods after Maria (with an emphasis on marginalized experiences).
- Citizen-led GIS survey and cartographies of hazards, shelters and response agencies across the island.

The research will produce the following outputs:

An online hurricane 'resilience' map of Dominica - documenting historic and recent storm recoveries; and plotting hazard sites, shelters and support agencies to reduce future risks to wellbeing. A map that is publicly accessible, informative and easy to navigate - for citizen, policy maker and scholar alike.

A series of multi-stakeholder symposia, research enskillment workshops and practice-based interventions - to build research capacities, share models of best practice (both indigenous and scientific) across scales, specialisms and sectors.
A cluster of public project film screenings, a visual arts exhibition and Caribbean Climate Conversations podcast/radio show - to showcase key outputs to Dominican, British, Jamaican and international publics (promoting informed ecological citizenship).

An online digital hub - an archive of research outputs to stand as a public cyclone resilience resource; and a blog space to offer a home for the pre-existing (but at present piecemeal) public conversation on disaster resilience that is ongoing in the Caribbean.

A series of project investigator publications - academic articles, publicly disseminated info-zines and an edited book featuring research outcomes",1
BB/R001537/1,4396,The 4-dimensional plant: enhanced mechanical canopy excitation for improved crop performance,"There is an urgent need to improve crop yield (tonnes per per hectare) in order to meet the needs of a growing global population and declining fertile agricultural land base. One of the current important targets for crop improvement is photosynthesis, a neglected trait in previous plant breeding efforts.

Photosynthesis requires the uptake of carbon dioxide by leaves and its 'conversion' into carbohydrates using water and absorbed solar energy. However high rates of photosynthesis, on which yield depends, are sensitive to environmental changes such as light intensity, temperature and other factors. Crop productivity is the sum total of photosynthesis in leaves in a canopy, many of which shade each other and have different ages. We can calculate the potential productivity of whole canopies based on leaf photosynthetic attributes and other physical and physiological factors. When we do this the theoretical productivity tends to be much higher than the measured productivity which is partly due to the way leaves respond when re-constructed into a large three dimensional canopy. In this state, plants exist as a community which has emergent properties that we cannot necessarily predict from plants grown individually. If we can eliminate the gap between the theoretical and measured productivity we can achieve a step change in productivity. 

Photosynthetic rate is sensitive to light intensity. The difference in light intensities that exist within the canopy is significant and is affected by the architecture of the canopy i.e. the angle, shape and size of leaves and their position within 3 dimensional space. This means that the light intensity has great variability in space and time within canopies. Photosynthesis is not perfectly adapted to instantaneously match the fluctuations in light intensity - its lag results in substantial reductions in productivity and even water use efficiency.

This proposal tackles a much ignored factor. Plants 'move' in light to moderate wind and this occurs on a daily basis, sometimes continually during growth which shifts the light patterns within the canopy. In recent work we found that movement has a strong effect on the rate at which light levels change in the canopy with strong implications for canopy photosynthesis. Such movement of the canopy plays a major part in how fast or slow light flecks are generated, and where in the canopy they appear. It seems that movement may enable the production of more rapid 'lightflecks', enhancing photosynthesis at the canopy level. We don't consider high speeds that result in damage, but we do incorporate lodging in our assessments of canopy viability.

In a recent paper (Burgess et al (2016) Frontiers in Plant Science 7, 1392) showed that canopy movement has the means to alter photosynthetic responses at the canopy level. We also developed the techniques to generate high resolution 3D images of field grown wheat and rice canopies and for 'tracking' moving canopies. In this proposal we will bring these techniques together to produce models of canopies of rice and wheat and make these models move realistically in response to physical factors. At the same time we will use wheat and rice populations and panels with varied physical characteristics and responsiveness to wind and create data driven tracking movies of these canopies , making the 3D reconstruction move realistically. We will create methods for predicting light distribution in these canopies combining ray tracing techniques with field measurements of light distribution. We predict that the most productive property is for leaves to be highly responsive to wind at the top of the canopy but retaining a strong stiff stem.
At the same time we will measure photosynthesis and biomass production in wheat lines which are amenable to genetic analysis so that we can discover the hereditary basis for the movement. Therefore the results will be used in plant breeding.",1
NE/R002576/1,8234,Measuring Ancient Rates of Weathered Petroleum Accumulation in the South China Sea,"IODP expeditions 367 and 368 are drilling sedimentary successions to basement at locations in the South China Sea. This is to investigate crustal-break up mechanisms during tectonic rifting. Rifting in this way creates a sedimentary basin which is subsequently filled by sediment. 
 
The sediment-fill within the South China Sea is derived from a number of hinterlands in Southern China and neighboring countries in which there are both productive and non-productive petroleum systems. The erosion of formations within these petroleum-bearing hinterlands, and the subsequent transport of the petroleum-bearing sediments to the South China Sea by river, will have lead to the accumulation of trace amounts of petroleum within sediments over geological time. 
 
Measuring residual petroleum is complicated because most of the components of petroleum degrade at the Earth's surface, leaving only the most chemically resistant components behind. Analysis of the organic content of sediment by GC-MS can detect a few of the compound-types present in weathered petroleum, but with increased weathering the amount that can be detected decreases. Eventually only the most asphaltic and heavy petroleum-components remain. This residual petroleum is difficult to analyse, and so for South China Sea samples will be analysed by a new surface enhanced Raman scattering-based method. This method is highly sensitive and capable of detecting sub parts per billion levels of residual petroleum. 
 
The use of newly developed methods for analysing trace amounts of weathered and residual petroleum in this context will greatly help in their trial and development. This development is needed to prepare these technologies for routine environmental base-line monitoring as well as more general petroleum and oil analysis. During this project measurements will be made during shipboard activities using a portable instrument, and then compared to laboratory-based measurements. This comparison of off-shore and laboratory methods is key for developing methods that can be applied at point of need.
 
From a geoscience and natural science perspective, examining weathered petroleum accumulation over geological time in this way, at a fixed position, has a number of benefits and advantages. One of these is access to a pre-human baseline for petroleum within sediments; e.g. measurements are made on sediments deposited before human exploitation of petroleum began. Another benefit is access to data from the multiple climatic and depositional modes experienced by the site over the it's long geological history. This helps to understand how climate change in the modern era may affect the attenuation of petroleum in the natural environment.",1
NE/R013209/2,24723,Tidal energy operational and spatial planning optimisation,"The UK, is committed to reduce greenhouse gas emissions by 80% by the year 2050 relative to 1990 levels, and to meeting 15% of its energy from renewable sources by 2020. Research suggests that the combined operation of tidal stream and range power schemes can exceed 12% of the UK's energy demand from a sustainable, clean energy source. In comparison with other renewable energy sources this comes with complete predictability which means that tidal can play a vital role in meeting the nation's energy needs. At the time of writing this proposal, pilot projects for tidal stream and range based energy generation are in the advanced stages of planning and development within the UK. The first tidal stream turbines installed within a pilot array in the Pentland Firth off of Scotland have just started to generate power. For tidal range-based technologies, the UK Government's &quot;Hendry review&quot;, released on the 10th of Feb 2017, recommended that tidal lagoons (tidal range structures) can play an important role in the UK's energy mix. This provides a roadmap towards the development of the Swansea Bay lagoon as a pathfinder project and the first tidal range energy structure of this type worldwide. Construction could commence in 2018, with much larger industrial projects to follow subsequently.

We are thus at a crucial stage in the development of a new tidal-based renewable energy sector where the UK currently leads the world. This project seeks to build on this strong position by providing timely research on the environmental and ecological impacts of new, larger tidal developments in a manner that supports decision making by stakeholders, including coastal engineers, financiers, and primarily those concerned with environmental impacts. This project builds upon a strong foundation of recent work at Imperial College London that has provided the preliminary demonstration of computational methods for the representation of turbine arrays and tidal range structures within multi-scale models, as well as the optimisation of array designs and tidal plant operations to maximise power or profit, while minimising environmental impacts. 

The proposed research will focus on the optimal spatial planning and operational control of prospective tidal range projects. Recent computational modelling findings suggest that up-scaling the development of marine energy infrastructure beyond the pilot scale poses a formidable challenge. Industrial proposals need to comprehensively evaluate and compensate for impacts on environmental processes that relate to water quality for sensitive species and tidal dynamics alterations. A quantification of environmental impacts (e.g. tidal flushing, Dissolved Oxygen) via simulation software can become computationally demanding when multiple processes are modelled at a large scale. Opportunities to reduce the computational load could stem from the fact that many of the environmental constraints can be described as objective functions. The optimisation proposed will be fully coupled to the underlying tidal dynamics, so that changes to tidal range structure design and control can feed back to the hydro-environmental processes and vice-versa. 

The research will be conducted at the interface of academia and industry, and will be informed by marine energy developers, technical consultants and experts in environmental and coastal processes. Input from industry will be in the form of observed and model data that will be compared against the results of the tidal energy optimisation software. The data will also inform the optimisation method's constraints, and will be used to validate corresponding coastal models that aim to assess optimised designs of a series of industrial tidal range energy proposals. The overarching motivation of the research will be to inform environmental impact assessment practices and the sustainable development of upcoming clean energy technologies that will be developed by the UK's industry.",1
NE/R001529/1,15850,Evolution of thaumarchaeotal metabolism under contrasting oxygen conditions,"Many of the important ecological processes essential for life on earth and for the sustainability of our environment are performed by microbes (the bacteria and archaea) that are astonishingly abundant and diverse on the planet. Their functional diversity has arisen through many millions of years of adaptation to environmental change. Despite the contribution of microbial activity to global nutrient cycles and environmental stability, our inability to grow most microbes in the laboratory has severely limited our understanding of the ways in which they adapt to change and evolve. Recent technological innovations remove this limitation and allow us to study adaptation in microbes. The first innovation is the ability to sequence genomes of microscopic single cells extracted from the environment, allowing identification of genetic changes involved in adaptation and inference of how genomes have changed through deep evolutionary time. The second is the use of this genetic information to improve our ability to cultivate microbes, enabling physiological studies.

This project aims to use these cutting-edge technological advances to answer key questions about the mechanisms that generate this vast microbial functional diversity in nature, one of the greatest and most exciting challenges in biology. It will focus on a microbial group, the Thaumarchaeota, which are very diverse and abundant and have enormous environmental and economic impacts because of their role in oxidising ammonia fertilisers (resulting in greenhouse gas production and annual loss of &gt;$70 billion of nitrogen fertilisers). As not all Thaumarchaeota perform ammonia oxidation, it is important to understand the distribution and activity of other Thaumarchaeota in the environment. This project will therefore address important environmental concerns about soil security and environmental change.

In this project, soil will be incubated at varying oxygen concentrations to determine the Thaumarchaeota that are active under different conditions. Novel thaumarchaeotal genomes will be extracted from soils with different oxygen preferences using a cutting-edge technology, single-cell genomics, which enables sequencing of the genome of individual microscopic cells. This will establish the genetic basis for the differences in these oxygen preferences. We will compare these new genomes with those previously available to trace the evolutionary origin of the genes and metabolic pathways implicated. We will test our evolutionary inferences using physiological studies of laboratory cultures, using novel techniques and genomic information, to isolate organisms never previously grown in the laboratory. Finally, the relative abundance and activity of these groups will be assessed in several ecosystems to determine their ecological relevance. 

The project will address the crucial and exciting scientific and technological challenge of understanding the processes leading to the enormous functional diversity of microbes in terrestrial ecosystems, and will have broad environmental and socio-economic impact. It will increase our ability to predict the impact of environmental change on microbial diversity and ecosystem functions and will ensure better management of soil by facilitating the development of improved strategies for fertilisation utilisation and reduced greenhouse gas production. As the microbes studied in this proposal are unexplored, limited current information is available but their role in biogeochemical cycles and potential involvement in plant-microbe interactions is likely, offering novel scope of environmental and ecosystem understanding. Through various events, the scientific findings of this project will be disseminated to the public of all ages and to governing bodies and policy makers to communicate the importance of understanding adaptation in the face of environmental change and the need for better management of natural capital for ecosystem services.",1
NE/K013513/1,26208,Influence of population connectivity on depth-dependent diversity of deep-sea marine benthic biota,"Species populations are connected to each other through both movement of adults (migration) and eggs, larvae and juveniles (dispersal). If populations become isolated from one another (i.e. are no longer connected), then through genetic mutation, drift and natural selection, they may become so different that they evolve into new biological species. Understanding how populations become isolated is critical to understanding the process of speciation. In the marine environment many species do not move as adults (e.g. corals) or move very slowly (sea urchins). This means that for different adult populations to remain connected they rely on dispersal of early life history stages. Most marine species have a larval stage that lives in the plankton for a period of time, moving with the currents, before settling in a new area. It is larval dispersal that keeps distant populations connected. So understanding patterns of larval dispersal is important to understanding connectivity. 

In the deep-sea (&gt;200m) the bathyal region of the continental slope has been identified as supporting high species richness and being an area where the rate of origination of new species may also be high. The reasons for this are not clear, but given the importance of connectivity to population isolation and speciation, it follows that the key to understanding patterns of species diversity in this region lies in understanding connectivity. New research has suggested that because the speed of the currents that carry larvae decreases as you go deeper, larvae might not be able to travel as far, leading to a greater tendency for populations at bathyal depths to become isolated over a given distance, and thus increasing the chances of speciation. 

This study aims to test this theory by investigating how patterns of connectivity vary with depth. This will be done in 3 ways: 1) using genetic analysis (similar to DNA fingerprinting) to compare how related distant populations are and if they become less closely related as you go deeper, 2) using a model of ocean currents to simulate the movement of larvae between sites, and 3) to look at the range and abundance of species present at distant locations to see if those at shallower depths are more similar to each-other than those at bathyal depths.

This research has important implications for the sustainable management of the marine environment. Humans increasingly rely on the marine environment to supply us with food, building materials, fuel, and to soak up carbon slowing the progress of human induced climate change. However, our increasing use of this environment is starting to affect is 'normal' functioning, affecting the processes that allow it to provide us with food, fuel, etc. To try to help protect and sustain these 'ecosystem functions', Governments all over the world are setting up networks of Marine Protected Areas (MPAs) to ensure against serious ecosystem disturbance and cascade effects resulting from overexploitation that ultimately impair ecosystem function. There are many questions to be answered when trying to set up an MPA network, but one important question is where to put them to make sure that the populations that live within them are not isolated from each other but are connected. This research will help answer this question in the deep sea, and thus help managers, governments and society ensure the long term health of the ocean.",1
NE/S006990/1,5716,As Good as (G)Old? Comparing Biodiversity and Ecosystem Services of Restored and Natural Mangrove Forests in the Wallacea Region (CoReNat),"Mangrove forests are unique intertidal ecosystems connecting the land- and seascape. They provide habitat to terrestrial and marine species, sustain the livelihoods of millions of mostly poor people globally, and are considered as high priority habitats in climate change mitigation strategies, due to their extraordinary carbon sink capacity. Mangroves forests are degraded globally, with land use change being the single most serious threat at present. Successful restoration/rehabilitation of diverse, functional, resource-rich and resilient mangrove forests is a major development challenge in many countries, including Indonesia. The so called Blue Revolution - the conversion of mangroves to (unsustainable) aquaculture ponds in the 80s and 90s - is one major reason why the country has lost 40% of its mangroves over the last three decades. This has caused manifold problems for people's lives. Halting and reversing Indonesia's loss of mangrove natural assets is key to improve coastal livelihoods and reduce poverty. The Indonesian government currently spends around $13 million a year for planting mangroves on degraded areas. Most planting projects in Indonesia and elsewhere in the world have failed, and it is mostly understood why. There are however numerous critical information gaps in understanding how successful the &quot;successful&quot; projects are in regards to recreating diverse and functional self-organising and self-maintaining systems. 

CoReNat will investigate outcomes of established community-based mangrove restoration/ rehabilitation (R/R) projects in the heart of Wallacea - North-Sulawesi - Indonesia, to unravel whether these mangroves are &quot;As good as (G)Old?&quot;. The overall project aims are to assess whether mangrove ecosystem biodiversity, functions, resilience and service provision have been restored, and to make evidence-based recommendations for maximizing the success of future R/R efforts in Wallacea (and beyond). Combining UK and Indonesian experience, expertise and scientific excellence, CoReNat will provide evidence-based recommendations to relevant stakeholder to guide future ecological R/R efforts.

CoReNat takes a novel interdisciplinary approach to deliver a comprehensive ecosystem evaluation of established restored/rehabilitated and adjacent natural (reference) mangroves, bringing together paleoecology, geoscience, botany, zoology, environmental microbiology, ecological network analysis combined with next generation sequencing, toxicology and bioexploration. 

CoReNat will 
- provide new data on the region's (mangrove-associated) biodiversity and species interactions, for conserved as well as for rehabilitated/restored mangrove forests
- apply and generate innovative new tools for the field of mangrove restoration
- provide data that will allow a better understanding of the biodiversity, functioning and services of mono-specific versus multi-specific replanted mangroves
- support the provision of solutions to mangrove conservation, restoration/ rehabilitation and management
- explore current local use of conserved and restored mangroves, as well as potential new avenues for business and innovation, to help balance Indonesia's need for conservation with economic development",1
NE/N016548/1,33363,The Global Methane Budget,"Methane is the second most important greenhouse gas contributing to human-induced global warming. Atmospheric methane concentrations have increased sharply since 2007, and dramatically in 2014, for reasons that are not understood. 

The overall increase since 2007 is comparable to the largest growth events over the past 1000 years. The recent rises have occurred worldwide, but after an Arctic pulse in 2007, the growth has been primarily in the tropics and southern hemisphere. Strong growth continues in 2015. Carbon isotopic evidence suggests that the increase is due to sources that are predominantly biogenic in origin, with changes in the anthropogenic sources from fossil carbon and burning (e.g., natural gas leakage, coal mining and so on) playing a subordinate role. This, taken with the tropical locus on growth, suggests that the increase has primarily been driven by meteorological change (e.g., temperature, rainfall). 

Moreover, the global methane budget is currently not well understood. &quot;Bottom-up&quot; estimates, made by aggregating inventories of emissions (e.g. from gas leaks, fires, landfills, cows, etc) or from process models (e.g., wetlands) balanced with known loss processes, are significantly different from '&quot;top-down&quot; budgets assessed by direct measurement of methane in the atmosphere. Why this discrepancy occurs is not known.

The project has four components:
1. Better Observations are needed to derive estimates of emissions. The project will support a UK observation network for methane and its isotopes. Continuous stations will be at Kjolnes (Norway), Weybourne, Jersey, NERC ship RRS JC Ross, Cape Verde, Ascension, Falklands, Halley Bay, Hong Kong, with partner stations in Canada, Spitsbergen, Bolivia, S. Africa, India, Rwanda and Malaysia. Flask or bag sampling (for methane, 13C and D/H isotopes) will also be undertaken at these stations and at a number of continental stations in S. America, Africa and S, SE and E Asia, with offline analysis in the UK. A D/H measurement facility will be set up. The UK FAAM aircraft will carry out flights across the Atlantic tropics, from Azores to Cape Verde to Ascension.

2. Process Studies will address the largest information gaps in the global budget. Tropical emission fluxes and isotopic signatures are not well constrained. Field campaigns will be undertaken in tropical wetlands in Amazonia, Africa, India and SE Asia, and C4 savanna biomass burn regions. Poorly understood anthropogenic sources will be studied in Kuwait and S, SE and E Asia. Characteristic isotopic signatures of regional emissions will be determined, to support global and regional modelling. Land surface modelling and satellite studies will study emissions and responses to change in temperature and precipitation. Major sink processes will be investigated in the tropical atmosphere, with vertically and latitudinally resolved OH and Cl budget studies by the FAAM aircraft, and quantification of tropical uptake by soils.

3. Atmospheric modelling will be used to derive regional and global fluxes, apportioned by source type and geography using integrated in situ and remote sensing observing systems. We will carry out regional trajectory studies using models like NAME to assess regional emissions. Global modelling using 3D models will test synthetic estimates of the methane mole fraction and isotopic record. Global inverse modelling for mole fraction, 13C and D/H will be used to estimate fluxes by geographic source and source type, including a comprehensive assessment of the uncertainties that remain once all available observations have been used.

4. Integrative studies will use the results from the project to test top-down and bottom-up emission estimates, and evaluate the responses of the global methane budget to projections of climate change.

The project will deliver a state of the art greenhouse gas monitoring network and much better knowledge of the global methane budget.",1
ES/P004326/1,28718,Moving with Risk: forced displacement and vulnerability to hazards in Colombia,"The project focuses on a critical but under-researched theme in studies of forced displacement: the processes through which people forced from their homes by conflict can commonly become exposed to heightened risk from environmental hazards in the places where they resettle. Effectively, such people exchange one form of catastrophic risk for another, often with little real choice in the process. The collaborative project will pioneer an innovative methodology using the expressive arts in Colombia, where five decades of conflict have generated what is currently the world's largest population of internally displaced people. Colombia is also one of the countries most prone to natural hazards including landslides, floods, earthquakes and volcanic hazards. The activities that are proposed aim to deepen understanding of how and why the transition to new risk occurs, analyse how people perceive and respond to risk in their places of resettlement, and strengthen the capacity of both themselves and the agencies responsible for supporting them to manage the implications on their lives, livelihoods and wellbeing. The work with marginalised people, struggling to rebuild their lives in hazardous settings, often with limited resources, will have strong resonance for developing countries across the world where two forms of risk - conflict and disaster - commonly interact. Moreover, the signing in June 2016 of a ceasefire agreement in Colombia creates a window of opportunity that makes work to assist organisations to support the long-term wellbeing of conflict-displaced people particularly timely.

The research and engagement will centre on four case studies, working with people displaced by conflict in urban and rural settings within the Departments of Tolima, Caldas and Risaralda in west-central Colombia. To understand how men and women experience forced displacement and relocation into areas prone to natural hazards in Colombia, and to explore innovative ways through which they could be incorporated into local processes of disaster risk reduction, this project will use an innovative combination of qualitative methods. Social science methods of interviews and life histories will be merged with exploration of creative arts with study participants. The idea is that focusing on artistic expression, especially popular music which plays a special communicative role in Colombia, will provide a window for us to build relations of trust and reach a deeper and richer understanding of the diversity of their experiences, vulnerabilities, perceptions and responses. The proposed research brings together methods in a way that has seldom been robustly applied in the field of displacement and ongoing risk.

But this programme is not solely about research. A key objective of the project is to build capacity, not only amongst displaced people but also within the organisations responsible for supporting them and managing risk. Through a series of workshops in which musical and other forms of artistic expression will be promoted, we intend to use creative arts to help people recognise their rights and develop their own capacities to reduce risk. Also present at these workshops will be key partners in the risk management organisations, who will take an active role and benefit from the opportunity to explore new ways of working with marginalised displaced people. The idea is that this will encourage organisations that have struggled to include these communities in risk management systems to view them less as victims and beneficiaries, and more as active partners in reducing disaster risk. If successful, we will help promote this new way of working beyond the case study areas to the national scale of disaster risk governance and support for displaced people. At a time when the potential for peace holds promise for making life better for so many who have been forced from their homes by decades of conflict, the project is particularly pertinent.",1
EP/M013200/1,6863,Measurement and Analysis of bioenergy greenhouse gases: Integrating GHGs into LCAs and the UK Biomass Value Chain Modelling Environment (MAGLUE),"To meet the 2020 renewable energy target the UK is going to need biomass, and lots of it. DECC has an aspiration for an additional 20-38TWh of biomass electricity by 2020 and this will require around 12-23 million dry tonnes of biomass. This is a huge quantity of material, the vast majority of which would be imported as pellets from Canada and the USA and burnt in converted coal fired power plants. Other imported feedstocks for liquid fuels might include Brazilian ethanol from sugar cane and oils from palm oil in Southeast Asia. The UK is not alone in wanting to use more biomass. The Netherlands, Belgium, Denmark, and Sweden all expect to use more, and estimates of future EU demand for wood pellets alone, for example, range from 23-80 million tonnes. One single coal power station in the UK is looking to source up to 10 million tonnes of biomass each year. If the UK wants biomass power on a large scale it is clear that the power generators will need to become major players in the transatlantic wood pellet trade. 

Against this background of increased demand, there remains significant uncertainty on whether the use of biomass for energy is environmentally sustainable. Any type of managed land use can incur a carbon 'debt' - a net loss of carbon or other greenhouse gases to the atmosphere that contributes to global warming. Other greenhouse gases include methane and the oxides of nitrogen. But quantifying the net impact of a bioenergy crop relative to what it might replace (sometimes called the counterfactual), is less than straightforward. This has led to many claims and counter-claims from commercial interests, environmental groups and academics, on the real greenhouse gas impact of land use change to bioenergy systems, where there still remains much disagreement and controversy.

The project described here is aimed at addressing this controversial issue - quantifying the real GHG balance of different land use transitions to bioenergy crops, for both UK and imported bioenergy feedstocks. We will deploy sophisticated state-of-the-art instrumentation that is able to measure GHGs very rapidly, to gain a better insight into the dynamic range of GHG emissions that can occur in such systems, including when fields are ploughed and planted and when fertilisers are added. Following data collection, we will extend our analysis by modelling a wide geographical range across the UK and for biomass feedstock sourced from other areas of the world. The models we use should work if we can utilise available datasets, globally, for weather, soils and yield data of the range of crops of interest.

The GHG data in such systems are usually used to develop emissions factors that are inputted into whole life cycle assessments (LCAs) of carbon (or C equivalent) costs, but these in the past have often been unverified data. We will assess the quality of past data and from our measurement and model campaigns we can test the effectiveness of emissions factors and how they might be improved from our work, including for overseas feedstocks. Finally, in an allied project we have developed a value chain model to optimise the technology options for the UK for bioenergy, depending on how cost, GHG balance and land availability are defined. We will run this model to identify the best bioenergy chains, in terms of GHG balance, for the UK and test scenarios ('what if' questions), to determine how much imported feedstock might be sustainable in the future.",1
31793,43905,DEVELOPING PROTOTYPE VOC SENSOR-BASED PRODUCTS FOR DETERMINING SOIL HEALTH ON-FARM,"Feeding 9.8 billion people in 2050 in a climate change context will depend on our skills to keep soils alive. Food production is directly correlated with soil health. To manage and improve soil health, farmers need reliable information about the chemical, physical and biological properties of their soils. There are methods available to assay soil nutrients and determine the physical properties of soils. Only respiration-based methods are currently available to farmers to measure the microbial contributions to soil health, but these give no information on the microbiota present and are affected by other sources of CO2 in the soil. Next-generation sequencing has potential as a biological indicator of soil health, but the costs are high, the tests take hours to conduct, and the data obtained requires experts in order to interpret it.

Our solution is to tap into the wealth of information contained in the volatile organic compounds (VOCs) released by soil biota. These have been demonstrated to be excellent indicators of soil biota activity, but their detection and analysis currently requires laboratory-based instrumentation and skilled personnel. In preliminary work we developed a sensor that can detect soil VOCs and demonstrated that its responses can be correlated with soil health. In this project we will determine the responses of such sensors to a wide range of different soils and cropping systems. These will be correlated with conventional soil health indicators and next-generation sequencing data. Machine learning will be used to process the data obtained to provide a cloud-based database that can be accessed directly by sensors in the field. Use of robots to deploy the sensors with associated GPS data will be investigated to provide farmers with comprehensive and fine-scale data of soil health on their farms so that they can assess the impact of farming practices on soil health and adapt these to increase soil health and productivity. Testing every square meter of land data would be unfeasibly expensive with current testing methods (&pound;60/sample) as the average UK farm size is 930,000 sq. m..

The project will be led by P.E.S. Technologies, a start-up company that developed a plastic electronic sensor for soil VOCs, in collaboration with Hutchinsons, UK agronomy specialists, and the Small Robot Company. Academic partners will be NIAB-EMR, the leading UK horticultural research organisation, the Natural Resources Institute with long experience in VOC profiling, and the University of Essex with expertise in machine learning.",1
NE/P003060/1,15683,Impacts of deglaciation on benthic marine ecosystems in Antarctica,"Environmental changes due to ice loss and deglaciation disturbances will significantly impact Antarctic ecosystems at different levels of biological complexity and spatio-temporal scales. At the lower level of biological organization, changes in key environmental parameters, such as temperature, salinity, productivity and turbidity, may have significant effects on important fitness traits such as growth, survival and fecundity of individuals. These effects may percolate to higher levels of organization such as population and community levels. Thus, lower growth, higher mortality rates and lower fecundity may affect the demographic dynamics of local populations. In addition, at a community scale, in a stressed environment some species may become locally extinct or they may be outcompeted by stronger competitors due to a decrease in individual performance. Alternatively, pioneer species with weak competition abilities would dominate highly perturbed sites. In this way, ice loss and disturbance from deglaciation may promote changes in species diversity and community structure at different directions and spatial scales, moving communities to alternate stable states. Over a longer time scale, all these ecological effects have consequences on an evolutionary scale in determining genetic diversity and gene flow, which may reduce the evolutionary potential of species. Under this scenario, this project aims to investigate the impacts of physical
disturbance arising from climate-warming induced deglaciation on benthic communities around the West Antarctic Peninsula. We adopt a multidisciplinary approach across nested scales from individual to ecosystem level, and from an ecological to evolutionary scale, evaluating genetic, physiological, population, community and ecosystem impacts of this perturbation. In addition, we use sclerochronology to develop biological proxies for reconstructing long-term and short-term environmental changes in Antarctica.",1
2238163,39469,Artificial Intelligence &amp; Data Science for Sustainable Futures,"Our interaction with the natural environment plays a crucial role in all aspects of society: our health, wealth, safety and future development. The increasing availability of large and complex data sets from diverse sources (e.g. environmental monitoring; satellite remote sensing; climate modelling; electronic medical records; social media; and contributions from citizen science) presents an exceptional opportunity to transform our understanding of both the effects of environmental change and our planet-transforming power. 
This PhD will develop methods for integrating of data from multiple inter-related sources using Artificial Intelligence (AI) to provide evidence for informed decision-making and increase our understanding of environmental challenges. The ability to fully exploit the power of data offers the possibility of a step-change in our ability to respond to some of the most pressing issues facing society; including climate change, health oceans and clean air. 
Achieving this goal will require the ability to:
source and integrate data from multiple sources; 
develop and apply modelling and computational frameworks that take account of both the data source and the application in question; 
meet the operational needs of end-users, including accessible computational facilities, suitable time-lags between data retrieval and processing, and the production of user-defined outputs that integrate with existing business processes.

The result would be the information and tools that are required for decision making across a variety of sectors, including energy, water, transport, agricultural and government policy. It will also support efforts to address some of the most important challenges faced by society today, including mitigation and adaptation to climate change, air quality, reduction and reparation of environmental and ecosystem degradation, and preparedness and response to natural hazards.
However, there are challenges associated with discovering and accessing suitable data; gaps and inconsistencies in the data and when it is available; and technical complexity in integrating different data types. Similarly, there are often disconnects between the communities generating data, and those who are making decisions. These challenges mean that society has yet to fully exploit the full potential of environmental data to empower individuals, organisations and businesses and support informed decision making. This PhD will aim to address these challenges and, ultimately, to provide a step-change in our understanding of the effects of changes in our environment and to provide solutions to challenges based on the use of data and AI.",1
EP/M022099/1,28470,The creation of localized current and future weather for the built environment,"It is well known that climate change will have a significant impact on UK building design and energy use. It is also known within the building science and architectural communities that the current weather files used for thermal modeling of buildings only represent average weather rather than heat waves or cold snaps. As was shown by the 14,000 deaths in Paris during the 2003 heat wave, this is a highly serious issue and there is the need to ensure future buildings are designed to deal with future weather, or extremes of current weather.
In addition, the current weather files used by the construction industry and building scientists divide the UK into only 14 regions, with, for example, the whole of the South West peninsular (including up-land areas) being assigned the coastal Plymouth weather file. It is known that this can easily lead to a 200% error in the estimation of annual energy demand. The scale of this error is such that it renders many of the dynamic simulations carried out by engineers questionable. This is unfortunate when simulation is used within the framework of the building regulations, but it is fatal when trying to use simulation to estimate how resilient a pre-existing building is, or the danger its vulnerable occupants might be in. 
The aim of this project will be to see if a method can be devised that is capable of creating local weather from 2015 to 2080 covering the whole UK at a resolution of 5km, and to include within this files that represent various excursions from the mean: e.g. heat waves and cold snaps. 
An interdisciplinary approach is envisaged with the project separated into six work packages:
WP1 We will use a method already published by the team together with the UKCP09 weather generator to produce current and future typical weather at a resolution of approximately 5km. 
WP2 The work in the previous work package will initially require the creation of thousands of years of weather per site. Within these initial years will reside a large number of weather events of interest to the building scientist or engineer. These files will be used in computer models of 1200 differing architectures and building uses to identify what are the key drivers of weather variable coincidence that defines the likelihood of building system failure or thermal issues for occupants. 
WP3 Having characterised which events best describe the stresses on a building, its occupants and systems in WP2. Event years (i.e. times series of weather data variables on a one hour time step that represent atypical hot, dry, cold and wet periods) will be created for the whole UK. 
WP4 Having generated the event years, and simulations from the 1200 buildings, the two will be recombined to produce the first map of UK resilience to a changing climate. Although others have looked at the regional resilience of the built environment using average weather years, the concern is not about the response of building and occupants to such average time series, but to more extreme events. 
WP5 Given the large number of files proposed, guidance will need to be given on which to use in practice, and how this might be expressed in the building regulations and other documentation. 
We plan to use case studies as the main guidance tool. This will add greatly to their intellectual validity within the target audience of practicing engineers. In total, we expect the guidance to be tested on &gt;100 real building projects. 
WP6 Impact. All weather files produced by the project will be publicly available for a minimum of 10 years. A series of road shows will be undertaken at the end of the project. At these events the results of the project will be presented to a large number of users. The idea will be to introduce the whole UK built environment community to the idea of designing resilient buildings aided by the weather data produced by the project. A short film will also be produced for those that cannot attend and for an international audience.",1
EP/T00360X/1,45727,Designing a resilient relief supply network for natural disasters in West Java Indonesia using optimisation-via-simulation: Relief-OpS,"In this project, we will develop methods that optimise the delivery of essential relief items following a natural disaster. These include optimising warehouse locations; inventory management strategies particularly for perishable relief items; and robust routing for post-disaster distribution. The optimisation will make use of an agent based simulation model that we will build with input from key decision-makers, designed to mimic the complexities of post-disaster relief efforts.

The Sendai Framework for Disaster Risk Reduction 2015-2030 puts a strong emphasis on Disaster Risk Management, acknowledging the importance of risk management and strengthening resilience against disasters. Based on the Sendai Framework, the Indonesian government produces a national plan for disaster risk management which highlights the needs for Indonesia to improve its preparedness and response to natural disasters. To execute the plan, Indonesia has established the national board for disaster management overseeing several regional boards for disaster management.

DRM activities span four phases: mitigation, preparedness, response, and recovery. Based on the Indonesian national plan, we focus our research on the preparedness phase (activities performed prior to disaster to allow more efficient response activities such as pre-positioning inventory of relief items) and the response phase (activities following a disaster to reduce its impact). The majority of research in DRM solves the preparedness and response phases of DRM separately, leading to suboptimal solutions. Furthermore, the solutions tend to be based on just one type of disaster. Another gap is that most research assumes that relief items are non-perishable, relief distribution is well coordinated, and demand and damages are known immediately after a disaster. Our focus on multi-disaster situations incorporating all of the complexities of multiple organisations providing relief support will result in more realistic models, filling the gaps in the literature in DRM and resulting in more impact. The research also extends previous Optimisation-via-Simulation methodology to multi-objective, multi-level problems.

In this project, we will work with West Java regional board from specifying the requirements for the decision support system to developing realistic scenarios to evaluate our methods. West Java province is chosen because it has the highest multi-disaster risk in Indonesia due to the population size, population density, high contribution to Indonesian GDP and being the centre of rice production in Java island (rice is the main staple food in Indonesia). As we will implement the national standard procedures for disaster preparedness and response, the decision support system can be customised by other regional boards to suit the characteristics of their regions by changing the parameters (for example, map, demography, infrastructure). Therefore, we will also organise a practitioner workshop to present our findings and to provide training for all regional boards to use the decision support system. The decision support system can also be used for training purposes which will strengthen the preparedness of the regional board officials.

Finally, this project will build capacity in this vital area of research. The research assistants in the UK and Indonesia will gain from regular project meetings, interactions with investigators and the scientific advisory board members, and relevant training in Southampton, Padjadjaran or other places in the UK and South East Asia. We will also organise a research workshop for Indonesian researchers who are interested in OvS, ABS and Operational Research in DRM",1
NE/N005937/1,13761,SeaDNA - Assessing marine biodiversity and structure using environmental DNA: from groundtruthing to food web structure and stability,"DNA evidence has revolutionised our understanding of the natural world. It has helped us to appreciate how species are related to one other, how environmental change can lead to species divergence and how individual populations become adapted through evolutionary processes to their local environments. It has also been particularly useful in quantifying the diversity of species in communities of microorganisms that cannot readily be seen and assessed using standard microscopy. 

Importantly, DNA in the natural environment can also be used in a &quot;forensic&quot; manner. Traces of DNA from skin, blood, faeces or mucous can be used to identify which species have recently been present in the local environment. Given recent developments in DNA sequencing technology, this &quot;environmental DNA&quot; (eDNA) promises to revolutionise the way we probe biodiversity in our environment, particularly in marine environments that can be very difficult to sample reliably. Traditionally we have used specialist grabs and nets to survey species larger than microbes in marine communities. However, sampling free eDNA in surrounding water is potentially faster, less expensive and less destructive than such gears. Use of trace eDNA also holds potential to identify species that are not reliably sampled in the environment, either because they are rare, small, or adept at avoiding nets and grabs. 

The utility of eDNA as a tool for sampling aquatic environments has been mostly tested in freshwater systems, and there are only a handful of studies that have tested the approach in the marine environment. Thus, there is a need to further evaluate the potential using a combination of laboratory experiments and field surveys. As an important first stage, we need to establish how long eDNA from fish and invertebrates persists in the marine environment before it is broken down beyond the point of detectability. This will tell us how well an eDNA-derived species list reflects the species community at the sampling site. We will conduct a set of laboratory experiments that will enable us to quantify the rate of eDNA break-down, and identify main environmental variables that influence this rate of decay. We will then aim to develop the laboratory and field methods needed to reliably detect DNA from these species groups, before testing these methods in experimental communities that we will assemble in laboratory aquaria. 

An important stage in testing the ability of eDNA to be used as a tool in surveying and monitoring marine species is to survey the natural environment using both traditional methods (e.g. nets), and eDNA methods. We will do this in two UK marine habitats that are important for fisheries, conservation and environmental monitoring, namely estuaries and inshore shelf seas. We will also do this in an open ocean habitat, the Southern Ocean, which is an important habitat for fisheries and oceanic megafauna such as whales. We will directly compare data from eDNA methods to those from traditional methods to ask if eDNA accurately captures the fish and invertebrate communities, and if the method has the added ability to inform us on the presence of species that are typically rare or difficult to sample, some of which may be new to science. 

Finally, we will use the eDNA derived species lists to reconstruct the food webs present in our sampling locations. We will use these data to test how stable marine communities are over space and time, and how environmental variables such as temperature affect their composition and stability. The results of these analyses will provide insight into the role of eDNA in helping us to understand how future climate change may affect fished species.",1
NE/R01695X/1,22080,Ion Microprobe Facility (IMF),"The ability to precisely and accurately measure the chemical and isotopic compositions of materials on very fine scales, down to only a few thousanths of a metre, is critical for understanding and evaluating the whole spectrum of Earth and environmental earth system processes, and hence finding ways to solve or manage the societal issues that arise from them. This ability - quantitative microanalysis - is central to modern Earth System Science. Processes that occur on Earth often dictate particular behaviours in elements and isotope ratios. Precise determinations of these sensitive elements that occur in very, to extremely, low abundances in minerals, glasses, organic remains and skeletal materials allow geoscientists to investigate the effects of processes on different timescales. Current applications include, for example, evaluating the conditions of mineral and ore deposit formation, reconstructing the evolution of past volcanic eruptions in order to constrain future hazard, determining fluctuations in seawater surface temperatures over time and their relationships with global climate change, and even monitoring of long-term climatic variations from cave deposits. Accurate and precise isotopic measurements of stable and radiogenic isotopes further enable geoscientists to measure ocean acidification associated with global climate change, quantify the amounts and types of sources for fluids involved in a large variety of important earth processes from the surface to the deepest mantle, and determine the ages of ancient and recent rocks and minerals formed at both low- and high-temperatures. This proposal is to provide continued UK science community support for a world-class laboratory that enables the UK to excel in the quantitative microanalysis of Earth materials, and explore fundamental questions that have consequences for the planet, the environment and its population: the Edinburgh Ion Microprobe Facility.",1
EP/R041504/1,15520,Development of a Novel Self-Healing Composite for Sustainable and Resilient Concrete Infrastructure,"Concrete is the most widely used construction material in the world. The construction industry annually uses 4.3 billion tons of ordinary Portland cement (OPC) as binder for concrete, accounting for around 7% of global CO2 emissions. To reduce the environmental impact of concrete industry in the UK, industrial by-products, such as pulverised fuel ash (PFA) and ground granulated blast-furnace slag (GGBS), are usually used for partial replacement of OPC. Although partial replacement of OPC can reach up to 50%, the total replacement of OPC in concrete with these wastes is not feasible without the addition of alkaline activating agents.

Geopolymers, also called &quot;alkali-activated materials&quot;, that are cement-free eco-friendly materials synthesized at ambient or elevated temperature by alkali activation of aluminosilicate source materials such as low-calcium PFA and GGBS, have been drawing a lot of attention as a promising alternative to OPC. GPC has many advantages over OPC concrete (OPCC), such as light weight, good fire resistance, low alkali-aggregate expansion, and good resistance to corrosion, acid attack and freeze-thaw cycles. Using geopolymer as the binder in concrete can help reduce embodied energy and carbon footprint by up to 80%. However, GPC is inherently brittle similar to OPCC and susceptible to cracking that would facilitate corrosion of reinforcing steel and impair durability of reinforced concrete (RC) structures, and thus hinder its widespread application. In addition, the resilience of concrete infrastructure that associates with the usability of RC structures is a major concern. It is essential for GPC to possess the capability to recover permanent deformation upon yielding (i.e., re-centring) or the ability to reduce residual crack sizes (i.e., crack closure) when subjected to cyclic loads in order to maintain the functionality and serviceability of a structure over its service life. As such, it is vital to develop strain hardening fibre reinforced GPC, also known as engineered geopolymer composite (EGC) to suppress the brittleness of GPC and improve its durability through multiple crack propagation with controlled crack widths. 

In this project, for the first time, a novel self-healing EGC that integrates the greenness potential of GPC and the energy absorption capacity of shape memory alloy (SMA) fibres without permanent deformation will be developed. The project involves the development of a novel mix design methodology that integrates micromechanical modelling, design of experiment and life cycle analysis. A range of advanced experimental techniques (e.g., in-situ X-ray computed tomography imaging, image volume correlation, and scanning electron microscope) and modelling approaches (e.g., multiscale lattice Boltzmann-finite element method, and multiscale fracture model) will be used to characterise microstructure and simulate engineering properties of EGC respectively, which will provide insight into the overall performance of EGC and its self-healing efficiency.

This research will make it possible to develop a novel EGC with eminent mechanical properties and desired crack-healing capacity. It would expedite the use of GPC and SMA fibres in civil infrastructure applications, particularly for concrete structures subjected to dynamic loads and aggressive environments, which will help greatly enhance resilience, sustainability and durability of concrete infrastructure. The outcomes of this project are expected to result in direct benefits to society by extending the lifetime and by reducing the environmental impact, and repair and maintenance costs of RC structures.",1
710766,30471,Intelligent Gas Grid Management,"Utonomy was founded in May 窶・5 to develop technology for reducing leakage in low pressure
gas distribution networks by optimising pressure in the network. We want to verify use of
advanced predictive analytics to reduce overall pressure and therefore gas leakage which is
directly proportional to the pressure in the network.
Natural gas (used in the networks) is comprised largely of methane which is a potent
greenhouse gas and leakage of gas is a big contributor to global warming. Although only 14%
of greenhouse gas emissions worldwide are methane, it traps up to 84 times more heat than
CO2 (over 20 years). This smaller amount of methane is 12 times worse for climate change
than CO2 over 20 years. In the UK, leakage from the gas network is estimated at 7,000 GWh
(1% of gas transported) costing the consumer &pound;180m pa and releasing 10m tonnes pa of CO2e
(the method by which the greenhouse effect of all gases are measured is by comparison to
CO2). By optimising the pressure, we expect to reduce leakage by more than 20%.
The Intelligent Gas Grid Management (IGGM) project, will develop and test a method of
predicting demand and demand/pressure relationships automatically regulating pressure in a
network to keep it just above the minimum. To achieve this, we will undertake R&amp;D on the
two most challenging aspects of the proposed solution 1. Mathematical analysis of large data
sets to develop a predictive software control model 2. A means of accurately adjusting the
governor窶冱 (gas pressure control valve) outlet pressure through a mechatronic hardware
design. The PoC output will be software that allows us to model the leakage savings on an
example gas network, plus hardware that demonstrates that precise governor control can be
achieved within cost and reliability targets. To exploit outcomes, we will approach gas
distributors for trials/commercial partnerships and seek investment &amp; funding to develop a
prototype for an end-to-end pressure control system.",1
EP/T003995/1,35999,Partnerships for Resilience through Innovation and Integrated Management of Emergencies and Disasters (PRIMED),"The network for Partnerships for Resilience through Innovation and Integrated Management of Emergencies and Disasters (PRIMED) primarily aims to strengthen community preparedness and resilience as a strategic approach for addressing three key global challenges, i.e., sustainable development and poverty reduction, disaster risk reduction (DRR) and climate change. Participation of communities in disaster management programmes is recognized as key for minimizing the severity of natural and climate related hazards on the most vulnerable and recovery from disaster, thus ensuring sustainable development for all. Efforts are shifting away from reactive emergency response frameworks to more proactive management approaches that incorporate varying socioeconomic and cultural interests, socially differentiated groups (such as those based on gender, age, physical challenges), capabilities and resources for effectively reducing vulnerability and sustainably increasing resilience at the local level. 

Many of these communities struggle with deploying and managing sustainable infrastructure, such as services for energy access via renewable or fossil fueled electrification programs, roads and transport services. Small and medium sized municipalities in these developing nations, especially, are often constrained in terms of financial and professional capacity. At the same time, public servants need to manage complex planning and policy processes to ensure that the communities they are serving will have appropriate systems in place to respond to climate shocks. This includes sufficient information to ensure that new human settlements, and associated energy and transport services settlements, will be built so as to be climate compatible, with reduced vulnerability to future events, whilst at the same time enabling sustainable development. 

The PRIMED network will, therefore, facilitate social innovation and knowledge co-creation, taking as a starting point, applications and models of resilience interventions and building sustainable infrastructure where success has been achieved through improved community partnerships, leadership training, participative research and action oriented education. Partnerships created within the PRIMED network will bring together international and national academics, researchers, policy and decision makers, practitioners, and community members that represent the various social groups, to share their varied perspectives, reflections and experiences of what works. These interactions will enable the team to:

1. Understand and define constraints and opportunities 
2. Define mechanisms required for increasing the participation of diverse coastal social groups, including the marginalized, in disaster mitigation and preparedness
3. Identify effective educational tools that improve leadership skills of community members
4. Improve community capacity to take action and build their overall resilience to coastal hazards
5. Improve the management of complexities associated with climate resilient and low carbon development policy and planning.",1
NE/P012183/2,4528,"Climate related size shifts in aquatic species: mechanism, prediction and mitigation","Body size is linked to nearly all aspects of an animal's life, be this metabolism, reproduction or survival. Similarly, the structure of food webs, competition, predator-prey interactions and population productivity can all be influenced by body size. For these reasons, body size is often described as a 'master trait', and variation in the size of species has fascinated biologists for over a century. The size at which a species matures can change depending on the environment, and shifts in the size of animals and size-spectra of biological communities as a result of climate change are likely to have worldwide ecological and economic impacts. 

In ectotherms, individuals of the same species regularly grow to a smaller adult body size in the warm than in the cold when reared in the laboratory. This near-universal biological phenomenon, known as the Temperature-Size Rule (TSR), occurs in over 80% of ectothermic species, from bacteria to fish and amphibians. Similar patterns in body size have also been seen in nature; larger species are often found at higher colder latitudes, whilst adult body size has been shown to vary seasonally with temperature over an annual cycle, as subsequent generations experience different environmental conditions during growth and development. With average global temperatures predicted to rise by more than 2 degrees Celsius by the end of this century, reduced body size has been described as the third universal response to climate warming.

Size reduction with warming is much greater for aquatic species than for species living in air. This has been attributed to oxygen availability, which is much more limiting in water than in air. Consequently, aquatic species struggle most to meet their metabolic demands in the warm, and growing to a smaller adult size is thought to be an adaptive response to cope. In addition, reduced oxygen availability independent of temperature has also been shown to decrease size at maturity. Deoxygenation is increasing in geographic extent and severity in regions of the world's oceans and in freshwater systems, and is predicted to significantly worsen over the coming decades. Clearly, climate warming combined with reductions in oxygen concentrations present a double jeopardy to aquatic species. There is an urgent need to quantify, understand, predict and develop mitigation strategies to deal with warming and oxygen-induced changes in body size in aquatic ecosystems. Our proposed research aims to tackle these issues by addressing the following key questions:

Q1. How do changes in temperature and oxygen concentration influence body size in ecologically and economically important but under-represented aquatic species, and do aquatic species adapted to environments with low and high oxygen availability adjust their size differently?

Q2. How have body sizes changed in aquatic species in relation to temperature and oxygen availability over recent decades? Are these responses similar to patterns observed in the laboratory and across seasons and latitudes? We cannot rely on laboratory and seasonal estimates to predict future shifts in size. Describing body size changes over decades in natural populations is a critical next step, and importantly, will increase the accuracy and reliability of our predictions.

Q3. What are the most important traits (e.g. feeding mode, reproductive strategy, mortality risk) associated with variation in the strength of temperature- and oxygen-induced body size change, and can we use this information to accurately predict body size change in the future?

Q4. Does body size reduction with warming fully compensate for increased metabolic demand at higher temperatures, and how might this affect the total productivity and efficiency of transfer from food to flesh that can be supported in warmer conditions? Can we use this information to contribute to informed decision making in the aquaculture and fisheries industries?",1
752215,8201,Rightstuff,"&quot;Rightstuff is the online marketplace for everyone who wants to shop with the environment in mind.
Search for the products you want. We weigh up the environmental impact of brands and products, and show you which we think are the best for your budget. We窶冤l show you our best five products within your search criteria and price range. We explain why we think one is better than the next, making it easier than ever to shop for 窶枠reener窶・goods. What窶冱 more, we only allow sellers who are committed to good working practices and environmental standards to sell on our marketplace.&quot;",1
104182,26894,VALUABLE: VALUe chain And Battery Lifecycle Exploitation,"&quot;Project VALUABLE's key objectives are to develop commercially viable metrology and test processes as well as new supply chain concepts for recycling, reuse and remanufacturing of automotive lithium-ion batteries to create a complete End-of-Life (EoL) supply chain network within the UK.

The consortium's vision is to 1) increase the value-add of the battery supply chain in the UK, 2) decrease the environmental impact, and 3) optimise future battery design for EoL. By bringing together many disparate parts of many sectors, the project will provide an efficient and effective route to providing second life battery applications, whilst reducing the packs / cells being fed into the waste streams.

The project will investigate key areas that are providing difficulties in dealing with automotive batteries at their EoL: 1) the lack of reliable and cost-effective test methods, 2) the lack of remanufacturing/recycling and reuse processes, 3) the lack of effective value chains, and 4) lack of design considerations for EoL in battery design.

To implement efficient processes, the project will investigate and develop advanced 'machine vision' capabilities, to determine which packs have second life potential and at what level and which are for recycling.

This development of advanced testing capability in the EoL processing line, will enable the consortium to explore significant value chain applications for end-of-life batteries, ranging from remanufacturing to go back into the same vehicle model, to use in lower demand mobility applications, through to use as energy storage mediums for the energy market. The test results will also aid future first life battery pack design, providing OEMs and battery producers with routes to both realise additional value from future applications for used batteries and to move towards 95% recyclability.

In conjunction with the development of new designs and processes, the project team will also explore the growing legal and regulatory issues surrounding the battery producer responsibility / waste classifications in the UK and Europe.

In addition, not only will the battery cells be assessed, but the charge controllers, outer jackets, and other components. Reuse of these products contributes to the recycling targets, but also supports improved material recovery routes through better material separation.

The project brings together partners across the supply chain, developing new EoL testing techniques, and in creating a UK-based EoL supply chain. The project is not only supported by the supply chain but also an industry-wide OEM support represented in a guiding advisory group.&quot;",1
NE/M011577/1,14127,New approaches for the quantitative detection of human pathogenic viruses within the freshwater-marine continuum,"Viruses pose one of the biggest threats to human wellbeing being responsible for numerous infections and millions of deaths worldwide each year. Most of these viral diseases are passed via the faecal-oral route in which contaminated food and water are frequently implicated in the primary infectivity phase. Although many of these infections are self-limiting, the societal and economic burden should not be underestimated. For example, Norovirus (NoV) is estimated to cause over 2 million cases of illness in the UK each year resulting in millions of days of lost productivity and an economic burden estimated to exceed &pound;100 million to the NHS directly and over &pound;2 billion annually to the wider economy. Worryingly, it is clear from a range of critical reviews that the burden of waterborne disease is likely to increase in Europe in response to climate change. This increasing problem is being exacerbated by increased pressure on wastewater infrastructure (due to population rise), sewer misconnections and a greater incidence of storms and flood events causing the release of untreated sewage (stormwater discharge) into river networks and the coastal zone. Considering the magnitude of the problem and the disease burden forecast for the near future, it is timely to develop new strategic approaches for mitigating against viral contamination and to develop new and improved risk assessment tools for protecting human health. 

In view of this, our proposal aims to address the critical need to develop and validate new tools for the detection and surveillance of human pathogenic viruses in freshwater, estuarine and coastal environments. Specifically, we will design and test experimental and modelling tools to permit the robust recovery and quantification of viral populations from contrasting matrices (e.g. seawater, freshwater, sediments, effluent, shellfish). These tools will be designed to capture the viral populations in both space and time. We will focus on viruses of strategic iortance from a human health perspective (e.g. Norovirus, Sapovirus, Hepatitis A/E), however, these will be placed in a wider context via metavirome analysis of RNA and DNA viral communities. These techniques will be deployed and demonstrated at the catchment-to-coast scale whilst simultaneously answering fundamental questions about the temporal and spatial dynamics of viral flow. This knowledge will be used to validate next generation mathematical models capable of predicting viral flow through the river network and coastal zone. Combined, this information will be used with key stakeholders (e.g. Cefas) in the implementation of new methods and guidelines for assessing infection risk (e.g. in recreational waters, beaches &amp; shellfisheries) and for protecting human health. 

Our proposal directly addresses the strategic aims of the NERC Environmental Microbiology and Human Health (EMHH) Programme. As requested by the call, we will provide &quot;scientific evidence to support fast and efficient identification of pathogenic microorganisms in environmental media which can be used in appropriate tools and models for the protection of public health targeting the freshwater and coastal zone&quot;. The work is also directly relevant to the policy objectives and strategic aims of the Food Standards Agency, Defra and European Union (DG Sanco, and DG Mare).",1
NE/P006035/1,17485,Can we detect changes in Arctic ecosystems?,"Ecosystems are communities of organisms that interact with each other and their environment. They are often considered in terms of food webs or chains, which describe the interactions between different organisms and their relative hierarchies, known as trophic position. Ocean ecosystems provide key services, such as nutrition, control of climate, support of nutrient cycling and have cultural significance for certain communities. It is thus important that we understand how changes to the environment reshape ecosystems in order to manage climate change impacts.

The Arctic Ocean is already being heavily impacted by climate change. It is warming faster than any other ocean region and as it absorbs fossil fuel emissions, it is gradually acidifying. Arctic sea ice is declining by 10% per decade. This affects the availability of sea ice habitats for organisms from plankton to mammals and modifies the ocean environment. Finally, the Arctic is affected by changes in the magnitude of water movement to and from the Pacific and Atlantic Oceans and composition of these waters. Thus Arctic ecosystems are being impacted by multiple concurrent stressors and must adapt. 

To understand how Arctic ecosystems will evolve in response to multiple stressors, it is crucial to evaluate the effects of on going change. Often these questions are tackled by studies that focus on a specific ecosystem in one location and document the various components of the food chain. However the Arctic is diverse, with a wide range of environments that are responding to unique stressors differently. We require a new approach that can provide information on Arctic ecosystems from a pan-Arctic perspective over decadal timescales. 

To effectively monitor changes to pan-Arctic ecosystems requires tracers that focus on key ecosystem components and provide quantitative information on ecosystem structure, providing information for management and conservation of ecosystem services. Our goal is to respond to this challenge. We will focus simultaneously on the base of the food chain, controlled by the activity of marine phytoplankton, and key Arctic predators, harp and ringed seals. Seals are excellent candidates to monitor the food web due to their pan-Arctic distribution and foraging behaviour, which means they are exposed to the changing environment. 

Nitrogen and carbon stable isotopes are often used to examine ecosystems as they are modified during trophic transfer up the food chain. Hence, they can quantify seal trophic position and food chain length, key determinants of ecosystem structure. Crucial in this context however is the isotope value of the base of the food web, known as the isoscape, which is itself affected by a range of environmental characteristics and fluctuates in space and time. Equally, by virtue of changing migration patterns, seals themselves may feed on similar prey in different isoscapes, which would affect the interpretation of ecosystem structure from stable isotopes. These are the major challenges in using stable isotopes.

We will link stable isotopes to novel tracers of the food web, known as biomarkers. When these tracers are compared against observations of the shifting isoscape and data on seal foraging, they permit seals to be used to monitor the Arctic ecosystem by quantifying their trophic position and overall food chain length. Via a range of observational platforms, our new food web tracers will be mechanistically linked to the spatial and seasonal trends in the Arctic isoscape and seal behaviour. By then combining historical observations from around the Arctic basin with state of the art ocean and seal population modelling, we can quantify past and future changes in Arctic ecosystems. This will provide information on past changes to Arctic ecosystems, but also put in place an approach that can be used to monitor future changes and aid in the management and conservation of ecosystem services.",1
NE/T006102/1,45693,Methodologically Enhanced Virtual Labs for Early Warning of Significant or Catastrophic Change in Ecosystems: Changepoints for a Changing Planet,"Virtual labs are emerging as a key component in the construction of future digital environments, particularly to abstract over the complexities of the underlying distributed networks of sensors and associated computational infrastructure. We define a virtual lab as a transdisciplinary collaboration space hosted in the cloud (public/private/hybrid) that allows stakeholders to access a range of data, analytical methods and assessment tools (e.g. visualisation tools and/or statistical tools), and to execute these analyses using the elastic capacity of a cloud. In the environmental science community, most existing virtual labs focus on the problem of integrating often complex and heterogeneous data. We seek to significantly advance the state-of-the-art by enhancing virtual labs with sophisticated methodological capability, embracing state-of-the-art data science techniques to assist in the societally-relevant interpretation of these data. 

This is a bold and broad vision and, to make this feasible in a year, we elect to work with a particular family of data science techniques, that is, changepoint detection methods, designed to identify fundamental changes and anomalous behaviour in data, typically within time-series, but also applicable across space and time and to complex, multivariate problems.

This feasibility study will therefore bring together a cross-disciplinary team working on virtual labs, changepoint methods and evidence for impacts of global environmental change on ecosystem structure and function. Our approach will foster a deep, cross-disciplinary dialogue through workshops, enhanced by rapid prototyping of virtual labs to stimulate thinking about what is possible/desirable w.r.t. ecosystem early warning methods.

The project will build on the rich, complex, multi-faceted data available from the Environmental Change Network (ECN), that offers detailed multivariate 25-year long data sets for a range of ecosystems in the UK. We seek to understand the role of data science, including, but not limited to changepoint detection, in the construction of environmental early warning alert systems capable of operating at a variety of scales, from catchments to global planetary level systems.",1
NE/S002871/1,46463,"[Viet Nam] Valuing the benefits of blue/green infrastructure for flood resilience, natural capital and urban development in Viet Nam","Flooding is the most damaging and costly hydrometeorological hazard affecting millions of people globally every year. In Viet Nam, low-lying coastal cities, particularly in river deltas, face increased flood risk and vulnerability due to rapid urban development and climate change. To reduce flood risk in urban areas, the recent decade has seen increased appreciation of the potential of Blue/Green Infrastructure (BGI), such as natural and man-made wetlands, vegetated river banks and restored floodplains, to reduce flood risk and provide additional benefits, such as controlling water pollutants, providing recreational opportunities, improving air quality and increasing resilience to other stressors, such as heat waves and noise pollution. However, despite the growing interest in BGI in a flood risk management context, assessments of the effectiveness and viability of such measures have in the past been mostly piecemeal, focusing on individual impacts of such measures (e.g. flood risk reduction, provision of urban green space). Such sectorial assessments cannot account for the potential trade-offs or complementarities between the multiple impacts of individual installations, let alone whole networks of BGI. Therefore, ValBGI seeks to develop a multidisciplinary, stakeholder-informed assessment framework for the effectiveness of BGI to reduce flood risk and improve urban natural capital. Thereby, the project examines the role of BGI in short- and long-term urban development, with application to the city of Can Tho, Viet Nam. This holistic framework integrates a number of disciplines and does not only follow an interlinked and multidisciplinary research agenda but also advances the academic state-of-the-art in the individual disciplines involved. This includes the engagement of key stakeholders in the research process to co-develop solutions and disseminate evidence to key decision-makers; innovative high-resolution modelling of flooding and BGI at the city-scale; and spatially explicit assessment and valuation of changes in the provision of ecosystem services enabling the quantification of the investment into urban natural capital effectuated by BGI. 

To achieve these objectives, the project comprises four work packages which function as interlinked components within the multidisciplinary assessment framework: (1) The operational backbone of ValBGI is a work package that establishes a stakeholder group to work alongside the research team from start to end. This component assesses (and when necessary stimulates) the awareness of alternative natural processes-based BGI options among local and regional urban planners and other key stakeholders. (2) A second work package reviews existing flood models for Can Tho and the Vietnamese Mekong Delta and develops a new high-resolution modelling system to assess the effectiveness of selected BGI measures in reducing flood risk. (3) In the third work package, changes in the provision of ecosystem services following the installation of BGI measures will be assessed and mapped. (4) In the fourth work package costs and benefits of BGI measures (in terms of flood risk reductions and improvements of urban natural capital) are quantified by means of valuation, and cost-benefit analyses of BGI scenarios are conducted. 

The continuous stakeholder engagement in ValBGI ensures awareness for and uptake of the research outcomes by decision-makers to maximise impact of the evidence produced. Furthermore, the holistic approach provides a better understanding of the potential trade-offs and complementarities between flood risk reduction and improvement of natural capital generated by BGI. Exploring all simultaneous impacts of BGI is beneficial in providing environmental managers and urban planners with a complete array of information for supporting planning decisions.",1
2098296,14373,&quot;Environmental Policy and Development&quot; Topic: Assessing progress in climate change adaptation at different levels,"In recent years adaptation to climate change has seen an increasing level of political commitment and implementation. According to the Global Climate Legislation Study, more than 65 countries have put in place national frameworks for adaptation to climate change (Nachmany &amp; Fankhauser, 2016). An important question for scientists, governments and the many actors involved in dealing with climate change is which effect implemented adaptation efforts have had, individually and collectively. Are we adapting to climate change and is the magnitude sufficient? Are there spatial differences in achieved adaptation levels? How can we even measure successful adaptation? And how can such an assessment inform policy making and implementation?",1
2282612,35725,New insights into rapid climate events from Galapagos and Southern Ocean deep-sea corals,"The unprecedented rise in greenhouse gases over recent decades has emphasised the importance of examining the links between carbon and climate during intervals of rapid warming. The last glacial termination (~18-10 ka) witnessed rapid (decadal) increases in atmospheric pCO2 and temperature, thus presenting a unique opportunity to examine the links between the carbon cycle and global climate on timescales relevant to the modern day. The ocean doubtless plays an important role but a major challenge remains finding suitable archives that record how the deep sea behaves. Deep-sea corals offer a solution to this problem. Unlike reef-forming corals found in shallow tropical areas, deep-sea corals do not have algal symbionts so they are not restricted to shallow waters. This project offers the opportunity to establish high resolution deep-sea climate records from Stylasterid corals. Stylasterid corals are widespread in the global ocean, and their geochemistry reflects their growth conditions- however they have not been previously been used in studies of the past - opening up an exciting new field of research. The aim will be to develop and use the skeletons of fossil deep-sea Stylasterid corals to provide unique insights into the oceanic processes in the past with a focus on the last deglacial transition. The PhD will include development of geochemical proxies and radiometric dating techniques, reconstructions of past oceanographic conditions and interpretations in light of global climate and environmental change.",1
132761,23331,A Combined Water Production/Dew Point Cooling Unit for Low Carbon Vehicles,"This project MACwill develop a mobile air conditioning system to reduce both the direct carbon emissions by being more energy efficient avoiding the use of high global warming R134a used in the current MAC systems. The proposed system will both meet the new EU regulation, which requires the phase-out of the R134a starting on 1st January 2013, and the strong preference expressed by vehicle manufacturers for non-flammable refrigerants.",1
NE/R009244/2,44526,"NEC06484 UK: mySoil-sample, crowdsourcing digital soil data from industry and policy","There is no life without soil to provide food, feed, fibre and wood. Understanding how soils are changing in response to land use management, climate change, and pollution is at the forefront of environmental research to reduce degradation and deliver vital functions such as, food production, transforming and recycling waste, and storing carbon. We have identified an important market failure that results in the loss of high quality strategic soil data for industry and policy. Farmers collect soil samples every year that they have analysed in commercial laboratories, this data lacks basic location information and is generally collected through paper based systems inhibiting data flows that would stimulate new business opportunities. 

Therefore, we will turn farmer's soil analysis into 'smart soil data' to unlock the secrets of the soil. More than 0.5 million soil samples, collected by the farming industry every year are without location information and digitally undiscoverable. 'smart soil data' is digital, discoverable, with gps positioning and accredited laboratory analysis. By making soil data smart we can begin to address the questions for which we need big data, such as why have we reached a yield plateau, and why does yield decline follow crop rotation, is soil carbon stock declining? In order to unlock these secrets we need 'smart soil data'. MySoil sample will address this, a web and app based digital data capture system built on the tried and tested NERC iRecord platform. We will:
 
i) build a digital data hub for owners to privately store or share industry data, making anonymized data discoverable and interoperable. 
ii) a web and smartphone soil sample data collection system with GPS, and
iii) create anonymous digital data pipelines to interpretive benchmarking portals for industry. 

This will open up new markets and business opportunities for collecting and using high level anonymized, 'smart soil data'. We call our system 'mySoil-sample', which builds on our success in crowdsourcing soil data using 'mySoil' (4000+ records) and wildlife data using 'iRecord' (50,000+ records). 

The new data acquisition system will provide a strategic data resource that will add value to data and inform both industry and policy makers. This is now vital, as Brexit may pose a range of new challenges for farmers and agri-business to remain competitive. There has never been more need to understand how our natural resources can respond to this economic and societal challenge. We will use the power of the crowd (farming and conservation communities), combined with tried and tested NERC digital crowdsourcing data acquisition systems, both web and app based to support industry and policy.",1
NE/P019048/1,6018,SWEET:Super-Warm Early Eocene Temperatures and climate: understanding the response of the Earth to high CO2 through integrated modelling and data,"The Earth's climate is currently changing rapidly, primarily due to emissions of greenhouse gases caused by human industrialisation. These emissions are projected to increase through this century, and under some scenarios atmospheric carbon dioxide (CO2) concentrations could reach more than 1000 parts per million (ppm) by the year 2100, compared with 280 ppm prior to industrialisation. In order to predict the sociological, environmental, and economic impacts of such scenarios, and thus to better prepare for them, the only tool at our disposal is climate modelling. In order to assess our confidence in predictions from climate models, they are routinely tested under conditions of known climate. However, this testing (and associated tuning of the models) is almost exclusively carried out under modern climate conditions, and relative to recently observed climate change, for which CO2 concentrations are less than 400 ppmv. As such, our state-of-the-art climate models have never been tested under the high CO2, super-warm climate conditions to which they are primarily applied, and upon which major policy decisions are made.

However, there exist time periods in Earth's deeper past (for example the Eocene, about 50 million years ago) when CO2 concentrations were similar to those expected by the end of this century; but climatological information from these time periods is currently sparse and is associated with large uncertainties, and the exact concentrations of CO2 are only poorly known. Recent changes in our understanding of how the geological record preserves climate signals, and developments in laboratory techniques, mean that for the first time there exists a new and exciting opportunity to remedy this situation and provide a much-needed evaluation of our very latest climate models in a super-warm world.

In SWEET, we will apply these emerging techniques, and develop new methodologies and tools, to produce a global dataset of Eocene temperatures. Coupled with new and high-fidelity reconstructions of Eocene CO2 concentrations, and state-of-the-art maps of the 'palaeogeograpy' (continental positions, mountain ranges, ocean depths etc.), we will use this dataset to test a state-of-the art climate model under high atmospheric CO2, Eocene conditions. The model, UKESM, is identical to that being used by the UK Met Office in the international 'CMIP6' project, which itself will be the primary input to the next Intergovernmental Panel on Climate Change (IPCC) assessment report. We will also use our data and additional model simulations (running at high spatial resolution) to investigate the relative importance of the various mechanisms which determine the response of the Earth system to high CO2 and to changes in palaeogeography.

A characteristic of SWEET is that we will take full account of uncertainties in the geological data and the modelling, and our model-data comparisons will be underpinned by a statistical framework which incorporates these uncertainties. We will also adopt a 'multi-proxy' approach by using several independent geological archives to reconstruct temperature. For one of these archives, namely the oxygen isotopic composition of the fossilised shells of microscopic marine creatures from the Eocene, we will apply a particularly innovative approach which will enable us to 'resurrect' previously discredited data, by using an extremely fine-scale 'ion probe' to investigate how these isotopic signatures of past climate change are recorded in individual fossils.

SWEET has strong links to UK Met Office, and to the international DeepMIP project, which is part of the 'Palaeoclimate Modelling Intercomparison Project', itself part of CMIP6. We expect our results to feed into the next IPCC assessment reports and therefore to ultimately inform policy.",1
2269375,37830,Using morphometrics to explore biodiversity and resilience in archaeobotanical assemblages,"Morphometric analysis of wheat grains/chaff will be used to assess two potential sources of morphological variation: 1. Intra-species diversity i.e. between landraces and 2. Variation relating to environmental conditions/stresses. Data from analysis of modern wheat will be applied to archaeobotanical assemblages in a series of case studies. The research will explore how farmers may have cultivated different wheat varieties or 'landraces' in certain environments to produce desired characteristics and/or mitigate environmental risk-factors. Focus is placed on wheat due to its role as a major dietary staple in the past and present.

Loss of genetic diversity in modern cereal crops has prompted increasing concerns over sustainability; particularly in the face of climate change. In this context, studying archaeological intra-species diversity allows us, not only to assess adaptability of past arable strategies, but also to make comparisons with modern arable systems. Equally, research will seek to identify vulnerability of yields by identifying symptoms of wheat impacted by stress factors, e.g. drought or soil exhaustion. It is hypothesised that intra-species diversity and vulnerability to environmental conditions will manifest themselves distinctly in wheat morphology, and that such distinctions will be discernible in archaeobotanical material.
Research Context
Recent studies have demonstrated the potential for identifying intra-species variation through morphometric analysis of modern wheat and barley grains respectively (Bonhomme et al. 2017; Wallace et al. 2018). Both studies established applicability of the methodology to charred archaeological material. However, it remains unresolved whether morphometrics can discern effects of environmental stresses and whether these can be distinguished from differences between landraces. While there has been substantial research into the effect of environmental factors such as water availability and temperature on wheat growth, this has tended to be quantified in terms of overall yield. For archaeobotanical applications, quantitative data on the morphology of environmentally-stressed grain/chaff is needed. 
Methodology 
Intra-species variation will be studied through morphometric analyses of multiple varieties of modern wheat with Momocs in R. Environmentally-determined variation will be assessed using existing plant experiment archives, with supplementation through further growing experiments possible. Across both categories, multivariate analysis will test the degree to which different types are successfully separated by the quantitative variables generated by morphometric description. Analysis will be repeated after charring to test the model's applicability to the most commonly encountered form of archaeobotanical remains. 
Archaeological Application
The modern wheat study will indicate the potential for distinguishing between morphological differences deriving from intra-species variation and those caused by environmental stress. These findings will be applied to archaeobotanical case studies, including early medieval data available via the ongoing 'FeedSax' project. Evidence of landraces and/or growth-stressed grains, when supported by environmental and contextual data, may be used to develop theories on the strategies utilised, and challenges faced, by past farmers. For example, stable isotope values of anomalous types may shed light on conditions in which distinct landraces were grown and/or provide independent confirmation of environmental stress.
More broadly, the research should aid interpretation of morphological anomalies previously observed within the archaeobotanical record, such as 'short-grained' wheat types. Categories of variation could be described and made available to researchers via an open-access platform. This would provide a tool for archaeobotanists to study biodiversity and resilience in past arable systems and inform debates concerning our future food-",1
EP/N011201/1,13061,Structural and Fire Resistance of a Reusable Steel/Concrete Composite Floor System,"One sixth of the world's CO2 emissions from energy and industrial process are released from the production of steel and cement, most of which is used in construction. Although reducing embodied energy in structures is increasingly being considered by structural engineers, it is very difficult to achieve meaningful results with today's construction methods because the different existing mainstream structural systems, whether steel, concrete or composite construction, use similar amounts of virgin materials and have similar embodied energy values. We propose a radically different approach to reduce the environmental impact of construction: by making structural components reusable at the end of life of the structure. This can potentially reduce the use of new materials of a structure by 50%. The concept of reusable structural components has been talked about, but no feasible solution is available. Without making structural components reusable, at the end of life of a building, although all the steel and concrete materials in the building structure remain serviceable, the building is demolished destructively, larger steel elements are recycled by energy-intensive melting, and the rest of the material is landfilled. This approach to construction is clearly wasteful - of energy, emissions and potentially cost. 

This project aims to develop a reusable composite floor system to be used in steel/concrete composite structures. It is important that this method of construction is developed as a mainstream structural engineering solution, rather than limited to very special conditions, so as to maximize the benefits of design and construction of reusable structural components at the end of life. Steel/concrete composite structures are chosen because this building type is the most commonly used in the UK.

The proposed reusable floor system is a totally different form of construction, with new modes of structural behaviour that have not been investigated before. A complete rethink of composite floor structural and fire engineering design is necessary to ensure safety of the proposed floor system. Extensive new physical tests at ambient and elevated temperatures and in fire for the different components of the proposed floor system have been planned to identify the different modes of behaviour and failure of the system. Supplemented by extensive numerical simulations, this project will develop thorough understanding of the structural and fire performance of the new structural system to develop practical design methods. This project will be carried out in collaboration between the Universities of Bradford and Manchester, which have international leading experiences in composite structural behaviour and design at ambient temperature and in fire, and have dedicated and experienced research teams and experimental facilities.

A steering group, consisting of high level representatives from key construction companies, will advise the research teams to ensure practical relevance of the research and to help promote the outcomes of the research. Various impact pathways have been planned, including a dedicated website for the project and APPs for designers, promotion of the research outcome to relevant Eurocode 4 (Eurocode for composite structures) committees (where the two applicants, Professors Lam and Wang, represent the UK for structural safety (Eurocode 4 Part 1.1, or EN 1994-1-1) and fire safety (Eurocode 4 Part 1.2, or EN 1994-1-2)), and a one-day colloquium at the end of the project.",1
NE/R017662/1,23235,How do the P&aacute;ramos store water? The role of plants and people.,"P&aacute;ramos are high mountain grassland-peatland biomes (3000m-4000m) that cover a total area of circa 35700km2. They are crucial for the livelihoods and wellbeing of millions of people living in Colombia and neighbouring Northern Andean countries (Venezuela, Venezuela, Ecuador and Peru). P&aacute;ramos are the main source of water in these regions, are used for crop cultivation and grazing and contain a unique source of untapped genetic diversity. While the P&aacute;ramos have the potential to support, through the exploitation of its biodiversity, local and regional development, the combined pressure of land use and climate change has already degraded many P&aacute;ramo areas and their potential demise is a cause for concern for many, including local communities, regional and national policy and decision makers and researchers in Colombia. All agree that any future exploitation requires a sustainable approach and that the management of these systems should enhance the P&aacute;ramo's resilience to climate change. 
However, there is still very much which is not known about the functioning of the P&aacute;ramos and without this knowledge there is a risk that interventions which are designed to achieve sustainability and enhance resilience are not effective or worse detrimental. P&aacute;ramos are described as sponges that capture and store water from the atmosphere. Few quantitative studies have investigated the mechanisms behind this process and even less is known about the relative role of the plants and the soil of this complex system. Also, P&aacute;ramos are socio-ecological systems that have been shaped by the human populations that have inhabited them over several centuries. This interaction is continuing to date with local communities relying solely on the P&aacute;ramo for their livelihoods.
This interdisciplinary 3 year project aims to, jointly with Colombian collaborators, establish how the diversity of habitats and of plants within the P&aacute;ramos contributes to water regulation, via direct storage in live agetation and via the supply of organic matter in the soil. We will carry out a large field and drone campaign in the Colombian P&aacute;ramo Guantiva-la Rusia to collect and analyse data on plants, soil and hydrology. We will carry out satellite image analysis to map landscape scale land cover and peatland condition and improve models so that they better represent the hydrology of the ecosystem. The project will also identify how local P&aacute;ramo inhabitants, particularly crop and livestock farmers, interact currently with the P&aacute;ramo ecosystem through their day-to-day farming practices. We will invite local people to participate in workshops and storytelling to jointly discover how they understand they are affecting and are affected by the P&aacute;ramos' water regulation. We will, as we learn more about the functioning of the P&aacute;ramo, feedback our findings to the local people and so help them initiate more sustainable solutions.",1
NE/N001435/1,20336,Climate of the LAst Millennium (CLAM): An Integrated Data-Model Approach to Reconstruct and Interpret Annual Variability in North Atlantic Circulation,"The ocean circulation of the North Atlantic is variable and pivotal in controlling regional and global climate. This variability occurs both naturally, and it is anticipated, in response to anthropogenic activity. Internal and forced natural variability in this system has so far largely been characterised in terrestrial archives and models rather than in the real ocean. It is critical that we understand the magnitude, timescale, drivers and impacts of this variability if we are to correctly attribute observed trends in the North Atlantic circulation, and develop robust early warning systems of, and plan adaptation to, future change. In CLAM we aim to utilise a network of robustly calibrated and verified absolutely dated sclerochronological proxy archives from NW Scotland, N. Iceland and the Gulf of Maine, together with high-resolution climate models, to investigate the mechanisms and forcings driving variability in the circulation patterns of the North Atlantic over the last millennium. This proposal is a resubmission (NE/M002160/1, Jan 2014, graded 8) in which we address minor concerns highlighted by the reviewers, notably we: (i) eliminate fieldwork risks - having completed all necessary sample collection using independent funding; (ii) further-demonstrate the powerful nature of the methodologies and potential findings though additional preliminary model-proxy analyses; (iii) greater societal impact via the development of a deeper collaboration with the Met Office Hadley Centre, and (iv) deliver improved value for money, through associated cost savings.",1
NE/R01082X/1,2646,Response of Ecologically-mediated Shallow Intertidal Shores and their Transitions to extreme hydrodynamic forcing in UK settings (RESIST-UK),"Salt marshes exist around the globe on low-lying, low gradient coastal fringes. Amongst providing many services to society (valued at around &pound;1,500 per hectare per year), they are valued for their ability to protect coasts from the erosive force of waves and tides, even during extreme storm surge events. They are, however, nationally and globally in decline. In the UK, the area of salt marsh reduced by 13% between 1945 and 2010 (from 37,300 to 32,500 ha). This loss has not been compensated for through marsh restoration efforts (only 1,320 ha created by 2012). There is high uncertainty as to how these natural coastal protection features (or their artificially restored or re-created equivalents) will respond to the combined effects of future changes in sea level and possible changes in the magnitude and/or frequency of storms.

The grass/shrub covered surfaces of salt marshes appear remarkably resistant to storm impact. Given sufficient sediment supply, they can also 'grow' vertically to track rising sea levels. The loss of marsh area over time is therefore more often due to a landward retreat of their most seaward margin or the lateral widening off the tidal channels that drain them. These boundaries are often undercut, with marsh material loosened and removed by tidal currents and waves. Such retreat may reach several metres per year and is of great concern to coastal engineers, planners, and managers, relying on the 'storm buffering' function of these environments.

We know little about the force required to 'cut into' salt marsh material (the 'substrate'). The substrate itself is composed of sediment laid down over time by the tides, alongside organic materials resulting from plant growth and invertebrates living in the soil. Its resistance to wave or tidal forces therefore varies within and between marshes. But this resistance has not, so far, been measured in a way that allows coastal engineers to take it into account when predicting the impact of future enviromental scenarios (e.g. greater water depths and stronger tidal currents or waves). 

In this project, we will sample and analyse in detail the substrate of a more sandy (Warton, Morecambe Bay) and a more muddy (Dengie, Essex) marsh, as well as of two restored marshes (two East coast managed realignment sites) and their adjacent natural equivalents. We will determine what these substrates are composed of, how this varies between and within each of these marshes and how it affects the resistance of the marsh substrate to wave and tidal forces. State-of-the-art technology (unmanned aerial vehicles (UAVs) or 'drones') and the latest satellite products will then allow us to produce a map of the physical marsh vulnerability of marsh systems, both in their entirety and within marsh, to these types of forces. 

Coastal planners, engineers, and managers will benefit through being able to better predict marsh loss into the future and design suitable preventative measures. Anyone watching our three-part documentary short film series will benefit through a better understanding of the scientific methods we use. The global community already using existing satellite products built into web-based tools for assessing the coastal protection function of salt marshes will benefit by being able to access predictions of the resistance to wave/tide erosion that we will build into those tools.",1
NE/S013237/2,34757,CASCADA: Toxin or Treat?,"The most sensitive glaciers to climate warming in the 21st century are situated in tropical mountain regions, and thus, serve as valuable sentinels of climate change. Most attention to date has focused on the quantity of meltwater released from these glaciers, because of the impact on global sea level and water security. The concurrent changes in water quality are much more poorly constrained, but have implications for drinking water, agriculture and industry. Peru holds 71% of all tropical glaciers, all of which have undergone high rates of mass loss and retreat in the last two decades. However, certain rivers fed by glacial meltwater are becoming acidic, with concentrations of metals often above World Health Organisation standards. This is thought due to the exposure of metal-rich (sulphidic) rocks in retreating glacier forefields, which release sulphuric acid and metals once oxidised - this acidity can no longer be neutralized by the intense chemical weathering which takes place beneath glaciers. 

The overarching hypothesis that CASCADA will test is that glaciated catchments in the Cordillera Blanca are evolving along a trajectory from pristine conditions, where glacial runoff is an important nutrient source for downstream ecosystems (&quot;treat&quot;), to those in which the same runoff is toxic to ecosystems and human health (&quot;toxin&quot;). CASCADA unites Peruvian experts in water resources, glaciology and ecology with UK geochemists, glaciologists and technologists to investigate and generate solutions to the cascading impacts of glacier retreat on water quality in Cordillera Blanca rivers. It employs cutting edge in situ monitoring technologies to capture first time data on the year-round quality of Cordillera Blanca rivers and to develop and test a novel wetland management model to remediate rivers with high metal toxicity. A strong partnership with local water users' committees under a citizen science scheme and the formation of an engagement board with governmental institutions and local communities will ensure capacity building and the transfer of technology for integrated wetland management and water quality reporting. Thus, CASCADA provides the transformative process understanding required to deliver a step jump in our ability to predict water quality evolution in deglaciating terrains and to develop effective solutions to toxic catchments.",1
BB/P022677/1,19870,Genomic approaches to increasing resilience in oilseed rape seedling establishment in the Yangtze River basin,"In China poverty is present predominantly in rural regions where annual incomes still depend heavily on returns from crops. A key cause of poverty is financial stress resulting from poor yields, which increasingly are affected by stochastic occurrence of extreme weather, particularly drought and flooding. The Yangtze River Basin is a globally-significant rapeseed growing area, using so-called semi-winter varieties drilled in the hot and seasonally dry month of September and harvested the following year. Around 14 million hectares are under drought stress (20 times the entire UK planting area), and drought during germination and seedling establishment is particularly detrimental to yields. Climate change is threatening rapeseed growing in the Yangtze River Basin because it is both increasing September temperatures, and increasing the frequency and duration of droughts. These conditions are hostile for seed germination and seedling growth, and can even induce dormancy and prevent germination altogether. To continue cultivation it will therefore be important to produce new varieties with enhanced tolerance to heat and drought stress during germination and early seedling growth.
In the modern genomic era the availability of large genotyped populations is greatly accelerating the process of linking traits to individual genes and markers. The principal bottleneck for gene discovery has become our ability to perform smart high throughput phenotyping under relevant conditions for revealing crop properties. This proposal aims to exploit a new phenotyping platform at JIC which automates seed germination, root and shoot growth measurements and increases the frequency of scoring from the traditional once per day to once per hour. We aim to optimise conditions on the platform to mimic the temperature regime and water potential of the Yangtze River catchment in September and screen oilseed rape varieties for germplasm with enhanced ability to germinate and establish effectively under stressful conditions. We will then use statistical tools to identify genes and markers underlying the beneficial traits, and the identity of these genes will be used to form and test hypotheses for the underlying biological mechanisms. We aim to use one European population and one Chinese population derived from a F1 rapeseed variety developed by our partners in the Oilseed Crop Research Institute (OCRI), Wuhan, that will shortly be released onto the Chinese market. This use of elite close-to-market germplasm maximises our chances of translating initial discoveries into new varieties in the shortest possible time window.
In order to understand whether improved material has a chance of mitigating climate change impacts it is also necessary to produce a theoretical framework that links crop establishment performance to weather variation. To do this we will produce hydrothermal time models of rapeseed establishment, modelling existing varieties and our best germplasm under Chinese conditions and test the models in a set of field trials. This will pave the way for a larger study aiming to understand for how long and under what emissions scenarios rapeseed cultivation can continue with current practises in the Yangtze River Basin.",1
AH/P005063/1,21394,Finding Common Ground,"There are hundreds of community groups across Scotland tackling the climate change and developing sustainability initiatives on a local level. These groups often struggle to establish collaborative partnerships with other groups in the same region, particularly across religious differences. Launched with AHRC/ESRC funding in 2013, the Ancestral Time (AT) project is the most sustained empirical study of religious environmentalism to date. It was precisely with these barriers in mind that we sought to develop a more nuanced account of how and why religious groups mobilise around environmental issues in Scotland. Over the course of conversations with third sector practitioners we became aware that a lack of understanding around possible &quot;common ground&quot; served as a barrier to collaboration between secular and religious community groups on areas of common concern. These groups often have overlapping purposes and stakeholders, but can struggle to bridge differences in language and narrative concerning environmental care. We have also found that there is a significant desire to collaborate with community-level environmental practitioners by major British environmental charities (especially WWF and RSPB), Scottish government agencies and businesses targeting sustainability.

This follow-on project seeks to mobilise the new knowledge generated in the AT project among new audiences. In collaboration with representatives from our project partner Eco-Congregation Scotland, we will seek to address the existing gap in understanding through a series of 7 separate regionally-hosted participatory workshops. Each workshop will draw together representatives in a different region from a range of local community groups for a participatory discussion in the form of &quot;open space&quot; (Owen, 2008; Chambers, 2011). At each workshop representatives from each practitioner group, including Eco-Congregation Scotland will be invited to share the story behind their work. Aspects of group dynamics will be illuminated through brief presentations by project researchers. The overarching goal will be to find common ground, bridging apparent differences and finding common language and strategic goals around which secular and religious groups can cooperate on environmental care. Participants will be invited to work together to identify resources, barriers, and 'shared ground'. The project researcher will keep a record of these discussions in order to generate a series of case studies which can provide the basis for a collaboratively authored summary of best-practices for community-level collaborations on environmental issues in Scotland, highlighting possible ways for secular and religious groups to find 'shared ground'.

The final symposium, to be hosted at the University of Edinburgh, will draw on participants from the seven workshops and the research team to present case studies and best practices to an audience including scholarly researchers, civil servants, local authorities, leaders of environmental charities and representatives from the business sector who provide technology and finance to communities involved in sustainable initiatives. The symposium will emphasize participation and collaboration through select plenary addresses, &quot;open space,&quot; short oral presentations, and world caf&eacute; style discussion. Not only will this project generate new partnerships to address climate change mitigation efforts in Scotitsh communities, but it will also help third sector groups to generate new understanding of roadblocks to collaboration and modes of environmental action which our team will feed back to the research community. By drawing academic practitioners into engagement with well-informed practitioner group representatives we expect to generate a new research nexus between the fields of religious studies, human geography, social anthropology, and sociology around grounded research of grassroots environmental activism in a religious context.",1
NE/R000670/1,18962,The colonisation of hydrothermal vents by complex life: a natural experiment in macroevolution,"Our proposal unites a multidisciplinary team of researchers from mineralogy, palaeontology, deep-sea biology and genetics to provide an integrated picture of when and how some of the most remarkable environments on our planet were colonised by highly-specialised animals, and inform modern deep-sea conservation challenges.

The discovery of hydrothermal vents in the deep sea during the late 1970s revolutionised our understanding of the limits of life on our planet. These explorations uncovered incredibly lush ecosystems supported by chemosynthesis, a carbon-fixation process previously deemed insignificant, and faunas with many novel adaptations to surviving in this dark habitat characterised by the ejection of extremely hot, toxic fluids from the seafloor. Despite their seemingly-hostile conditions, we now know that animals have thrived around vents for at least 440 million years, and that diverse taxonomic lineages have continually adapted to this environment over the course of Earth's history. Surprisingly, rather than functioning as evolutionary refuges in which ancient relict faunas have survived in isolation from large-scale environmental changes, evolution at vents appears to have occurred numerous times. This suggests that vents have an intriguing role as incubators of evolutionary novelty, their importance in evolution also highlighted by theories that life itself originated within this setting.

Since their initial exploration, significant milestones have been achieved in surveying these ecosystems and in understanding the intimate interactions that modern vent faunas have with the microorganisms that support them. However, answers to fundamental questions of when animals first transitioned to occupy this environment, the processes driving the adaptation of new vent animals and the biological basis for vent colonisation are still lacking. A grasp of these principles is vitally important to understanding how animals adapt to unstable temperature regimes, and of how large-scale environmental changes affect the deep sea, the world's largest ecosystem. This is particularly pertinent today as the deep sea is increasingly affected by human activities, but how it responds to impacts such as climate change and mining operations is unknown.

To gain vital evolutionary insights into the colonisation of hydrothermal vents, both in the modern ocean and throughout Earth history, we propose a comprehensive research programme guided by four hypotheses: H1) animals colonised hydrothermal vent environments soon after the Cambrian Explosion of life; H2) new vent habitat formation has repeatedly driven vent animal evolution over time; H3) ancient vent animals exhibited similar associations with microorganisms to modern vent animals to survive within harsh vent environments; and H4) adaptation to vent environmental regimes is evolutionarily rapid.

We will assemble primary data for this project from field studies of key geological localities in Norway, Canada and Tasmania, which likely contain the oldest known bone-fide vent animals, and the southern Ural Mountains where a remarkable 100 million year fossil history of ancient vents is preserved. Together, these regions contain some of the best-preserved ancient hydrothermal vent deposits in the world. Collected fossil samples will be subjected to new detailed palaeontological investigations, and high resolution sulphur isotopic analyses. To investigate recent and ongoing adaptation at modern hydrothermal vents we will work on samples of traditional non-vent fauna that we can observe colonising new hydrothermal systems, using advanced DNA techniques.",1
ES/S006761/1,37186,Developing co-created smart city solutions for managed adaptation and monitoring of hydro-meteorological climate change related risk in Mexico,"The sharp growth of Latin American cities in the last decades has led to an increase of vulnerable communities in informal settlements on land exposed to hazards. These are affected by climate change-related risks such as changes in surface, temperature, droughts, flooding, and more aggressive hurricanes, heightening the need to improve the resilience of such communities. Diseases associated with new atmospheric conditions are some of the consequences, further increasing the displacement of people towards cities. As urban areas expand, current levels of vulnerability, socio-spatial segregation and inequality are aggravated by an increasing demand of housing. In order to reduce disasters it is essential to develop innovative, co-created strategies for managing risk and increase resilience. 'Smart city' approaches offer an integrative perspective, establishing the potential for emerging collaboration between city governments and technology contractors. However, these technological solutions tend to be dependent with top-down ideas, which do not necessarily take into account the needs of, or benefit for people living in poor informal communities. Those challenges that 'smart cities approaches' are faced with reflect a need for context-specific strategies and solutions that respond to the needs of the most vulnerable. Therefore, the aim of this project is to enable city communities to monitor and mitigate climate change-related risks as well as enable communities to develop strategies to adapt to those risks through the co-creation of local, bottom-up initiatives using smart-city solutions.

The project will develop an interactive networking smart-technology, enabling city-communities to share best practice on monitoring climate change-related challenges, and to allow them to create solutions that enhance managed adaptation, in close collaboration with local and national institutions, and other relevant stakeholders. The research is structured around three work packages aimed to address the following questions: (i) how do local communities and local institutions perceive and adapt to climate change-related risks and what are the roles of private and public sector organisations in taking adaptive action? (ii) how could a co-created smart-technology help communities to monitor and adapt to these climate change risks? (iii) how can this technology, using community knowledge and experience, help create and influence climate change-related local and national policies?

The research will focus on a pilot case study in M&eacute;xico City (Pen&oacute;n neighbourhood), where a traditional community is confronting flooding risk challenges. Using focus groups and semi-structured interviews, the research will implement an interactive dialogue between community members, government institutions, as well as NGOs and other stakeholders, including support agencies, and private businesses. This dialogue will result in the development of risk-mitigating strategies and actions, including smart technologies, which will be tested over the project, in order to evaluate pilot experiences and upscale these into a larger city area. Lessons learnt about risk management in Mexico City have the potential to be easily disseminated across the developing world.

Communities will be empowered through engaging in identifying, developing and testing strategies for risk-monitoring, mitigation and adaptation. The social, economic and political aspects of impacted communities, as well as an understanding the the physical origins of climate change risks, will contribute to developing resilience and prevent the consequences of exposure to hazards. Finally, considering both the macro-scale and the local scale, understanding that change can emerge in collaboration with local communities and policy makers, the project will provide, along with best community practices, opportunities for interaction and negotiation between actors for increasing resilience and reducing vulnerability.",1
NE/S015833/1,46639,Quinquennial (half-decadal) carbon and nutrient dynamics in temperate forests: Implications for carbon sequestration in a high carbon dioxide world,"Having more carbon dioxide (CO2) in the atmosphere has increased rates of photosynthesis, promoting greater tree growth and carbon storage in forests. This process is called 'CO2 fertilisation' and results in 2-3 billion tonnes of carbon being removed from the atmosphere each year, which is 25-30% of the carbon put into the atmosphere by human activity annually. CO2 fertilisation, thus, greatly reduces rates of global warming. 

The fight against climate change relies on CO2 fertilisation continuing into the future; the Paris climate agreement emphasises that global efforts are required to limit the amount of carbon we release to that which trees, soil, and oceans can absorb naturally. Increased carbon storage in mature forests, due to CO2 fertilisation, is considered to be the most important reason for the current carbon uptake. But, looking forward, it is highly uncertain whether such high rates of uptake will continue, because the production of plant biomass also requires the uptake of nutrients from soils. The availability of key nutrients (especially nitrogen and phosphorus) may severely limit the ability of trees in mature forests to continue to grow more rapidly. 

Studying mature forests is particularly important when determining whether nutrient availability may limit future carbon uptake by land ecosystems. Firstly, as discussed above, mature forests are likely the most important absorbers of carbon on land; secondly, nutrient availability is generally low in mature forests because the roots of mature trees may have already fully explored their soils in their search for key nutrients. If mature forests are unable to access more nutrients in the future and maintain their carbon uptake, then this would have major implications for our society. It would mean that we would have to reduce our carbon dioxide emissions by a greater extent, and more rapidly than currently expected, if we are to avoid the most serious consequences of climate change. 

Temperate forests currently absorb almost as much carbon as the emissions from all EU nations. While tropical rainforests are, of course, important, mature temperate forests are calculated to be fourfold more efficient at absorbing carbon, and so merit special attention. To be able predict how mature temperate forests will respond in the future, it is critical that we determine whether greater carbon dioxide concentrations in the atmosphere will allow mature trees in temperate forest to:

1) take up more nutrients from soils, and/or,
2) increase the efficiency with which they use available nutrients to produce new plant tissue.

Manipulating CO2 for whole stands of mature forest is challenging and expensive, and until now there has been no experiment that would have allowed us to address the uncertainties discussed above. All this has changed with the establishment of a new experimental facility in mature oak forest in central England. Leveraging a &pound;15m philanthropic gift and an equivalent University of Birmingham investment, a whole-ecosystem free-air carbon dioxide enrichment (FACE) experiment has been set-up, which is successfully forest patches to CO2 concentrations more than one third higher than current levels. In the FACE ecosystem, the canopy trees are at least 160 years old and the site has been forested for the last 400 years. 

QUINTUS aims to carry out the detailed measurements of nutrient cycling (more than 20,000 analyses) that are required to answer the two key processes outlined above and, thus, determine how a mature temperate forest responds to rising atmospheric CO2. This new experimental understanding will then be used to develop and test the next generation of the computer models which are used to predict future rates of climate change. QUINTUS will deliver a foundational change in our understanding of future C uptake in temperate forests, and in mature forests generally. Such an advance is urgently required and has major societal relevance.",1
NE/R016704/1,21023,TerraMaris: The Maritime Continent - Driver of the Global Climate System,"The Maritime Continent (MC) is the archipelago of tropical islands that lies between the Indian and Pacific Oceans, with a population of over 400 million. It comprises large (Sumatra, Java, Borneo, and New Guinea) and many smaller islands, with high mountains. High solar input warms the surrounding seas, which supply an abundance of moisture to the atmosphere, turning the whole region into an atmospheric &quot;boiler box&quot;. Deep convective clouds rise up over the islands every day, leading to average rainfall rates in excess of 10 mm per day, approximately three times the rainfall rate over the UK. As well as supplying local agriculture, rain that falls over the MC has a far-reaching, global effect on weather and climate. Tremendous heat energy is released by condensation into the atmosphere in these convective clouds. This heat source drives giant, overturning circulations in the atmosphere: the Hadley and Walker cells, which feed into the jet streams and lead to weather and climate changes far downstream, even over the UK. For example, the origins of the infamous cold winter of 1962/63 and the recent very cold March of 2013 have been traced to atmospheric convection over the MC. For these reasons, the MC has been described as the engine room of the global climate system.

Due to the complex nature of the distribution of the islands, and fundamental inadequacies in current models of the atmosphere (mainly related to their representation of convection), both climate predictions and weather forecasts show serious errors over the MC, particularly in their simulation of rainfall. Up until now, these errors have been extremely difficult to address, as there has been a lack of suitable observations over this region. Computing power, and the atmospheric modelling expertise to harness the advances in computing resources, has been inadequate to run computer models with sufficient detail to resolve the convective processes and their interactions, which are the building blocks of atmospheric circulation, for long enough to allow interactions with larger scales.

However, we now stand on the cusp of transforming our understanding of atmospheric processes over the MC. Computer power and modelling expertise have progressed to the point where we have the capability to run simulations of the atmosphere at sufficient resolution to accurately capture the complex distribution of islands, and to accurately model the convective processes themselves. In response to this, the international Years of the Maritime Continent (YMC) field experiment (2017-2020) will make the measurements of the atmosphere and ocean at the very small scales that are needed to evaluate and understand the outputs of these new model simulations. 

Through TerraMaris the UK will take a leading role in YMC, by making observations of convective processes over the MC using the UK meteorological research aircraft, atmospheric radars, balloon and land-based measurements on the islands, and observing the surrounding seas using autonomous underwater and surface vehicles. This unprecedented suite of coordinated observations will complement measurements being taken by our international partners. The UK and the TerraMaris research team has led the way in developing high-resolution atmospheric modelling over recent years. We will apply the skills and knowledge learned to understand the complex mechanisms behind the multiple scales of convection and atmospheric circulations that have made the weather over the MC such a tough problem to crack. This knowledge will enable ground-breaking advances in atmospheric modelling, to improve weather forecasts and climate prediction over the MC region, with direct benefit to the substantial regional population. The downstream effects will see these benefits extend to the far corners of the globe, improving global and regional medium-range weather prediction, and climate projections.",1
NE/N010027/1,32837,Characterising the Ice Shelf/Ocean Boundary Layer,"Global average sea level is rising by approximately 3 millimetres per year. Given the huge economic and societal impacts of this change, accurate forecasts of sea level are urgently needed to inform policymakers considering mitigation and adaptation strategies. Melting of the ice sheets of Antarctica and Greenland currently contributes about one third of sea level rise. The future of this melting is highly uncertain, and the worst-case scenario involves a substantial ice-sheet contribution to dangerous sea-level rise. 

The largest contribution to sea level rise from ice sheets occurs when the ocean melts the base of ice shelves (floating extensions of the grounded ice sheet). The melt rate of ice in seawater is determined by the transfer of heat and salt from the ocean towards the ice. Observations reveal a turbulent boundary layer in the ocean beneath ice shelves, where vigorous mixing is driven by the flow of rising meltwater, large-scale circulation in the ocean, and tides. Mixing of heat and salt in the boundary layer influences the ice melt rate, but the physical processes involved are poorly understood and will not be resolved in climate models for the foreseeable future. The proposed project will improve our understanding of the ice shelf/ocean boundary layer and develop improved representations of ice-shelf melting for use in climate models.

To achieve these aims we will use a suite of numerical models and the latest observations. We will start with direct numerical simulations (DNS) to model a small box of ocean next to an ice shelf (~1 cubic metre) at ultra-high resolution (~1 millimetre). This will provide insight into the turbulence near the ice and its interaction with melting. We will then use large-eddy simulations (LES) to study a larger volume (~1 square kilometre in area by 100 metres height) at high resolution (~10 centimetres - 1 metre). This will resolve the largest turbulent motions in the whole boundary layer. Both models will be validated using recent observations obtained from mooring sites at the George VI and Larsen C ice shelves (Nicholls, NE/H009205/1). The model results will in turn help interpret and understand the observations.

We will use these numerical models to devise and calibrate parameterisations for ice melting and vertical mixing for use in ocean climate models. We will add candidate parameterisations to a one-dimensional (vertical) model that incorporates many popular ocean mixing schemes, and test them directly against the DNS and LES results. We will begin with existing parameterisations and modify them as needed to match the high resolution models. The successful parameterisations will be implemented in the UK ocean model (NEMO) and shared with climate modelling groups (including the Met Office) to improve predictions of sea-level rise.",1
102347,6272,Community Action Platform for Energy (CAPE),"SmartKlub and its collaborators will develop a free to use tool 窶廚ommunity Action Platform for Energy窶・(CAPE) in order to make it easy for communities and local suppliers to procure and supply energy efficiency or distributed energy projects at scale. CAPE combines various data sets, including satellite, energy and social information so that communities identify opportunities of highest need and impact for councils and community groups to act upon. By doing this, expertise and scale are socialised to allow citizens to address fuel poverty and sustainability goals without needing to become a lone expert, in order to successfully join the energy revolution. Suppliers (especially local companies with local know how) can then engage with a much larger group of customers with aligned needs, many times more cost effectively, without having to undertake mass marketing that has thus far failed. Suppliers simply pay a commission to access readymade projects. SmartKlub窶冱 ambition is that CAPE allows many cities to scale community energy measures at a significant scale in order to achieve a tipping point in social energy objectives like fuel poverty and climate change.",1
NE/R013578/1,11760,Droplet microfluidic based sensors for high resolution chemical sensing on autonomous underwater vehicles,"Chemical processes within the oceans underpin the planet's natural cycles of life. Marine ecology, for example, depends on where and in what quantity nutrients (such as nitrate and phosphate) are transported, as these constitute the ultimate base of the food chain. The oceans are also in dynamic equilibrium with the atmosphere and are intrinsic to how the world will adjust to the effects of anthropogenic carbon dioxide. Thus better understanding of oceanic chemical dynamics is not only of academic interest, but will also lead to better protection of marine life and improved models to understand and predict climatic change.

To properly understand ocean chemistry, however, we must be able to accurately measure the temporal and spatial distributions of chemical species within the environment and how they change in response to different stimuli. The vastness of the oceans provides a logistical problem however - how can we possibly characterise such a large and complex body of water? One compelling answer to this is to employ autonomous underwater vehicles (AUVs) equipped with chemical sensors. AUVs can travel to remote locations for months at a time without need of human interaction and as such offer a highly efficient way to gather information about the chemical dynamics of the ocean.

The current state-of-the-art chemical sensors (which automatically sample and analyse the water using miniaturised laboratory assays) provide superlative analytical performance (accuracy, precision, sensitivity) but suffer from inefficient use of resources (power, fluid) and low measurement frequencies - limiting their applicability to AUVs. In response to this, during this fellowship I will develop a new type of chemical sensor based around droplet microfluidics. Droplet microfluidics involves the generation, manipulation and measurement of discrete droplets of water dispersed within a stream of oil flowing along tubing hundreds of microns in width. As the droplet volumes are so small (sub-microlitre), chemical treatments and measurements can be quickly and precisely performed, meaning droplet microfluidics offers a rapid and highly efficient route to continuous sampling and chemical analysis of the environment.

While droplet microfluidics is a proven and widely used tool for laboratory-based analytical chemistry, it is only now making its way into the first field-deployable devices. In this fellowship I will drive improvements in the sensitivity, measurement frequency and applicability of field-deployable droplet microfluidics to develop droplet microfluidic sensors suitable for use on AUVs. The sensors will be highly efficient (low power and fluid use), capable of measuring several different chemical parameters with high sensitivity (meaning they can be used in a wide range of marine environments) and at high measurement frequencies (which translates into richly detailed spatial data when used on moving vehicles). This project will be a key step towards the widespread, routine usage of sensors to monitor chemical change in the marine environment, in particular on AUVs. It will lead to chemical sensors being a ubiquitous tool in environmental science in the future, eventually deployed in large volumes throughout the oceans on static moorings and ocean-going autonomous vehicles.",1
BB/P022847/1,7388,Moringa; delivering nutrition and economic value to the people of Malawi,"Lack of adequate nutrition in Malawi is a critical concern and without intervention, the provision of adequate food is an unachievable outcome. Malawi also faces significant challenges in establishing and operating a food and nutrition security programme. Our innovative solution is to establish production of a high-protein, micronutrient rich crop (Moringa oleifera), which will be locally grown by smallholder farmers, and processed on-site to supply Malawi's proposed scaled-up nutrition programmes. This project will not only contribute towards nutritional security for the poorest and most vulnerable in Malawi, but will deliver recognised additional economic benefits through two commercialisation opportunities; provision of functional plant-based protein isolates as an increasingly desirable food ingredient for local and export markets and scientifically-evaluated fair-trade products to enter the growing international market for nutraceuticals. We have partnered with Africa Growing plc who have provided significant investment in proof-of-concept Moringa plantations in Malawi since 2011. Strong networks and collaboration agreements are in place with the National Farmers' Association (100,000 members), which will help sustain local economies. Contract growing by smallholder farmers ensures the benefits cascade down to the rural population, providing a product grown in Malawi, processed in Malawi for the people of Malawi. 

Moringa is widely regarded as a 'miracle tree' it has been described by many as 'a nutritional and medicinal cornucopia' and all parts of the plant are edible. Our preliminary data has shown that Moringa leaves, which can be repeatedly and sustainably and cropped are high in protein (28%) and fibre (14%). The commercial source analysed was found to be extremely rich in beneficial bioactive constituents considered to contribute towards prevention of life-style-related diseases (type-2-diabetes, cardiovascular disease and cancer), as well as important micronutrients. Moringa performs well in less-fertile soils and being drought resistant and perennial is likely to be more resistant to climatic change. Additionally, sequestration of CO2 will contribute to climate change mitigation. This proposal will evaluate the nutritional and economic value of Moringa grown in Malawi. We will assess the nutritional composition, grown across several sites in terms of its potential to contribute towards meeting the nutritional requirements of vulnerable groups. With 47% of children stunted, infant mortality at 11.2% (live births under five) and maternal mortality (675 per 100,000 births) one of the highest in the world, young children and expectant mothers are an important target group. HIV/AIDS sufferers also benefit from improved nutrition, as efficacy of current anti-retro viral drugs require a nutritious and balanced diet. We will compare Moringa to the supplemental formula adopted by the World Food Programme, which is currently imported from multinational chemical companies. This will be evaluated in human dietary intervention, providing evidence beyond that of product labelling. The project will identify additional economic opportunities for Malawi by exploring the development of novel GM-free, protein-rich functional food products and fair-trade scientifically evaluated nutraceuticals, both of which are highly desirable in growing international food and health markets. This will lead to greater empowerment of the country, enabling it to influence its own nutritional and economic future. There is also potential to expand the project into other LMICs where severe malnutrition is a concern. Additionally, it will strengthen the UK research base, allowing researchers working in nutrition and food formulation to benefit from working in a socioeconomic setting, identifying barriers to effective translation and establishing connections with academics, government and non-government organisations in Malawi.",1
NE/S005137/2,39416,LOCKED UP: The role of biotic and abiotic interactions in the stabilisation and persistence of soil organic carbon,"Loss of soil organic carbon (SOC) through human land use is one of the most pressing environmental challenges of the 21st century. SOC loss contributes to climate change, makes soils less suitable for crops, reduces soil fertility through associated loss of nitrogen (N) and phosphorous (P) as plant nutrients, and reduces water holding capacity and drainage to aquifers - adversely impacting drought and flood resistance, water quality and water availability. The international initiative &quot;4 per mille&quot; addresses the threat of SOC loss to food security, climate regulation and water resources and aims to reverse global SOC losses through sustained, incremental (e.g. 0.4 % per year) increases. 

Our research project aims to transform fundamental knowledge of the processes and mechanisms of SOC production and persistence in soil to inform land management innovation, and quantify the capacity and time scale to increase persistent - i.e. &quot;LOCKED UP&quot; - SOC stocks. Our hypothesis is that persistent SOC is produced by a series of complex but testable interactions between soil microbes and soil minerals: 1) relatively rapid microbial transformation of plant biomass input to soil, which produces; 2) specific classes of SOC compounds including extracellular products and components of dead cells that are essential precursors to persistent forms, which are then 3) stabilised against microbial degradation through chemical sorption to soil minerals, which can remove SOC from the microbially accessible C pool; and 4) physically protected against microbial degradation through aggregation of soil particles and soil organic matter, where SOC is protected from microbial degradation in inter and intraparticle pore spaces. 

Our approach is to undertake linked laboratory studies, field sampling and modelling to obtain fundamental knowledge of key functional groups of soil microbes, the microbial operations and their rates which transform SOC to forms which then persist with minerals and within mineral aggregates; and to quantify how these transformations and persistent forms respond to changing environmental factors - plant input C:N ratios, water stress, indigenous microbial community composition, redox status, ionic composition and nutrient status of pore waters, temperature, and physical disturbance. The complex and interactive stages of forming persistent SOC will be quantified in stages, in model systems of microbial cultures, aqueous media and selected minerals in built and real soil matrices, as an idealised and experimentally tractable representation of the soil environment. In multi-factorial experiments that account for the range of environmental conditions, we will quantify rate laws and constants for SOC transformations based on first principles of mass balance, biological growth, chemical mass action and physical-chemical colloid interactions. The results will be implemented into an existing soil process model. This advance in mechanistic knowledge will allow us to build model simulations from a strong first principles understanding of the SOC transformation dynamics and resulting changes in soil structure and bulk properties. We will test these advances against independent data from manipulation experiments on whole soil cores from agricultural sites. Manipulation of additional soil cores - obtained from selected soil types and biomes to reflect specific regions and land uses around the world - will be carried out with application of the mechanistic soil process model. The experimental and model results will be used to assess - for key soil types, climate regions and land uses - the potential maximum, time scale and persistence of SOC that can be obtained from hypothesised land-use practices to increase stocks of persistent SOC - e.g. by changing tillage practices, vegetation cover and water management.",1
BB/M018466/1,6687,FACCE ERA-NET+ An integrated approach to evaluate and utilise genetic diversity for breeding climate-resilient barley,"ClimBar will identify genome regions, genes, and alleles conferring the traits needed to breed resilient barley varieties adapted to the climatic conditions predicted for 2070 in different European environments. Predicted conditions and adaptive plant traits for the northern Mediterranean Basin are also applicable to the southern, non-European side and will be relevant to Stakeholders representing farmers from that region. The phenotypic responses of a tailored barley germplasm diversity set that is relevant to resilience, sustainability, and quality will be determined under anticipated conditions of altered water and nutrients, CO2, and pathogen pressure. The set will include cultivated barley, landraces from key European production regions differing in aridity and pre-figuring climate change effects, and wild barley from the Fertile Crescent, which represents the gene pool from which domestication occurred and also carries resilience adaptations. These responses will be connected to genes and genome regions by Genome Wide Association Studies (GWAS) using extensive sequence variant, epigenome, and transcript abundance datasets, and by ecogeographic analysis. The genetic and genomic data sets will be leveraged from earlier (barley 9K SNP set; exome capture) and ongoing (WHEALBI exome capture) studies, which will serve to define the germplasm included in WP1, and will be complemented by planned ClimBar studies (ChIP, small RNA). Therefore, a very large amount of mostly transcribed sequence information will be available to declare and use polymorphisms with a density of coverage and representativeness of germplasm exceeding all previous efforts in this species. Plant phenotyping will be carried out under field conditions within regions expected to experience differing climate change scenarios, and under controlled greenhouse conditions where detailed physiological phenotypes will be collected. Genes and landraces and CWR associated with environmental conditions will be identified by ecogeographic analysis of genetic diversity. Based on observed plant responses and predicted climate scenarios, proposals for genomic selection (GS) and ideotype models for 2070 will be developed, and relevance to interim conditions assessed. Collaborative interactions with agro-economic modellers as well as climatic modellers will set up to estimate harvests in 2070 and their impact on the agro-economy, based on data collected within ClimBar",1
NE/S002545/1,13192,MOSAiC: Floe-scale observation and quantification of Arctic sea ice breakup and floe size during the autumn-to-summer transition (MOSAiCFSD),"This project investigates multi-scale sea ice processes in the so-called marginal ice zone (MIZ), a region in the Arctic Ocean typically consisting of small, discrete ice floes in summer. This MIZ is very dynamic, easily affected by waves and wind, which enhances the heat and momentum exchanges between ocean and atmosphere. This dynamic MIZ has been grown during past decades, and is projected to grow to an even greater extent (almost all sea ice cover becoming the MIZ by 2080). 

The very inherent process within this expanding MIZ is sea ice freeze-up, deformation, spring breakup and summer melt. In autumn, open water and ice floes survived the summer melt consolidate to form a continuous sheet of winter ice that contains a mixture of multiyear ice (from last summer), first-year (grown from autumn) and newly formed ice (grown later season). This winter ice is then deformed and fractured to form leads/cracks or ridges. In spring, this winter ice breaks apart into small discrete floes, which will be further broken apart or melt in summer. We hypothesize that this seasonal evolution of ice floes is linked and should be understood to improve sea ice-ocean/climate model prediction. 

In this project, we aim to generate new observational data and understanding of this seasonal evolution of ice floes, at the year-long MOSAiC drifting station. For this, we will conduct small-scale (below 2 km) observation of sea ice freeze-up, deformation, spring breakup and summer melt using a combination of high-precisions GNSS buoys, drifters and airborne/satellite observations. This small-scale observational data will be combined with large-scale observation of deformation (above 2 km), ice types/features and floe size, forming a unique multi-scale data set, which will provide a comprehensive picture of the seasonal of ice floes. We will also explore the possibility to incorporate the generated data set into specific models to measure and demonstrate the impact of our process study. 

The data set and knowledge gained from this project will enable modelling communities to develop, calibrate and validate their new/existing model parameterisations of sea ice-ocean and climate models, thus improving climate projection in the Arctic and providing improved advice to national and international governing bodies for climate change issues.",1
752817,1517,Streamlined Production Process,"As a food food manufacturer, the business is currently facing tensions between ensuring food safety (e.g. via packaging or chilling) and reducing environmental impacts (e.g. packaging, energy use and greenhouse gas emissions). Expert advice is required with enabling more innovation within the company through reducing energy usage, followed by waste prevention, recycling and disposal. Advice is needed with developing new resource efficient processes and setting the standard for the industry.",1
NE/N016394/1,19191,Sustaining Himalayan Water Resources in a Changing Climate (SusHi-Wat),"In this project, we propose to investigate how water is stored in, and moves through, a Himalayan river system (the inter-linked Beas and Sutjej catchments) in northern India at daily to decadal timescales and to use the resulting insights to develop and test a robust model of the whole system that can be used to inform current and future decision making to support the sustainable development and management of the region's water resources. Building on the success of the MICCI project (within the Changing Water Cycle - South Asia programme) in the region, the project will address user requirements centred on understanding and managing the effects of climatological and hydrological variability and socio-economic development on delivery of critical ecosystems services, notably the irrigation water supply-hydropower generation-flood risk management nexus.
A combination of state-of-the-art modelling, field studies, satellite-based remote sensing and observation will be developed to improve the process-based understanding of Himalayan water resources availability and quality, considering meteorology, surface-water, groundwater, seasonal snow, permanent snow/ice, soil and vegetation. These stores and flows will be considered within a 'whole-system' framework that explicitly recognises their inter-dependencies and interactions.
The improved understanding will be used to set-up, calibrate and validate a robust system model of the river basins using the widely used Water Evaluation And Planning (WEAP) software system. This model will integrate both 'natural' catchment processes and human modifications of the river basin system into account. These latter include irrigation, hydropower generation, and inter-basin water transfers. The whole system model will be used to understand how the impact of climate change, land-use change and population growth will affect water resources (including flood risk management), water demand (irrigation and public water demand) and inter-sectoral competition for water supply (for water transfers, irrigation and hydropower) through their interactions with the hydrological cycle. The results will be used to inform decision-making and support the sustainable development of India's water resources and hence long-term socio-economic growth
The project will involve collaboration between internationally-leading scientists at 4 Indian institutions (IIT-Roorkee; NIT- Hamirpur, National Institute of Hydrology-Roorkee and the Indian Institute of Science- Bangalore), 2 UK Universities (Heriot-Watt University and Cranfield University) and one UK research institute (British Antarctic Survey). It will build on an existing and thriving collaboration between many of the UK and Indian partners. We will work with key regional and national stakeholders in India (farmers, agricultural advisers, river basin management board and the national farmers association) to ensure the relevance and impact of the research.",1
BB/M025047/1,8457,Bilateral NSF/BIO-BBSRC - Translational landscape to link cell growth with proliferation in the root meristem,"Our life depends on growing plants. Projected population increases together with anticipated disruptions to agricultural production by climate change create a pressing need to achieve step-change improvements in agricultural production to guarantee security of global food supplies. Increases in the application of nitrogen fertilizers underpinned the &quot;green revolution&quot; but are unsustainable. Work described in this proposal will contribute to an alternative route to increased agricultural production, which could be described as a &quot;second green revolution&quot;. According to this strategy, agricultural productivity is increased through use of crops in which growth responses are optimized to sustain the increase in biomass in what would otherwise be limiting environments. Plant growth fundamentally depends on maintaining growth and proliferation of cells, which occurs in the meristems. The rate of cell production must be aligned with developmental cues, available energy, nutrient supplies and environmental conditions. Cytoplasmic growth in meristematic cells is largely constrained by protein synthesis and is coupled to cell division to maintain cell size homeostasis. There are evolutionarily conserved sensing and intracellular signalling mechanisms that inform cells on the available nutrient supply. Central to this is the so called TARGET OF RAPAMYCIN (TOR) protein, so named after an antifungal compound produced by a bacterium that was discovered in the Easter Island, Rapa Nui. TOR is central for cell growth mainly through the regulation of protein synthesis and connecting protein synthesis and cell proliferation, but these regulatory mechanisms are not well understood in plant cells. TOR is a master regulator and also functions through other output pathways. One main route of TOR function is through stimulating ribosomes to increase the translational capacity of cells for protein synthesis. Recent findings unexpectedly show that a canonical ribosomal protein target also functions as a transcriptional regulator (repressor). We found that this is in association with a key controller of the cell cycle, the RETINOBLASTOMA RELATED (RBR) protein, named after the cancer in the eye when mutated in humans. RBR and its partner proteins are thought to constitute a switch that controls cell proliferation and cell growth and can be flicked by environmental conditions. In this project we shall use root meristematic cells to systematically uncover transcriptionally and translationally regulated genes that function to connect cell growth and proliferation. We will then design experiments through which we can precisely observe the molecular behaviour of the components of the switch in time, as we alter the growth conditions, while at the same time following changes in growth through microscopic movies. These types of experiments will produce a wealth of data that allow building a comprehensive knowledge of the regulatory network. With additional help from carefully optimized computer models, we can learn the functioning of this cellular decision making circuitry and make predictions at different environmental and nutrient conditions what is the extent of cell proliferation and therefore root growth. Having achieved to construct such a predictive model we will test its performance in different real life situations, such as what happens to root growth in dark, or under limited nitrate or sucrose. We might also find that we missed some components, and this will prompt us for further experimentation. Having perfected the model we can start adapting it to other growth-altering conditions, such as stress, or to other parts of the plant important for crop yield, such as fruits or seeds.",1
NE/T002263/1,44498,Collaborative Research: NSFGEO-NERC: Aeolian dust responses to regional ecosystem change,"Overview: The proposed research will establish dust emission responses to regional ecosystem change across North America due to three disturbance regimes: 1) numerous discrete, small scale (&lt;10 ha), abrupt ecosystem changes associated with energy (oil and gas) development; 2) discrete, large scale (&gt;1000 ha), abrupt ecosystem change associated with fire and ecological feedbacks that promote invasive grasses and altered fire-wind erosion regimes; and 3) diffuse, large scale (&gt;1000 ha), pervasive ecosystem changes associated with sustained shrub invasion of desert grasslands. New dust emission models driven by remote-sensing and broad-scale standardized ecological datasets will be used to resolve the mechanics of soil and vegetation-aeolian transport interactions. The models will be calibrated using data from National Wind Erosion Research Network observatory sites, then applied to explore patterns of dust emission across the study regions. National ecological datasets will be used to analyze the drivers and interpret dust emission responses to regional ecosystem changes across the disturbance regimes. 

Intellectual Merit: This proposal examines the geomorphic mechanisms and impacts of regional ecosystem change (land use and land cover change) on the magnitude of North American dust emission. Dust originating from North American deserts is regionally important for its profound impacts on human health and transportation systems, water resources, agricultural production, and its feedbacks to biogeochemical cycling and climate. Dust source regions are experiencing changes in ecosystem structure and function due to drought, land use and management pressures, and climate change. Plot-scale research has explored the interactions between vegetation change and aeolian processes in drylands. However, the significance of ecosystem changes for current and future regional dust emissions has not been established over large areas. This research will transform our understanding of how different types of ecosystem change due to human land-use pressures and natural disturbances impact regional dust emissions. Findings will significantly improve our understanding of the coupling between the dust cycle and anthropogenic drivers of ecosystem change.",1
NE/P011098/1,28005,NSFDEB-NERC:Mycorrhizal drivers of SOM formation and decomposition,"Soils in natural temperate ecosystems store substantial amounts of carbon in the form of soil organic matter. This represents a vital service by these ecosystems (including forest, grasslands as well as wetlands), as these organic matter reservoirs have been built up from decaying vegetation that previously fixed carbon in its biomass from atmospheric CO2. There is significant uncertainty regarding the persistence of this reservoir of carbon in soils, both from climatic influences and changes in land use. 

The influence of temperature on the formation of plant biomass as well as decay processes are well researched, but have so far been largely considered separately. More recently, it has emerged that fundamental differences in the way in which vegetation interacts with microbial organisms in the soil have significant impact on the storage of carbon in soil organic matter. The symbiotic relationship of plants with particular forms of fungi (mycorrhizas) is of particular interest. The role of these fungi in the supply of nutrients to plants is well established, but recent findings highlight important influences of these organisms also on the formation and decomposition of organic matter. Changes in vegetation form can drastically influence the type of fungal (i.e. mycorrhizal) diversity in the soil, with direct implications for organic matter formation and decay. However, the interaction between vegetation form, fungal association and soil organic matter storage has not been investigated systematically.

This research addresses the way in which changes in vegetation that also alter the type of mycorrhizal fungal association results in changes in organic matter storage. Specifically, we will investigate a switch from grasslands to coniferous forests. This kind of vegetation change is relatively common in temperate regions due to an encroachment of trees near treelines, following a warming climate, and managed land use changes where upland pasture may be planted with commercial forestry or for 'rewilding' efforts. Our methodology combines experimental decomposition studies with ecosystem model development to enable a new generation of predictive models (based on existing modelling tools) able to incorporate plant-microbial interactions. Land managers and policy makers alike require a full understanding of the consequences of this kind of vegetation change on soil carbon storage, as apparent benefits in carbon uptake by vegetation may be annulled by corresponding losses in storage within the soil.",1
NE/T004169/1,43392,Issues of Uncertainty and Scale in Derived Products,"When deciding how land should be utilised, planners require information about the status of that land and its relative suitability for different uses. For instance, planners might wish to compare the value of land for agricultural production (which might be determined from soil properties), for resource extraction (which might be determined from mineral resource information) and for housing (which will require information about flood and subsistence risk and the suitability of the land for building). The information required to make these assessments is often provided as spatial data products in which the relevant environmental property (e.g. soil pH or flood risk rating) is estimated on the nodes of a spatial-grid which covers the relevant landscape. 

These spatial data products are derived from the data and models which are available for the landscape under consideration. A soil pH spatial product might be produced by interpolation of the pH values that were measured in a soil survey of the region. Alternatively, a mathematical model that integrates information about climate, topography and drainage might be used to determine the flood risk.

This project addresses two problems in such use of spatial data products. First, the planners are unlikely to be aware of or account for the uncertainty that is associated with the product. Some uncertainty will almost inevitably arise because it is rarely possible to measure at every relevant location. Second, the spatial product describes the expected value of the environmental property for a specific spatial scale and this might not be the scale at which information is required. For instance, in a mineral resource product, the horizontal scale of the estimates might correspond to the diameter of the boreholes in which the mineral concentrations were measured. However, planners might be interested in the mineral concentrations at a spatial scale equal to the size of a quarry. These issues propagate further if a spatial data product is used as an input to a mathematical or empirical model that leads to a further data product especially if the model has been designed to relate environmental properties at a scale which is inconsistent with the data products.

In this project we will consider strategies for minimising, quantifying and communicating the uncertainty and scale related issues of spatial data products. We will relate these issues to two pertinent data sets regarding the carbon content of UK soils. We will determine how a spatial survey of such data might be cost-effectively designed to yield accurate estimates of the property of interest at different spatial scales. We will develop a statistical algorithm that can use the data that result from such a survey to produce data products at different spatial scales and explore the feasibility of making this algorithm available to end users of the data. Finally, we will consider the propagation of uncertainty when spatial data products are used to derive further products. In particular, we will quantify the uncertainty that results from using a spatial product of the radiometric properties of the soil as an input to a model of soil carbon concentrations. We will quantify this propagated uncertainty and explore the information that must be provided to users of the radiometric product if they are too are to be able to determine the degree of uncertainty that will appear in a resultant product.

This project is primarily a statistical study of the issues of scale and uncertainty in spatial data products. However, in addition to statisticians the project team includes experts in product development, data science and earth science who will provide valuable information and advice regarding about the project findings can be communicated to users of spatial data products.",1
NE/N018656/1,29903,Sustainable gas pathways for Brazil; from microcosm to macrocosm,"Both in Brazil and globally, gas is at a crossroads. On one hand it is abundant, has an increasing share in global energy supply, is relatively clean-burning and is often an economically competitive fuel. On the other hand the gas supply chain and its combustion emit carbon dioxide and methane, which lead to global climate change. Alongside this, gas production, distribution and use have non-trivial life cycle interactions with natural capital and ecosystem services. For gas to have a sustainable future role arguably the principal challenge is in enabling its continued production and use .

Brazil could greatly expand domestic gas production from two sources. First, it has the world's second largest bio-fuel industry (and is the largest exporter), and bio-ethanol production by-products can be used to produce decarbonised gas. Second, large natural gas reserves have recently been found in offshore deep water pre-salt. Yet Brazil faces complex challenges in making the most of its gas resource potential; key among these is a limited national distribution infrastructure, concerns over the environmental impacts of gas production and supply chain choices on unique ecosystems, and questions over the distribution of socio-economic benefits flowing from sugarcane-energy resource exploitation. There are also issues to be addressed to ensure that gas-related developments in Brazil continue to bolster social, as well as economic, objectives, and foster inclusive as well as environmentally-sound economic growth.

The key technical opportunities for gas in Brazil are twofold: 
(1) The first is in the decarbonisation of gas, given that Brazil has a substantial bio-ethanol industry (worth US$33billion in value added annually), which produces vast quantities of bagasse and other wastes. These waste products can be used to produce biogas/biomethane. In 2015 Brazil produced 7Mt of bagasse, and this is projected to rise to 26Mt by 2030, which could produce up to 1.9bcm methane per year. 
(2) The second technical opportunity is the use of significant pre-salt reserves (potentially combined with the bio-methane) in power generation to counter seasonal fluctuations in natural flow hydro electricity output. The technical challenges to capitalising on these opportunities are in technology performance and cost for low carbon gas production, creating a comprehensive infrastructure to support the distribution of gas, and determining the most beneficial use of the significant pre-salt offshore reserves.

This project will investigate these opportunities via an interdisciplinary approach, encompassing process engineering, socio-economics, ecosystem impacts, and energy systems modelling:
(1) Process engineering simulation and optimisation will be developed for sugarcane ethanol production, including investigation of how this process needs to be adapted in order to use the waste products (e.g. bagasse) to co-produce biogas and/or biomethane alongside the ethanol.
(2) Investigation of the socio-economic implications of bio-methane from bio-ethanol bioproducts, drawing on the engineering process characterisation, in order to identify the ways in which it can contribute to livelihoods, growth, and other development objectives.
(3) the ecological consequences of increased use of natural gas in Brazil will be considered. This will translate gas development scenarios into land use projections, and estimate the impact of the land use change on the carbon cycle, water quality and provisioning of drinking water to population centres.
(4) The project will culminate in the production of self-consistent quantitative scenarios of gas development in Brazil to 2050. These will be produced via a qualitative narrative scenario development followed by application of a state-of-the-art energy transition simulation modelling to provide quantitative estimates of the role of gas in Brazil.",1
NE/N012550/1,21551,Nordeste,"The northeast region of Brazil is relatively dry compared to the rest of the country, with unusually irregular rainfall patterns and associated frequent droughts. The soils there tend to be relatively fertile and so, despite crop failures sometimes occurring in drier years, the area is reasonably densely populated with about 15% of Brazil's population living there; but under what are generally impoverished conditions. This has led to extreme land-use pressures on the natural vegetation and widespread degradation of remaining lands.
As in other parts of the world with similar soils and climate, the natural vegetation of the area is a form of deciduous scrub, known locally as Caatinga. Probably because Caatinga typically lacks the complexity and grandeur of moist tropical forests, this vegetation type has been to a large extent neglected to date both in terms of conservation programmes and scientific enquiry. This neglect has serious consequences given the enormous destruction of the Caatinga, which exceeds that of the neighbouring biomes of Amazonia and the Cerrado. Because of their potential importance in future warmer and drier climates in Brazil, conservation of the plant species of the Caatinga, which are adapted to high temperatures and seasonally erratic rainfall, is vital. 
Designed as an integrated research program involving both Brazilian and UK researchers 'Nordeste' will attempt to redress this neglect:
1. Through the establishment of a permanent plot network similar to that existing in moist tropical forests, allowing measurements of Caatinga canopy structure and dynamics and both their short- and long-term responses to climate change to be evaluated for the first time.
2. With the aid of new DNA barcoding measurements designed to better quantify the biodiversity of the region.
3. Through a comprehensive analysis of the biogeochemistry of natural and disturbed ecosystems to develop an understanding of how nutrient cycling processes vary in response to variations in soils and climate and human activity
4. Via a series of detailed structural, physiological measurements across the wide range of different Caatinga sub-types found in the region. These will be made both above- and below-ground and in natural and degraded ecosystems of the region. A special emphasis will be placed on measurements designed to help us understand why it is that under certain circumstances it is that very high biomass stands of Caatinga occur despite the very low rainfall. 
5. Glasshouse experiments comparing water stress responses of seedlings native to moist forest, savanna and caatinga will also be undertaken in order to try and understand what specific metabolic adaptions are involved in plant adaptions to frequent and/or erratic conditions of extreme soil water deficit.
6. Via an integrated modelling program to provide new parameterisations of surface fluxes for semi-aid ecosystems in general and to provide new insights into variations in woody plant shoot: root allocation patterns in response to variation in precipitation regime.
To achieve these aims, the project has been designed as a series of six inter-related field-based workpackages, with a seventh workpackage focussed on modelling of species distributions, ecosystem fluxes and developing a mechanistic understanding of caatinga vegetation functional responses to both variations in climate and soil properties. 

Designed with a view to also producing a series of well-defined products to assist both policy makers and local communities to better manage this unique resource - for example, online guides to ecologically dominant and economically useful plants, the study will serve to provide a valuable first step towards a better understanding of Caatinga vegetation and its responses to anthropogenic and land-use change pressures.",1
1818589,31308,Feedback mechanisms on soil susceptibility to erosion processes in a changing climate,"The impacts of climate change on the mechanics of soil degradation processes are largely unknown, yet may profoundly affect soil functions and associated delivery of vital ecosystem services. This PhD research project will use the world-leading experimental facilities at Cranfield University to investigate how projected climate change scenarios will impact on soil aggregate stability and soil erosion. 
Climate change is predicted to increase rainfall erosivity and impact soil moisture and temperature through changing cycles of warmer and wetter conditions, and different rainfall regimes. These factors are the prime drivers of physico-chemical aggregate formation and breakdown, and strongly influence the biological community that impacts aggregate stability through the production of extracellular polymeric substances (EPS) and fungal hyphae. Therefore, the aim of this research is to investigate how the predicted effects of climate change will impact soil aggregate stability, erodibility and erosion rates.
In an innovative and unique experimental programme, the student will use the facilities in Cranfield University's rainfall simulation laboratory and controlled environmental chambers to subject soils to simulated future climate change scenarios. She will be responsible for all stages of the study design and implementation: designing an experimental study, collecting soils from the field, incubating them in environmental chambers, quantifying the biological and physico-chemical properties of the soil, quantifying erosion rates by rainfall simulation, and analysing environmental data using multivariate statistics.",1
1926128,22902,Poetic Cartographies in the Age of the Anthropocene,"Drawing on the work of Felix Guattari (1995, 2000), his collaborations with Gilles Deleuze, and other feminist theorists that critique and apply their work to the social sciences, I will explore:
1. How cartographies of poetry - the cognitive, ritual and social references generated in relation to affective registers within a milieu - are productive of new regimes of subjectivation
2. How these cartographies might be mobilised using Guattari's technique of metamodelisation to create these new subject positions that are crafted out of the associations and affective responses that poetry brings to the fore
3. How these subjectivities thus offer new ways of thinking, and thus responding, to the urgent ethical and political challenges of the Anthropocene.
Overall aim: To bring together the novel disciplinary combination of geography and poetry to generate unique empirical data through the creation and application of new concepts and techniques. My intended impact is to contribute to a body of evidence that can inform ongoing debates and policy decision around the need to adopt 'ethico-aesthetic' paradigms in response to the urgent challenges presented by climate change.",1
1948742,13812,Climate Adaptation Policy and Its Relation to Practice in North-East Tanzania,"This research will provide an ethnographic casestudy of a climate change adaptation project in
North-East Tanzania. It will follow in the academic tradition of the actor-oriented approach within the anthropology of development, placing the adaptation project itself as the locus of in-depth study. The approach will prioritise the often overlooked angle of 'how' development works, rather than seeking to form a judgement over 'whether' it works (de Sardan, 2005). Utilising Mosse's (2005) conceptualisation of the actororiented approach, it will delve into the hidden complexity of project practice, with the adaptation project being explored as a socially constructed arena involving interactions between the different lifeworlds and discourses of the actors involved. It will seek to understand the logic through which such interactions come to produce necessarily unpredictable effects and examine the role of 'brokers' in generating coherent interpretations of practice and thus sustain the legitimacy of the project. In following this approach, the research will provide a relevant contribution towards filling the gap in knowledge regarding the relationship between the climate change adaptation policy model and how this becomes expressed as project practice and events they come to generate and legitimise. This will be examined in the context of the Integrated Climate Change Adaptation and Resilience Programme set in the East Usambara Mountains of Tanzania.",1
NE/R01079X/1,31441,FUTURE-STORMS: Quantifying uncertainties and identifying drivers of future changes in weather extremes from convection-permitting model ensembles,"Climate change is arguably the biggest challenge facing people this century, and changes to the intensity and frequency of climatic and hydrologic extremes will have large impacts on our communities. We use climate models to tell us about what weather in the future will be like and these computer models are based on fundamental physical laws and complicated mathematical equations which necessarily simplify real processes. One of the simplifications that really seems to matter is that of deep convection (imagine the type of processes that cause a thunderstorm). However, computers are so powerful now that we are able to produce models that work on smaller and smaller scales, and recently we have developed models which we call &quot;convection-permitting&quot; where we stop using these simplifications of deep convection. These &quot;convection-permitting&quot; models are not necessarily better at simulating mean rainfall or rainfall occurrence but they are much better at simulating heavy rainfall over short time periods (less than one day) which cause flooding, in particular flash-flood events. They are also better at simulating the increase in heavy rainfall with temperature rise that we can observe; therefore we are more confident in their projections of changes in heavy rainfall for the future.

A few &quot;convection-permitting&quot; modelling experiments have now been run for different parts of the world but all of these have been over small regions, only the same size as the UK, or smaller. All of the experiments so far have concentrated on rainfall and none have examined how &quot;convection-permitting&quot; models might improve the simulation of other types of extreme weather such as hail, lightning or windstorms. In fact we know very little about how these types of extremes might change in the future. We also have no idea of the uncertainty in our experiments in terms of our predictions of future changes as we have only run one model simulation in each region - this is not useful for planning climate adaptation strategies where we really need to understand the uncertainties in our future predictions so we can plan for them. 

In FUTURE-STORMS we are running these &quot;convection-permitting&quot; models over a very large area (the whole of Europe) and we are comparing models from two different climate modelling teams at the UK Met Office and ETH Zurich in Switzerland. In addition to this we are now able to run a number of different climate models over the same region, which allows us to assess some of the uncertainties in future changes to heavy rainfall and other storm-related extreme weather. This will let us explore how heavy rainfall might change across Europe and what might be causing this. It will also allow us to look at whether these new models are able to simulate other types of extreme weather like hail, lightning and windstorms which have a huge impact on Europe, and how these might change in the future. 

Ultimately, we need better information on how extreme weather events might change in the future on which to make adaptation decisions and FUTURE-STORMS intends to provide this important advance, alongside translating this information into useful tools and metrics for use in climate change adaptation.",1
NE/M020622/1,5099,Infrastructure KE Fellowship (Enhancing the resilience of infrastructure to climate change &amp; extreme weather using automated monitoring technologies),"Key components of the UK transport and utilities infrastructure networks were built more than 100 years ago. This is particularly true of geotechnical assets (i.e. cuttings and embankments) within the rail and canal networks, and earth dams within the water utilities network. These structures were often very poorly constructed compared to modern engineered infrastructure earthworks. Materials were typically selected on the basis of availability, rather than suitability - consequently many of these structures are deteriorating, and require considerable resources for maintenance and remediation. This was clearly demonstrated this year with extreme rainfall causing numerous earthwork failures and major disruption to critical UK infrastructure.

Current monitoring approaches are very often inadequate for predicting slope failure events. They are overly reliant on meteorological data and surface observations, such as manual walkover, aerial photography, or site investigation (i.e. boreholes and trial pits), which do not adequately quantify (spatially or temporally) subsurface processes that occur as &quot;precursors&quot; to slope failure. Instead, failure is typically identified after it has been initiated, which, in many cases, is too late to implement low cost preventative interventions. There is a growing recognition by geotechnical asset owners that emerging low cost ground sensing technologies (e.g. geophysical ground imaging; new ground motion, pore pressure and moisture sensors; intelligent networks; wireless communications) could provide automated monitoring of the internal condition of assets at unprecedented levels of spatial and temporal resolution - thereby providing early warning of potential slope failure and enhancing the resilience of their networks to environmental risks. This is exemplified by Network Rail's new policy of increasing the number of small scale 'refurbishment and maintenance' interventions, and fewer high cost 'renewal' interventions, which will be underpinned by the significantly increased use of remote monitoring technology.

However, there are a number of major barriers to the uptake of these novel technologies by industry. These include limited industry awareness, caution in adopting novel technology, and lack of case studies validating and demonstrating new technologies for slope monitoring applications. Some of the emerging technologies also require specialist input that is currently available within the research community, but which existing geotechnical monitoring consultancies and contractors cannot yet provide. This is particularly true of some of the geophysical ground imaging technologies, which require complex workflows to derive information relevant to asset owners. An additional challenge is the need to interface new workflows and data streams with current industry standard information delivery systems so that the resulting data is accessible and intelligible to end-users and beneficiaries of the technology.

This project will therefore seek to engage both researchers and industry stakeholders to overcome these barriers to the uptake of automated condition monitoring technologies. I will seek to (1) understand current industry monitoring practices, (2) identify key emerging monitoring technologies that could be applicable for slope monitoring, (3) consider approaches for near-real-time analysis and delivery of remotely streamed monitoring data, (4) raise awareness amongst asset owners and service providers of new technological monitoring solutions, (5) produce a series of guidance documents detailing emerging technologies. To achieve this I will build on my links to industry and academia already established through a series of collaborative infrastructure research and innovation projects funded by the research councils (NERC and EPSRC) and a government development agency, and my participation in EU COST Action TU2012 ('Impact of climate change on engineered slopes for infrastructure').",1
NE/M02007X/1,10593,Uncertainty reduction in Models For Understanding deveLopment Applications (UMFULA),"Central and Southern Africa (C&amp;SA) exemplifies the issues that FCFA aims to address: a complex mix of remote and regional climate drivers that challenge conventional climate model simulations, high levels of poorly simulated multi-year climate variability, an extremely low level of investment in climate science relative even to other parts of Africa but particularly West Africa; high physical and socio-economic exposure to climate that projections indicate may become drier and more variable in the future; and low adaptive capacity resulting in decision-making and medium-term planning that is inhibited by significant political, institutional and economic barriers. Meanwhile economic growth and significant infrastructure planning is taking place within C&amp;SA in the absence of adequate climate information.

Deficient understanding of many key climate features in C&amp;SA is one barrier to the integration of climate information into decision-making. UMFULA will provide a step-change in climate science in C&amp;SA. Our objectives include: (i) fundamental research into key climate processes over C&amp;SA and how these are dealt with in models; (ii) a process-based evaluation to determine how models invoke change and whether that change is credible; (iii) production of novel climate products (Work Packages WP1-2) encompassing convection permitting and very high resolution (c4 km) ocean-atmosphere coupled simulations that will reveal processes of high impact events and as yet unexplored complexities of the climate change signal. We will also focus on neglected but critical elements of the circulation such as the links between C&amp;SA and the role of local features including the Angolan Low, Botswana anticyclone, Angola/Benguela Frontal Zone, and the Seychelles-Chagos thermocline ridge. Based on this research and through co-production with stakeholders we will generate improved and streamlined climate information for decision-makers (WP3).

We will use a deliberative and participatory methodology to test findings from FCFA pillars 1 and 2 with stakeholders based on deep engagement in two contrasting case studies: the Rufiji river basin in Tanzania, and sub-national decision-making in Malawi. They are carefully selected as exemplars of multi-sector, multi-stakeholder, and multi-scale decision situations which can be compared for transferable lessons on the effective use of climate services.

In-depth understanding of decision-making contexts, including political economy, theories of institutional change, and individual motivation from behavioural sciences will inform how to tailor and target climate projections for most effective use (WP4). The case study areas (WP5-6) will test these findings through a co-produced framework of C&amp;SA-appropriate decision-making under climate uncertainty to identify robust climate services-informed intervention pathways (portfolios of policies and investments that could work well over a broad range of climatic and socio-economic futures). Our Capstone Work Package (WP7), and major outcome, will be the synthesis of best decision-making models and appraisal methods that are transferable in the African context and enable effective use of climate information in medium-term decision-making.

The seven UMFULA Work Packages cut across the three FCFA pillars to ensure maximum complementarity and integration. We are a consortium with world-leading expertise in climate science, decision science and adaptation research and practice, together with stakeholder networks and strong, long-standing relationships in C&amp;SA. We comprise 5 UK and 13 African institutions.",1
ceh020015,29689,CEH Soils and Land Use,"Measure and model change in soil function and quality, and quantify change in land use and land condition. Assess the role of climate change and land use change in driving changes in the structure and function of our soil and land, and develop solutions to conserve, enhance and manage multiple ecosystem services from local to global.",1
AH/N00597X/1,24107,Cross-pollination: Re-valuing Pollinators through Arts and Science Collaboration,"Most of the foods that we eat rely on insects for pollination. The populations of the honeybee and wild pollinators have rapidly declined due to habitat change, global warming and disease. There is a burden of responsibility for researchers and public bodies to explore ways to halt this decline. To date, most of the response to this challenge has been led by natural and social/economic scientists and although the arts community has worked on awareness raising projects there has been little collaboration. Responding to this observation, this network will bring together arts researchers with natural and social scientists, beneficiaries and policy makers to 
explore the role that the arts can play in increasing understanding of the causes of the decline in pollinator populations and influence policy decisions to help halt this decline.

By bringing the network members together the 'Cross-pollination' project will: 
- help scientists produce better understandings of pollinator decline; 
- explore new collaborative ways of working where the perspectives of the 'arts' and 'sciences' enrich each other; 
- help change the perceived value of pollinators; 
- and effectively influence decision-making.

Drawing on existing networks, Liggins (PI) and Christie (Co-I) will bring together key researchers, artists and stakeholders to participate in a series of exploratory arts workshops that will explore theories of aesthetics, sensory perception, differences in perspectives and language, and investigate possible creative interactions and partnerships. From these meetings a series of speculative art interventions will be set up to produce art works and explore ideas arising from the collaborations. Using the methodology of the 'Art Crit', not normally used within the scientific community, Cross-pollination will enable researchers from various disciplines and stakeholders to interrogate the art process, to share reflections, and explore the range of value judgments. Throughout the process, artists will be partnered with scientists and decision makers with the expectation that a future research agenda will be developed. 

Confirmed participants include award winning scientists in the area of pollinator research from the UK and USA and high profile arts researchers from the fields of aesthetics, perception and community arts. An important addition are two linguists studying the language of environmental research and its affect on perceived values. The Co-I Christie's expertise in the Valuation of Nature for Ecosystem Service Sustainability, will provide a further focus for the project. PI Liggins has undertaken a number of science/art projects, most recently with the NBGW and is presently contributing to the NERC project Duress Theme 5 led by Co-I Christie to deliver research through arts practice, particularly looking at differences in perception of value.

A number of the representatives in policy making organisations are also involved, such as Pollinator Taskforce Wales, Intergovernmental Science -Policy Platform on Biodiversity and Ecosystem Services (IPBES) Deliverable 3a Global Pollinator Assessment. Co-I Christie has led a number of research projects involved in the economic evaluation of nature and bio-diversity and was PI the NERC Valuing Nature Steering project. Further confirmed beneficiaries, who have been involved in the development of Cross-pollination include the BumbleBee Conservation Trust (Bee Wild project), BugLife, The Bee Garden at the National Botanic Garden of Wales (NBGW), Dr Beynon's Bug Farm, and the Heart of Wales Line and Arriva Trains Wales 120 Miles of Garden project. The NBGW, where some events will take place, is well-placed to disseminate many of the ideas and findings to the general public, as there is an established Bee Garden Visitors Centre, and there are already links with other National Gardens, such a Royal National Garden of Scotland and the Nanshan Botanic Gardens in China.",1
MR/S012893/2,38589,Integrating participatory approaches and traditional models to strengthen One Health responses to zoonotic diseases in India's changing environments,"Zoonotic pathogens, that circulate between animals and humans, like the Leishmaniases, and Nipah and Chikungunya viruses, cause 60% of emerging infectious disease events worldwide and disproportionately affect people in tropical, resource-poor areas. Aside from impairing human and animal health, zoonotic diseases are detrimental to livelihoods and economies, for example, preventing small-holder farmers being lifted out of poverty by increasing livestock production. The impacts of zoonotic diseases are increasing and shifting globally, as the environment and societies undergo rapid change. Our lack of knowledge on how these pathogens circulate between wildlife, livestock (as well as possible insect and tick vectors) and people, and how people are exposed as they use the landscape makes it difficult to understand these changes in terms of impact, and to develop effective disease control strategies in many local settings. Effective management and understanding of zoonotic diseases requires cooperation of policy-makers and managers from across the animal health, human health, agriculture and environment sectors, from national and international decision-makers down to district managers that all interact with the disease system, as advocated by the global One Health initiative, that recognises the &quot;interconnectedness of human health, wildlife and domestic animal health and the environment&quot;. Surveillance, decisions and policy need to be better integrated across sectors, and research that leads to informatics to support management decisions, like maps and forecasts must be informed by the knowledge, priorities and needs of local disease managers and policy makers. More-over, neglected endemic pathogens that affect poor communities need to be better represented in policy frameworks and surveillance systems.

Focussing in India as a key global hotspot for endemic and emerging zoonotic diseases and small-holder livestock communities, and bringing together a network of stakeholders with experts in public and animal health, ecology, epidemiology and social science, this project aims to reduce health, welfare and livelihood impacts of zoonotic diseases by better understanding links between surveillance, knowledge, research and models across sectors and improving current information systems that support intervention. The research underpinning these improvements will include:
(1) Mapping of key stakeholders in each sector, their priorities and needs for decision-support tools 
(2) Identifying where surveillance data, knowledge and skills exist and could be leveraged across sectors to better understand and manage zoonotic diseases
(3) Understanding the full range of potential socio-ecological drivers that might cause disease impacts to increase 
(4) Interpreting geographical patterns in disease impacts in relation to environmental data within models to disentangle social, climate and landscape factors precipitating disease for case-study diseases and settings and, in turn, predicting outcomes of intervention
(5) Building capacity in research, data analysis and cross-sectoral collaboration to underpin future One Health approaches in India.

Improved decision-support tools will help disease managers to better target vaccination and communication efforts towards the communities that are most at risk and help managers in agriculture and environmental sectors to understand how, for these communities, disease impacts may coincide with other negative impacts of environmental change. 
The project platform and approach of co-developing research and decision support tools on zoonotic diseases with stakeholders across sectors, accounting for their needs and underlying ecological and social processes, will build significant capacity in science, policy and practitioners to respond to these emerging and endemic global threats.",1
NE/S00677X/1,15498,Thwaites Interdisciplinary Margin Evolution (TIME),"The West Antarctic Ice Sheet (WAIS) contains 2 million cubic kilometers of ice. The global scientific community considers the it the most significant risk for coastal environments and cities, given its potential contribution to future sea-level rise. The risk posed by the WAIS is exacerbated because it is in direct contact with the warming ocean, and its bed slopes inland; this latter aspect makes the ice vulnerable to extensive and prolonged retreat. Although scientists have been aware of the precarious setting of the WAIS since the early 1970s, it is only now becoming apparent that the flow of ice in several large drainage basins is undergoing dynamic change, which is consistent with - although not certain to be - the beginning of a prolonged and potentially unstoppable disintegration. Two of the fundamental global challenges facing the scientific community today include understanding the controls on the stability of the WAIS, and enabling a more accurate prediction of sea-level rise through improved computer simulations of ice flow. In the TIME project, we directly address both challenges by
a) using frontier technologies to observe rapidly deforming shear margins hypothesized to exert strong control on the future evolution of the Thwaites Glacier outlet of the WAIS, and
b) using observational records to develop parameterizations for important processes which are not yet implemented in the ice sheet models used to predict the contribution of WAIS to sea level rise.

TIME will test the key hypothesis that the future evolution of ice flow through the Thwaites Glacier Draining Basin is governed by the dynamics of its shear margin - the boundary at the edge of the glacier across which increased ice flow is observed. To test the hypothesis the team will set up an ice observatory at two sites on the eastern shear margin of Thwaites Glacier. The team argues that weak topographic control makes this shear margin susceptible to outward migration and, possibly, sudden jumps in response to the drawdown of inland ice when the grounding line of Thwaites retreats. The ice observatory is designed to produce new and comprehensive constraints on important englacial properties, which include ice deformation rates, ice crystal fabric, ice viscosity, ice temperature, ice liquid-water content and basal melt rates. The ice observatory will also establish basal conditions, including thickness and porosity of any subglacial sediment layer and the deeper marine sediments. Furthermore, the team will develop new knowledge with an unparalleled emphasis on the consequences of variations in these properties for ice flow, including a direct assessment of the spatial and temporal scales on which they vary. These knowledge will be obtained from three field-based geophysical platforms:
 - Active-source seismic surveys will be carried out in 2D and 3D, uniquely using wireless geophones,
 - A network of broadband seismometers, to identify the icequakes produced by crevassing and basal sliding,
 - Autonomous radar systems with phased arrays to produce sequential 3D images of rapidly deforming internal layers while potentially also revealing the geometry of a basal water system at the bed. 

Datasets will be incorporated into numerical models developed on different spatial scales. One will focus specifically on shear margin dynamics, the other on how shear margin dynamics can influence ice flow in the whole drainage basin. Upon completion, the project will have confirmed whether the eastern shear margin of Thwaites Glacier can migrate rapidly, as hypothesised, and if so what the impacts will be in terms of sea level rise in this century and beyond.",1
104646,4832,Intelligent gas grid control,"Methane leakage from gas distribution networks is a serious financial and environmental issue.

<U+2022> Methane's impact on global warming is 84 times greater than CO2(1)

<U+2022> Gas lost globally is estimated at 300,000 GWh or &pound;16 billion p.a.

<U+2022> The impact on global warming is equivalent to 1,700 million tonnes of CO2e which is more than 4 times total UK CO2e emissions.

Other than replacing pipes, which has a massive capital cost, the only means of reducing leakage is through improved management of the pressures in the network. By reducing the average pressure in the pipes, methane leakage can be reduced. This is because the leakage is proportional to pressure e.g. a 15% pressure reduction results in 15% less leakage.

Existing pressure management technology is out of date, expensive, time-consuming to install and requires continuous manual intervention.

Utonomy is developing a solution that enables gas distribution networks (GDNs) to remotely adjust pressures in their network or to control pressures based on time of day. A key part of this solution is an innovative actuator that can be retrofitted to the thousands of gas governors feeding the network. This solution will shortly be trialled with one of the larger GDNs.

While the current Utonomy solution already provides benefits in terms of lower operating costs and lower leakage, a further significant improvement could be achieved by using a more sophisticated control solution. The purpose of this project is to develop software, which uses self-learning algorithms and statistical methods to forecast the demand in the network and to calculate the optimum settings of all the governors at any point in time. The software would enable the pressure in the network to be continuously and automatically controlled so that it is as low as possible without going below the minimum. Utonomy proved the viability of this approach during a very successful Innovate UK proof of concept project carried out in 2016.

Over 20yrs IPCC Fifth Assessment Chapter 8 table 8.7",1
NE/P007716/1,3878,Mechanisms and consequences of tipping points in lowland agricultural landscapes,"Ecosystems provide a number of benefits to people, including food and timber production, areas for recreation, pollination of crops, fresh water, and the storage of carbon, which can help reduce the risk of climate change. People also benefit from wildlife, including both plant and animal species, both in terms of their aesthetic value, and from the functional role that such species play in the ecosystems of which they are a part. Many ecosystems in the UK, as in many other parts of the world, are currently at risk because of the combined effects of climate change, aerial pollution, changing patterns of land use and other forms of human disturbance. These factors can interact with each other, leading to major changes in ecosystems, which can affect their ability to provide benefits to people. Research is needed to identify which ecosystems are at risk of rapid transitions occurring, so that appropriate management and policy responses can be identified. Information is also needed on the potential impacts of such ecosystem &quot;tipping points&quot; on humans, through changes in the provision of ecosystem benefits. This project aims to provide this information, by studying the landscapes of Dorset, a southern English county. Here we will examine data that have been collected over a period of 80 years in a variety of different types of ecosystem, to analyse the changes that have occurred. We will use this information to see whether any tipping points have occurred in the past, or might occur in the future, which could affect human society. We will also study tipping points by comparing ecosystems along gradients of environmental degradation. In addition, we will explore whether the environmental degradation that has already happened in Dorset, or might happen in future, could affect employment and prospects for economic development. We will test the idea that factors such as climate change, aerial pollution and land use change could cause a tipping point in ecosystems, which could have major economic consequences. We will achieve this using a combination of field data and computer models, which we will use to forecast how such impacts might occur at the landscape scale. The project will help increase understanding of how major ecological changes occur in agricultural landscapes typical of much of the UK, and their potential impacts. This information will be of value for identifying which ecosystems are particularly at risk of tipping points, what are the processes that cause such tipping points, and what the implications of them might be for human society. We will also examine how such problems might be averted in future, through the development of appropriate management and policy responses.",1
NE/S012567/1,39812,Pathways Of Dispersal for Cholera And Solution Tools (PODCAST),"Cholera is a waterborne epidemic disease in humans. It is a major public health threat, affecting 1.3 to 4 million people each year worldwide, with 21,000 to 143,000 reported fatalities. Outbreaks are caused by the bacterial pathogen Vibrio cholerae, found in many coastal, estuarine, and brackish waters around the world. The origin of the current pandemic of cholera was a single population of pathogens in the north-eastern Indian Ocean basin, which spread globally, in several transmission events. Transmission pathways include direct human-to-human infection, and human-environment interactions, including ingestion of contaminated water, aggravated by emerging antimicrobial resistance through release of antibiotics into the environment. Vibrio pathogens are found as free-floating forms or attached to living (plankton) and non-living (sediment) hosts. They flourish under warm temperature, moderate salinity and turbidity. The major environmental reservoirs of Vibrios, their connectivity, how they might be affected by climate variability and the associated impact on human health remain largely unknown. There is a clear imperative to reduce human risk from cholera bacteria to meet Global Goals related to 3-human health, 6-water quality, 13-climate and 14-life under water. 
Focusing on the northern Indian Ocean, currently a hotbed of outbreaks of cholera and related diseases, the PODCAST project will pinpoint the impact of large-scale oceanic and climatic processes on the transmission dynamics of cholera (Goals 6, 13, 14) and their impact on public health (Goal 3). Scientists from India, Japan and the UK will work collaboratively to: 1) identify environmental reservoirs of Vibrio cholerae as well as possible advective transport via ocean currents and long-distance transmission routes for cholera outbreaks; 2) characterise the influence of climate perturbations on cholera outbreaks and environmental transmission routes; 3) build an epidemiological model integrating environmental and human-to-human transmission routes; and 4) produce forecasts for cholera outbreaks in coastal regions. 
The research will be developed in consultation with end-users, including local communities relying on water resources for livelihoods, income generation and recreation; governments; health services; intergovernmental agencies; and policy makers for whom we will provide tools and Vibrio disease risk map products that will support evidence-based policy decisions and actions to achieve Global Goals.
The work will be organised in four Work Packages. WP1 (Abdulaziz-India; Sathyendranath-UK) will generate new in situ observations of biophysical variables (including Vibrio pathogens and antibiotics) at selected sites in open-ocean and coastal locations; and process satellite data (ocean-colour, salinity, altimeter and temperature) over entire northern Indian Ocean. WP2 (Platt-UK; Clark-UK; Nonaka-Japan), focussing on models and using data from WP1, will develop an epidemiological model including components of human-to-human and environmental transmission routes of cholera outbreaks; a particle-tracking model to study sources and connectivity between environmental reservoirs of Vibrios; and a climate-variability model to generate past and future indices of large-scale patterns of climate variability. WP3 (Racault-UK), based on the influence of environmental conditions, regional circulation and climate variability on risks of outbreaks at coastal locations in the northern Indian Ocean (WP 2), will focus on producing a cholera-outbreak prediction system for coastal regions of the northern Indian Ocean. The user-engagement, policy information and practice interventions will be addressed in WP4 (Menon-India; George-India) in which we will engage with local communities, policy-makers, and intergovernmental agencies (WHO, IPCC) to identify needs, assess benefits, best practices and uptake of results from PODCAST to reduce risks of Vibrio diseases to public health.",1
NE/S00579X/1,29914,SEANA -Shipping Emissions in the Arctic and North Atlantic atmosphere,"Shipping is the largest means of moving freight globally. Ships consume dirty fuels, making them one of the most important sources of anthropogenic aerosol in the marine atmosphere. Aerosols from shipping can affect the climate directly through absorption and scattering of radiation, with an overall cooling effect to the atmosphere. They can also indirectly influence the climate by changing cloud properties, e.g., albedo and lifetime, which further cools the atmosphere.

Two key challenges for assessing future climate impact of shipping emission are (i) knowing the status of the present-day aerosol system - as a baseline from which any climate predictions are made and (ii) quantifying the amount of pollutants emitted. 

Currently little consensus exists on the impact of shipping emissions in the Arctic and North Atlantic Atmosphere (ANAA) primarily due to a lack of observations and insufficient model skills. Recent modelling work suggests that the Arctic aerosol baseline should account for a disparate range of natural sources. Few models are sufficiently comprehensive, and while some models can reproduce aerosol in some Arctic regions, there is evidence that models can produce similar results via different sources and processes. An inability to reflect the aerosol baseline processes can have significant impact on the reliability of future climate projections. 

Shipping is also undergoing significant changes. In January 2020, a new International Maritime Organisation (IMO) regulation comes into force, which reduces, by more than 80%, the sulphur content in maritime fuel oils. Superimposed on that, recent climate induced changes in Arctic sea ice are opening up new seaways enabling shorter sea passages between key markets. Significant growth in shipping via the North West Passage (NWP) is anticipated in the coming years. Thus, there is a short window of opportunity to define current atmospheric conditions, against which the impact of these changes must be determined.

SEANA will take advantage of the above-mentioned opportunity to make multiple atmospheric measurements over multiple platforms to understand the present-day baselines - sources of aerosol particles including the contribution from shipping - and to determine the response of ANAA aerosol to new fuel standards after 2020. Extended measurements will be conducted at two stations adjacent to the NWP enabling the source of particles to be apportioned using receptor modelling approaches. In addition, SEANA will participate in a Korean cruise to the west side of the NWP, and a NERC cruise to the east, to measure both natural and anthropogenic particles and aerosol processes in two contrasting Arctic environments.

These new observations will be integrated with recent / ongoing measurements at partner ANAA stations to generate a benchmark dataset on aerosol baseline in ANAA to constrain processes in the UK's leading global aerosol model, ensuring that the model is reproducing the baseline aerosol in the ANAA faithfully. We will then test the models' response to significant reductions in shipping sulphur emissions using observations taken during the transition to low-sulphur fuels in 2020. The revised model, which can reproduce current &quot;baselines&quot; and accurately predict the response of emission changes in the ANAA, will then be used to predict the future impact of shipping on air quality, clouds and radiative forcing under multiple sea-ice and shipping scenarios. 

SEANA will deliver a major enhancement of UK's national capacity in capturing baseline ANAA aerosol and responses to emission regulations, results of which will inform shipping policy at high-latitudes.",1
NE/S010211/1,39325,Wisdom teeth: refining our understanding of mammalian evolution through dating dental enamel,"Directly dating mammal fossils older than the limit of radiocarbon dating (~50,000 years) is very challenging, and this has led to a research focus on the most recent past in forming our understanding of mammalian response to changing environments. However this narrow time window is extremely limiting if we aim to understand the effects of climate change on land-based organisms, or unpick our own evolutionary history. We are hard-pressed to pinpoint the major evolutionary drivers for African mammals, and to compare patterns across a large, diverse continent. This problem notably includes our own ancestors. The fundamental problem preventing the required comparisons is chronology, and specifically a method that can date fossils directly.
 
Our project team has been developing and employing methods for dating using the breakdown of the original proteins trapped within fossils. Excitingly, we have just made a methodological breakthrough which enables amino acid (a protein breakdown product) dating to be undertaken on the small amounts of amino acids remaining in tooth enamel (a resistant crystalline material composed of calcium phosphate with small amounts of protein). Dating enamel has the enormous advantage of providing a direct date on mammal teeth (critical fossils of interest) and the new method now enables routine amino acid analysis, successfully dating UK material up to 3 million years in age. This technique is ripe for development to a range of mammalian species and additional geographic regions, potentially revolutionising our understanding of mammalian evolution (including humans) during the last few million years, and their response to environmental change, at the local and the global scale.

This proposal will address the three areas of technology development needed for this dating method to be used routinely, but the time frame it opens up (the last ~4 million years) will enable a significant shift in the range of research questions we can address. The three strands of technological advance proposed are: 1) a microfluidics (&quot;lab on a chip&quot;) approach, which will enable both a significant decrease in the physical sample size needed, as well as preparation / analyses to be undertaken outside specialist labs; 2) combining analysis and imaging of both the organic and inorganic fractions to understand their structure, function and any impact on the protein breakdown; and 3) using advanced chemical models to understand the breakdown reactions.

We will then apply these methods to two regions of Africa of particular evolutionary interest: east Africa (including the Rift Valley) and southern Africa (including the 'Cradle of Humankind'). Initially calibrating the dating approach on reliably dated material, we will then expand it to material that is currently of unknown age. The developed chronology will also enable models of human-environment interaction to be tested, providing a breakthrough in our understanding of our evolutionary past. 

This project will therefore take the latest advances in dating and apply them to a region where the palaeoenvironmental record can help shape the understanding of the sensitivity of Africa's biota (plants and animals) to changes in temperature and rainfall patterns. Understanding large mammals' responses to environmental and climate change is critical for developing appropriate conservation measures, and we will also gain insights into the timings and drivers of the evolution of our human lineage.",1
103991,5558,Amphibious robot for inspection and predictive maintenance of offshore wind assets-IFROG,"UK and EU governments have committed to ensuring 20% of total energy consumption is sourced from renewables by 2020. Diminishing fossil fuel resources and adverse environmental impacts of other sources of energy is driving growth of wind farms, especially offshore wind farms as they deliver better performance per turbine due to better wind conditions and do not compete with agricultural land use. Reducing operation &amp; maintenance (O&amp;M) costs remains a key priority for offshore wind industry. Foundation maintenance alone accounts for ~65% of O&amp;M costs. InnoTecUK (robotic and automation solution provider) is partnering with two renowned research &amp; technology organizations (TWI Ltd and Brunel Innovation Centre -BIC) and end-user (The Underwater Centre -TUC) to develop and demonstrate an automated system (iFROG) for inspecting and streamlining maintenance of offshore wind assets. The new system will reduce maintenance costs by 50%, saving &pound;150k p.a. per turbine. This will improve the cost-effectiveness and sustainability of offshore wind; encouraging future investment and benefiting energy security and the environment.",1
BBS/E/C/000I0310,12515,S2N - Soil to Nutrition - Work package 1 (WP1) - Optimising nutrient flows and pools in the soil-plant-biota system,"'Soil health' is an as yet imprecise concept recently taken up by scientists and policy makers. It relates to a range of factors which influence the capacity of soil to support the productivity, efficiency and resilience of a given production system. This work package (WP) will develop the scientific basis for the concept of soil health by describing and modelling the biological, chemical and physical processes in soil and the dynamics between them that act singly or together to promote efficiency of nutrient utilization (ENU) and enhanced crop performance. This will provide fundamental empirical and mathematical evidence to determine the mechanisms which mediate the nutrient and energy (C flow) cascade from complex organic and simple inorganic inputs to plant-available nutrients in soils. The role of rhizosphere microbial community structure and function on nutrient transformations and supply to plant roots is a central theme of this WP, including the potential for self-organisation of soil structure at the aggregate scale that is mediated by root and microbial activity and the interaction with the mineral matrix. The trade-offs between the rate, efficiency and resilience of macro- and micronutrient flows to plants in contrasting arable and managed grassland systems will provide an operating envelope for a given soil and production system subject to external stressors, imposed by climatic variability and management. The cumulative knowledge will inform the development of the next generation of soil models (building on RothC) that link macronutrient (N, P, and C) dynamics to physical properties including water storage and availability using directly-measurable mechanistic parameters. Critically, this WP will deliver a set of sustainability indicators related to enhanced ENU from soil-to-plant that will provide mechanistic scale targets for the field, farm and landscape-scale interventions that are researched in this strategic programme (WP2 I0320 and WP3 I0330).",1
1916667,25911,Socio-Energy Systems in the Anthropocene: Island Metabolisms and the Contested Geographies of Energy Transition,"Climate change has moved energy-society relations centre stage. Political struggles and class relations are finding new expression in the geographies of carbon lock-in, the geographies of (renewable) energy transition, and the geo-spatialities of alternative energy futures; these struggles are themselves shaped by the materiality of socio-energy systems. 

Islands have become emblematic figures in the Anthropocene. The dynamics of energy development and change on islands, embedded within complex multi-relational systems, highlights particularly well the ways in which energy transitions more generally are shaped by their spatial and material context, the need to develop frameworks that account for geographical specificity, and the ways both material location and spatial form capture shifts in the operation and contestation of power. 

As the energy transition unfolds under the dictates of fossil capital, and many previously peripheral places such as islands become both 'sustainable-development laboratories' and sites of energy extraction and struggle, how are class relations and conflicts over the appropriation of energy surpluses (re)surfacing and being (re)interpreted and (re)expressed in this moment? How can we trace and position struggles over island time-space, land and resources into broader contexts of historical global capitalist relations? 

I focus on four islands, two in northern European countries transitioning from oil-based economies (Scotland and Norway) and two in southern European countries emerging from post-crisis situations (Spain and Greece). Drawing on eco-Marxist theories of metabolism, I use a 'relational comparison' framework, which focuses on spatio-historical specifications, interconnections and mutually constitutive processes, and root this in a dialectical and historical-geographical materialist understanding of energy systems. I use desk-based exploratory research, interviewing and storytelling, and critical ethnographic techniques.",1
BB/T004282/1,42171,AAFC IWYP Aligned Call; Circadian clock editing in wheat,"The overall aim of this project is to utilize advanced biotechnology, genomics, functional genomics, and breeding techniques to develop next-generation wheat germplasm that will increase the security of global wheat production and address the need for a 50% increase in genetic yield potential by 2050 (IWYP). Global warming is predicted to increase temperature and the frequency of extreme weather events, and also to alter precipitation patterns and abundance, thus changing water availability to crops. Another direct consequence is that the number of frost-free days in many regions will become comparable to what is typical of more southern regions, however the day length will remain unchanged. For this reason, alignment of photoperiodic requirements with the growing season is key to the successful integration of high yielding wheat genotypes. It is imperative that we protect wheat production by developing next-generation germplasm that is adaptable and resilient to anticipated variable climatic conditions. This project will seek to generate and deploy genetic variation in circadian clock genes with relevance to IWYP aims of increasing yield in several ways: 1. We will harness the power of circadian clock genes in controlling yield and stress responses. 2. We will optimize growth through modulation of circadian clock genes for yield increase and improved stress responses. 3. The circadian clock mutant (ccWheat) germplasm will be incorporated into wheat breeding at AAFC and elsewhere. 4. Mutational breeding tools, genome editing and methods to control recombination, will be further developed for accelerating breeding for yield and stress responses.",1
BB/N020707/1,33322,Resilience of the UK food system to Global Shocks (RUGS),"The ability of the global food systems to rebound from shocks and in particular the resilience of the UK food system is the focus of this project. Growing populations, changing diets (in response to income changes) and bioenergy are increasing pressures on the agricultural system globally to produce the commodities demanded. The location and intensity of food production is also changing, due to the globalisation of food supply and increasing international trade in agricultural commodities. Environmental considerations are also having an influence, both through climate change impacting crops and driving adaptation strategies, and through sustainability thresholds (e.g. water or deforestation). A progressively interconnected global food system, coupled with increasing demands and constraints, increases risks (i.e. reduces resilience) to global shocks. Events that shock supply or demand in one or more regions can affect the global market, and impact producers and consumers around the world. A notable example is the 2007/08 food price spike, as well as the continued price volatility.

To understand UK food resilience the global system needs to be considered, due to this interconnectedness. Even for commodities where domestic consumption is largely produced within the UK, global markets have a significant role in determining the UK market prices, e.g. recent milk price movements. Using stakeholder consultation the project will define a set of shock scenarios. These will then be simulated in a novel model of the global food system to assess the impact on food price for the average UK consumer, and the results then analysed to identify key messages for policy maker, the food supply chain, and the public.

A diverse set of shocks scenarios with the potential to impact UK food security will be developed. These will range from relatively business-as-usual scenarios, to more extreme events. A range of future climate and socio-economic scenarios (i.e. populations and incomes) will be used, both as scenarios in their own right and as context for some of the other shocks. For example, the shocks will include; variations in trade barriers, adjustments in dietary patterns, bioenergy demand, alternative rates of technological development, and geopolitical insecurities (e.g. war). They will be described qualitatively and quantitatively, including an assessment of uncertainty and likelihood.

The effect of the shocks will be evaluated by extending and using existing coupled models, development under a EU FP7 project (LUC4C). The model departs from the usual global economic optimisation approaches previously applied to agricultural systems, and offers a more detailed spatial representation of crop and pasture yields for a range of intensities, i.e. fertiliser and irrigation rates. The model also relaxes some of the more restrictive market assumptions. The model does not require market equilibrium and is able to represent non-economic governmental response behaviour, e.g. the imposition of trade barrier due to supply shortages. A further complexity is the two-way interaction between climate and the global food system. Climate change effects crop growing condition, the probabilities of extreme weather events, and will influences producer adaptation to changing conditions. But climate is also affected by land use, a substantial proportion of total anthropocentric carbon dioxide emissions are associated with land use change. To represent the feedbacks between land use and climate the project's model framework includes a coupled climate system model, vegetative model, and land use model.

Policymaker, industry and supply chain stakeholder interventions to potentially increase the resilience of the UK food system will be examined, based on the simulation results. The project will also consider the effect of market power, and the policy and regulatory environment in mitigating or increasing the UK food system's resilience.",1
1945814,33800,Parameterizing the impact of fjord circulation on the ocean forcing of melting ice sheets,"Melting of the Greenland ice sheet currently accounts for about a quarter of the observed global mean sea level rise (contributing approximately 7.5mm over the period 1992-2011), and therefore has significant impact on the large fraction of the global population who are influenced by changing sea level. Greenland ice melt is also increasing freshwater input to the North Atlantic, with the potential to alter ocean circulation and significantly influence the climate in north-west Europe. Predictions from state-of-the-art climate models incorporate the atmospherically-driven surface melt of ice sheets, but the component of marine melting is missing.

This marine melting occurs in hundreds of fjords around Greenland where glaciers meet the ocean. Observations suggest that decadal variability in regional ocean temperature causes significant variability in ice loss. Warm water arriving at the ice front drives increased melting of submerged glacier snouts and ice shelves, leading to acceleration of inland regions of the ice sheet. The increased flux of ice from the land into the ocean impacts sea level.

Due to the geometrical confinement in fjords, the transport of ocean heat towards the ice depends on fjord circulation occurring on scales too small to be represented in a modern global climate model. The representation of this missing process requires a parameterization scheme that is driven by and affects the modeled ocean properties. The lack of such a parameterization is a serious limitation of contemporary climate models: the oceans around Greenland are predicted to warm in the future, but we cannot accurately predict the impact on glacial melt and sea-level rise because we lack the tools required to address the problem. As a result, recent IPCC reports have struggled to accurately estimate this contribution to sea-level rise.

This project will develop and implement a simple parameterization of glacial melt in response to ocean forcing, that can be used to represent small-scale fjord processes in large-scale ocean and earth system models. Our team will develop a simplified model to capture the exchange rates of heat and salt between a fjord and the wider ocean, and their impact on ice sheet melting, using physical constraints and fluid dynamics theory. We will calibrate the response of this model to a range of ocean conditions and fjord geometries, using high-resolution ocean simulations in a localized fjord setting and comparing to ongoing measurements in Greenland fjords. The simplified model will act as a parameterization of melting that can be applied to a wide range of fjords, and we will implement this in the Met Office ocean model. The final coupled model will predict local ice melt rates that drive an ice sheet model and control freshwater fluxes to the ocean.

Our parameterization will provide an adaptable tool for immediate use in climate and Earth system models at the Met Office and other climate modelling centres worldwide. It will be of flexible design, providing initial predictions based on current knowledge, but allowing new constraints to be incorporated from future field campaigns and modeling studies that account for new processes.

We will enhance the training of a student from a Science, Technology, Engineering &amp; Mathematics (STEM) background, and translate their skills to tackle environmental challenges and address a key UK skills gap. We will dovetail intensive training at Oxford University on the core knowledge and skills for environmental research, with hands on experience of high performance computing, code development, and working in industry at the Met Office.

In summary, our intensive researcher training will infuse STEM skills into environmental science, whilst simultaneously forging new understanding of the impact of ocean circulation on glacial melting in Greenland fjords, and developing a dynamically-based parameterization of these effects for use in future climate model projections.",1
2266711,36060,Compound-specific radiocarbon analysis as new tool to investigate C-dynamics in sustainable agriculture,"Agriculture intensification is a key source of anthropogenic carbon dioxide, in turn contributing to global warming and climate change. Whilst numerous agricultural practices aim to improve productivity, such as ploughing or use of inorganic fertilizers, they also disrupt natural carbon storage mechanisms. Causing mineralisation of the organic matter to carbon dioxide, then emitted to the atmosphere. Carbon sequestration in agricultural soils represents a vital opportunity to recover soil organic matter and combat anthropogenic carbon dioxide emissions. As such the UK has joined the 4 pour mille initiative which aims to increase carbon storage in agricultural soils by 0.4% per year. To achieve this goal the current amount of carbon stored must be quantified and the mechanisms driving soil organic matter storage must be understood. Recently, the view that compounds possess an intrinsic recalcitrance, due to their molecular properties, has been fundamentally questioned. Instead current research has postulated that biological and physico-chemical stabilisation mechanisms are responsible for long term persistence. However, this stabilisation may vary between biochemical classes and locations. 

The project will utilise the long term experiments conducted at Rothamstead Research, studying both fresh and archived soils. Highly developed fractionation methods will be used to isolate and quantify characteristic target compounds. These fractions will also be purity checked using high field NMR approach pioneered at the University of Bristol. Additionally, 14C measurements using the University of Bristol radiocarbon accelerator will be used to determine the turnover rates of these target compounds and elucidate how these rates are dependent on the biological or physico-chemical protection mechanisms versus their intrinsic recalcitrance. Selection of these target compounds will be in collaboration with Rothamsted Research, as this mechanistic understanding will contribute to development of the RothC model, as well as informing agricultural management decisions aiming to improve agricultural sustainability.",1
NE/P002536/1,4522,A coupled climate-vegetation-mammal-human model for simulating Late Quaternary megafaunal extinctions,"The period 60,000-5,000 years ago saw the extinction of up to a thousand species of large vertebrates ('megafauna') across six continents. Understanding the cause of these extinctions is important for several reasons. It is the most recent substantial extinction event in the geological record; there is a background of detailed knowledge about environmental change against which to view the responses of the mammals; and humans are strongly implicated by many researchers as partial or exclusive causal agents. For all of these reasons, understanding the cause of the extinctions, and the reasons why some species survived while others did not, can provide a unique historical analogue for addressing the current biodiversity crisis. 

The two main contenders for the megafaunal extinction are vegetation change driven by climate, and hunting by humans, either separately or in combination. Although the extinction was worldwide, we will focus on Europe, northern Asia and North America as these areas have the best data on the distributions and extinction of the mammals. We will first develop computer-based simulations of local climatic conditions across the study area; for the first time climate changes will be modelled on a year-by-year basis over the past 40,000 years. Using this information we will model vegetation types across the entire area. When climate changed, vegetation changed, but our model will be crucially more realistic than previous ones in that we will allow for the lags in vegetational response as plant species expand slowly across large areas (e.g. trees may have taken 1500 years to arrive in northern Europe when climate warmed after a long cold spell). In addition, the model estimates not only the type of vegetation but its productivity, i.e. amount of growth each year, of crucial importance to herbivorous mammals. 

Many of the mammals that went extinct (such as the woolly mammoth and wooly rhinoceros) were grazing species adapted to the productive grasslands of the last glaciation, and the predators that depended on them. Many of those that survived were browsing (woodland) mammals or those of mixed habitats. We will develop, for both victims and survivors, a biological profile for each species including their body weight, reproductive rate, and preferred foods. These will be determined from living relatives and from direct evidence such as wear on fossil teeth that indicates diet. We will also establish their climatic tolerance from the range of climates they occupied in the past.

Adding the mammal fauna to the modelled climate and vegetation, and running the computer model from 40,000 years ago up to the present, the effect of climate changes on the vegetation, and the effect of both on each mammal species, will be evident. Moreover, the model will include feedback from the feeding activities of the mammals to the structure of the vegetation itself. A final element in the model is the addition of variable levels of human hunting, the distribution of people being determined from known archaeological sites. Analysis of all the data will determine if climatic and vegetational change, with or without the addition of hunting, are sufficient to account for the extinction of some megafauna and survival of others. This will be determined by comparing model results with the known pattern of range changes and extinction based on the fossil record. 

The vegetation model that we develop would also allow prediction of likely responses to future climatic changes. Similarly, the climate simulations will be applicable to other processes (e.g. the changing extent of arctic permafrost). Our results will be directly relevant to various stakeholders, informing landscape management and biodiversity conservation strategies. We will ensure that they are communicated to such stakeholders, as well as to the scientific community and wider public.",1
NE/R012938/1,14222,A systems approach to synergistic utilisation of secondary organic streams,"Food and plastic wastes from industries and wastewater from food and pharmaceutical manufacturing plants contain significant amount of valuable resources. In the UK, a total of 10 million tonnes of food waste is generated (household: 71%; manufacturing: 17%; hospitality and food service: 9%; retail and wholesale: 3%), with a value of over &pound;17 billion/year, involving 33 TWh of final energy demand and 20 million tonnes CO2 equivalent of greenhouse gas emissions. These wastes together with the embedded resources are currently under-utilised and are mostly sent to landfill. This can pose serious environmental hazards and pollution, affecting human health and ecosystems. If these wastes and resources can be recovered into useful products such as chemicals, fuels and energy, this would meet the soaring industrial and consumers' demand in the future. The current technologies and practices in the UK in treating, managing and disposing these organic wastes are not able to cope with the increase in waste generation due to rapid urbanisation. Conventional industrial practices take the resources from finite resources such as fossil fuels, turn them into products that we use for transport fuels, electricity, commodity chemicals, plastic bags, and dispose all the residues to landfill after processing. If these residues can be reused in the same manufacturing plant or sent it to another nearby processing plant, the imbalance in supply and demand of resources in the industry can easily be resolved. A holistic thinking of the needs and constraints in the urban area, industrial systems, waste management systems and ecosystems are crucial in addressing the complex problem effectively. Therefore, the objective of the proposed research is to explore the interaction between urban, ecological and industrial supply and demand, and make use of the relationship to enhance the reuse and recycling of resources. This also calls for technological advancement in industrial and waste management sstems to transform wastes into value-added products. This research will look into multiple product generation and using a combination of technologies to achieve higher performances and reduce the unfavourable features as in the existing technologies, with the consideration of the sustainability impacts on economy, environment and society. The approach will streamline the transition from fossil to bio-based economy and transformation of industrial strategies in the UK towards sustainable production and consumption patterns.",1
EP/P034594/1,27100,Redefining power generation from carbonaceous fuels with carbonate looping combustion and gasification technologies,"Following the Paris Climate Change Agreement, 197 countries, including the UK, are now obligated to reduce their anthropogenic greenhouse gas (GHG) emissions to hold the global mean temperature increase from pre-industrial levels well below 2 deg. C and pursuing efforts to limit it to 1.5 deg. C. Meeting this ambitious goal requires near-complete decarbonisation of the power sector, as it generates a third of the anthropogenic GHG emissions. To maintain its sustainability and international competitiveness, as well as to meet the environmental targets, the UK economy requires a secure supply of low-carbon electricity at an affordable cost. This is especially important in light of the forecast 30-60% increase in the peak electricity demand in the UK by 2050. Although the unabated conventional fossil fuel power systems are well-suited to flexibly meet the market demand, and thus to balance the intermittency of the renewable energy sources, they are heavy CO2 emitters. 

As there are no other technologies that could significantly reduce emissions from conventional power generation from fossil fuel, which are expected to remain in the electricity mix for the foreseeable future, carbon capture and storage (CCS) is seen as crucial to decarbonising the power sector. Yet, the integration of the most mature technologies, such as oxy-combustion and chemical solvent scrubbing, to the conventional fossil fuel power plants is predicted to reduce their electric efficiency by 7-13% points. This corresponds to an increase in the electricity cost by at least 60%. Carbonate looping, which is based on the reversible carbonation reaction of CO2 with a metal oxide, is regarded as an emerging CO2 capture technology that can reduce the electric efficiency penalties to 5-8% points. 

The main reason behind such improvement is the high-temperature operation (500-950 deg. C) of carbonate looping that enables high-grade heat recovery and a clean and efficient syngas generation. As this process can act as a standalone combustor or gasifier, carbonate looping combustion and gasification can be seen as an emerging class of technologies for thermochemical conversion of carbonaceous fuels whose feasibility, in conjunction with high-efficiency power cycles and/or solid oxide fuel cells, needs to be thoroughly evaluated. Following the results of the preliminary studies performed by the applicants and the developments in nuclear and solar power generation technologies, it is speculated that such novel power generation systems will have higher net thermal efficiency (&gt;38%HHV), lower CO2 specific emissions (&lt;100 gCO2/kWh) and affordable cost of electricity (30-60 &pound;/kWh) compared to conventional fossil fuel power generation systems.

This proposal will employ the state-of-the-art engineering procedures to develop, and assess the feasibility of, novel power generation concepts based on the emerging carbonate looping process and high-efficiency power cycles, and/or fuel cells. These concepts will be identified through a design matrix generated during screening of carbonate looping cycles, power cycles and fuel cells. Then, the process models of the sub-systems included in the design matrix will be built using first principles and validated with data retrieved from the literature. Synthesis of novel power generation concepts will be conducted by employing the process wide approach to process modelling. The initial configurations of the concepts will be revised by employing the heat exchanger network and parametric analyses. The concepts will be then assessed in terms of thermodynamic, environmental and economic performance using both deterministic and probabilistic approach. In addition, the reliability, availability and maintainability assessment will be performed. Finally, the feasibility of the novel power generation concepts will be assessed and benchmarked against the conventional fossil fuel power plants in the multi-criteria analysis.",1
NE/M012689/1,21805,The Gibraltar Archive: a half million year reference record of rainfall isotopes in the western Mediterranean,"The Gibraltar reference record will be an important contribution to the study of the Earth's past climates, an intrinsically difficult topic because information about past conditions must be deduced from indirect evidence. We shall use speleothems from caves in Gibraltar, mainly calcite stalagmites and flowstones built up as precipitates from dripping water. Their chemical composition reflects climate, and each specimen provides a layered record which may cover any period from a few decades to tens of thousands of years. To construct a longer record multiple specimens must be accurately dated, so that overlaps can be put together to form a continuous sequence. Dating relies on the radioactive decay of traces of uranium to its daughter thorium over the time since the specimen was formed. For each speleothem we shall date the oldest and youngest layers and several in between, identifying any time gaps and constructing an age model which will correlate it with other specimens. We have already assembled an archive of 24 speleothems but require 200 more dates to form them into a full composite record. Our first aim is to obtain these dates.

Our second aim is to chemically analyse every layer and interpret the results in terms of changing climates in Gibraltar over the last half-million years. Mineral chemistry thus stands proxy for the true climate. This raises two issues - which chemical variables are signals of climate, and what aspects of climate are reflected by each one? We shall measure d18O and d13C - the ratios of different types of atoms in the elements oxygen and carbon - and the concentrations of Mg, Sr, Ba, Y and P. These are all known to be partially controlled by climate, but each is also influenced by local factors such as water flow through soil and rock, or CO2 levels in cave air. Our previous work in Gibraltar separated the local and climatic influences by monitoring the modern environment for 10 years. We found that d18O in each year's deposit tracked the d18O in rainwater. However the speleothems we shall now analyse formed under different climatic conditions from today, so we must deduce the influences of climate from the shifting relations among the chemical variables during each specimen's growth, using chemical principles plus the insights from cave monitoring. On ice age time-scales temperature affects d18O as much as rainfall, and to allow for this we shall use independent records of sea surface temperature, making the assumption that cave temperatures tracked the surrounding sea. In this way we shall isolate the signal of changing d18O in rainfall from the complex chemistry of our speleothems.

Stepping up in scale from Gibraltar and its caves, rainfall d18O varies across Europe, the Mediterranean and Middle East in a pattern reflecting atmospheric circulation and the transport of rain-bearing air. Gibraltar stands between the Mediterranean and Atlantic, the former being the source of winter rain from North Africa to central Asia and the latter the main moisture source for Europe. By comparing our d18O record with existing cave records in Israel, we shall reconstruct the uptake of Mediterranean water vapour through climatic shifts on all timescales from decades up to ice ages. Also of interest are millennial-scale shifts that occurred repeatedly during the last ice age and are recorded in cores through the Greenland ice sheet as episodes of higher d18O. They show up in Gibraltar speleothems, allowing us to infer changes in circulation from the gradients of d18O up the Atlantic.

Finally, we intend the Gibraltar archive to be a yard-stick for comparison with all paleoenvironmental and paleoceanographic data in the region. It will provide a high-resolution account of climate changes on land, at the junction of two oceans, and support an emerging framework of long records that in future may feed into computer modelling experiments that will deepen our understanding of ice age climates.",1
MR/P024513/1,16560,Health in a changing climate: the dynamic challenge of snake bite in South Asia,"Snakebite is a neglected tropical disease (NTD) and despite being less well publicised and studied, has a far greater impact than many other NTDs such as dengue or leishmaniasis. There are estimates of up to 120,000 deaths per year globally with considerable additional morbidity resulting, for example, from limb damage or renal failure. This burden of disease is relatively hidden as snakebite not only predominantly affects poorer countries in the tropics and subtropics, but it also mainly affects the rural poor, particularly agricultural workers and subsistence farmers in lower-middle income countries (LMICs). 

In many countries, snakebite is seasonal and is distributed unevenly across a country because of complex interactions between human behaviour, climate, varying geography and other factors affecting snake distributions. This means that there are substantial challenges in estimating the number of deaths and complications of snakebite. National surveys are rare because they are so difficult to carry out. The variation in numbers of snakebite across countries and over any one year means that it is difficult to estimate national and regional numbers from time-limited small local studies. This absence of accurate numbers for many countries and regions means that the problem does not get the international attention that it requires and makes it extremely difficult for local public health authorities to plan appropriate health services. 

Improved methodological approaches for mapping snakebite risk are therefore urgently needed, particularly when considering the potential for global environmental and climate change to exacerbate snakebite impacts. Examples such as the peak of snakebite deaths in India during the monsoon and in Bangladesh during floods illustrate the potential for environmental factors to influence disease. In Sri Lanka, bite and envenoming patterns also vary between climatic zones, with bite and envenoming incidence changing with altitude and rainfall. Climate change is thus likely to be an important yet currently unrecognised contributor to altering snakebite risk in affected areas, potentially impacting on snakebite incidence by altering snake abdundance, distributions and behaviour, altering human abundance and behaviour or both. 

This study aims to improve the ways in which the epidemiological burden of snakebite can be estimated and mapping risk using modelling of the interactions between snake and human distributions, behaviours and environmental factors and to investigate the extent to which climate and land-use change will impact upon this burden. The study will develop and validate methodologies using data from Sri Lanka and, in future, use these approaches to improve estimations of the snakebite burden and map risk over wider geographical areas in South Asia, and predict how they may change in the future. This approach will facilitate the diversion of appropriate resources towards addressing this major problem and will provide accurate information about the distribution of the snakebite burden at relevant scales to help health managers target resources appropriately and explore interventions that will help manage this risk and its associated socio-economic impacts in LMICs.",1
NE/P020925/1,27646,RCUK-SEA: Using Nexus Thinking to Empower Community-Based Management of Mangrove Fisheries,"Malaysia formally recognises the national and international value of its mangrove resources and has awarded them extensive protection. Nevertheless, the total area of mangroves continues to decline and mangroves are threatened by environmental degradation as natural resources are traded-off against population growth and economic development. The solution to mangrove degradation no longer lies in resource protection, but in fostering understanding that mangroves are embedded within a context of complex interactions of multiple uses involving stakeholders with different interests, i.e. the mangrove nexus.

Mangroves support highly productive fisheries, but mangrove destruction has severely affected the livelihoods of fishermen who are known to be among the most economically disadvantaged in Malaysia and many other developing countries. While efforts are made at many scales by different stakeholders against mangrove fishery loss, there has been a tendency for them to work in isolation with little communication between them. Opportunities for mangrove dependent fishing communities to engage in the management of the resource on which they depend have been limited.

Through an application of nexus thinking, this project will improve understanding of the interdependencies, tensions and trade-offs between the mangroves, their associated fishery and their users, in the context of human and environmental change. The Klang Islands mangrove forest will be used as a case study. This forest (ca. 15,000ha) forms part of a larger tract of mangrove forest stretching over 100km along the coast of the state of Selangor. The coastline maintains some of the most productive cockle and coastal fisheries in Malaysia. To support the continued and sustainable use of the Klang Islands fishery and the communities dependent upon them, this project has three aims: 1) to progress the application of nexus thinking to the sustainable management of Klang Island fishery resources; 2) to set the foundations for community-based fishery management in the Klang Islands mangrove system, 3) develop a programme of environmental education emphasising the importance of mangroves.

Working with three project partners (Penang Inshore Fishermen Welfare Association, Department of Fisheries, Selangor and Wetlands International) these aims will be achieved through a series of stakeholder workshops, supported by student projects and effective knowledge exchange. The project will initiate communication between stakeholders (fishermen, government, industry and NGOs) and begin a process of empowerment that will encourage fisheries dependent communities to directly participate in fishery resource management. This will directly support the mission &quot;Creating a developed, independent and progressive fishermen community&quot; outlined by the Fisheries Development Authority of Malaysia. It will also contribute to strengthening the participation of stakeholders and cooperation between planning and implementation agencies, one of four objectives identified for the implementation of coastal zone management since the Ninth Malaysia Plan. To ensure that this project legacy can be capitalised upon, the structure and mechanisms for ongoing community engagement projects will be established (e.g. appointment of appropriate local community heads, creation of lines of communication between local fishermen associations and local government, identification of roles for project partners).",1
NE/S013318/1,35987,PEGASUS: Producing EnerGy and preventing hAzards from SUrface water Storage in Peru,"The Peruvian Andes is home to 71% of the world's tropical glaciers, and the meltwater they supply is an essential resource for people downstream who depend on it for irrigation and sanitation. Further, hydropower plants driven by glacial meltwater provide more than 40% of Peru's electricity. However, Peru's glaciers are receding rapidly, threatening this supply, as well as releasing sediment to valley areas and revealing topographic depressions that may become natural reservoirs for glacier runoff. These thawing landscapes are also very active and can pose risks to downstream people and infrastructure. PEGASUS will assess the opportunities and threats that rapidly evolving landscapes, and natural resources, will bring to the people and businesses of three glacierised Cordilleras of the Peruvian Andes - Urubamba, Vilcabamba and Vilcanota - and make recommendations that will maximise the potential prosperity that can be gained in the face of continued environmental change.
 
Modelling the climate of mountain catchments such as those in Peru is complex because of the interaction of large-scale weather systems with local-scale winds and extreme relief. Uncertainties in modelling the climate feed into projections of glacier change, which themselves are limited by a lack of data on previous glacier behaviour for calibration, and downstream river flows for validation. Robust climate modelling is also required for predictions of permafrost (freezing) heights, which are a key control on ice and bedrock stability, and thus avalanche risk. PEGASUS will produce new and refined projections of climate that will drive cutting edge glacier and permafrost models, to yield firm predictions of how the glaciers and freezing levels will change on a 5-yearly interval from now until the end of the century.

As the glaciers recede and hillslopes become more active, sediment will be released into the valleys, and lakes will develop where ice existed. Some of the sediment will be trapped within these glacial lakes, and some will be transferred downstream by river flows. The rate of sediment release by glaciers in advanced states of recession is poorly known, and the role of lakes in capturing the sediment is also poorly quantified. PEGASUS will perform field measurements and modelling to improve understanding of the role of glacial lakes in removing, conveying and storing sediment being released from the glaciers, and characterise the impact this will have on downstream water quality and critical hydropower infrastructure.

The locations of future glacial lakes can be predicted by modelling the thickness of the current glaciers and identifying subglacial depressions that will be revealed as the ice recedes. Using a Digital Elevation Model (DEM) of this ice-free terrain, it is possible to make a quantitative assessment of the hazard that these new lakes, as well as existing glacial lakes, pose to downstream areas if they were to burst catastrophically. PEGASUS will carry out this assessment for the largest lakes in the Urubamba-Vicabamba-Vilcanota study area and then undertake additional fine-resolution and physically-based numerical modelling to robustly quantify the effects of flooding and debris flows on people, land, the downstream river dynamics, and hydropower infrastructure.

PEGASUS will then identify the barriers and opportunities that exist to the use of these lakes for water storage and hydropower development. This assessment will integrate consultations with government (CORECC), a large hydropower company (EGEMSA) and, crucially, communities living in the catchments of the lakes we have analysed. The recommendations that follow will provide information on the sustainability of existing and future hydropower schemes, how to manage water use in future decades and formulate policies that reflect the needs of all stakeholders, and the potential hazards that unstable mountain environments may pose to lives and livelihoods in future years.",1
NE/L013444/1,2912,"Ice shelves in a warming world: Filchner Ice Shelf system, Antarctica","That our planet is warming is undeniable. Recent increases in greenhouse gas concentrations have seen an associated warming of the atmosphere and oceans, a reduction in the total amount of snow and ice and a rise in sea level of approximately 3 mm/year. Although the precise rate of future temperature rise may be uncertain, there is little doubt that it will increase. 

In response to a warmer climate, large areas of the Antarctic Ice Sheet could become unstable, resulting in sudden and permanent loss of ice. Indeed for one relatively well-studied region, the Amundsen Sea Sector, this may already be underway. However, our understanding of the processes, the likelihood of collapse and the potential impact on sea-level remains poor, especially in the very different climatic regime of the Weddell Sector. This project aims to address what will happen in the near-future to a region that spans one fifth of Antarctica and the impact changes here could have on global sea-level by the end of this century. We aim to do this in three stages:

We will study and understand the intricate relationships between the atmosphere, the ocean and the ice sheet in the important Weddell sector of Antarctica, which contains Filchner Ice Shelf and its catchment basins. We will determine how the atmosphere determines the ocean conditions, and how these in turn determine the melting at the base of the ice shelf. In a carefully designed field campaign we will collect data both to improve the way the models work, and also to validate their results. This first stage will yield a system of models that gives a detailed representation of the physical processes currently at work, and by using the natural variability in the system we will determine the sensitivity to change of each linked process.

The next step is to force the boundaries of our modelled system with the best available estimate of the atmospheric and oceanographic properties expected over the 21st century. We will then be in a position to determine how the ocean conditions beneath the ice shelf will change, together with the rate of melting at the ice shelf base. As the melt rate changes, so will the ice shelf geometry: we will determine how the rate of ice flow from the continent responds to these changes, and its impact on sea-level rise.

In the final stage we will widen the scope of the study from our large, yet still regional area, to a global context. The models to be used in the first two steps, (atmosphere, ocean and ice) are high resolution, state-of-the-art but limited-area models. We will work with our Project Partner, the Met Office Hadley Centre (MO), to incorporate our improved understanding of processes and their sensitivities within the next generation of global earth-system predictive models. Finally, we will assess the reliability of our predictions. This will be done first by ensuring consistency between the different regional models, run both within the project and by our project partners at the Alfred Wegener Institute in Germany. We will then use a limited ensemble of runs of the new generation of MO coupled climate models to quantify the uncertainty in our predictions of the contribution of the Antarctic Ice Sheet to sea level change.

The future contribution of the Antarctic Ice Sheet to sea level rise remains the least well constrained component in the budget. By bringing together from across the community leading experts in polar meteorology, oceanography, ice-ocean interaction, glaciology and model uncertainty, this project will provide the largest single improvement in the prediction of future sea level change. New observations and data are essential, but expensive. Rather than using costly commercially-available infrastructure, AWI and NERC will share the logistic burden with the project delivering excellent value as a result.",1
105146,42871,OPTI-BEEF: precision agricultural solution to monitor lifetime productivity and product quality,"&quot;There is currently extensive inefficiency in the UK beef sector. Producers routinely assess the performance of their animals by eye and frequently retain them on farm too long, resulting in animals becoming too fat. This leads to increased variable farm costs, reduced annual capacity of beef finishing units and sub-optimal price paid for carcasses -- for a finishing unit producing 300 animals per year this equates to a cost of &pound;11,400\. Over-fat animals also increase the primary processing costs for abattoirs and have a higher environmental impact per kg of product produced.

The price paid to the producer for a beef carcass is also predominantly assessed subjectively by eye. Lack of confidence in the reliability of carcass evaluation makes it difficult to agree quality-based payments that reflect the true value of carcasses.

This project aims to develop on-farm and in abattoir technologies to automate and optimise on-farm selection of animals for slaughter and carcass evaluation. The project will integrate automated data gathered across the whole life of individual beef animals (from calf to carcass) to create an enhanced decision support platform to modernise and drive efficiency improvements across the UK beef supply chain.&quot;",1
ES/S011692/1,18009,"Taking the environment seriously in production network research, policy and practice: Insights from Kenyan horticulture","This proposed research maximises the academic and non-academic impact of PhD research on the environmental, economic and social dimensions of Kenyan horticultural farmers participation in production networks. Fresh fruits and vegetables is one of Kenya's foremost foreign exchange earners, and over 12 million farmers depend on the sector for their livelihoods. Kenyan farmers face a very challenging environment, needing to simultaneously address the effects of changing trade patterns and environmental change. Much horticultural trade occurs through value chains, which are a series of linkages from the initial stages of production or farms, through processing and intermediaries and ultimately to retailers and consumers. While Kenyan farmers can find particularly lucrative opportunities through exporting to European and other developed country markets, they need to comply with stringent private standards with escalating environmental requirements which are mandated by global (or Northern) supermarkets. At the same time, regional supermarkets within East Africa are expanding and have their own standards requirements, including with environmental dimensions. Standards can threaten farmer livelihoods, while climate variability and extremes tend to further marginalize farmers' from selling into global and regional markets. The research addresses the socio-economic-environmental implications on how farmers participating in different value chains struggle with different environmental pressures.
The fellowship will build on PhD research involving a rigorous, mixed-method approach, including 106 key informant interviews, six focus group discussions and a survey of 579 farmers across four counties in Kenya (Murang'a, Machakos, Nyandarua, Meru) where snow peas, garden peas, avocados and mangoes are produced. It demonstrates that farmers' ability to environmentally upgrade, i.e. use greener products and processes in farming and adapting to climate change, varies immensely between farmers exporting to Europe compared to those selling regionally.
A central aspect of the programme of activities during the fellowship will be three articles for high impact journals on how farmers are embedded in different production networks, how they can upgrade and on regional entrepreneurial farmers. A research visit to Kenya will provide an essential opportunity to maximise the non-academic impact in relation to Kenyan horticultural communities and policymakers. It will also enable new pilot research on an emerging challenge within the Kenyan horticultural sector - Agtech and Foodtech as part of the 4th Industrial Revolution. This pilot research will provide initial insight into how new digital technologies may restructure horticultural value chains, setting a basis for future research projects. In addition to engagement events with sustainability standards' stakeholders in Europe, I will make a visit to Copenhagen Business School to collaborate with a leading researcher on the environment and production networks. 
The fellowship will have a strong knowledge exchange component, focused on two key audiences - a sustainability standards stakeholders in Brussels, Geneva and London; and Kenyan horticultural policymakers and communities. A series of stakeholder meetings, workshops and policy notes will be conducted to exchange the research results with these groups. My findings will thus be used to shape legislation in Kenya on standards and contribute to creating resilient livelihoods for farmers. The fellowship provides an opportunity to make a significant contribution to emerging research on environment and production networks within academia, and to provide an evidence base to inform decision making in policy and practice. In sum, this fellowship is an excellent stepping stone to disseminating my research, building new networks and partnerships and learning new communication skills to be a successful researcher.",1
NE/P016375/1,22517,Expedition 363 West Pacific Warm Pool: planktonic foraminifer biostratigraphy and the evolution of Pulleniatina,"This grant supports the participation of UK scientists Professor Paul Pearson in Expedition 363 of the International Ocean Discovery Program which plans to study the history of the 'Indo-Pacific Warm Pool' over the last 15 million years. It includes costs to cover his time while on board ship (2 months at sea) and post-expedition scientific study.

Sea surface temperatures exceed 28oC across a huge area of the tropical western Pacific and Indian Oceans. Known as the Indo-Pacific Warm Pool (IPWP), this area is fundamental to the global atmospheric circulation and hydrologic cycle. The IPWP is intensifying with global warming, but modelling its likely future is challenging. Expedition n363 aims to study its temperature and climatic history over the past 15 million years, including through glacial to interglacial climate cycles and back to the globally warm Miocene epoch. Understanding its past history will help determine if its current temperature is near to its likely maximum or if global warming can cause much greater intensification in the future.

Professor Pearson is a specialist in the study of microscopic fossils called planktonic foraminifera. He will study the evolution of the ocean plankton in the region over the study period, in relation to climatic change and sea level fluctuations which greatly affect the distribution of land masses and shallow seas and hence ocean current patterns. The foraminifera are also used to determine the age of the sediments drilled (called biostratigraphy) and providing other expedition scientists with a high quality planktonic foraminifer biostratigraphy will be one of the main features of this project. In additional there is a particular focus on an evolutionary lineage of foraminifera called Pulleniatina which has considerable untapped potential for stratigraphic work and also as a case study in the detailed speciation and extinction of a group of plankton. Study of this group will be facilitated by the large populations and varying morphology exhibited by them and because, like snails, they can be left or right handed and the pattern of coiling through time and across space is highly complex and potentially very informative.",1
NE/M004295/1,12014,Vegetation Effects on Rainfall in West Africa (VERA),"Rainfall is the climatic parameter of greatest importance to the populations of the tropical continents. The arrival of monsoon rains drives a rapid transformation of the landscape, allowing crops to grow and river networks to refill. Yet predicting where and when rain will fall in the tropics is a notoriously difficult problem. Progress has been made in predicting how remote ocean conditions, such as El Nino, can affect rainfall in different parts of the tropics. However local factors such as vegetation also play a role. For example, when tropical forests are cut down for agriculture, we have evidence that this affects rainfall both locally, and across neighbouring countries. Indeed, climate scientists have to take into account future deforestation rates as well as greenhouse gas emissions when they assess how tropical climate will change in the 21st century.

Vegetation affects rainfall through the process of transpiration. When plants absorb carbon dioxide for photosynthesis, they lose water from their leaves. Trees are able to extract this water from several metres below the surface using their deep roots, allowing them to continue photosynthesising for months without rainfall. Crops and grasses on the other hand start to run out of soil water during dry spells, which reduces transpiration. Instead the solar radiation absorbed by the plant canopy raises the air temperature. Replacing forests with crops and grasslands changes the rates of moistening and heating of the atmosphere, particularly when the shallow-rooted species start to run out of soil water. These changes in turn affect the development of winds, cloud and rain.

The details of how the atmosphere responds to vegetation is an area of significant scientific debate. Firstly, there is evidence that clearing patches of forest may increase rainfall over the cleared area and reduce it over the remaining forest, depending on the particular weather patterns. On the other hand, new results have shown that as air masses cross the continent, they pick up additional moisture from forests, which then leads to more rain several hundred kilometres further downwind. Finally, by controlling the balance between heating and moistening of the atmosphere, the vegetation can affect the winds bringing moist air off the ocean, delaying or extending the rainy seasons which characterise tropical climate.

Although these 3 vegetation effects are each known to affect rainfall, we rely on computer models of the vegetation and atmosphere to understand how they might work in combination. Capturing the essential physical processes within a model is very challenging. In particular, there are large and long-standing uncertainties in the description of cumulonimbus storms (thunderstorms, which dominate the rainfall of many tropical regions) within the models. However through recent advances in computing power, we are now able to run these models for entire seasons with sufficient spatial detail to properly capture storms.

In this project we will use data from satellites and the latest weather and climate models to get to the heart of how vegetation affects rainfall. Focusing on West Africa, one of the most climatically sensitive regions of the world, we will examine cloud and vegetation observations from the last 30 years to detect where deforestation has changed rainfall, and how the rapid greening of the savannah each year affects the monsoon rains. We will perform new computer simulations, incorporating the detailed development of thousands of individual storms, and examine what happens when we artificially deforest a region in the model. These results will allow us to assess the performance of the somewhat cruder models used to forecast climate change globally. By focusing on specific processes in the climate system, our results will help to improve these models, and at the same time provide robust conclusions on deforestation to guide land managers.",1
EP/P012493/1,19806,Listening to Infrastructure,"Infrastructure is vital for society - for economic growth and quality of life. Existing infrastructure is rapidly deteriorating, the rate of which will accelerate with increasing pressures from climate change and population growth, and the condition of the large majority of assets is unknown. Stewardship of infrastructure to ensure it continuously performs its function will be a colossal challenge for asset owners and operators. The performance of new infrastructure assets must be monitored throughout their life-cycle because they are being designed and constructed to withstand largely unknown future conditions. The UK must be better prepared to face these grand challenges by exploiting technology to increase understanding of asset deterioration and improve decision making and asset management. 

This research is central to EPSRC's priority area of Engineering for Sustainability and Resilience. The goal is to transform geotechnical asset management by developing new, low-cost, autonomous sensing technologies for condition appraisal and real-time communication of deterioration. This new approach will sense Acoustic Emission (AE) generated by geotechnical assets. AE is generated in soil bodies and soil-structure systems (SB&amp;SSS) by deformation, and has been proven to propagate many tens - even hundreds - of metres along structural elements. This presents an exciting opportunity that has never been exploited before: to develop autonomous sensing systems that can be distributed across structural elements (e.g. buried pipes, pile foundations, retaining walls, tunnel linings, rail track) to listen to AE - analogous to a stethoscope being used to listen to a patient's heartbeat - and provide information on the health of infrastructure in real-time. The idea to use AE sensing to monitor geotechnical assets in this way is novel - it is expected to lead to a disruptive advance in monitoring capability and revolutionise infrastructure stewardship.

AE has the potential to increase our understanding of how assets are deteriorating, which could lead to improved design approaches, and to extract more information about asset condition than existing techniques: not only deformation behaviour, but also, for example, changes in stress states, transitions from pre- to post-peak shear strength, and using correlation techniques it will be possible to locate the source of AE to target maintenance and remediation activities. AE sensing will also provide real-time warnings which will enable safety-critical decisions to be made to reduce damages and lives lost as a result of geotechnical asset failures.

The number of asset monitoring locations required per unit length to achieve sufficient spatial resolution will be less than other monitoring techniques, and significantly lower cost. Piezoelectric transducers, which sense the AE, are now being developed at costs as low as a few tens of pence per sensor - this recent technological advance makes this research timely. AE sensors could be installed during construction to monitor condition throughout the life-cycle of new-build assets (e.g. HS2), and retrofitted to existing, ageing assets.

This will be the most fundamental and ambitious investigation into the understanding of AE generated by SB&amp;SSS yet attempted. The findings will mark a major leap forward in scientific understanding and our ability to exploit AE in novel asset health monitoring systems. The fellowship aims to develop robust diagnostic frameworks and analytics to interpret AE generated by geotechnical assets. This will be achieved using a powerful set of complementary element and large-scale experiments. The outcomes will be demonstrated to end-users and plans will be developed with collaborators for: full-scale field testing with in-service assets to demonstrate performance and benefits in intended applications and environments; and implementation in commercial products that could have significant societal and economic impact.",1
104978,35634,Bifacial PV Albedo Research,"&quot;Bifacial solar panels (BFPV) are designed to allow light to enter and power to be generated from both sides. Moreover, they are often more durable because both sides will be made UV resistant, and potential-induced degradation concerns are lowered when using a frameless structure.

Unfortunately, there are also issues that are limiting the wide adoption of the new, more efficient technology. While for measuring the performance of traditional PV modules there are already international standards, no standard exists for BFPV. Furthermore there is presently much uncertainty in the calculation of energy output of BFPV. As a consequence, the risks for investors increase and limit the proliferation of BFPV.

PV has always been a priority in UK but unfortunately, the incentives cuts have slowed down new investments. There is a need for more efficient technologies to make the PV market more self-sustainable and preserve the thousands of related job places.

The mini-project builds on the cooperation between RINA and the National Physics Laboratory (NPL), with the aim of developing an innovative method to perform yield studies, with reduced uncertainty on the output of solar PV systems, over their lifetime. The mini-project focuses on a key problem in assessing the energy output of BFPV plant: the accurate evaluation of the effect of albedo.Thanks to more reliable albedo measurements, the technical and financial risks of investors are reduced, consequently boosting the investments in BFPV.

The key objectives of the project are:

1\. Evaluation of the effect of spectral albedo on BFPV yield modelling accuracy.

2\. Determination of reliable spectral albedo data sources for use in BFPV system yield modelling

3\. Determination of the requirements of spectral albedo data for BFPV system modelling.

4\. Determination of the financial impact of replacing the effective albedo data with spectral albedo data in BFPV system modelling.

Benefits from the project will affect the whole value chain of energy, from generation to consumption. More reliable yield prediction will encourage investments, generating not only more power but also new jobs in direct and satellite activities. The higher efficiency guaranteed by the BFPV technology will favour a decrease of electricity price for consumers. Finally, the increased share of PV energy in UK scenario will have a positive effect on the environmental impact, reducing the CO2 emissions.&quot;",1
2268871,41694,3D Nanostructured Thermoelectric Materials,"The world's energy consumption is reaching 16 terawatts and is predicted to triple by 2050.
Meeting this huge demand along with great concerns over climate change has now led to an urgency for the development of cleaner and renewable energy sources. Thermoelectric (TE) materials are systems that can directly convert thermal waste heat into electrical energy. It has potential to make significant contribution to the development of low carbon power generation highlighted in the Clean Growth Strategy of the UK Government. In order to achieve this goal, a key challenge is to improve the efficiency of TE materials and reduce manufacture cost. The success in this endeavour will lead to wide scale applications in power generation and efficient cooling of thermoelectric technology beyond the current niche markets (example: spacepower generation and cooling laser diodes or infrared detectors). This project seeks to develop a new breed of 3D thermoelectric metamaterials that have controlled nanostructured features upon the 100 nm scale, allowing unprecedented control over electronic and phononic properties and offering a highly controlled pathway for understanding the effect of nanoscale topology. 

The project involves the manufacture of novel 3D nanostructured thermoelectric materials using two-photon lithography. The fabricated samples will be subject to standard physical characterisation such as scanning electron microscopy and atomic force microscopy. Furthermore, the electronic and thermal properties of 3D TE samples will be measured using both nanoscale scanning probe measurements and bulk transport measurements. The student will also benefit from interactions with theorists at Exeter University. Ultimately, the project will develop a new breed of TE devices with a step change in performance.",1
NE/T00908X/1,38120,The GeoX Suite: Environmental cells for NERC research using in situ imaging,"Improving our understanding the natural world; how it has evolved, how it continues to evolve, and how it responds to human impacts and climate change are the main goals of all earth and environmental researchers. This work allows improvements in global stewardship, hazard mitigation, and more sustaiable resource management.

In recent years the development of very powerful x-ray imaging techniques allows us to see inside our samples without destroying them; meaning we understand the internal structures of rocks, soils, ice, plants, animals and man-made materials better than ever before. However, the most cutting edge systems allow us to collect images in just fractions of a second and allow us to put experimental equipment inside the imaging equipment. This means that with the right experimental equipment we could improve our understanding of the processes themselves: by watching them happen. 

Imaging our geological samples under the relevant geological conditions could help us answer some of the outstanding challenges in earth and environmental research: working at high temperatures we could capture how bubbles drive volcanic eruptions; using pressurised fluid cells we could look at how corals adapt to changing ocean conditions; by imaging while we compress rocks under very high loads we could improve our understanding of fracture propagation during earthquakes; by working at low temperatures we could identify the processes controlling glacier movement or greenhouse gas release from melting permafrost, by imaging soil during wetting and drying we can understand how structure controls nutrient supply and drought resistance in plants; and if we combine pressure and temperature and deformation we can investigate how best to identify, extract and manage critical subsurface resources such as oil, gas, water, metals, minerals, and heat. 

This proposal will deliver the GeoX suite of experimental apparatus to do just that; allowing earth and environmental researchers to gain new insight and understanding into how the planet works. The GeoX suite includes aparatus that lets us heat and cool our samples, lets us deform them till the break, lets us inject fluids into them or extract fluids from them, or do all of these thindgs at the same time. This means we can investigate almost every environment we are interested in. 

The reserach done using the GeoX suite could ultimately help us improve our food and energy security, move towards a low carbon and low waste economy, reduce the impact of pollution in soils and sediments, preserve fragile ecosystems and environments, mitigate the effects of climate change, build more sustainable cities, and improve our ability to forecast and manage the risks and effects of natural events such as extreme weather, volcanic eruptions and earthquakes.",1
NE/P019730/1,5373,RELEASING DIVALENT CATIONS TO SEQUESTER CARBON ON LAND AND SEA,"The natural response of the carbon cycle to the warming induced by increased atmospheric CO2 features two negative feedbacks that remove CO2 from the atmosphere. One, caused by the greater acidity of the oceans, is for carbonate minerals to be dissolved, which causes an increase in the ability of seawater to contain carbon (as the bicarbonate ion). The other is for warmer conditions to increase the rate at which silicate minerals dissolve, with the products either precipitated as carbonate minerals, or flowing to the oceans. This silicate weathering also removes CO2 from the atmosphere.

Intentional acceleration of these two weathering feedbacks is a potential approach to remove the CO2 added to the atmosphere by burning of fossil fuels, and therefore alleviate extreme climate change. Such an approach is challenging, however, because to be useful at a significant scale (i.e. 1-10 GtC pa removal), requires a dramatic increase in weathering relative to natural rates. Whether such accelerated weathering is a feasible route to remove significant atmospheric CO2 is unknown. This proposal will address this unknown, and provide a comprehensive assessment of the feasibility of CO2 removal by accelerated weathering, including consideration of the technical, economic, environmental, and societal aspects of the approach.

The core of our work will be a life-cycle assessment of the enhanced-weathering approaches that might lead to 1-10Gt removal of CO2 per year. This modelling will start from the availability of minerals for weathering, paying particular but not exclusive attention to waste materials from industries such as mining. It will consider how the weathering of these minerals might be enhanced, either through treatment in mining waste piles or, in collaboration with project partners, by addition to soils. It will also consider the fate of the weathered materials, either as carbonate on land or in the sea, or as alkalinity in the sea. It will assess the economic cost of such approaches, the energy requirements, the environmental damage they would cause, and the societal limitations on such approaches (e.g. social acceptability, political, legal, governance).

In some key areas, understanding is not yet sufficient to allow this life-cycle assessment. We will address these gaps in knowledge by five specific pieces of research. These will:
1. Characterise how much waste material is available for enhanced weathering, including its location, its grain size, and its chemistry and mineralogy. This is critical information to underpin the life-cycle assessment.
2. Measure how quickly typical minerals weather and how this weathering rate changes with temperature and, particularly, through addition of microbes that are known to cause accelerated weathering of silicates.
3. Assess how best to scale up weathering to the 1-10GtC pa level. This will be done by both modelling of possible engineered approached to weathering, and by experiments on piles of silicate and carbonate minerals (each of 10 cubic meters), in which the conditions are altered and responses measured.
4. Assess the response of the ocean to increased alkalinity resulting from enhanced weathering. If more carbonate is produced in the ocean, it reduces the effectiveness of enhanced weathering; we will measure the rates of both inorganic and biological carbonate formation and their impact in the C cycle globally.
5. Consider how society will response to possible scenarios for accelerated weathering, and whether this may limit such an approach. Will enhanced weathering be socially acceptable? Will there be the political will to pursue it? Are their legal or governance barriers?

Information from these five &quot;research components&quot; will provide critical information for the life-cycle assessment, and thereby allow the overall potential and challenge of enhanced weathering CO2 removal to be fully assessed.",1
1814189,684,Alternative Carbon Fixation Pathways in Cyanobacteria,"The carboxylation step of oxygenic photosynthesis is catalysed by Rubisco - converting RuBP, CO2, and H2O into 2 molecules of 3-PGA as per the Calvin (CBB) cycle [1]. Rubisco also catalyses a side-reaction with O2 (photorespiration), producing one molecule each of 3-PGA and 2PG [2,3]. This reaction is undesirable as 2PG is energetically costly to recycle [3,4] and inhibits central metabolic reactions [2,5,6,7], reducing the productivity of oxygenic photosynthesis.
O2 is a competitive inhibitor of CO2 [8,9], hence increases to atmospheric CO2 should favour the Rubisco carboxylation reaction. However, as the rate of photorespiration increases with temperature [10], carbon assimilation is becoming less efficient due to global warming. This has impacts for agriculture - compounding the effects of pollution, desertification, and population growth on food security. At current atmospheric CO2 levels, photorespiration rates are approximately 25% [11]. Therefore, even if solutions to global warming are found, the capacity to improve on photosynthetic productivity remains. 
There are six known naturally occurring carbon fixation pathways [12]. Of these, only the 3-Hydroxypropionate bi-cycle (3HP) is oxygen tolerant [13,14,15] - and thus suitable to replace the CBB cycle. Oxygen tolerant synthetic carbon-fixation pathways are being developed [16].
A cyanobacterium model organism (Synechocystis PCC. 6803) has been selected for this project, for ease of genetic manipulation and it's fast growth rate. As Synechocystis and plants perform photosynthesis in a similar way, this work is a proof of concept that can be adapted into plants. However, plants lacking carboxysomes [17], and not producing vitamin B12, vital to 3HP bi-cycle function, are could cause limitations to research translation [18]. 
The 3HP bi-cycle was modelled into Synechocystis using Flux Balance Analysis (FBA) and predicted a 30% growth rate improvement compared to the CBB cycle [19,20]. Further work is needed to validate results. 
A thermodynamic model for Rubisco will be produced to better study the photorespiration-temperature relationship [10]. A comparative genomics aspect of the work will be used to predict novel carbon-fixation pathways. 
This project will use the Golden-Gate modular cloning system to implement the 3HP bi-cycle into Synechocystis. The flexible design properties of this method should help address problems found during previous studies [19], and enable solutions to potential downstream problems. Due to limitations in adapting Golden Gate systems to Synechocystis in previous work [21], the Gibson assembly method will be used in parallel. 

Bibliography
[1]Bassham, et al.1954. JACS.76,1160-1170. [2]Anderson.1971. BBA - Enzymology.235,237-244. [3]Bauwe et al.2010. Trends Plant Sci.15,330-336. [4]Maurino &amp; Peterhansel.2010. Curr Opin Plant Biol.13, 249-256. [5]Busch.2013. Plant Biol.15, 648-655. [6]Peterhansel &amp; Maurino.2011. Plant Physiol.155, 49-55. [7]Kelly &amp; Latzko.1976. FEBS Lett.68, 55-58. [8]Bowes &amp; Ogren.1972. JBC.247, 2171. [9]Peterhansel, et al.2010. ASPB. 8,e0130. [10]Ku &amp; Edwards.1977. Plant Physiol.59, 986-990. [11]Busch.2013. Plant Biol.15, 648-655. [12]Bar-Even et al. 2010. PNAS.107, 8889-8894. [13]Herter et al.2002. J. Bacteriol.184, 5999-6006. [14]Herter et al.2002. JBC.277, 20277-20283. [15]Zarzycki et al.2009. PNAS.106, 21317-21322. [16]Schwander et al.2017. Science.354, 900-904. [17]Kaplan &amp; Reinhold.1999. Annu Rev Plant Physiol Plant Mol Biol.50, 539-570. [18] Helliwell et al.2011. MBE.28(10), 2921-2933. [19]Cotton.2016. Introduction of an Alternative Carbon Fixation Cycle into Synechocystis sp. PCC 6803. Doctor of Philosophy(unpublished). Imperial College London. [20]Chua et al.2017. Flux Balance Analysis of Alternative Carbon Fixation Pathways and Photorespiration in Synechocystis sp. PCC 6803. PLOS(submission). [21] West.2017. Alternative Carbon Fixation Pathways in Cyanobacteria. MRes(unpublished). Imperial College London",1
NE/R004528/1,15303,Fingerprinting 'El Nino Costero': a unique opportunity to document the signature of an extreme flood event in northern Peru,"The northern coast of Peru has been experiencing anomalously warm (4-5C) sea surface temperatures (SST). These high SSTs have produced intense and prolonged rainfall that has resulted in extensive flooding, and on the 26th March 2017, the Rio Piura in northern Peru burst its banks leading to loss of life, displacement of people and damaged infrastructure. Peru is intimately linked to the El Ni&ntilde;o-Southern Oscillation (ENSO): fishermen first identified El Ni&ntilde;o in the late 19th Century off the north coast of Peru. The phenomenon driving this current acute rainfall event has been dubbed 'El Ni&ntilde;o Costero' or Coastal El Ni&ntilde;o, but is not El Ni&ntilde;o per se as it is not being driven by anomalous SSTs in the central Pacific (Ni&ntilde;o 3.4), which generally defines the onset of El Ni&ntilde;o. Rather it represents more local (Ni&ntilde;o1+2) El Ni&ntilde;o-like conditions last known to have occurred in 1925, which is considered the most intense flooding of the 20th Century. Despite Peru's preparedness for the global El Ni&ntilde;o in 2016, the country appears to be overwhelmed by the sudden shift from La Ni&ntilde;a drought to the intense rainfall of El Ni&ntilde;o Costero, suggesting this type of locally driven El Ni&ntilde;o event has hitherto been overlooked. It is essential to establish a record of El Ni&ntilde;o Costero alongside ENSO, especially as the 1925 event was the most extreme on record. If local SSTs cause El Ni&ntilde;o-like conditions and play an important part in climate dynamics in northern Peru, but have so far been overlooked, then we don't have a full understanding of tropical Pacific climate change. Critical to understanding equatorial Pacific climate change are records of extreme flood events that reflect El Ni&ntilde;o-type behavior, and in particular how El Ni&ntilde;o Costero fits within the wider climate picture. This proposal is based on a unique opportunity to quantify and determine the dynamics and evolution of a large magnitude flood, and to use its sedimentary signature, coupled to climatological data over the l unequivocally fingerprint and calibrate past El Ni&ntilde;o-type events in recent lake sediments. We will (a) undertake a geophysical survey of lakes in the Rio Piura catchment that act as repositories of flood-waters and sediments, and we will identify modern flood sediments and determine their depth and extent; (b) recover and survey surface sediments related to flooding to characterize their flood signature using grain size, geochemistry and mineral magnetics; (c) recover and date short sediment cores from our survey lakes and directly compare the flood signature of the 2017 El Ni&ntilde;o Costero to the 1925 event, as well as putting it in the context of 20th Century ENSO variability. Our study will provide a framework for reconstructing El Ni&ntilde;o-related flood events from lake sediments over the recent past in northern Peru, but has the potential to establish a much longer-term (Holocene and older) history of all El Ni&ntilde;o variability in the region.",1
NE/P000053/1,10188,Impact of an extreme rainfall event on solute and sediment dynamics in a mineralised river system,"Over the weekend of 5 - 6 December 2015 the most intense rainfall ever recorded in the UK fell over parts of Cumbria, peaking at 341.4 mm over a 24 hour period at Honister Pass, resulting in widespread flooding. It is now widely acknowledged (e.g. statement to the media in December 2015 by Rory Stewart MP) that such 'flash flooding from intense rainfall' (FFIR) events are likely to become more frequent in the UK due to the effects of climate change. Prior to the floods of 5-6 December 2015, Newcastle University researchers spent several years measuring the effects of varying flow conditions on the amount of polluting metal and sediment discharged from the Coledale Beck, some 10 km due north of Honister Pass. These metals include zinc which is toxic to fish along with cadmium and lead that are toxic to most flora and fauna. At the head of the Coledale Beck lies the abandoned Force Crag metal mine (a rain gauge at the mine showed that 223.8 mm of rain fell in a 24 hour period during the weekend of 5-6 December 2015). A novel treatment system, completed in April 2014, treats some of the polluted water that emerges from the mine. Nevertheless, although the treatment system works efficiently, we know that some pollution of the Coledale Beck persists, mainly as a result of metals discharged to the river from other locations around the mine site. These sources arise primarily from sediments in the abandoned spoil heaps and in the river itself. The flash flooding of 5-6 December resulted in wholesale changes to the geomorphology of the Coledale Beck. Large volumes of sediment were carried down the river, whilst new sediments were exposed due to landslides and erosion. Because we already hold baseline data relating to the export of metals and sediments under different hydrological conditions from the Coledale Beck, we are uniquely positioned to now investigate how such extreme rainfall events change the whole-system dynamics of metal and sediment cycling in such upland river catchments. In particular, due to the geomorphic impacts of the December 2015 floods on the Coledale Beck system it will be possible to evaluate how exposure of new sediments influences the behaviour of metals. This is important because the form of metals in rivers (their 'partitioning') determines the readiness with which they may be carried downstream, and also influences their toxicity to the ecology of such rivers. These issues in turn have implications for users of water further downstream (e.g. fisheries, utility companies). Because hydrological extremes are likely to increase in the future as a result of climate change, we need to understand how these events change the physical and chemical characteristics of rivers, so that it is possible to plan adaptive strategies to better deal with such events. The research will be undertaken by collecting samples of waters and sediment along the length of the Coledale Beck on 10 separate occasions, thereby ensuring that samples are collected across a range of flow conditions. The results will be compared with baseline data previously collected, to determine what changes in patterns of metal and sediment movement are caused by extreme events. These results will be complemented by laboratory tests and geochemical modelling to help us assess the likely toxicity of the sediments and metals in the river to aquatic life. The intended outcome of this research will allow transfer of the results of the work to other river systems. There are 450 such rivers in England and Wales negatively impacted by abandoned mine pollution. The research is urgent because rivers are dynamic systems with key changes being driven by high magnitude events. However to properly understand the effects of flash flooding events such as that of 5-6 December 2015, it is critical to undertake sampling and analysis as soon as possible after the event itself.",1
NE/L010992/1,13576,"South Asian methane emissions, inferred from surface, aircraft and satellite observations","Methane is a powerful Kyoto Protocol regulated greenhouse gas and has the second largest radiative forcing after carbon dioxide. Globally, a large fraction of methane emissions are naturally occurring from sources such as wetlands and termites. In South Asia, natural wetlands are a smaller but still significant source of methane compared to the larger anthropogenic sources such as rice paddies, ruminants, fossil fuel emissions and biomass burning. Global average emissions of methane are generally well constrained but in order to specifically quantify emissions from South Asia, measurements taken in close proximity of South Asian sources are required. To fulfill this objective, a measurement site in Darjeeling, India was established in 2011 to measure methane on-site and collects over 70 measurements per day. In this project, methane emissions from each source sector (fossil fuel, wetlands, cattle, etc) will be quantified using surface, aircraft and satellite observations of methane concentration over South Asia.

Satellites currently measure methane concentrations around the globe and are powerful tools because of their global coverage, while surface sites only measure at one location. The main limitation with satellites is because they can be prone to errors in areas where clouds and dust can mask the methane signal. One of the avenues of research that will be done in this proposal is to combine all of the surface, aircraft and satellite measurements together and use the combined data to provide information on the quality of the satellite observations over South Asia. This will help to better understand how these satellite observations can be used over this region in the future. 

One of the main sources of atmospheric methane in India comes from rice paddies, also known as anthropogenic wetlands. The process that governs these emissions is similar to that occurring in natural wetlands. When water covers the surface of the soil, oxygen is deprived to lower layers of the soil. In these &quot;anoxic&quot; zones, bacteria metabolize organic matter in the soil through a pathway that leads to methane production. However, the human influence on water management, fertilizer use and other agricultural practices makes rice paddy methane production a very different problem from a naturally driven wetland process. For example, humans artificially alter the water table level through the use of irrigation. Farmers also add additional nutrients into the soil, providing more organic matter and nitrogen for bacteria to utilize than would be found in a natural wetland. Furthermore, rice paddies are often created in areas that wouldn't otherwise contain wetland and thus are artificially introduced. 

One of the main objectives of this research is to improve our understanding of the processes that drive methane emissions from wetland sources in India (from both natural wetlands and rice paddies). I will employ a &quot;wetland&quot; model, modified to include agricultural practices, to simulate emissions from the ground as well as a model of atmospheric transport to link the processes producing methane in the soil to the measurements that we make in the atmosphere. These atmospheric observations will be used to improve the processes in the wetland model. Using this tool, I will produce the most accurate and up-to-date methane emissions estimates, from all sources, from the Indian subcontinent. Finally, I will project emissions of methane from rice agriculture in India to the year 2100 using projected rice-growth and future climate scenarios such as those used in the Intergovernmental Panel on Climate Change Fifth Assessment Report (IPCC AR5).",1
NE/P002692/1,26545,Will fertility loss at high temperatures determine species responses to climate change?,"The climate is warming, and this is predicted to result in an increase in extremes of temperatures. Understanding how this will affect the survival and distribution of organisms is vital if we are to prevent massive losses of species, and invasion by harmful pests. The impacts of climate change are often estimated by examining the temperatures that kill animals. However, this may be flawed. In most animals, from beetles to birds to badgers, males typically lose their fertility at a far lower temperature than that required to kill them. If increasing temperatures cause all the males in a population to become sterile, then that population will not survive, even if the temperatures are nowhere near high enough to actually kill any animals. Unfortunately, there has been very little systematic investigation of this, so we do not know whether this possible impact of increasing temperatures on male fertility really is likely to be a threat to nature.

We will rectify this situation by examining the impact of ecologically relevant high temperatures on fertility in male Drosophila fruit flies. We focus initially on a model species, D. pseudoobscura, to provide a detailed examination of how temperature impacts on fertility. We will determine the impact of high temperature and extreme temperature shocks on male fertility, and whether cooler night time temperatures can restore fertility. In many insects and reptiles, after mating with a male, females may store sperm for weeks, months or even years. In some cases the females are better at maintaining the sperm at extreme temperatures than the males are, as male insects of many species often die quicker than females in harsh environments. We will examine whether female sperm storage can ameliorate the impacts of temperature on male fertility. Most importantly, this study on D. pseudoobscura will allow us to work out standard techniques to evaluate these impacts of temperature on male fertility generally. 

With the knowledge gained from this case study, we will then examine how temperature impacts on fertility in a panel of 50 Drosophila species, carefully chosen to cover a range of lifestyles, habitats and temperatures, including tropical species, temperate species, and species that have spread worldwide. Most importantly, all these species are really well known, with excellent data about the climates they live in, and the temperatures they can survive in the laboratory. We will work out the fertility impacts in all 50 species, and then be able to correlate this with the distributions of the species. If the fertility data predicts the climates where the species are found in nature better than the high temperature fatality data other people have already collected, then we will know that male fertility really does impact on where species can survive in nature. We should also begin to be able to predict which groups it is particularly likely to be important for. For example, we might find that species where males mate many times in their lives, in which males typically have large testes and produce huge numbers of sperm, may be better able to remain fertile at extreme temperatures. Species where males typically mate only a few times in their lives may easily be rendered infertile. Alternatively, species restricted to areas where temperatures vary very little (such as rainforests) may be particularly vulnerable to temperature extremes, whereas species that regularly encounter rapidly changing temperatures may remain fertile even in extreme conditions.",1
NE/S003614/1,5796,Detection and Attribution of Regional greenhouse gas Emissions in the UK (DARE-UK),"In order to mitigate the effects of climate change, governments, private companies and individual citizens are taking action to reduce emissions of greenhouse gases (GHGs). Our project will provide new information that can be used to better evaluate the change in emissions that result from these actions. We will help the UK government track the effectiveness of emissions reductions policies that have been implemented to meet the targets laid out in the Climate Change Act (2008), which mandates that GHG emissions are reduced by 80% below 1990 levels by 2050.
 
The UK has played a major part in recent scientific and technological advances in emissions reporting and evaluation. Its GHG emission inventory, which is compiled based on data relating to human activities and rates of emission from each activity, is world-leading. Furthermore, the UK is one of only two countries that regularly submits a second estimate of emissions, those derived from atmospheric measurements, as part of its annual United Nations Framework Convention on Climate Change (UNFCCC) submission. This second &quot;top-down&quot; estimate can be used to assess where uncertainties lie in the inventory and where further development is needed. However, limitations exist in our scientific knowledge and in our technical capabilities that prevent the UK, or any other country, from further improving its emissions reports through the incorporation of atmospheric data. Through the NERC Greenhouse Gas &amp; Emissions Feedback programme, which ended in 2017, we demonstrated the ability to quantify the UK's net national GHG fluxes using atmospheric observations. However, we have not yet been able to separately estimate fossil fuel and biospheric carbon dioxide sources and sinks, or determine the major sectors driving changes in the UK's methane emissions. This proposal will develop new science to address these needs, and pave the way towards the next generation of GHG evaluation methodologies. Our work will span four key areas:

1) Improving models of emissions from individual source and sink sectors to determine when and where GHG emissions to the atmosphere occur from both natural and anthropogenic systems.
2) Utilising new surface and satellite atmospheric GHG observations, such as isotopic measurements of methane and carbon dioxide, and measurements of co-emitted or exchanged gases (oxygen, carbon monoxide, nitrogen dioxide and ethane) to provide information on emissions from different sectors.
3) Utilising enhanced model-data fusion methods for making use of these new observations and for better quantifying uncertainties.
4) Integrating data streams to determine the highest level of confidence in the UK's emissions estimate.

To improve the transparency of national reports, scientists and policy makers have been strongly advocating for the combination of such methods in the reporting process. The UNFCCC, at its 2017 Conference of Parties, acknowledged the important role that emissions quantified through atmospheric observations could have in supporting inventory evaluation (SBSTA/2017/L.21). Through our close links to the inventory communities in the UK and around the world, the IPCC and to UK policy makers, we can ensure that our work will be used to update and improve the UK's GHG submission to the UNFCCC and will showcase methods of best-practice.",1
132957,18420,A3C Carbon Capture,"Carbon dioxide is a major greenhouse gas and methods of capturing these emissions from power stations and

industry are being developed. Studies have shown that without capturing our carbon emissions it will be very

much more expensive to meet our decarbonisation commitments. However the changing mix of power plant

and growing role of renewable technologies is making conventional carbon capture processes appear less

attractive while industrial application is restricted by process complexity and high costs.

The future generation mix will comprise renewable and nuclear generation supported by fossil fuelled power

stations working when power from nuclear and intermittent sources cannot meet demand. PMW Technology

has brought together concepts from other sectors to create a disruptive carbon capture technology that is

about half the cost of the alternatives when applied to this future generation mix. Working with academics

from Chester and Sheffield Universities and industrial partners, PMW Technology will validate the process and

map its characteristics to target future development on the most effective design to remove carbon cheaply.",1
EP/R010986/2,39893,From atoms to plant: co-production of green transport fuel and levoglucosan from waste biomass,"Converting biomass waste to bio-products will simultaneously provide a route to waste-disposal, and a process for the production of useful, economically attractive products. Within all the products derived from biomass waste, liquid hydrocarbon transport fuels are promising for the UK to meet its 2020 renewable energy target of providing 10% of its transport fuel from renewable sources. They will help to tackle the challenges of climate change and the ever-increasing fuel demand.

The current waste-to-liquid technologies, however, are facing main problems of high production cost and technical uncertainty. To address these problems, we will develop a breakthrough technology in this project. This novel technology will co-produce liquid transport bio-fuel and one value-added bio-chemical. By doing this, high economic profits will be expected when comparing with conventional liquid bio-fuel plants. The co-production system will additionally benefit to the reduction of the biofuel's high oxygen content, which is known as the main source that leads to poor stability, immiscibility and low calorific value of the produced fuel.

The integrated production system will be designed and evaluated within this project, with the involvement of three universities (Queen's University Belfast-QUB, Aston University-AU, and North China Electric Power University-NCEPU), three academics, one PDRA, and two PhDs (one is funded by QUB, the other is funded by NCEPU). The project is also highly industrial geared by directly involvement of two UK-based companies: Hirwaun Energy Ltd, who will provide a pilot scale biomass pyrolysis reactor for results validation, and Green Lizard Technologies Ltd, who will provide suggestions on the technology scale-up.

Through the development of this innovative technology, high national impact will be realised to achieve the UK's 2020 Renewable Energy targets through the conversion of over 16 million tonnes per year of the UK's lignocellulosic biomass into advanced fuel together with value-added co-products. It will also have a positive impact on the UK's target of reducing carbon dioxide emissions and increasing the use of renewable materials.",1
BB/S019669/1,44994,UK Crop Diversity Bioinformatics Resource,"We are requesting a High-Performance Computing (HPC) cluster that will be dedicated to support and expand the work that of a consortium of six leading UK research organisations with a focus on the characterisation and utilisation of novel genetic diversity for both the improvement of current crops as well as the breeding of novel varieties. The platform will be open to researchers at the participating institutions and their extensive network of collaborators. We will also develop and deploy common genomics workflows relevant to the common interests of the partners in crop diversity informatics. 

Developments in sequencing and genotyping technologies together with advances in environmental monitoring and characterisation are leading to rapid changes in the opportunities that are available to evaluate and utilise genetic diversity in crop plants and their wild relatives to adapt to the changing landscape of agriculture. This is driven by the increasing impact of climate change as well as by evolving agricultural practices and commodity demand. UK Research Organisations host a wide range of key expertise and information resources that have the potential to play a critical role in ensuring that this potential is fully realised. A major factor in developing the research infrastructure to support and nurture such activities is the provision of access to suitable computational resources that are tailored to the key data resources and analytical tools that that play a central role. A consortium of UK Research Organisations including NIAB, Royal Botanic Gardens, Kew (RBGKew), the Natural History Museum (NHM), the James Hutton Institute (JHI), Royal Botanic Gardens, Edinburgh (RBGE), and Scotland's Rural College (SRUC) have identified a need for additional computing resources beyond what they already host individually, centred on BBSRC-funded work around crop diversity. An high-performance computing (HPC) resource focused on the common needs of our organisations and tailored to the software and data resources which are relevant to this mission will deliver efficiencies in the use of resources, both in terms of computing hardware and systems administration. In addition, it will act as a focus for sharing data, developing new methods of analysis and delivering training, and a platform for developing new collaborative programmes of innovative science. Within the partner organisations alone, the platform will support the work of more than 400 scientists including a large proportion of early career researchers and PhD students. We propose to host the facility at JHI's data centre.",1
NE/S01120X/1,44617,ScotIce - How fast could ice caps collapse?,"Average surface air temperatures have been rising everywhere on Earth over the last century and are predicted to continue to rise for at least the next century. One of the clearest indicators of this warming is the shrinking of glaciers and the marked reduction of sea ice in the Arctic, where atmospheric warming is most pronounced. Melting of sea ice does not contribute to sea level rise, but meltwater from land-based glaciers and ice caps ends up in the oceans and is a major contributor to sea level rise. How fast will glaciers and ice caps melt? Will they disappear in decades, adding all of their water rapidly to the oceans, or will the melting occur over a longer time span, with a less rapid but ultimately the same amount of sea level rise. For the 150 million people living within 1 m of high tide, and those concerned about maintaining trillions of pounds worth of global coastal infrastructure, answering the question of how fast glaciers and ice caps will melt and contribute to sea level rise is important.

ScotIce will determine how fast ice caps can melt by analysing the collapse of the ice cap that existed in Scotland about 11600 years ago and disappeared at a time when temperatures rose by 8C, the same as the temperature rise predicted for the Arctic by 2100. By measuring how quickly the ice cap disappeared we will learn how fast present day equivalent sized ice masses subjected to similar warming could disappear, thus providing data needed for sea level rise models to make more informed predictions.

To quantify how fast the Scottish ice cap collapsed we need to be able to determine the rate of change of the former ice mass. We will use surface exposure dating with the cosmogenic nuclides 10Be and 26Al produced in the mineral quartz in rock by cosmic rays, that is, when the rock is exposed to the sky. Conversely, the production of the nuclides in quartz stops when the rocks are covered by a few metres of ice. Surface exposure dating is the only technique available to directly date when landforms become exposed as ice melts. We will measure the concentration of these nuclides in glacially abraded and plucked rock surfaces and glacially transported boulders, located at the maximum, intermediate and minimum extent of the ice cap. Because we know how fast the cosmogenic nuclides are produced in quartz, we can use the measured cosmogenic nuclide concentration to determine when the sampled rock surface became exposed from under the ice. In other words, we can determine when the ice disappeared from the sample site. The age difference between the maximum and minimum ice extent provides the retreat rate which will be integrated with independently dated climate proxy archives to look for causal relationships.

To be able to test the hypothesised rapid collapse of the Scottish ice cap we first need to improve the surface exposure dating technique from the current routine 2-3% to 1% or better measurement precision for 10Be and 26Al. Analytical improvements to the accelerator mass spectrometry (AMS) that is currently used to measure 10Be and 26Al will allow us to resolve the rate of ice cap collapse. However, there are some questions for which AMS is unlikely to provide the necessary precision. To resolve if the decline of the ice cap was steady or episodic requires the development of an entirely new methodology for measuring 26Al by positive ion mass spectrometry (PIMS) being pioneered at the Scottish Universities Environmental Research Centre (SUERC). Developing Al PIMS has the potential for leading to a paradigm shift in how Earth and Environmental scientists determine the rate of natural processes and date landscapes. 

ScotIce empirical data on ice cap collapse will inform predictive sea level models, while improved AMS precision and new Al-PIMS has the potential to revolutionise surface exposure dating and open up new fields of research for the UK and international science community.",1
NE/N01247X/1,27190,Nordeste: New science for a neglected biome,"The northeast region of Brazil is relatively dry compared to the rest of the country, with unusually irregular rainfall patterns and associated frequent droughts. The soils there tend to be relatively fertile and so, despite crop failures sometimes occurring in drier years, the area is reasonably densely populated with about 15% of Brazil's population living there; but under what are generally impoverished conditions. This has led to extreme land-use pressures on the natural vegetation and widespread degradation of remaining lands.
As in other parts of the world with similar soils and climate, the natural vegetation of the area is a form of deciduous scrub, known locally as Caatinga. Probably because Caatinga typically lacks the complexity and grandeur of moist tropical forests, this vegetation type has been to a large extent neglected to date both in terms of conservation programmes and scientific enquiry. This neglect has serious consequences given the enormous destruction of the Caatinga, which exceeds that of the neighbouring biomes of Amazonia and the Cerrado. Because of their potential importance in future warmer and drier climates in Brazil, conservation of the plant species of the Caatinga, which are adapted to high temperatures and seasonally erratic rainfall, is vital. 
Designed as an integrated research program involving both Brazilian and UK researchers 'Nordeste' will attempt to redress this neglect:
1. Through the establishment of a permanent plot network similar to that existing in moist tropical forests, allowing measurements of Caatinga canopy structure and dynamics and both their short- and long-term responses to climate change to be evaluated for the first time.
2. With the aid of new DNA barcoding measurements designed to better quantify the biodiversity of the region.
3. Through a comprehensive analysis of the biogeochemistry of natural and disturbed ecosystems to develop an understanding of how nutrient cycling processes vary in response to variations in soils and climate and human activity
4. Via a series of detailed structural, physiological measurements across the wide range of different Caatinga sub-types found in the region. These will be made both above- and below-ground and in natural and degraded ecosystems of the region. A special emphasis will be placed on measurements designed to help us understand why it is that under certain circumstances it is that very high biomass stands of Caatinga occur despite the very low rainfall. 
5. Glasshouse experiments comparing water stress responses of seedlings native to moist forest, savanna and caatinga will also be undertaken in order to try and understand what specific metabolic adaptions are involved in plant adaptions to frequent and/or erratic conditions of extreme soil water deficit.
6. Via an integrated modelling program to provide new parameterisations of surface fluxes for semi-aid ecosystems in general and to provide new insights into variations in woody plant shoot: root allocation patterns in response to variation in precipitation regime.
To achieve these aims, the project has been designed as a series of six inter-related field-based workpackages, with a seventh workpackage focussed on modelling of species distributions, ecosystem fluxes and developing a mechanistic understanding of caatinga vegetation functional responses to both variations in climate and soil properties. 

Designed with a view to also producing a series of well-defined products to assist both policy makers and local communities to better manage this unique resource - for example, online guides to ecologically dominant and economically useful plants, the study will serve to provide a valuable first step towards a better understanding of Caatinga vegetation and its responses to anthropogenic and land-use change pressures.",1
2287903,38403,"Agroforestry, soil health and delivery of public goods","Agroforestry is the practice of deliberately growing trees in combination with arable crops and/or pasture on the same piece of land. It is seen as a sustainable land management practice, where trees and agriculture co-exist to provide multiple benefits. Therefore growth and innovation in agroforestry has the potential to improve farmland productivity, resilience and diversity while maintaining and/or improving the provision of other ecosystem services, via improving soil health, sequestering carbon and slowing water runoff. While long-established in sub-tropical and tropical climates, uptake of agroforestry in temperate agricultural systems has been slow, particularly in the UK. In order to realize this potential, there is urgent need for greater understanding of how planting trees in temperate agricultural systems impacts upon soil health indicators and thus helps to reduce flooding and mitigate climate change. While literature reviews have shown that agroforestry can increase the amount of carbon stored in the soil and thus help to mitigate climate change, the majority of studies (~80%) were located in tropical and sub-tropical climates, with less than 20% in temperate climates. It is unclear how long it takes to see an improvement in soil health and whether planting trees on pastures has the same benefit for soil health as planting trees on arable land. Recent studies in the UK have shown that planting trees on farmland can increase soil infiltration rates. However, these studies were carried out at one site. In addition, it is not clear if similar impacts would be observed in lowland agricultural systems; highlighting the need for further research. The major aim of this project is therefore to determine the impact of agroforestry on soil health, in particular its impact on soil carbon storage, soil structure and hydrological properties.",1
ES/P007406/1,29141,Strategic Network: New National Planning for Sustainable Development in the Global South,"Summary
This initiative addresses a key challenge faced by developing country governments as they seek to achieve the 17 UN Sustainable Development Goals agreed in September 2015. Many of these countries are seeking to guide their own development through a set of processes, policies and practices that can usefully be termed the 'new national planning'. Following an era of often ritualistic national planning, the 1980s and 1990s saw the very idea of producing national development plans as discredited. This was partly due to a lack of local ownership and commitment to plans produced, but also due to donors and international financial institutions promoting more market and less state centred ways of achieving development goals. While the 2000s saw the return of something approaching a comprehensive policy framework for development in the form of national Poverty Reduction Strategy Papers (PRSPs), there is now evidence that national development planning has firmly come back into vogue. Our initial research shows that over 100 countries, a majority of them in the global south (including many of the largest and fastest growing), have a national development plan or similar document. These are usually very different from the formalistic national development plans of the 1960s and 1970s and involve much greater use of measurement, evidence and modelling. This is a renewed interest and belief in National Planning albeit in a very different globalised context characterised by unpredictability and complexity. The Sustainable Development Goals will be implemented through locally driven plans that take into account this global complexity and uncertainty and yet reflect the priorities and contexts of individual UN member states. Planning approaches cannot therefore be the same as before and indeed our preliminary dataset is showing the emergence of new ways of planning that strive to cope with uncertainty and complexity. 

This new national planning has attracted little research interest, yet there is growing evidence that it has implications for how countries respond to the global and local challenges confronting them. Little systematic mapping of national planning processes and outcomes has been done and there is limited understanding of the processes shaping the new national planning at the national or global level. Neither the World Bank nor the UN, for example, have assembled comparative studies or datasets. More importantly, some crucial questions are emerging not least related to whether this new national planning produces better national ownership, accountability and ultimately better development outcomes than did either the PRSPs or the previous generations of planning (or non-planning). Our partnership will investigate this topic through a cross-disciplinary research/practitioner network and will strengthen capability for research and innovation across seven ODA recipient countries. We will establish a multi-disciplinary network of scholars, practitioners and policy makers who will analyse and better understand this re-emergence of national development planning in the global south. This strategic network on the 'new national planning' will create a new research and knowledge community that understands how national planning helps governments to achieve the Sustainable Development Goals in an era of complexity and uncertainty brought on by combined effects of forces of globalisation and climate change. The network will analyse development plans and create: an analytical framework for comparing plans; a detailed database of this new generation of plans; (at least) seven detailed case studies of the new national planning in ODA countries: and, a comparative analysis of National Planning in the 21st Century. The network will bring together policy makers, researchers and other development actors to identify key areas for future research and actively seek funding to establish a major applied research programme.",1
EP/P030831/1,22037,Surface Engineering Solid State Dye-Sensitized Solar Cells,"Dye-sensitized solar cells (DSC) can be described as a form of &quot;artificial photosynthesis&quot; because, in both cases, light is harvested by a pigment (chlorophyll in photosynthesis or a synthetic dye in DSC). This is interesting because photosynthesis is ~5% efficient in terms of the incident light energy (i.e. photons) captured to the energy in the photosynthetic by-products. Despite this apparently low efficiency, photosynthesis has supported the planet's biosphere for aeons. One reason for this is the huge amount of sunlight which reaches the Earth's surface every day. This has been estimated to be ~6,000x more than annual global energy consumption despite the growing global population using huge amounts of energy. Given that the sun will last for billions more years, sunlight is vastly more abundant than any other energy source currently available. In this context, if we use 10% efficient PV, using only 0.2% of the Earth's surface would meet energy demands whilst releasing only trace greenhouse gases during production and none during operation. This will slow the accelerating pace of fossil fuel related climate change.

Whilst PV uptake has increased hugely recently (~11GW in UK and &gt;225GW globally), this still represents a tiny fraction of current energy demand; the question is why? Crystalline Si PV currently dominates the market (~90%) but is heavy, rigid and is usually made from batch-like processes into limited product forms (rectangular, encapsulated, glass panels). And despite these products being available for many years, they are still bolted onto frames attached onto existing roofs with wires often running across open roof-space. They do not fit, they are a &quot;bolt-on&quot; solution.

This research will develop PV which can be printed by continuous (roll-to-roll, R2R) processing. Because R2R is faster than batch processing, it will reduce manufacturing costs but increase the amount of product which can be made. R2R product can also be made to any length or width which will revolutionise PV product form. Perhaps most importantly, by varying the PV substrate, this will enable PV to be fully integrated into roof/wall panels or windows. This will drastically reduce installation and balance of systems costs (i.e. PV panel mounting system, DC/AC power inverters, wiring, switches, battery storage) which make up almost half of the cost of most PV installations. 

DSC technology is already in commercial production (www.gcell.co.uk) and is already known to be suitable for R2R processing. In addition, DSC raw materials are non-toxic and abundant. Whilst DSC device lifetimes &gt;25,000h have been reported (equivalent to ~25y operation), the liquid electrolytes used can leak and are corrosive to some metals which increases substrate costs. This proposal will exchange this liquid electrolyte for a solid, charge carrier to make solid state DSC (ssDSC) devices to avoid these issues. 

Whilst ssDSC have been made before, it has been difficult to control their construction because this involves depositing 2 thin layers of different chemicals onto porous metal oxide particles in a porous film. The resulting inconsistent layer coverage causes energy losses which limits device efficiency. To overcome this, we will use self-assembling molecules and computer modelling to explore surface chemistry/structure to speed-up the research. Thus, we will design dyes and charge carriers to behave like &quot;self-parking cars in a car park&quot; and move to the correct position before fixing themselves in place. Then, by controlling the self-assembly process, we will add multiple dyes into the device to increase light harvesting to improve device efficiency to reduce pay-back times; i.e. the time when the customer has saved enough money on their energy bills to pay off the system purchase costs. By combining computer modelling and experiment, we will cut design to manufacture times up to 10-fold by reducing the number of material modification cycles required.",1
EP/P010237/1,29171,Workshop: Introducing Zero-carbon Construction Sites (WIZCS),"Construction sites, as work places, use energy for two main purposes. The first is to provide lighting and/or heating for site offices and other site cabins; and power for office equipment, kettles, microwave ovens, hand tools, mobile telephones and other small electrical appliances. The second is to provide power for construction plant.

Energy used currently on construction sites leads to substantial carbon emissions. At any one time, there are tens of thousands of construction sites in the UK and their energy demand is huge, as is the amount of carbon emissions they produce. The need to reduce carbon emissions from all aspects of human activity is universally accepted and the construction industry needs to make its contribution to reducing carbon emissions. This makes construction sites legitimate targets for efforts to reduce carbon emissions.

There are initiatives driven by the Climate Change Act 2008 and European Union's Energy Performance in Buildings Directive such as the zero-carbon homes initiative that target the operation phase of construction projects. However, there is no specific effort, to date, targeted at reducing carbon emissions from construction sites that focuses on the energy used on the construction sites.

This workshop is based on the idea that the construction phase of construction projects presents an unexplored area of investigation with respect to reducing carbon emissions. The workshop is primarily designed to respond to this perceived gap in the body of knowledge and introduce the idea of zero-carbon construction sites (ZCS) and plan the agenda for the diffusion of the idea, via a zero-carbon construction sites scheme (ZCSS), as a means of facilitating a step-change in reduction of carbon emissions in the construction industry.

The workshop will be the first to bring together researchers interested in the intersection between construction site operations and zero-carbon energy. The researchers will include specialists in construction management, wind energy and solar energy and other low carbon or non-fossil fuel energy technologies. They will also include specialists in policy design and formulation. The workshop will bring these researchers together to interact with construction contractors and research and technology organisations as well as governmental and quasi-autonomous non-governmental organisations in order to define the research agenda about achieving zero-carbon construction sites.

Unlike other workshops that run for a day or on consecutive days, this unique workshop will be run over two days separated by a period of two weeks. The interval between the workshop days is included in the workshop design to promote reflection and consultation about the new agenda in order to maximise understanding and support for the post-workshop activities among the key participants. This is important because post-workshop activities will be the true measures of success of the workshop.

The workshop will be run using approaches such as break-out groups, open forums, brain storming and interrogative discussion. The approaches were chosen because of the potential to maximise chances of realising the envisaged impacts.",1
ES/P006671/1,22852,Governing Inclusive Green Growth in Africa,"The green economy has significant potential for delivering inclusive economic development in Africa; however the dynamics of this potentially paradigm-shifting phenomenon are poorly understood (Borel-Saladin &amp; Turok 2013, Mudombi 2013, Death 2014, ECA 2016). Comprising researchers from multiple disciplines, (from UK, Africa, and India), African think tanks, civil society organisations and government departments, the proposed Network aims to lay the foundation for a robust assessment and understanding of the dynamics of green growth governance in Africa and the implications for sustainable economic transformation in the continent. Particular attention will be paid to understanding key challenges for leveraging green growth as a means to tackle inequality and poverty plus interventions that can be honed to transcend existing barriers to deliver results at scale and enhance sustainability. 

Prompted by national circumstances and their international development partners, many African countries have started to embrace the concept of green growth. Countries such as Rwanda, Ethiopia, Kenya and South Africa have sketched ambitious plans to decouple economic growth from environmental pressures and 'leapfrog' to green, sustainable economies. For example, Ethiopia's ambitious, multi-sectoral Growth and Transformation Plan (GTP) to bring the country to a middle-income status within 10 years, runs alongside the Climate Resilient Green Economy (CRGE) strategy. The CRGE's principal aim is to achieve a high rate of economic growth without increasing the country's GHG emissions. However, till date, very little study has examined green growth in Africa with the result that significant questions need to be asked. For example: (i) what are the current greening activities taking place in Africa? (ii) in what ways do putative green economy activities represent a significant departure from 'business as usual'?; (iii) are green growth activities displacing, being mainstreamed or co-existing with 'brown' development?; (iv) what is the impact of national green growth strategies on inequality and poverty in Africa?; (v) what are the key motivations of African leaders and governments seeking to be front-runners in this area; and what are the reasons for reluctance among the slow or non-movers?; (vi) what are the environmental, technology, innovation, and ethical implications of greening? (vii) what is the local and international political economy of greening in Africa and who are the key actors?; (viii) what are the capacity needs required to achieve scale?; (vii) what are the successes, challenges, synergies and trade-offs associated with greening in Africa, how do these differ across countries, and what lessons can Africa learn from other developing countries?

Through a series of collaborative activities including: (i) workshops, (ii) mapping of existing green growth initiatives in Africa, (iii) initial political economy and socio-technical analysis; and (iv) an initial technology and capacity gap assessment, the network will lay a foundation for future research work in understanding the dynamics, prospects and limits of the green economy in Africa. Capacity will be built through collaborative planning, mentoring, and peer networks. Partnership with a leading research and policy think tank in India will promote South-South cooperation. Although our work will address issues on a continent-wide basis, our primary focus will be the following three countries: (i) Ethiopia, which is pursuing an ambitious growth agenda and greening strategy, simultaneously; (ii) Kenya, which has also made notable attempts to embrace the concept of greening development and is currently the first and only African country that has signed a national legislation on climate change; and (iii) Nigeria, the most populous and biggest economy in Africa, which has made some efforts at greening but is generally considered a laggard in this area (Okonkwo &amp; Uwazie 2016).",1
2245822,35500,"Towards an Integrated Marine Policy, Heritage and the Environment","The previous work in my masters dissertation characterised and classified the various approaches taken to the protection, conservation and management of underwater heritage in the UK and Bulgaria, through: identifying where they are lacking with respect to internationally accepted best practices; identifying a multidisciplinary approach that would be both generally applicable and offer more efficient and effective protection. My PhD aims to build on from this work through:
- a more specialised and informed study of underwater cultural heritage management systems globally (aided by working with the UNESCO 2001 Convention on the Protection of Underwater Cultural Heritage Secretariat in Paris)
- using this knowledge to create and potentially apply an integrated marine heritage management template to industry standards that addresses these identified issues
- creating an integrated, multidisciplinary global database accessible to all marine asset stakeholders which aims to collect, analyse and distribute live information, with the aim to better conserve, manage and propagate underwater assets.
The human population is expected to reach 10 billion by 2050. Due to the increasing population there have been a number of defining social, environmental and economical issues surrounding the conservation of the world's underwater assets including heritage, fish stocks, biodiversity and marine ecology. The management of underwater assets such as these is critical and complex due to various global threats such as climate change and rising sea levels. In relation to this, the ocean space is becoming more valuable to various industries such as renewable energy, land expansion, fishing, offshore oil, and various other human resources. 
There is clear urgency in working towards better conserving the world's underwater assets, as has been documented throughout various disciplines that work within the underwater environment. In despite of this, as indicated in the aforementioned masters dissertation, there are various inconsistent and often ineffective management systems that lack communication and particularly integration throughout the different disciplines and industries that work within the ocean sector. 
By working within the UNESCO 2001 Convention secretariat, a unique understanding of the industry from multiple perspectives will be achieved. Through gaining a professional understanding of a globally active heritage management organization such as this, knowledge of previous, current and future management successes and failures may be utilized to create a more effective integrated management template and database system - of which none currently exist. 
There is a proliferation of academic papers suggesting that a more effective integrated management system is crucially necessary to successfully manage our oceans. However, there is limited academic knowledge on the pathways to establishment and implementation of such a system. This PhD aims to create a single resource based on the current advantages and disadvantages of ocean management systems around the world which will: 
a) provide an understanding and detailed analysis of the complexities of ocean space management
b) create a systematic, integrated underwater resource management template and run a testing period to assess success
c) create an integrated database system which acts to store, analyse and share data from all ocean based industries and disciplines with an aim to educate, predict and aid in the effective management of the ocean space",1
1941538,32164,The Big Chill - Observing and modelling cold air outbreaks,"In this project you will investigate cold-air outbreaks using a number of case studies gathered from aircraft-based field campaigns. You will run the Met Office's Unified Model (the MetUM) at high resolution to simulate these cases and make use of the detailed in-situ observations to challenge the model forecasts. You will test various new model parameterizations, for example, testing the 'blended' 3D/1D turbulence scheme; testing new developments in cloud microphysics parameterization; and simulating cloud streets (Liu et al. Geophysical Res. Lett. 2004). The MetUM is a state-of-the art numerical weather and climate prediction model, which is used for operational weather forecasting, seasonal forecasting and climate modelling on all scales. Consequently your research with the MetUM is expected to lead to direct improvements in these applications. You may also make use of a 'Single Column Model' version of the MetUM, which is simpler to run and allows controlled single point experiments. 

The observational data includes one cold-air outbreak case from GFDex (the Greenland Flow Distortion Experiment; Renfrew et al., Bull. Amer. Meteorol. Soc., 2008) in which the aircraft followed a Lagrangian 'air parcel', thus allowing sources and sinks of heat and moisture to be accurately observed. It also includes several cold-air outbreak flights from the ACCACIA project (flying over sea ice around Svalbard in the Arctic during March 2013), and from the PIKNMIX project (flying over the sea between Iceland and the UK). Several case studies will be chosen for closer examination and simulation. You will also have the opportunity to take part in a major international field campaign focused on the Iceland and Greenland Seas in March 2018, when new aircraft-based and ship-based boundary-layer observations of cold-air outbreaks will be made. The Iceland Sea is relatively little-studied, but this is now changing, as we are discovering it plays a critical role in creating and transporting dense water from the subpolar seas into the North Atlantic and this role is now being affected by Arctic sea-ice retreat (Moore et al., Nat. Clim. Change, 2015; and see https://theconversation.com/declining-winter-sea-ice-near-greenland-spells-cooler-climate-for-europe-42976). This field campaign will enable a considerable step forward in our understanding of these processes, and your contribution will contribute to furthering our understanding of the role that cold-air outbreaks play in this critical region.",1
ES/S015264/1,38979,ORA (Round 5) Understanding Climate adaptation policy lock-ins: A 3 x 3 approach,"Adapting to worsening impacts of climate change is one of the biggest global challenges. Yet, limited action on the part of public authorities still prevails; institutions, infrastructures, technologies and societal behaviours appear resistant to change. Understanding this gap requires better knowledge of the way societies are governed, but the existing literature often overlooks this, going no further than describing 'barriers to change'. Better explaining what we term 'lock-ins' requires uncovering the dynamics that create and sustain them. That is the aim of this original and cross-disciplinary study. Taking an empirical, but theoretically reflective, approach, it examines three policy sectors central to climate adaptation - water management, health care, and biodiversity and nature conservation - in three countries: Germany, Netherlands and the UK. Although in principle all three are well equipped to deal with climate adaptation, each is subject to lock-in. The project will use a mixed methods approach to understand why lock-ins arise and persist in each instance, and will employ Qualitative Comparative Analysis to better understand the dynamics of lock-ins as they affect climate adaptation. It will confront observed (in)action with different approaches for explaining lock-ins, advance conceptual and empirical understanding of how lock-ins emerge and endure, and use the findings to provide informed recommendations for the design of more effective adaptation policies.",1
NE/P01531X/1,31052,"Megacity Delhi atmospheric emission quantification, assessment and impacts","Inventories of emissions of pollutants to air form the basis for model predictions of air quality, visibility, human exposure, human health impacts, and climate change. They are further required to understand relationships between individual source locations or source types and targets. None of the model predictions and analyses can be better than the emission database on which they are founded. This project seeks to greatly improve the emissions inventory for the wider Delhi area, one of the most polluted conurbations globally. The emission inventory will be compiled at a 1 km x 1 km resolution with diurnal and seasonal temporal profiles. It will cover NOx, SOx, NH3, total volatile compounds with breakdown into its chemical profile, particulate matter in fine (PM2.5) and coarse (PM10) size ranges, together with the toxic metal components within, as well as CO2 and CO as combustion tracers.
 To improve the emission inventory we will make laboratory-based measurements of emission factors and also measure, for the first time in India, the emissions from individual vehicles under real-world driving conditions to characterize the actual Delhi vehicle fleet. We will further perform the first micrometeorological flux measurements of these compounds above the city and study their enrichment along a transect. This will provide further information on potentially missing sources and serve as a direct assessment of the quality of the emissions inventory. 
 We will further apply a state-of-the-art chemistry and transport model to infer the concentrations that would be expected on the basis of the new emissions inventory for comparison against concentration data from air quality networks and the wider NERC-MRC-MoES-DBT programme.

ODA compliance:
By providing the emissions data required to assess human exposure and develop cost-effective solutions to combat air pollution in Delhi, the project will target poverty and development issues. Accurate knowledge of emissions is a key factor underpinning the development of mitigation strategies which will deliver improved public health, whilst further allowing economic growth. Both the UK and Indian research teams will benefit from their interaction and exploitation of complementary expertise. The project will leave a legacy beyond the project lifetime by increasing the research capacity of the Indian teams and providing the knowledge base which will allow the findings to be extrapolated to the rest of India. Thus, the project findings will continue to contributing to the improvement of life and welfare of more than a billion people.",1
NE/P008860/1,26397,Precision Soil Mapping,"In order to produce the amount of food required for an ever expanding population, farmers need to maximumise yield while minimising input costs. Precision farming - a concept based on responding to spatial and temporal differences within fields - has been adopted as a key tool by approximately one quarter of all arable farmers in the UK. It is thought that another 25% utilise some precision techniques but are not currently managing the differences within their fields, but rather just recording data. Studies have shown that variably applying seed and fertiliser, based on different soil properties, consistently give positive results. A two year experiment of variable rate nitrogen fertilisation at Cranfield University proved that detailed maps of soil fertility collected with an on-line soil sensor can result in &pound;50 per ha. net profit to the farmer when integrated with data on crop growth. Similarly, research from the Intelligent Precision Farming (IPF), one of AgSpace's software customers, has shown variably applying seed can produce 34% more yield. However, implementation of precision farming has traditionally been a labour intensive process thus making it cost prohibitive for many growers. The current practice of precision agriculture lacks high resolution, low cost soil maps that would enable farmers to manage in-field variations. With current advances in proximal and remote sensing technology and modelling of multi-data resources, it is possible to produce these maps to enable the implementation of advanced precision farming products on a wider scale, making them affordable to a larger market. To increase yields to the levels being discussed by the Royal Society (60% by 2050) requires a collaborative approach.

This large scale collaborative project aims to integrate satellite data with the UK's most comprehensive soil datasets to produce a 'precision soil map'. The map so produces would present an economically viable alternative to current soil survey methods, hile making use of these existing datasets. The level of data and technology available presents a very exciting proposal for arable and vegetable farming to embrace precision farming, enabling them to increase production efficiency, with reduced environmental impacts and at lower input costs. The reduction of environmental impacts will be largely achieved by reducing the amount of agrochemicals applied into the soil, so benefiting ground waters and surface runoff.

AgSpace will provide the raw satellite data for this project, and also ground-truthed data gathered from experimental farms. Cranfield University and the James Hutton Institute will provide access to England and Wales and the Scottish soils datasets, respectively. The project final product is a 'precision soil map' accessible to farmers at a resolution unrivaled in the UK. The new soil management zone map will enhance farmers' understanding of their own soil and will provide an economical route into the implementation of precision farming, which this consortium contends is one of the most important issues in combating yield shortages.",1
ES/R00269X/1,21418,Energy On the Move: longitudinal perspectives on energy transitions among marginal populations (a comparative study),"This research examines the energy practices of very poor women, men and young people living in informal settlements in peri-urban situations in Nigeria, South Sudan, Nepal and Bangladesh and how these are changing, drawing comparative lessons across the study countries. It challenges conventional approaches to energy transition research. Lack of access to clean energy limits economic development, stifles people's life chances and traps millions into extreme poverty. Sustainable Development Goal 7 makes bringing access to affordable, clean and reliable energy for the poor a necessary element in transforming the development prospects for the 1.4 million people currently without modern energy services. However, while considerable development activity is being devoted to bringing new technological products from renewable energy research centre laboratory benches into the affordable reach of the energy-poor, current approaches to energy transition are deficient, not least because they fail to take into account the specific contexts and needs of the poorest and most marginal groups in low income countries: the women, men and youth on whom we focus in this project. 

The study will explore the energy practices of those who have experienced displacement as a result of environmental precarity (disasters or climate change), or political conflict, and are living in peri-urban locations but unconnected to the electricity grid. They offer a prime example of vulnerable groups whose energy requirements continue to be (poorly) met by biomass: the implications are substantial and extend beyond energy to transport (since high biomass usage can put a massive transport burden on women and children through head-loading of firewood/charcoal) and to other sectors, e.g. food, water, health. The study's novel purpose is to understand the range of means by which the poor access energy for light, heat and cooking fuel, and how this may have changed over time. While it is likely there",1
NE/M017206/1,15030,Improving Model Processes for African Climate - IMPALA,"IMPALA will deliver a step change in global model climate prediction for Africa on the 5-40 year timescale by delivering reductions in model systematic errors, resulting in reduced uncertainty in predictions of African climate and enabling improved assessment of the robustness of multi-model projections for the continent. IMPALA will include key foci on continental convection and land-atmosphere coupling as fundamental drivers of local rainfall, and oceanic convection and aerosols as influencing global modes of variability and the teleconnection pathways by which they drive rainfall over various parts of the continent. Convection, land-atmosphere coupling and aerosols have been identified in the DFID/Met Office Climate Science Research Partnership (CSRP) as first order drivers of African rainfall and processes where contemporary models show significant uncertainties and biases.

IMPALA will use a single multi-temporal, multi-spatial resolution model, the Met Office Unified Model (MetUM), to allow rapid pull through of improvements made in the project into improved African climate modelling capability although the methodology and understanding will be widely applicable across all contemporary models. We will work through a pan-Africa lens to develop a benchmark suite of metrics targeted on key processes and user-relevant variables and will use the most relevant observations from past and future campaigns and latest remote sensing data. Strong links to partners and Regional Consortia (RC) will facilitate two-way evaluation and feedback, ensuring local understanding of relevant climate processes and required climate information in the regions. Evaluation of the impacts of the global model improvements, developed both within the project and through gearing from the ongoing model development process at the Met Office will be tested in idealised-scenarios of climate change.

The unique capability of the MetUM to run across a broad range of spatial and temporal scales will be central to the project. Running the MetUM as a cloud-resolving weather model, through to a multi-decadal climate model, will allow evaluation of physical processes controlling the uncertainty in key metrics of pan-African climate variability and climate change on the 5-40 year time scale. The latest global coupled models available at the Met Office will be harnessed to drive a higher resolution (4km) convection-permitting regional model, for the first time across the entire African continent, under both current and idealised future climates. This will deliver understanding of the roles played by improved local representation of convective processes and high impact weather on the climate variability and change over the continent and be used to improve convective, land-atmosphere coupling and aerosol parametrizations in the coarser-scale models. The results will also provide an important new resource for RC and other African-focused climate research, enabling better-informed evaluation of the robustness of multi-model projections. This, in turn, can be utilised by decision makers to improve risk management for health, agriculture and water resources and help protect the livelihoods of the most vulnerable, safeguarding societal development already achieved.

Key model results, metrics and observations will be made available to the FCFA RC and local partners through an interactive webpage. The consortium will also work closely with the FCFA Coordination, Capacity Development and Knowledge Exchange (CCKE) Unit in their pan-African cross-programme research activities.",1
NE/P015093/1,26871,Plausible policy pathways to Paris,"The Paris agreement commits nations to pursuing efforts to limit the global temperature rise to 1.5 degrees. This represents a level of transformation of the socio-economic and energy systems that substantially exceeds the scenarios that have been found using conventional integrated assessment models (IAMs). Such models generally ignore economic disequilibrium effects such as unemployment, which could become important under conditions of radical economic transformation, and neglect key dynamic processes that control the rate of uptake of new technologies. Rapid reductions in greenhouse gas emissions also potentially violate the simple scaling assumptions used to derive environmental impacts in IAMs because of the slow response of some parts of the climate system such as the ocean, as compared to the land. We plan to develop a set of more realistic dynamic pathways to reach the 1.5 degree target using a new, fully dynamic IAM that does not rely on equilibrium or pattern scaling assumptions. The assessment will identify policy options and the degree of negative emissions required and will quantify the resulting spatial patterns of climate change and the associated uncertainty resulting from incomplete knowledge of climate, carbon-cycle and socio-economic parameters.",1
NE/N018052/1,24741,The North Atlantic Climate System Integrated Study,"Major changes are occurring across the North Atlantic climate system: in ocean and atmosphere temperatures and circulation, in sea ice thickness and extent, and in key atmospheric constituents such as ozone, methane and particles known as aerosols. Many observed changes are unprecedented in instrumental records. Changes in the North Atlantic directly affect the UK's climate, weather and air quality, with major economic impacts on agriculture, fisheries, water, energy, transport and health. The North Atlantic also has global importance, since changes here drive changes in climate, hazardous weather and air quality further afield, such as in North America, Africa and Asia. ACSIS is a 5 year strategic research programme that brings together and exploits a wide range of capabilities and expertise in the UK environmental science community. It's goal is to enhance the UK's capability to detect, attribute (i.e. explain the causes of) and predict changes in the North Atlantic Climate System. ACSIS will deliver new understanding of the NA climate system by integrating new and old observations of atmospheric physics and chemistry, of the ocean state and of Arctic Ice. The observations will be complemented by detailed data analysis and numerical simulations. Observations will come from existing networks, from NERC's own observational sites in the North Atlantic, and from space. Seasonal surveys using the NCAS FAAM aeroplane will further enhance our observational strategy. A key dimension of the observational opportunity is that data records of sufficient length, for multiple variables, are becoming available for the first time. The modelling component will involve core numerical simulations with cutting-edge atmosphere, ocean, sea ice, chemistry and aerosol models using the latest parameterizations and unprecedented spatial detail, as well as bespoke experiments to investigate specific time periods or to explore and explain particular observations. ACSIS will provide advances in understanding and predicting changes in the NA climate system that can be exploited to assess the impact of these changes on the UK and other countries - for example in terms of the consequences for hazardous weather risk, the environment and businesses. ACSIS outputs will also inform policy on climate change adaptation and air quality.",1
2284748,45494,A new approach to navigating uncertainty in climate-related hydrologic risk,"Projections of future climate at the local scale are highly uncertain. This is partly because future emissions of greenhouse gases are uncertain (and to a degree unknowable), but largely because different climate models simulate quantitatively and qualitatively different changes in weather for a given forcing. The conventional approach to assessing uncertainty has been to use increasingly large ensembles of scenarios derived from multiple models. At the extreme, the UKCP09 climate projections are based on 10,000 scenarios. Additional uncertainty is added by boundary conditions, downscaling methods, choice of impacts models and model parameterization. The propagating uncertainties that result from these decisions has been conceptualized as the &quot;cascade of uncertainty&quot; (Wilby &amp; Dessai 2010 Weather). It can be challenging to apply such big data to real-world risk assessments and adaptation decisions, and attitudes to confronting this &quot;uncertainty monster&quot; (Van der Sluijs 2005 Water Sci. Technol.) are varied. Navigating the cascade of uncertainty is an overwhelming task (Smith et al 2018 J. Extreme Events), and there are increasing calls for new approaches to organize climate risk information in ways that align better with policy needs (e.g. Kennel et al. 2016 Science). 
One such approach develops and uses a small number of 'storylines' to characterise risk (Clark et al. 2016 Curr. Clim. Change Rep.). A storyline is a plausible pathway, without any a priori probability attached. Storylines offer the benefit of allowing an end-to-end quantitative analysis and thereby incorporating compound risk, which is difficult to do within a probabilistic framework in the face of the cascade of uncertainty. Storylines are also easy for lay people to understand, and so provide a natural language for communication in the policy arena.
This project develops the storyline approach, focusing on future drought risk in the United Kingdom. The proposed concept is to navigate the cascade of uncertainty to analyse and bound the system components contributing to climate influence on drought risk, and develop storylines that crystallize that risk (see details in Section 1d). The storylines will be developed to characterize the full range of potential changes in climate that are relevant to drought occurrence (such as change in the frequency of successive dry winters, and delays to the start of the winter recharge season). 
UK climate projections 2018 (UKCP18) will contain probabilistic projections, as well as ensembles of simulations, at global, regional, and national scale. In this project, using expertise from supervisors at the University of Reading and the Centre for Ecology &amp; Hydrology, the storyline approach will be applied to these climate projections and propagated through hydrological models. Working with Anglian Water, these results will then be applied to water resources and reservoir yield models in order to stress test current water resource management plans, and develop drought risk assessments. This work has the potential for direct application in policy via drought risk management plans in the Anglian region, and can provide widely transferable methods to help better manage climate change impacts on drought risk across the UK.",1
BB/P001432/1,17790,Oats for the future: deciphering potential of host resistance and RNAi to minimise mycotoxin contamination under present and future climate scenarios,"Mycotoxins are natural contaminants of a wide range of staple foods produced by fungi under conducive environmental conditions. The consumption of mycotoxin contaminated foods can result in several acute and chronic diseases in humans and animals. Oats, which have become more popular because if their health benefits can be infected by a Fusarium species, F.langsethiae, which can contaminate oats with the mycotoxins T-2/HT2 toxins. The EU has maximum recommended levels for these two toxins in place. F.langsethiae infects oats during ripening but produces no visible symptoms and is thus difficult to assess except by measuring the mould biomass in the ripening oat grain or by analytically quantifying the amounts of T2/HT-2 present. Limited work has been done on screening oat cultivars for resistance to F.langsethiae infection. Climate change (CC) scenarios has been suggested to probably exacerbate fungal infection and mycotoxin production partially via increases in pest reproduction and damage to ripening crops. Thus there is interest in understanding the relationships between interacting factors of CC including elevated temperature (+2-4oC), x2 or x3 existing CO2 concentrations (400 ppm vs 800 and 1200 ppm CO2) and episodes of drought stress. Very little information is available on how these interacting CC factors impact on infection by this Fusarium species and contamination of oats with the associated mycotoxin. This project is a collaborative project between Cranfield University in the UK and University College Dublin in Ireland to jointly address the issues of a better understanding of the relationship between this important fungal pathogen on different oat cultivars, the impact that CC factors will have on infection and mycotoxin contamination and the development of some novel methods for blocking the production of the mycotoxins.
The objectives can be summarised as being (a) In vitro examination of the effect of interacting environmental factors on growth and expression of biosynthetic gene clusters of F.langsethiae during colonisation of oat-based media and oat grains and on T-2/HT-2 toxin production by strains from the UK and Ireland. The effect of interacting CC factors the life cycle of the pathogen will be quantified. RNA-Seq technology will be used to study the gene regulation, focusing on the trichothecenes type A gene cluster for the first time; (b) a range of UK and Heritage Irish oat lines will be screened for distinct gene expression profiles relevant to differential mycotoxin contamination and potential resistance using sequencing approaches; (c) 'In planta' studies using two heritage and UK oat CVs will examine CC factors on plant/fungus gene expression patterns and differential mycotoxin contamination using non-acclimatised and acclimatised strains of F.langsethiae. The effects on shifts/fluctuations in T-2/HT-2 toxin production will be quantified; (d) the relative competitiveness of F.langsethiae and other Fusarium species such as F.graminearum and F.sporotrichioides and oat mycobiota will be examined under normal agronomic and CC conditions in in vitro and in planta studies on dominance at a molecular, colony and ecosystem level; and (e) minimisation strategies using interference RNA technology and novel delivery systems to interfere with the key TRI genes involved in T-2/HT-2 production. In planta trials will be carried out to test control efficacy of toxin production under normal agronomic and CC conditions for the first time.",1
BBS/E/T/000GP074,9988,Sequencing and exploitation of the genetic diversity in Vietnamese native rice lines to serve research and breeding programs,"We propose to develop a modern staple food for a population of 90 million in Vietnam and it is also one of the main exporter commodities of the country. Vietnam is experiencing an exceptional growth in its economic output and rising population. There is an increasing threat from climate change such as emerging pathogens, periods of droughts and rising sea levels. Under greatest risk are the deltas of the Red and Mekong rivers: the major rice growing regions of Vietnam. The rapid selection of rice varieties that are tolerant and resilient to these conditions will help to mitigate some of these challenges and ensure food security in Vietnam. The Earlham Institute (EI) in the UK and the Agricultural Genetics Institute (AGI) in Vietnam collaborated to sequence the genome of a reduced number of Vietnamese rice varieties to characterise the genetic variations in native lines and develop molecular markers that could be used to accelerate rice breeding. The application of new genomics technologies to improve crop breeding is one of the priorities at the National Institute of Agricultural Botany (NIAB) at UK. The project continues the partnership initiated between EI and AGI in collaboration with NIAB. We aim to expand the pilot project to complete the re-sequencing of around 600 lines. We will complement the generation of these data with the development of databases and the application of bioinformatics pipelines to identify associations of alleles with specific phenotypes. We expect to characterise markers that will enable more efficient rice breeding. The application of modern technologies to rice breeding will also provide an excellent example of how these strategies could be applied to other plant species such as wheat and barley. Rice has a simple genome for which many genomics resources have been already generated and it offers an excellent model for the evaluation and assessment of new strategies for breeding that could later be applied to more complex crops.",1
NE/S008853/1,21050,"Hikurangi Trough late Pleistocene palaeoceanography, biostratigraphy and Cretaceous Ocean Anoxia Events (OAEs)","Part I:

The regions of the world's oceans, which border Antarctica, are critical for controlling the Earth's climate. Firstly, the largely unhindered transit of ocean currents (the Antarctic circumpolar current, ACC) that circle and Antarctic continent enables the continued maintenance of its huge continental ice sheets. Secondly, a permanent thermal boundary between water masses extends to the ocean surface within the Subtropical Convergence (STC) in this region. Consequently, this is a region of high biological productivity due to the mixing of micronutrient-rich subtropical waters (STW) with macronutrient-rich subantarctic waters (SAW). As such the STC is a highly important sink for atmospheric CO2 due to high levels of primary productivity.

 This region is also influenced by the presence and extent of the Western Antarctic Ice Sheet (WAIS). The extent of this ice sheet has been shown to alter the latitudinal positioning of the Southern Hemisphere STC by up to 7 degrees from stadial-interstadial cycles of the Late Pleistocene epoch (last 800 ka), and may subsequently partially decouple global climate from atmospheric partial pressure of carbon dioxide. Previous studies highlighting the Late Pleistocene evolution of sea surface and intermediate waters within the southwest Pacific have indicated complex behaviour of the subtropical front (STF) throughout this interval. 

 Utilizing samples from site U1520D from within the Hikurangi Trough (Expedition 375), we propose a high resolution (&lt;1 kyr) study of late Pleistocene foraminifera to better constrain the regional paleoceanography over the last 130 ka, and how this relates to climate forcing. We aim to better understand the STC through paired measurements of oxygen isotopes and Mg/Ca trace element ratios of both planktonic (Globigerina bulloides) and benthic foraminifera (Uvigerina peregrina). G. bulloides is a symbiont-barren, opportunistic species which often dominates the foraminifer fauna, and sediment assemblage of the ocean floor, and is therefore an important source of geochemical information for palaeoceanographic studies. U. peregrina is an infaunal benthic species, which has also been used extensively to calculate intermediate water properties throughout the Pliocene-Pleistocene. These stable isotope and trace metal records are required to assess the scale and timing of surface and intermediate water temperature, and salinity across the STC. This data will subsequently contribute to our knowledge of the extent and influence of the WAIS and meridional gradient variability response to orbital forcing during a critical period of cryosphere development. 

Part II:

The Cenomanian-Turonian boundary (CTB) can be correlated globally in pelagic carbonate facies by a major turnover in fossil groups, and by a positive carbon isotope excursion, typically associated with dark marls or shales enriched in organic carbon. The dramatic changes within lithology are attributed to increased rates of oceanic-turnover and upwelling of nutrient-rich deep water masses, and high surface-water productivity. 
 Oxygen depletion and eutrophication of the Earth's oceans has been associated with warming in the geological past, and current observations show expansion of modern oxygen minimum zones. Clarifying the nature and mechanism of these oceanic anoxia events (OAEs), and there effect upon life is imperative to our understanding the possible implications that anthropogenic climate forcing may have upon the biodiversity of the modern ocean.
 We plan to utilize samples sourced from IODP Expedition 375 Hole 1520C, within the Hikurangi Trough, where an expanded section is been identified detailing the Cenomanian-Turonian boundary. Through foraminiferal faunal analysis and paired measurements of oxygen and carbon isotopes we aim to elucidate the nature of the CTB within the Hikurangi Trough, which represents a rare, well-preserved high-latitude example of a Cretaceous OAEs.",1
BB/R00580X/1,20290,Modelling Landscapes for Resilient Pollination Services in the UK,"Pollination services by wild insects, such as bees and hoverflies, can increase the total output of UK crop production by hundreds of millions of pounds annually. Changes in climate and land use can cause populations of these wild insects to decline and can displace certain species from their natural range. As a result, the pollination services provided by a community may decline or become very reliant upon a few key species. This greatly increases the economic risk posed to farmers, suppliers, retailers and consumers by further losses of pollinators, either as sudden, one time shocks or through the gradual impacts of pressures over a longer period. Changes to the landscape that affect pollinator populations will also affect the aesthetic and cultural value of the landscape for different people, potentially making them more or less willing to undertake measures to support pollinators, such as planting wildflower strips. At present, the exact impacts of various landscape and climate changes on pollinator populations and the pollination services they provide remains unknown.

This project, involving a team of ecologists, economists and sociologists, builds on data collected from several other studies to measure and map the current availability of pollination services, including their economic benefits, across the UK and how resilient they are to plausible future changes in the physical or economic environment. The project is divided into four work packages: work package 1 will develop new methods to map pollinator populations across the UK, based on existing data and estimate the economic value of these pollinator populations. work package 2 will use existing data, and a small amount of new data, to examine the links between pollinator visits and economic output in four major UK crops (apples, strawberries, oilseed rape and field beans), and identify the key tipping points where services will be inadequate. work package 3 will use innovative social science techniques to examine how changes in the landscape that affect pollinators will impact upon different people's cultural values for those landscapes. Finally, work package 4 will work with stakeholders (e.g. farmers, policy makers, retailers) to develop a series of realistic and relevant future scenarios that each consider changes in: i) the climate; ii) markets for different crops (which affects how much is planted); and, iii) wider land use. Combining information from all of the work packages, the project will examine how these changing conditions will affect pollinator populations, the economic benefits of the pollination services they provide and the impacts that changes in the landscape affecting pollinators will have on social values. The project will then examine the capacity of pollinator populations to recover their service providing potential after sudden events (e.g. extreme weather) under each scenario, as well as the vulnerability of crop markets to declines in pollinated crop production abroad. 

Throughout, the project will be supported by a steering committee of stakeholders who will work with the project team to ensure the outcomes are the most realistic and relevant to UK food systems. The projects outcomes, including detailed maps of pollinator populations and pollination services across the UK under current and future conditions and new information on people's landscape preferences, will be used to produce new outreach materials (in collaboration with a specialist artist), policy briefs and discussion workshops for a wide range of stakeholders.",1
1957379,37632,USING THERMAL NICHE THEORY TO PREDICT COMMUNITY DYNAMICS IN FRESHWATER ECOSYSTEMS,"Climate warming is one of the biggest drivers of change in many ecological systems. However, we remain largely ignorant about its impacts on many groups of organisms and their ecological interactions, particularly in freshwater environments. Within these systems, bacterivorous micro- and meiofauna are key taxa in regulating bacterial communities, and thus have consequences for bacterial-driven ecosystem functions (e.g. nutrient cycling). In the context of warming environments, it is critical to know how warming alters the complex web of interactions between bacteria and the grazer community, if we are to understand the functional implications of climate change. The studentship will use the ecological niche concept as a foundation to understand component and community wide responses to simulated global warming and the concomitant ecosystem functioning outcomes. The overall goal of the studentship will be to investigate how ecological niche breadth influences tipping points and community interactions, including food webs within freshwater lentic microbial eukaryote communities associated with warming.",1
NE/L013851/1,6493,SWAAMI (South West Asian Aerosol Monsoon Interactions),"Aerosol particles from pollution sources across the Indian subcontinent form a dense and extensive haze across India and the Bay of Bengal that increases in extent and magnitude in advance of the monsoon. As the aerosols, a large fraction of which arises from wood and charcoal fired cookstoves, absorb solar radiation as well as scatter it they can affect the heat balance of the lower atmosphere. It has been hypothesised that this aerosol can influence the monsoon through its role in redistribution of heat across the region in the pre-monsoon, and model studies have demonstrated that such effects can be important. However, current comparisons show model to model variability and under-prediction compared to observations, a strong indication that detailed aerosol properties are poorly represented in current models. The lack of accurate representation of aerosol in these models is compounded by a lack of measurements of sufficient accuracy and sensitivity to elucidate fundamental properties such as component mass, mixing state and optical properties, which need to be well characterised to improve model performance. This is limiting predictive capability at the present time and hence preventing the influence of aerosol in the Indian monsoon to be quantified. In addition to reproducing detailed properties of aerosol, models need to be able to accurately represent the horizontal and vertical distribution of different aerosols to predict their effects. As the monsoon progresses, pollution aerosol are removed by precipitation, but also lofted by convection. Dust advected from deserts to the west above the moist monsoonal flow become significant through the season. It is important that these aerosol layers are accurately represented in models and that robust measurements are available to rigorously challenge model predictions.

SWAAMI will contribute to the joint NERC-MoES programme &quot;Drivers of Variability in the Asian Monsoon&quot; through a detailed determination of aerosol physical and chemical properties across India in the advance of, and during, the Indian monsoon using UK and Indian research aircraft. The measurements will deliver a chemical and physical characterisation of the aerosol that is considerably more detailed than any previous and will enable assessment of aerosol composition and mixing state, provide source characterisation and deliver quantification of aerosol optical properties such as extinction, absorption and single scattering albedo. Such detailed characterisation will allow us to test representations of aerosol properties in regional and global climate models. Our planned aircraft measurements will be combined with syntheses of long term data from across the continent and previous field studies to provide a data set that can challenge how well models represent aerosol across the region. Improving model representations of aerosol properties and testing the extent to which this improves model performance against data will provide a framework for ensuring model aerosol schemes improve and in doing so will allow us to make more reliable predictions of aerosols effects on the heat budget of the region and hence improve our knowledge of how aerosols may influence the Indian monsoon.",1
ST/N002318/1,27834,"Development of a W-band gyro-amplifier for high power, wideband, pulsed coherent applications.","The project will consolidate our technology in developing a new class of high power, wideband millimetre wave amplifier which offers a ten-fold increase in available bandwidth and a five-fold increase in available peak power over the amplifiers used in current pulsed coherent applications such as radar, magnetic resonance, security imaging and remote sensing. It will bring step changes to these applications and the success of this research will have a huge worldwide technological impact and offer tremendous economic benefit to the UK. The proposal is a collaboration between two major millimetre wave groups at the University of Strathclyde and the University of St Andrews who collectively have decades of experience and vibrant international reputations in the development of high power millimetre wave sources, radars, instrumentation and components, plus a strong track record in commercialisation, industrial collaboration, and delivering on project objectives. The gyro-amplifier represents a core technology that is likely to lead to UK leadership in the field of high power millimetre wave radar.

Pulsed electron paramagnetic resonance (EPR) and dynamic nuclear polarisation (DNP) enhanced Nuclear Magnetic Resonance (NMR) instruments based on this gyro-amplifier technology will result in radically improved sensitivities. The EPR and DNP enhanced NMR (including the possibility of pulsed DNP-NMR and the use of phase and amplitude modulation) experiments will give rise to absolutely world-leading research. It will strongly enhance the UK's position as a world leader in a wide range of academic research areas, including physics, chemistry, biology, engineering and medicine.

Atmospheric sensing and space debris tracking based on such an amplifier will allow long range monitoring of clouds, aerosols, precipitation (therefore enabling better global climate and pollution models for better prediction of weather and pollution, better management of natural resources and mitigation of natural hazards) and tracking of space debris (increasing safety for space travel and satellite launching). This will lead to greater radar sensitivity, enabling measurement of smaller or more tenuous particulates, with finer resolution, at longer ranges or in a shorter timescale. The technology also has the potential to be applied to the ground based mapping of space debris, a major consideration for all orbiting systems including environmental monitoring satellites.

The high power capability of hundreds watts of the gyro-amplifier in this region will allow standoff, real time video rate security imaging and sensing enabling high resolution 3D imaging and highly sensitive sensing of most hidden contrabands such as explosives, illegal drugs and chemical and biological materials. The project has the potential to disrupt a large fraction of the existing X-ray based security market. The research team at Strathclyde is a world leader in this &quot;terahertz amplification&quot; area and can realise the application pull through collaborating with wide UK terahertz imaging and sensing community and industries.",1
NE/S001166/1,31412,ICAAP: Increasing Carbon Accumulation in Arctic Peatlands,"Predicting future climate change is one of the biggest scientific and societal challenges facing humankind. Whist carbon emissions from human activities are the main determinant of future climate change, the response of the earth system is also extremely important. Earth system processes provide 'feedbacks' to climate change, either reinforcing upward trends in greenhouse gas concentrations and temperature (positive feedbacks) or sometimes dampening them (negative feedbacks). A crucial feedback loop is formed by the terrestrial global carbon cycle and the climate. As carbon dioxide concentrations in the atmosphere and temperature rise, carbon fixation by plants increases due to the CO2 fertilisation effect and the lengthening of the growing season at high latitudes (this is a negative feedback). But at the same time, increasing temperatures lead to increased decomposition of the carbon stored in soils and this results in more carbon dioxide being released back to the atmosphere (this is a positive feedback). 

The balance of these competing processes is especially important for peatlands because they are very large carbon stores. Northern Hemisphere peatlands hold about the same amount of carbon that is stored in all the world's living vegetation including forests, so determining the response of this large carbon store to future climate change is especially critical. One hypothesis is that warming will increase decomposition rates in peatland soils to such an extent that large amounts of carbon will be released in the future. However, the vast majority of peatlands are in relatively cold and wet areas and evidence from past changes in accumulation rates suggest that for these regions, warming may lead to increased productivity that more than compensates for any increase in decay rates, leading to increased carbon sequestration overall. Furthermore, in the northernmost areas of the Arctic, there is potential for further lateral expansion of peatlands, increasing the total area over which peat accumulates. We intend to answer the question of whether changes in accumulation in Arctic peatlands plus the increased spread of peatlands in cold regions will lead to an overall increase in their carbon storage capacity.

Our approach will be to use a novel combination of data from the fossil record stored in peatlands together with satellite data to test a global model that simulates changes in both carbon accumulation rates and the extent of peatland vegetation over Arctic regions. If we can demonstrate that the model performs well in simulations of past changes, we can then confidently use it to make projections of future changes in response to warming for several hundred years into the future. We know that fluctuations in Arctic climate over the past 1000 years should have been sufficient to drive changes in peat accumulation rates and lateral spread, so we are focusing our analyses on this period. In particular, we know there were increases in temperature over the last 150-200 years and especially over the last 30-40 years. If our hypothesis that increased temperature leads to increasing accumulation and spread of Arctic peatlands is correct, we expect to see the evidence for this in the fossil record of peat accumulation and spread, and also in satellite data of vegetation change. Our previous work and our new pilot studies show that we can reconstruct accumulation rate changes and also that our proposed remote sensing techniques can detect peatland vegetation increases since the mid-1980s, so we are confident in our methodology. The model will provide estimates of northern peatland carbon storage change for different climate change scenarios over the next century and longer term to the year 2300. If we can show that there is a potential increase or even no change in carbon storage in Arctic peatlands, it will radically change our perception of the role of the Arctic terrestrial carbon store in mediating climate change.",1
NE/N018591/1,700,Robust Spatial Projections of Real-World Climate Change,"Climate change is one of the leading global challenges facing society and the planet. Predicting how the climate will change as human activities lead to emission of more greenhouse gases is a global scientific challenge for climate scientists.

We use models of the climate to make predictions. Because of limitations in computing power, and because of gaps in our understanding of the climate, these models are not perfect. Predictions from the models are, therefore, also not perfect. We are faced by the huge challenge of extracting robust information from climate models about how real-world climate will change in the future under specified scenarios of different greenhouse gas emissions. Such projections are central to leading climate change assessments, such as those produced by the Intergovernmental Panel on Climate Change (IPCC).

This project will provide a step-change in the ability of climate scientists to produce robust projections of climate change and to quantify the uncertainties in projections. A new framework will be developed that combines information from models, observations and our basic understanding of climate with modern statistical techniques to produce projections. 

This new framework will be applied to three important climate regimes of Earth: tropical and subtropical temperature and precipitation change; middle latitude cyclones and anti-cyclones; and polar temperature and sea-ice changes.

We will bring together leading UK scientists (many are IPCC authors) from the Universities of Exeter, Reading, Oxford and East Anglia, and the Met Office, to address this grand challenge in climate science. We aim to precipitate a cultural shift that unifies diverse approaches from techniques to understand climate process and statistical methods and consolidate the UKs position as a world-leading centre for climate projection science.",1
103789,21017,VO+: Novel Manufacturing Porcess for Reducing Material Used in PE Film,"Polyethylene (PE) is the most common polymer film, used widely in packaging and non-packaging applications to provide unmatched benefits in terms of design flexibility, strength and cost. The PE film industry is focussing on achieving material reduction &amp; light-weighting to reduce the environmental impact of its products. Several relevant technologies are available; however all have limitations that prevent widespread adoption (high cost, inadequate mechanical properties, and incompatibility with thin films). VOID Technologies Limited (VOID) proposes to advance its nano-cellular light-weighting technology (branded VO+) in PE film from TRL3 to TRL5, to deliver competitiveness and growth in the manufacturing and materials sectors by: (1) Developing materials for targeted performance specifications including applications that require light-weighting, high strength and toughness, and moisture control. (2) Significantly reducing raw material used in PE film production leading to a cost reduction compared to standard PE film, whilst maintaining strength. The project will result in significant growth for VOID giving increased employment, substantial ROI and a platform technology which can be developed further for additional markets.",1
EP/M00337X/1,28614,MATERIALS 5R BY INDUSTRIAL SYMBIOSIS IN THE CEMENT INDUSTRY - UNDERSTANDING METABOLISM OF TOXIC METALS IN CO-PROCESSING,"Portland cement is traditionally manufactured by heating limestone and clay at high temperature in a kiln. On a global scale, cement production is responsible for about 7% of the CO2 emissions that we suspect of causing climate change and consumes more than 5,000,000,000 tonnes of raw materials. In recent years, there has been an increasing trend towards replacing both the fuels and minerals used in cement production with industrial wastes. This practice helps to conserve both fossil fuels and natural mineral resources.
 In general, wastes now fed to the cement kiln contain mainly combustible materials and the same harmless elements that are present in natural cement raw materials, so there is no undesirable effect on cement quality or the environment. However, it has been suggested that some wastes containing toxic metals could be used in cement kilns, and we need to know more about what happens to these potential pollutants during cement production and use, to decide whether such wastes can safely be added in the cement kiln. This collaboration between researchers in Environmental Engineering at University College London in the UK and Materials Scientists at the China Building Materials Academy and South China University of Technology therefore aims to conduct a scientific study of the fate and behaviour of toxic metals from untreated wastes, through the cement kiln, to hydrated cement pastes and the environment. We will use advanced techniques for chemical analysis and materials characterisation, including x-ray absorption spectroscopy with high energy x-rays from the UK's Diamond Light Source, and the Beijing Synchrotron, to see how the form of metals changes as they pass through the kiln and when water is added to the cement, and to understand how much metal-bearing waste can safely be added before undesirable effects occur. 
 The new understanding gained in this work will support decision-making by industry and the government, about the use of waste in making cement.",1
NE/M014363/2,14900,How do eukaryotic CO2 fixers co-exist with faster growing prokaryotic CO2 fixers in the oligotrophic ocean covering 40% of Earth?,"The principal aim of the proposal is to explain the ecological basis of the most extensive biome on Earth - co-existence of eukaryotic CO2 fixers with faster growing prokaryotic CO2 fixers in the open oligotrophic ocean. Eukaryotes dominate CO2 fixation in most of Earth's biomes, e.g. terrestrial, freshwater and some marine (coastal and polar waters), with one but major exception: the oligotrophic oceanic gyres, covering 40% of Earth. Why have energetically superior eukaryotes been unable to outgrow prokaryotes despite millions of years of co-evolution in the gyres?
We hypothesise that co-existence of CO2 fixing eukaryotes and prokaryotes is sustained by episodic nutrient pulses into the surface sunlit waters complemented by feeding of CO2-fixing eukaryotes on prokaryotes, i.e. bacterivory. Using the combined expertise of our research team strengthened by novel experimental approaches we will address the following questions: What is the impact of nutrient pulses on growth rates of CO2-fixing prokaryotes and eukaryotes? How do nutrient pulses affect bacterivory? Is selective feeding by CO2-fixing eukaryotes a mechanism for controlling growth of CO2-fixing prokaryotes?
We will find out how general the answers to the above questions are by focusing on experimental work in the subtropical gyres of the Atlantic and Pacific Oceans, which comprise nearly three quarters of the total oligotrophic open ocean area. The three gyres we will investigate are of different geological ages and differ in composition of depleted inorganic nutrients. We will use isotopic tracers in combination with flow cytometric sorting to directly measure impact of nutrient pulses on microbial group-specific growth rates and bacterivory rates. Morphology, taxonomic identity and physiological potential of flow sorted microbial groups will be characterised by ultra-structural, molecular and metagenomic analyses. The effects of nutrient pulses on cellular biomass of CO2 fixing prokaryotes and eukaryotes will be assessed by electron microscopy of flow sorted cells coupled with energy dispersive X-ray spectroscopy. 
The experimental evidence will be synthesised into a generic concept to explain the mechanism of co-existence of the smallest eukaryotic and prokaryotic CO2 fixers of increasing global biogeochemical significance owing to expansion of the oligotrophic ocean under the influence of modern climate changes. Thus, the project will test the extent of inorganic nutrient control of biological CO2 fixation in the largest Earth's biome.",1
NE/M013030/1,23562,"REFUGIAL POPULATIONS AT TRAILING-EDGE RANGE MARGINS: ATTRIBUTES, SURVIVAL AND CONSERVATION","Many species currently survive as localised, refugial populations in regions where they used to be more widespread under more favourable past climatic conditions. These species survive in localised habitats and/or microclimates that are atypical of the surrounding region; for example, a cold-adapted species in Britain might survive on a locally cold, north-facing site when the climate warms. Refugia have been extremely important in allowing species to survive past climatic changes, and are likely to be so again under anthropogenic climate change. Despite this, the local conditions that support population refugia are poorly understood. Thus we have little idea of the attributes (locations, habitats, microclimates) of sites where species may persist in future as the climate changes. Understanding these attributes is vital for informing future conservation policies as well as for developing a deeper fundamental scientific understanding of the dynamics of species' geographic distributions. 

We will take advantage of the opportunity presented by anthropogenic climate change to observe the creation of refugial populations directly, by studying four species of northerly-distributed butterflies in Britain. Butterflies are ideal study species for this project because there are excellent distribution records in Britain over the past four decades of climate change, and because local microclimate and microhabitat conditions affect all butterfly life stages, from birth to death. We will re-survey sites in Britain for which we have historical distribution data since the 1970s, and which we re-surveyed in 2004-05, to determine where species have survived, and where they have become extinct. We will use dynamic population models that incorporate environmental information for species to identify the local microclimatic and habitat characteristics of locations where populations have survived since the onset of anthropogenic climate change in the 1970s. We will examine the generality of our butterfly findings by studying climate refugial formation in other northern invertebrates. We will then use our models to project the consequences of future climatic changes for species, to the year 2100, and determine the degree to which refugia coincide with the locations of existing protected areas in Britain.

The proposed work will provide the first investigation of, and predictive models for, the attributes of locations that promote population persistence in range retreating species. The project will address fundamental questions about the dynamics of species' ranges under climate change, as well as producing results of considerable practical value for policy makers. It will open up a new avenue of research on understanding the impacts of climate change on biodiversity, and provide a concrete body of scientific evidence to inform the debate on developing effective conservation strategies under climate change.",1
710708,8654,Smart Separations - a novel microfiltration system for air purification and emissions control,"Smart Separations is developing a proprietary microfilter technology that can be easily
tailored to suit many different needs by varying the pore size in a controlled manner. The
regularity of the pore size is a unique selling point in many different markets and applications.
New filters based on this technology are highly innovative and potentially highly
commercially disruptive.
The chemical industry is suffering from out-dated processes to clean, purify and filter their
exhaust fumes. These gas emissions are usually cleaned through scrubbing, which typically
relies on toxic organic solvents to dissolve particles and other gases and molecules resultant
from the chemical processes. The main hurdle is that thousands of tons of toxic organic
solvents and/or treated water are being used in this process, leading to higher environmental
risks and a huge increase in energy requirements to clean and recycle both the solvents and
the water.
Following a very successful TSB Proof of Market award, the company has identified an
application of the technology in cleaning air and heavily reducing carbon and other
greenhouse gas (GHG) emissions, such as in car exhaust fumes and industrial processes.
Smart separations now wishes to prove the filtration concept. This Proof of Concept grant will
thus allow the development of a series of initial, basic pre-prototype filtration products,
followed by specialist laboratory testing of air purification and emissions. The grant at this
stage would help leverage the positive results from the Proof of Market study and allow for
concept demonstration to provide basic proof of technical feasibility. The world market for
industrial scrubber, absorber, adsorber and biofilter systems will reach &pound;4.3bn by this year
(2015). Incineration is the largest single market, which we plan to tackle first. Our technology
has the potential to disrupt and expand the market potential through retrofitting and by
simplifying and/or reducing implementation costs",1
NE/R012822/1,23074,Understanding the links between pelagic microbial ecosystems and organic matter cycling in the changing Arctic,"The Arctic Ocean's key role in regulating the global climate is highly sensitive to climate change. Arctic temperatures have increased more strongly than the global average during the recent past, causing a loss of multiyear sea-ice and fundamental changes in ecosystem structure and function. Arctic primary production and biogeochemical cycling are projected to change. Longer ice-free periods and thinner sea-ice increase light availability, enhancing phytoplankton production, which may also be further stimulated by increased carbon dioxide.

We have assembled a multidisciplinary UK/German team to address this NERC/BMBF Arctic call with a renowned track record of pioneering research concerning the structure and function of marine pelagic ecosystems, including extensive research in the Arctic. This project has the overarching aim to improve our understanding of how short-term (e.g. seasonal- scale) and long-term (e.g. climate-driven) changes in the physical environment of the Arctic Ocean are impacting pelagic microbial ecosystems and how these affect current and future organic matter (OM) biogeochemistry.

The focus of our activities principally addresses Challenge 1 &quot;To develop quantified understanding of the structure and functioning of Arctic ecosystems&quot;. Our multidisciplinary team with expertise in marine microbial ecology, OM biogeochemistry, polar plankton ecology, and ecosystem modelling will fully characterise the microbial base (archaea, bacteria, protists including phytoplankton and fungi) of the pelagic Arctic food web in relation to OM cycling. Through a comprehensive multi-location and multi-seasonal cruise programme we will address major knowledge gaps in the links between Arctic microbial ecosystem structure and function across a broad range of sea-ice environments. Our sampling strategy, including the rarely sampled winter and early spring, will allow us to quantify impacts of Arctic seasonality on the structure and functioning of microbial ecosystems in relation to OM cycling, allowing us to track major changes in autotrophic and heterotrophic production. Combining observation and modelling, we will analyse the underlying mechanisms that impact microbial dynamics and subsequent OM cycling on seasonal scales. The model setup will integrate forcing data and results of NEMO-MEDUSA simulations. Data-model synthesis will enable us to resolve and constrain processes that remain either unresolved or are assumed constant in MEDUSA. Our model results will thus specify uncertainty ranges that may be accounted for in future projections of the Arctic with NEMO-MEDUSA and the UK Earth System Model (UKESM).",1
EP/R023689/1,21000,(H)olistic (A)pproach to the Design of Efficient Heat (R)ecovery Systems for Electrical (P)ower (P)roduction (HARP^2),"HARP2 is a &pound;1.2M consortium that brings together the Universities of Manchester and Huddersfield, as well as a range of industrial project partners, to achieve a technological step-change in the design and application of environmentally-friendly, high-efficiency and fully-integrated waste heat recovery systems for generation of electrical power. This demonstration project will cover three main areas: (i) novel topologies of thermoacoustic engines, coupled with (ii) reciprocating electrical machines using innovative drive/control techniques, and (iii) novel manufacturing technologies to fabricate complex multi-scale objects into compact and robust pressure systems. These have to be optimised for future low-cost and mass-production, and to fit a wide range of potential technological applications, including internal combustion engines for land and marine transportation, micro-CHP (combined heat and power) systems in domestic or small commercial gas/biomass fuelled boilers, railway rolling stock, or industrial process units, to name just a few.

To achieve this end, a challenging multi-disciplinary work programme has been developed requiring a close collaboration between research institutions. This must cover aspects of: modelling and experimental validation of thermoacoustic systems, in particular travelling-wave cascade engines optimised for maximum thermal efficiency, building and validating acoustic impedance coupling models between thermoacoustic systems and linear alternators (LAs), developing inexpensive alternator designs and appropriate control strategies for maximum power-point tracking using adaptive acoustic impedance matching, structural analysis for high pressure and fatigue loading, and suitable fabrication protocols in the manufacturing context to ensure the successful integration and packaging of all sub-systems into a working proof-of-concept demonstrator. 

Six industrial companies, familiar with R&amp;D and product development processes on the academia-ndustry interface, are supporting the project through their participation in the steering committee - denoted the Industrial Advisory Board (IAB) in the HARP2 programme - and through in-kind contributions of staff time and facilities to provide application-oriented guidance to the project. The companies include British Petroleum Plc, Spirax Sarco Ltd, Ricardo UK Ltd, Ashwell Biomass Ltd, European Thermodynamics Ltd and Reliance Precision Ltd, and are represented in the IAB by their technical leads. The companies cover relevant technical areas, in particular process industries, transport (road/rail/marine) and boiler manufacturers as well as the manufacturing sector. The intention is to grow the membership of the IAB through a mix of public engagement and dissemination activities targeted at industry and policy-makers.

This complex research programme aligns directly with the EPSRC &quot;themes&quot; of Energy (improvement in the UK's energy balance by a wider utilisation of waste heat from multiple sources and novel solutions for future renewable technologies), Manufacturing the Future (by devising novel and competitive products and processes and new materials concepts with bespoke properties), and, in an extended way, Global Uncertainties and Living with Environmental Change (by reducing environmental impacts of energy utilisation activities).

In particular, it aims to make significant contributions to the future of the UK's energy sector such as (i) unlocking the potential of co-generation and (ii) reduction in CO2 emissions. It is estimated that the technical capacity for cogeneration in the UK will be 40 GWe by 2030, while the technically recoverable heat from industrial processes amounts to 11 TWh/y, corresponding to 2.2 million tonne of CO2 being abated. The HARP2 TAG technology may provide significant contributions to achieving these two goals which makes the research extremely timely.",1
EP/P002331/1,27880,Data Assimilation for the REsilient City (DARE),"Data assimilation is an emerging mathematical technique for improving predictions from large and complex forecasting models, by combining uncertain model predictions with a diverse set of observational data in a dynamic feedback loop. The project will use advanced data assimilation to combine a range of advanced sensors with state-of-the-art computational models and produce a step-change in the skill of forecasts of urban natural hazards such as floods, snow, ice and heat stress. 

The research will use synthetic aperture radar (SAR) data to develop a tool for real-time detection of flooded urban areas. SAR sensors take images from space over a wide area and can see through clouds. The sensors have resolutions as high as 1m, and are able to image flooded streets. However, substantial areas of urban ground surface may not be visible to the SAR due to shadows caused by buildings. Furthermore, shadowed areas may be misclassified as water even if dry. Our new approach is to use a SAR simulator in conjunction with lidar data. The SAR simulator estimates regions in the image in which water will not be visible due to shadow, and masks these out from the ground surface considered, resulting in a more accurate flood extent. This type of information could be used by first responders to monitor vital infrastructure and understand the extent and depth of the evolving flood.

SAR images can also be used to extract water level observations, which may be assimilated into a flood inundation model, to calibrate the system and keep predictions on track. Our recent ground-breaking work demonstrates the possibility of earth-observation-based flood inundation data assimilation and forecasting over a rural area. In this new project we aim to carry out scientific and mathematical studies to increase the flexibility of our flood data assimilation system, so that it can be straightforwardly applied at any location in the UK (including urban areas). For example, the behaviour of the system is expected to change for larger floods, steeper rivers, faster flow etc. In addition, we will develop techniques to derive new types of water level observations from smartphone photographs, traffic and river CCTV cameras, that can also be assimilated to improve predictive skill.

A number of environmental hazards are caused by the weather (e.g., heat stress, high winds, fog). The skill of numerical weather prediction is strongly constrained by the accuracy of the initial data, as estimated by assimilating expensive observations. There are burgeoning sources of inexpensive datasets of opportunity (citizen science, sensor networks etc.) that could be used, however lack of knowledge about natural variability in urban areas hinders uptake of these data. This proposal addresses uncertainty due to urban natural variability in observation-model comparisons, by considering numerical weather prediction models on a range of scales, and observational data with different &quot;footprints&quot;. We will apply these results to citizen science automatic weather station data, car temperature sensors and commercial aircraft reports made to air traffic control (used to derive observations of winds and temperature).

The impact of this research will be guaranteed by working with operational providers of flood warnings and weather forecasts (the Environment Agency and Met Office). Commercialization of aspects of the research will be pursued in conjunction with the Institute for Environmental Analytics.

A network of researchers and industry working with digital technology at the &quot;Living with Environmental Change&quot; interface will be formed. This will have a programme of workshops, webinars, training and industry study groups to cross barriers between academic disciplines, creating bridges between academia and industry and providing space for junior and senior researchers to explore ideas. Funded pilot projects will kick-start activities and help define the future research agenda.",1
BB/N011759/1,4909,The genomics of thermal adaptation in a model pest insect,"One sixth of the world's crop production is lost to pests and diseases each year. Rises in global temperatures are expected to cause dramatic shifts in the range and abundance of food pests, with potentially alarming consequences for global food supplies. To protect food security in the context of a changing climate therefore requires multidisciplinary research into how pest species adapt to their environments, drawing from the fields of molecular biology, genetics, ecology and evolutionary biology. Understanding how organisms adapt to high temperature is especially important, as temperature increases affect organisms in a wide range of ways, from their DNA to their complex social behaviours.

Combining the principles of Darwinian evolution with DNA sequencing is an excellent way of studying how pests adapt to temperature. Pest species usually have very short life-cycles, so can evolve rapidly in response to changing temperatures. Studying how pests evolve in response to temperature using DNA sequencing is a promising way forward because i) many of the characteristics and processes thought to be important for how pests adapt to temperature, such as body size, development and stress response, have a genetic basis; and ii) it will enable us to identify new genes, and new biological processes, involved in adapting to climate. At present, however, we know very little about what kinds of genes are involved in adapting to temperature, and less still about how rapidly these genes can evolve and allow pests to spread.

I will study how food pests adapt to temperature. My study organism will be the red flour beetle, a major pest of stored grain that causes enormous amounts of wheat, rice and corn to be discarded each year. It is also a &quot;model species&quot; for DNA research, with detailed genetic information available, and is easy to rear and study in the laboratory. I will study how red flour beetles evolve in response to extreme temperatures in real time, using replicated populations that have been maintained in the laboratory at high temperature for 60 generations. By sequencing the genomes of individual flour beetles adapted to living at extreme temperatures, I will identify the genes and biological processes that govern adaptation to temperature, and find out how these genes interact with one another. Additionally, because I have samples available from every generation since this experiment was set up, I will be able to look at how genes involved in adaptation to temperature evolve over time, and in doing so determine how rapidly these important genes can respond to changing temperature.

The proposed research will give us a better understanding of how DNA enables individuals and populations adapt to their environments. And, importantly, it will help us generate better predictions of where and when food pests are likely to spread as the global climate continues to change.",1
BB/M017567/1,4959,Developing insect population models to support the design of GM control strategies,"The stable fly is a major nuisance insect with a global distribution and is capable of mechanically transmitting a range of important livestock and human pathogens. The stress and injury caused by its biting activity are estimated to cost the US cattle industry around $1billion/year. Its impact is projected to increase in regions including Brazil and Australia as a consequence of recent changes to the management of sugar cane and other vegetable waste. Better control methods for stable flies would therefore benefit animal welfare, bioenergy production and food production.

The industrial host of this project, Oxitec, is a world leader in developing methods for manipulating insect populations through the development and release of genetically modified strains. For mosquitoes, this typically involves the release of very large numbers of modified male insects to outcompete wild-type males. This has minimal impact because male mosquitoes do not blood-feed. To use similar approaches to control stable fly populations, there is a greater need for tools to design optimally efficient release strategies because male and female stable flies both blood-feed.

The proposed project will develop process-based models of stable fly populations and use modern statistical approaches to fit them to data. Process-based models explicitly model biological processes such as birth and death rates rather than simply modelling abundance. They are relatively complex and the difficulty of fitting them has historically been a limitation, but they are better for exploring the responses of populations to unusual circumstances such as climate change or control strategies. Recently, better statistical approaches to fitting complex models to data have been developed, such as Approximate Bayesian Computation (ABC).

The Mathematical Biology group at Pirbright has a history of successfully using cutting-edge statistical approaches to fit complex biological models to data. During the recent outbreak of Schmallenberg virus in northern Europe, the group used Approximate Bayesian Computation to fit a complex disease transmission model to the early stages of the outbreak, allowing inferences to be made about key disease transmission parameters which were provided to the European Commission to make outbreak management decisions. The conclusions of the model were later validated experimentally. The group also has a history of facilitating the acceptance of modelling outputs for policy decisions. For example, disease spread simulations provided by the group were recently used to help make the case for licensing a novel bluetongue vaccine product, and during the BTV outbreak in the UK in 2007 the group provided simulation outputs in real-time in response to queries from policymakers.

Process-based insect population modelling is a logical next step for the group's research into the spread of vector-borne diseases, as it will allow the effects of climate change and novel control strategies on insect vector populations to be predicted with greater certainty. The stable fly is an ideal species to begin with for several reasons. Firstly, as outlined above, the species is associated with a substantial and growing direct impact in many areas of the world and represents a large potential market. Secondly, an opportunity exists to develop the model in parallel with a GM control product and then use the project outputs to design optimal release strategies of the new strains, supporting its uptake. The academic partner maintains the only colony of stable flies in the UK and is able to support the project via materials and know-how. Colleagues at EMBRAPA have recently begun collecting a large dataset of population observations that they are willing to share for the project, and an outline population model was already developed during previous research activities.",1
NE/N016041/2,43356,Characterization of major overburden leakage pathways above sub-seafloor CO2 storage reservoirs in the North Sea (CHIMNEY),"Industrial emissions of carbon dioxide (CO2), including fossil fuel power generation, are recognised as a likely agent of global climate change and acidification of the oceans, but most economies will remain dependent on these technologies for the next few decades. Carbon dioxide Capture and Storage (CCS) has been identified as an important way of reducing the amount of CO2 added to the atmosphere. CCS is seen as making a key contribution to reducing mankind's greenhouse gas emissions by 80-95% by 2050 and keeping climate change derived temperature increases below 2 degrees C, as outlined in European Commission policy. In addition, CCS is considered an important way of reducing the cost of mitigation measures around the continued use of fossil fuels. Offshore storage of CO2 in depleted oil and gas reservoirs and saline aquifers is the option of choice for most European nations, and there is currently one operational storage complex (Sleipner, Norway), and several other commercial scale demonstration projects are in late stages of development (e.g. ROAD-Netherlands, Peterhead and White Rose-UK), and expected to be in full operation by 2020. 
A key element of CCS offshore is that there is confidence that the risks of any leakage are understood. The location and potential intensity of any possible CO2 leakage at the seafloor are critically dependent on the distribution of fluid (dissolved and gaseous CO2) pathways in the rocks overlying the reservoirs in which the CO2 is stored, and on the ability of these pathways to transmit fluid (termed permeability). Recent studies of the structure of marine sedimentary rocks in the North and Norwegian Seas have revealed that near-vertical structures, which resemble chimneys or pipes, cross-cut the sedimentary sequence. These structures may be pathways for fluid flow. Natural fluids from deeper rock layers have migrated through these structures at some point in geological time. If CO2 leaking from sub-seafloor storage reservoirs reaches the base of these structures, and if their permeability is sufficiently high, they could act as CO2 leakage pathways towards the seafloor and overlying water column. To provide a reliable prediction of potential seafloor seep sites, the degree to which these pathways are continuous and especially their permeability needs to be better understood.
In this project (CHIMNEY) we will collect new data over a chimney structure within the North Sea by using a ship to make new and unusual measurements with sound waves. We will use several different marine sound sources to make images of the chimney, using receivers at the sea surface, and also record the sound arrivals on sea bed instruments known as ocean bottom seismometers. By looking at the sound travel paths through the sub-surface from a range of directions and frequencies we will obtain information about fractures/fluid pathways in the chimney as well as the surrounding rocks. We will calibrate and understand our marine seismic results using laboratory studies of materials (synthetic rocks) that mimic the sub-surface rocks. By understanding the propagation of sound through synthetic rocks with known fluid pathways we can understand the results of the marine experiment. We will also drill into the chimney and collect core samples which we will analyse for core geology and fluid chemistry. A computer model of the sub-surface chimney will be constructed combining the results of the seismic experiment, rock physics, and chemistry. We will work with companies involved in CCS to build realistic computer models of fluid flow that tell us about the risk of leakage from chimney structures generally within the North Sea that are relevant to Carbon Dioxide Capture and Storage.",1
BB/N012429/1,28567,Oscillatory baffled reactor for enhanced 1C gas bioconversion for energy production and storage,"Societies globally have a critical need for energy and materials with minimal environmental impact. There are many technologies such as solar PV, wind, wave and tidal generation which can produce electrical energy with minimal environmental impact, however when compared to conventional fossil fuel generation systems they are more difficult to fit supply to demand. Therefore there is increasing interest in developing energy storage. The production of green methane and carboxylic acids by combining hydrogen using renewable electricity with surplus carbon dioxide from a number of industrial processes, has the potential to integrate gas, electricity and refueling infrastructures, decarbonise energy and chemical supply, contribute towards energy security, as well as providing economic benefits through expansion of market potential. Effective conversions of hydrogen and carbon dioxide have recently been achieved using a novel patented microbial process (filed by University of South Wales) for the production of green methane and carboxylic acids, however, productivity is limited by the rate at which gases can be solubilised into the liquid phase. This project will investigate the feasibility of using innovative and patented oscillatory baffled reactor (OBR) technology (own by NiTech Solutions Ltd) to optimise the solubilisation of input gases, therefore optimising the rate of green gas or carboxylic acids production and improving the technical and economic viability of the biotechnology processes. The project proposes a programme of collaborative research to determine the feasibility of utilising the OBR technology to enhance the gaseous rate of transfer and thus increase the microbial conversion of renewable hydrogen and biogenic or fossil carbon dioxide to either green methane (for energy use) or carboxylic acids (as energy vectors and chemical intermediates). The project addresses the challenges of production of liquid / gaseous biofuels, and the production of commodity, platform and intermediate chemicals and materials from gaseous substrates. The aims of the proposed research are to investigate and demonstrate efficiency benefits that the OBR technology can bring to the biomethanation / carboxylic acids biotechnology processes, the effect from these reactors systems on microbial communities and demonstrate the overall feasibility of the processes both in terms of productivity and energy efficiency, therefore justifying additional industry investment in scale up focused research and process deployment. The ability to produce low carbon sustainable energy, chemicals and materials to meet variable societal demands, using low temperature and pressure conversions, using a biocatalyst based microbial community and inexpensive non-metal based catalysts, and reduce energy lost through curtailment of renewable energy in the UK and across the world is expected to bring sound environmental and economic benefits for future generations.",1
BB/M018415/1,31298,FACCE ERA-NET+ GreenRice,"In Europe, rice (467 000 ha) is gown under permanently flooded (PF) conditions using irrigation waters of major rivers. Climate change, which already induces decrease in the river flows, is a major challenge in the production systems used to grow rice that needs also to cope with the increased demand of rice supply (net deficit of 0.86 Mt in Europe). Rice yields under existing production practices are therefore threatened by scarcer water availability and more frequent extreme weather events. In addition, PF rice fields emit greenhouse gases (GHG), mainly methane (CH4), that have a very strong warming potential. Alternative wetting and drying (AWD) is a system in which irrigation is applied to obtain 2 to 5 cm of field water depth. After a certain number of days (normally 2 to 7), when the field reaches a threshold of soil water potential, water is applied again. It is considered that water input can be reduced by 15-30% with no loss in yield and that GHG emissions will be reduced by up to 48 %. AWDS represents therefore an interesting alternative for European rice production. The objective of GreenRice is to test AWDS in three regions of Italy, Spain and France that are representative of the diversity of European rice growing areas. In the deltaic areas (Spain and France), rice and natural wetlands protected through natural regional parks are interdependent. We will evaluate the implications of shifting from a PF to an AWD system on rice environment and productivity. Changes on environmental elements such as water consumption, soil salinity, soil microbial community, GHG emission, soil chemistry, and arbuscular mycorrhizal (AM) colonization will be monitored. We will identify varieties that maintain their productivity under AWDS through whole genome association mapping of a large panel of temperate varieties and will set the bases for marker-aided breeding using genomic selection to predict the values of additional breeding lines. We will investigate traits determining adaptation to AWDS such as root development, AM colonisation, salinity tolerance and resistance to nematodes using the same large panel of European genotypes; AM symbiosis impact on biotic stress (blast) alleviation will be tested. An extensive gene expression study will identify the root types and genes of major importance in transport process and the degree to which they are affected by AWDS. The role of plant traits and the soil microbial community in modulating C, N and GHG cycling will be investigated in controlled environment studies. The results obtained will be disseminated to the local stakeholders (farmers and natural parks and spaces, mainly) and to the scientific community (through web site, database and publications). Scientists specialized in molecular genetics, functional genomics, phytopathology, agronomy, ecology, and bioinformatics from 7 institutions of 4 countries will be involved.",1
102976,6093,Reducing global fresh produce waste by developing our innovative ethylene scavenger as a self-adhesive label,"Every year, 33% of all food produced globally is wasted or lost during production or consumption. In the UK alone, annual waste is 15 mt (worth over &pound;19 bn) of which 75% could have been avoided. Across Europe 27% of all fruit &amp; vegetables are lost or wasted between processing &amp; consumption (FAO). Current UK food waste of 12 mt is associated with the production of 20 mt of greenhouse gas emissions. In addition, uneaten food occupies almost 1.4 billion hectares of land (~30% of the world窶冱 agricultural land) and around 550 billion m3 of water is wasted on a global scale from fruit &amp; veg which are never consumed (FAO). As the EC expects food waste to climb from 90 mtpa to 126 mt by 2020, across Europe, there is clearly a need to develop new technologies which are capable of prolonging the life of perishable produce. One way of prolonging the life of fresh fruit &amp; vegetable produce is through ethylene scavenging. Ethylene is a plant hormone responsible for premature ripening, salad wilting and colour loss. Our aim is to adapt our patented ethylene scavenging agent for use as a self-adhesive label to attach onto fruit packs/fruit punnets. It is envisaged the benefits of this new solution will be: <U+2022> Extend shelf life by at least 2 days; <U+2022> 50% reduction in fruit waste due to extended shelf life <U+2013> reducing biowaste by 24 thousand tonnes per annum (ktpa) &amp; reducing greenhouse gas emissions by 36 ktpa; potential to reduce this by up to 2.4 million tonnes; <U+2022> Completely safe for food application; <U+2022> Generate &pound;57 million in revenue for users of the technology; <U+2022> Create a total of up to 660 jobs throughout the fresh produce industry",1
NE/P007694/1,20848,"Quantifying ENSO-related bleaching on nearshore, turbid-zone coral reefs: a test of the turbid-zone reef climate change refugia hypothesis.","Over the last two months there have been increasing reports of the current El Ni&ntilde;o causing massive coral bleaching along Australia's Great Barrier Reef (GBR), with aerial surveys reporting that &gt;90% of reefs are bleaching, and with more that 50% of corals on these reefs already dead. However, these surveys cannot assess what is happening on the nearshore turbid-zone reefs, firstly because turbidity levels inhibit aerial assessments, and secondly because there is little ecological data against which to compare change. The bleaching response of corals on these turbid-zone reefs is however of significant scientific interest. This interest relates specifically to the hypothesis that there may be particular marine environments that might act as important refugia sites from bleaching i.e., settings that are more effectively buffered from surface warming such that coral populations remain largely unaffected. Reefs forming in well-flushed, highly turbid settings are one such candidate location for these refugia. Increased bleaching resilience has been hypothesized because high particulate content in the water may limit UV stress, and because the corals may be more readily able to switch to predominantly heterotrophic feeding modes - reasons for enhanced protection from thermal stress events that were initially hypothesised in the early 2000's. However, recent modelling now provides a global-scale framework through which the spatial extent of such potential refugia can be defined. What is lacking however is any empirical field evidence definitively showing that these turbid-zone reefs are actually able to withstand major coral bleaching events. 

Without doubt the best studied of these turbid-zone reefs are those along the nearshore areas of the GBR, which have been the focus of intensive study by the PI and his group since 2006. This work has largely focused on assessing rates and styles of reef growth, but our most recent work has had as its central aim an assessment of te spatial extent and contemporary ecological structure of these reefs. Working at sites in the central GBR we have undertaken an unprecedented mapping and ecological surveying campaign, collecting &gt;130 km of seafloor swath survey data and &gt;4,500 video still quadrats. The resulting datasets have enabled us to develop high resolution maps of reef structure and ecological composition, which show that despite their narrow bathymetric extent, these reefs are characterised by a clear depth-controlled ecological zonation, and that they exhibit high live coral cover (mean: 38%, but up to ~80%). We are thus in a unique position to quantitatively assess the extent to which this major bleaching event has impacted these turbid-zone reefs, and to test the recently proposed hypothesis that such reefs may act as critical climate change refugia sites.

In this project we will undertake a rapid assessment of the impacts of bleaching on the turbid-zone reefs in the vicinity of Paluma Shoals (central Halifax Bay). We will re-examine a suite of six proximal reefs using remotely-operated underwater video survey methods and collect ecological data along replicate transects across each reef. Video data will be used to determine species abundance and bleaching intensity. This will allow us to ascertain: 1) the total extent of bleaching-induced mortality; 2) the extent to which specific coral species have been impacted; and 3) any immediate impacts on the structural complexity and diversity of the reefs. We will also undertake comparable assessments at other turbid-zone reefs which have been the focus of our earlier studies e.g., further north around Dunk Island and to the south at Middle Reef- these reefs occupying similar geomorphic and sedimentary settings to the Paluma complex. The work would thus deliver not only data on the extent of turbid-zone reef bleaching, but also provide a robust test of the hypothesis that turbid-zone reefs may form critical climate change refugia sites.",1
NE/S011870/2,41528,Safeguarding Pollination Services in a Changing World: theory into practice (SURPASS2),"Insect pollinators have undergone declines across the world, a result of factors including intensive agriculture, habitat loss, climate change and invasive species. This represents a major concern in Latin America (LATAM) where it threatens economically important crops and wider biodiversity. The impact of these losses in LATAM remains poorly understood, undermining the capacity to develop policies vital to mitigate pollinator losses and support both agricultural production and wider ecosystem health. A new, coherent evidence base is required, that considers impacts on individual species, their distributions and populations, the landscapes they persist in and their unique capacities to deliver pollination to different crops. Without this it will not be possible to develop the applied experimental and modelling solutions policy makers need to deliver sustainable farming economies. This proposal builds on Newton Phase 1 project SURPASS, an international collaboration between 37 participants, that identified knowledge gaps, issues, and research areas that prioritise conservation and sustainable use of LATAM pollinators. The SURPASS2 goal is to deliver evidence for the creation of resilient pollination services for sustainable economic growth, improved human health and wellbeing as well as positive environmental and agricultural outcomes. This will be addressed by five main objectives, co-designed with academics and stakeholders that establish interconnected work packages that build capacity to manage pollination services and provide tangible outcomes. Our goals will be delivered through 4 work packages: 

WP1) Monitoring populations and understanding their distributions: before any effective solution can be developed to manage LATAM pollinators it is crucial that we understand the current distribution of species and develop and trial approaches for long term monitoring. Only by understanding where pollinators can be found can we develop applied solutions to manage them. We will design a standardised framework to assess the status and trends of pollinator populations through existing and new monitoring schemes, including citizen science. 

WP2) How does the environment in which pollinators live affect them, and how does this affect capacity to provide crop pollination: Land use change and land management represent fundamental factors affecting pollinator populations. We will undertake detailed landscape scale experiments across LATAM focusing on production of economically significant crops to understand how landscape management affects pollinators and the pollination services they supply. This will provide data for models and help growers, land managers and policy makers to optimise pollination to sustainably increase crop yields and quality. We will also quantify how invasive species of pollinators impact on wild and native insect pollinators and plants. 

WP3) Understanding national scale deficits in pollination for key crops identifying areas where pollination services are at high risk. Using cutting edge satellite imagery we will map nationally the occurrence of key insect pollinated crops. We will link this data to the distribution of insect pollinator communities to assess if these populations provide adequate pollination, as well as modelling how resilient these communities are to species losses. As each species of insect pollinator is unique their loss can have potentially huge consequences for agricultural production. 

WP4) Develop a national scale predictive framework to support policy goals of maximising benefits for agricultural productivity provided by pollination. This will integrate results from WP1-3 to model pollinator communities to develop effective strategies for decision making processes for different stakeholders that benefit from insect pollination. This will provide the framework to work with stakeholders to produce a roadmap for maximising pollination services and long term monitoring in LATAM.",1
NE/N020677/1,5607,U-Alert,"Key words: 
Africa, floods, heat waves, air pollution, climate change adaptation, mobile data, satellite, remote sensing, urban, risk

Summary:
Africa is one of the most vulnerable continents in the world to climate change with widespread low adaptive capacity and resilience. Climate change is already exacerbating many development challenges such as endemic poverty and inequality, ecosystem degradation, natural hazard related disasters and food security. The frequency and severity of extreme climatic events including droughts and intense rainfall events has increased in recent years. These climatic events are now having a significant impact on people's lives and livelihoods causing deaths and damage from heat waves, flooding and air pollution. Climate change is also making these events more unpredictable and difficult to manage, especially in densely populated urban environments where emergency services and infrastructure is often inadequate and thus unable to respond to rapidly changing situations and multiple simultaneous pressures.

At the same time, urban areas are becoming increasingly populated as people migrate from rural areas in search of better employment opportunities and a standard of living. Due to this sudden influx of people (and expansion of urban areas and slums), many vulnerable people are being forced on settle on marginal land such as flood plains and steep slopes and thus being placed at greater risk. There is a growing demand for new forms of environmental monitoring to better predict and be able to respond extreme climatic events. Unfortunately, many regions in Africa are characterised by poor environmental data and sparse weather stations, there is a lack of observations to validate and downscale climate change projections, accurately predict and assess impacts as well inform short/long term adaptation strategies. Many cities and infrastructure users in Africa are reliant on the services and expertise of international and national experts constrained by data limitations, who are reliant on coarse resolution climate data and projections which can result in misinterpretation and misinformation being issued. There is thus a pressing need for better localised hazard prediction systems to monitor and manage the impacts of extreme events such as flooding, heat stress and air pollution, informed from and delivered directly to at risk populations.

It has been demonstrated that signals sent between mobile phone antennas can provide an alternative means to measure rainfall intensity and duration in situations where in-situ data isn't available. This data can be combined with hazard models to predict the degree and extent of flooding in urban areas. Furthermore, other studies have demonstrated that accurate air temperature information can be derived from internal smartphone sensors and by measuring battery discharge fluctuations. Simultaneously, satellite derived aerosol measurements can provide information on air pollution and public health risks. The combination of the aforementioned mobile derived data and remote sensing techniques can be used to warn urban populations of impending climate risks. The growing number and use of mobile phones in developing countries allows SMS warnings and advice to be delivered to those in need of this information, as well as a means to collect data on essential climate variables through the creation &quot;citizen observatories&quot;. This project aims to assess the feasibility and scope of bringing together such technologies to collect information of urban risk and vulnerability, analyse it to produce warnings and deliver it directly to mobile phone users in affected areas in an &quot;easy-to-action&quot; message.",1
NE/R011451/1,20820,Evolutionary resistance: Does adaptation stabilise plant community structure and function under climate change?,"Globally, we depend on grasslands to support biodiversity and agricultural productivity, offer recreational areas, and provide a wide range of other valuable ecosystem services. For example, the UK dairy industry, which is worth ~&pound;4.27 billion per year, depends entirely on grasslands. At the same time, grasslands are among the most altered and least protected ecosystems, and they are now being to the imminent effects of climate change: warming, drought, flooding.

Grassland organisms may ultimately cope with climate change by adapting, via evolution, where environmental change selects for individuals of a species that have advantageous characteristics (specific 'phenotypes'). This adaptive response stems from both changes in phenotype, and changes in the way organisms express their characteristics in a new environment (called 'phenotypic plasticity). Both aspects increase the likelihood that organisms will thrive in the new environment. Both of these components of evolution can buffer populations against the adverse effects of climate change. However, we do not know how evolutionary change will alter communities of coexisting species or the important ecosystem processes that underpin the important benefits of grasslands to our society. 

This study focuses on species-rich grasslands, which have a high conservation value, and are an iconic feature of UK landscapes. They can contain more than 40 plant species per square metre and any of these coexisting species may evolve when exposed to climate change. Nobody knows how these adaptive changes in component species could influence grassland plant communities and the ecosystem as a whole, and whether they will allow grasslands to remain relatively unchanged (&quot;resistant&quot;) during climate change. This is because, to date, most scientists have studied climate-driven evolution in single isolated species, which does not allow us to assess how adaptation could influence interactions among co-existing species. 

Our research wil address this by studying climate-driven evolutionary change in plant communities in a natural grassland. For over two decades, we have exposed a species-rich grassland near Buxton, UK, to simulated climate change (warming, increased rainfall, and drought). Our research has shown very little change in the diversity and abundance of grassland plant species subjected to different climate treatments, meaning that the plant community is resistant to change. However, we have also shown that some of the plant species are adapting to the climate treatments, raising the possibility that evolution itself is the source of resistance to climate change and could explain the stability of the plant community in this species-rich grassland. 

Building on our previous work, our overarching goal is to use the Buxton climate experiment as a model to understand how evolutionary changes allow grassland plants to resist climate change at the community and ecosystem levels. In doing so, we aim to determine how species diversity contributes to the services that grasslands provide, and to better understand (and predict) threats to grasslands under climate change. 

We have designed a set of experiments to examine how evolutionary adaptation to climate changes in individual plants influences the stability of plant communities and important ecosystem processes. Over three years, we will measure i) the strength and direction of evolution in 16 coexisting plant species, ii) use mathematical modelling to predict climate impacts on grasslands and iii) test for these impacts using targeted experiments at Buxton. This will involve constructing model ecosystems, and measuring species responses, plant phenotypes, and ecosystem processes in the climate treatments. Our research will provide a unique, evolutionary view of how plants, and their phenotypes, contribute to the stability of grasslands and ecosystem processes during climate change.",1
NE/S006893/1,631,Forecasting biodiversity losses in Wallacea from ecological and evolutionary patterns and processes.,"The Wallacea region, lying between the Borneo to the west and Papau New Guinea to the east, is one of the world's biodiversity hotspots, hosting incredibly high levels of biodiversity, much of which is unique to the region. This exceptional level of biodiversity and endemism reflects evolutionary diversification and radiation over millions of years in one of the world's most geologically complex and active regions. The region's exceptional biodiversity, however, is threatened by climate change, direct exploitation and habitat destruction and fragmentation from land use change. Continued habitat loss and fragmentation is expected to precipitate population declines, increase extinction rates, and could also lead to 'reverse speciation' where disturbance pushes recently diverged species together, leading to increased hybridisation, genetic homogenisation, and species' collapse. Already, approximately 1,300 Indonesian species have been listed as at risk of extinction, but the vast majority of the region's biodiversity has not been assessed and we lack basic information on the distribution and diversification of many groups, let alone understanding of what processes drove their diversification, how they will respond to future environmental change, and how to minimize species' extinctions and losses of genetic diversity while balancing future sustainable development needs.

In response to the need for conservation and management strategies to minimize the loss of Wallacea's unique biodiversity under future environmental change and future development scenarios, we will develop ForeWall, a genetically explicit individual-based model of the origin and future of the region's biodiversity. ForeWall will integrate state-of-the-art eco-evolutionary modelling with new and existing ecological and evolutionary data for terrestrial and aquatic taxa including mammals, reptiles, amphibians, freshwater fish, snails, damselflies and soil microbes, to deliver fresh understanding of the processes responsible for the generation, diversification, and persistence of Wallacea's endemic biodiversity. After testing and calibrating ForeWall against empirical data, we will forecast biodiversity dynamics across a suite of taxa under multiple environmental change and economic development scenarios. We will develop a set of alternative plausible biodiversity management/mitigation options to assess the effectiveness of these for preserving ecological and evolutionary patterns and processes across the region, allowing for policy-makers to minimise biodiversity losses during sustainable development. Our project will thus not only provide novel understanding of how geological and evolutionary processes have interacted to generate this biodiversity hotspot, but also provide policy- and decision-makers with tools and evidence to help preserve it.",1
NE/R012830/1,26865,Pathways and Emissions of climate-relevant TRace gases in a changing Arctic Ocean (PETRA),"The Arctic Ocean is exceptionally susceptible to climate change. Recent studies have shown that surface seawater is warming faster than in other oceans. In addition, atmospheric CO2 dissolution in seawater is causing Ocean Acidification (OA). The documented retreat of sea-ice will increase light penetration, including UV. These environmental parameters (temperature, OA and UV) are highly likely to act as stressors and alter the Arctic Ocean ecosystem structure and function which in turn will feed back on climate. One such feedback is the cycling of climatically active trace gases and their emission to the atmosphere (here: CH4, N2O, DMS, CO). These trace gases are rapidly produced and consumed by a number of physical and biological processes. For example, the biggest source of CO in surface seawater is via UV-induced photochemical reactions. Yet, the likely response of trace gas cycling to climate change remains largely unexplored. This hinders our ability to predict the future direction of this important climate-feedback. We propose to investigate this feedback by a) developing the basic understanding which will underpin a predictive tool and b) developing the predictive tool itself (computer model). We will achieve this using three complimentary tools: 
Firstly, novel, high-tech spatial observations of trace gases (with depth as well as horizontal) which will allow us to identify major controls on their cycles and estimate their present flux to the atmosphere. 
Secondly, direct experiments where the three stressors will be manipulated while trace gas cycling pathways are monitored. The novelty of our approach here, lies in the use of individual and combined stressor manipulation (e.g. OA alone versus high temperature and OA together). This will allow us to explore potential synergistic or antagonistic effects between stressors. We will use state-of-the-art chemical and biological observations to track changes in trace gas cycling. For example, we will monitor the abundance and activity of key genes involved in trace gas cycling. These experiments will give us explicit and refined understanding of trace gas cycling in relation to the stressors. 
Thirdly, we will employ computer modelling which will translate this understanding into a predictive tool that will be used to predict the impact of future climate change. 
Finally, and in order to rapidly translate our relevant findings to policy, we will engage with the public, policymakers, international science programmes and Intergovernmental Panel on Climate Change (IPCC) through our comprehensive impact plan.",1
2292913,41158,Investigating the effects of environmental change on tropical montane bats,"Deforestation is a major threat to biodiversity in South-East Asia, particularly in Malaysia where more than 14% of forest cover was lost in the last decade [1]. Montane forest is being decimated at a greater rate than lowland forest because of the additional effect of climate change [2].
Approximately 20% of the 336 Malaysian mammalian species are threatened and these species are particularly sensitive to deforestation [3]. Malaysian montane forests are the last refuges for many vulnerable species. These forests are essential for maintaining habitat connectivity and gene flow across the peninsula and between the highlands and the lowlands. However, little research to date has attempted to assess how the volant mammalian (bats) community responds to the deterioration of montane forests in peninsula Malaysia. 
This project will combine well established ecological research methods, such as bioacoustics technique and mist netting, with molecular analysis to assess the bat community composition, distribution, diversity, population structure and gene flow across multiple montane forest sites with varying levels of disturbance. The outcome of this project will provide the scientific basis to inform conservation management and mitigation in high risk mammal biodiversity hotspots.",1
BB/N013360/1,10594,Indo-UK Centre for the improvement of Nitrogen use Efficiency in Wheat (INEW),"Wheat is the most important staple crop grown in the UK, and one of the two major crops grown in India. Nitrogen fertiliser is a key determinant of yield and the major cost of wheat production in both countries and excessive application can result in pollution of groundwater and increased production of greenhouse gases. Breeders and farmers in the UK and India have worked hard to improve the efficiency of use of applied nitrogen, by improving the uptake and utilization efficiency within the crop through genetic improvement, together with the precision of fertilizer application in the field. However, further improvements are required to face the challenges of increasing crop production for an expanding global population with increasing uncertainty of climate. Both yield and quality attributes are dependent upon nitrogen inputs and need to be incorporated into economic and sustainable solutions. 
We will therefore bring together the major UK and Indian wheat researchers with programmes on wheat improvement to determine the genetic control of nitrogen use efficiency in wheat. These comprise scientists from five Universities and Institutes in the UK and from six in New Delhi, Haryana and the Punjab, which is the major wheat-producing area of India.
The studies will focus on comparisons of wheat lines and populations which differ in their nitrogen use efficiency. These lines will be grown in field experiments in both countries and studied in detail using a range of biochemical and molecular genetic approaches. This will lead to the identification of genes and molecular markers that can be exploited by wheat breeders globally, and to new strategies for improving the precision of nitrogen application which will delivered to farmers via well-established mechanisms in both countries. Furthermore, since similar mechanisms are expected to determine nitrogen use efficiency in other plant species the results should be of wider applicability to other crops and countries.
In addition to supporting a closely integrated research programme in the UK and India, the Centre will also provide a legacy of shared facilities, technologies, genetic material and datasets that will facilitate longer term bilateral collaborations, and provide training in crop genetics and genomics and exchanges for early career scientists and students in both countries.",1
103916,1930,Butanediol Production in Clostridia,"More than $4T of products are made currently by petrochemical (oil) derived chemical processes and only 5 % of these potentially 窶彗ddressable markets窶・have been explored using biological approaches. There exists huge potential to reduce greenhouse gas emissions and oil dependency by further harnessing the power of Biology. Fermentation of engineered bacteria growing on sustainable feedstocks is one means to produce biochemicals. Much progress has been made but these efforts have concentrated on lab-friendly 'model organisms' which are relatively easy to genetically manipulate but which often do not scale up efficiently and economically to industrial processes. CHAIN Biotech focuses solely on microbes proven to be robust in industrial processes such as Clostridia bacteria. In this study we use new engineering tools to produce valuable chemicals called butanediols which are used widely in diverse array of applications including functional materials, pharmaceuticals and functional foods.",1
NE/P006566/2,27137,Marine Renewable Energy Directed KE Fellowship: Biofouling in the UK Marine Renewable Energy Industry,"When man-made structures, such as marine renewable energy devices, are deployed in the sea they are quickly colonised by communities of organisms growing on exposed surfaces. This marine growth, or biofouling, is often unwanted from an engineering perspective and can have consequences for structural integrity, efficiency, maintenance and functioning of devices. Non-native species are also commonly found on man-made structures, making biofouling a potential biosecurity risk and a possible vector for species invasions.

 Factors such as the type of species in the biofouling community, the geographical location and the seasonality of organism settlement and growth lead to a high degree of variability in biofouling properties such as mass, thickness and texture. At the moment marine renewable energy SME's conduct most of their design, efficiency calculations and maintenance planning based on very basic figures for biofouling thickness which do not take into account variability. Technical standards acknowledge the limitations of existing guidance and recommend that whenever possible, site-specific measurements should be used. Unfortunately, due to the newness of the industry, this data is often not available and SMEs and engineers are working with little more than a &quot;best guess&quot; when calculating for the effects of marine growth on devices.

Jen Loxton recently co-hosted a workshop which discussed biofouling on marine renewable energy devices with attendees spanning academia, regulatory bodies, and industry. Together this group identified 119 issues associated with biofouling with operational, financial or environmental impacts. A key priority which was identified to help solve many of these issues was improved knowledge exchange between science, engineering and marine industry. It was acknowledged that there is a lot of biofouling knowledge in the scientific and industrial communities but there is currently no pathway for getting this to the right people to inform renewable energy device design and maintenance decisions. It is this gap in communication which Jen aims to address in this KE project.

During the fellowship Jen will develop and launch a comprehensive online resource which will consolidate biofouling science in an accessible and industry relevant format for the UK marine renewable energy community. This resource will consist of:

- A website of biofouling knowledge, translated for industry
- An interactive tool/app powered by a database of UK biofouling distribution and characteristics

The website will provide a biofouling &quot;one-stop-shop&quot; for stakeholders associated with the UK marine renewable energy industry and help to inform engineering and operational decisions and increase awareness of potential environmental considerations. It is anticipated that it will increase the reach and impact of biofouling science.

A comprehensive database will be populated with biofouling science and species distribution data and will power the interactive tool/app. A user would specify location, deployment type and available observations of biofouling and the tool will generate a tailored suite of industrially relevant statistics and possible management techniques. Full specifications for the tool will be determined during the fellowship but examples of possible outputs include maximum biomass, thickness and rugosity of fouling, expected seasonal variations and known non-native species in the vicinity. The database will continue to grow during the life of the fellowship and beyond through live links with UK databases (e.g. NBN gateway) and the addition of user specified biofouling observations.

Information for the fellowship will be gathered from academia, regulatory bodies and from across the maritime industries, including oil &amp; gas, shipping, leisure boating and the aquaculture industries. The fellow will include data from previous NERC projects (e.g. EBAO and FlowBec), expanding the impact of this research.",1
EP/R018847/1,11631,CBET-EPSRC A Game-Changing Approach for Tunable Membrane Development: Novel COF Active Layers Supported by Solvent Resistant Materials,"Periodic water shortages in many regions throughout the world are increasing because of population growth, urbanization, economic development, and climate change. The need to provide a safe drinking water supply from increasingly complex sources polluted by multiple contaminants has motivated the development of novel membrane technologies. Pressure-driven nanofiltration (NF) and reverse osmosis (RO) membrane processes are increasingly used for drinking water treatment because they are capable of removing all pathogens and most organic and inorganic contaminants in a single treatment step. However, more widespread adoption of these technologies has been limited because of inadequate resistance of state-of-the-art NF and RO membranes to (bio)fouling, compaction, and chemical oxidation coupled with a relatively narrow range of solute selectivity. 
This project will overcome the current NF and RO membrane challenges by using pioneering interfacial polymerization (IP) methods to fabricate active layers of two-dimensional covalent organic frameworks (COFs) interfaced with compatible support media. 2D COFs are crystalline, permanently porous, and layered macromolecules with structure, chemical composition, and porosity set through the rational design of their monomers. COFs will provide separating layers comprising uniform pores with tailored size, shape, and variable chemical functionality in contrast to the amorphous and empirically optimized polyamide active layers present in the state-of-the-art NF/RO membranes. 
The project contributes fundamental knowledge towards a new class of membranes to affordably solve many of the global water challenges through the design, synthesis, and characterization of a new library of COF-based membrane active layers that will be formed directly on novel support layers and tailored to meet specific performance targets. The novel COF-based membranes have the potential of significantly decreasing the operating costs of membrane based water treatment systems and increasing broader implementation of these technologies.",1
NE/N013034/1,9888,Assessing the risk to the coastal and rural road network in Scotland due to the effects of storms and extreme rainfall events,"One of the key challenges for Scottish transport infrastructure is the identification and assessment of assets at greatest risk to damage from landslides, storms and flooding. This is particularly the case with the vulnerability of the rural and coastal road network. The Scottish Climate Change Adaptation Framework (Transport) states that the location and design of new infrastructure, must take account of an increased likelihood of risks from flooding and landslides. Many coastal areas already appear to be experiencing increased intensity of storms and extreme rainfall events and recent high profile events (e.g. inundation of A78, Skelmorlie, extensive damage to vital roads and causeways in the Western Isles, landsliding at Stonehaven and the repeated disruption along the A83 at the Rest and be Thankful, Argyll and Bute attest to the need for an accurate assessment of those areas at greatest risk and for the implementation of potential mitigation measures. Adaptation Scotland provides a wealth of existing science, data and advice on how to adapt in the face of increasing change, but there is a need to develop robust tools for using this to assess the corresponding risk and economic impact for effective whole-life asset management. 

The aim of the project is therefore to develop a robust risk management tool, easily utilized by asset managers to assess threats to rural road transport assets in Scotland that are likely to be at risk from the effects of extreme rainfall and storms and differing future climate change scenarios. This will be determined by the following objectives:

- Adaptation of an existing framework for landslide hazard assessment through the incorporation of recently-developed datasets to allow application also to flooding/coastal geohazards;
- Production of diagnostic criteria to assess the nature of the different hazards (these include susceptibility to the various hazards and the spatial relation to the asset or road), 
- Analysis of the risk posed to key areas of the network infrastructure (local and trunk roads) by means of an assessment of the elements at risk (road and road users) and their vulnerability within a multi-hazard environment;
- Assessment of economic impact to inform climate change adaptation plans and decision making for stakeholders at various levels from transport authority to local authority. Two case studies will be examined: (i) A78 Shore Road area and (ii) North and South Uists and Benbecula with island-linked causeways providing vital access to the Western Isles. 

The stakeholder is Transport Scotland.

Keywords. extreme events, adaptation, resilience, management tool.",1
NE/M020088/1,22911,Future Resilience for African CiTies And Lands (FRACTAL),"The problem: Building climate change resilience necessarily means building urban resilience. Africa's future is dominated by a rapidly increasing urban population with complicated demographic, economic, political, spatial and infrastructural transitions. This creates complex climate vulnerabilities of critical consequence in the co-dependent city-regions.
Climate change substantially complicates the trajectories of African development, exacerbated by climate information that is poorly attuned to the needs of African decision makers. Critical gaps are how climate processes interact at the temporal and spatial scales that matter for decision making, limited institutional capacity to develop and then act on climate information, and inadequate means, methods, and structures to bridge the divides. Current modalities in climate services are largely supply driven and rarely begin with the multiplicity of climate sensitive development challenges.
There is a dominant need to address this disconnect at the urban scale, yet climate research in Africa is poorly configured to respond, and the spatial scale and thematic foci are not well attuned to urban problems. Most climate-related policies and development strategies focus at the national scale and are sectorally based, resulting in a poor fit to the vital urban environments with their tightly interlocking place-based systems.
Response: FRACTAL's aim is to advance scientific knowledge about regional climate responses to anthropogenic forcings, enhance the integration of this knowledge into decision making at the co-dependent city-region scale, and thus enable responsible development pathways.
We focus on city-region scales of climate information and decision making. Informed by the literature, guided by co-exploration with decision makers, we concentrate on two key cross-cutting issues: Water and Energy, and secondarily their influence on food security. We work within and across disciplinary boundaries (transdisciplinarity) and develop all aspects of the research process in collaboration with user groups (co-exploration).The project functions through three interconnected work packages focused on three Tier 1 cities (Windhoek, Maputo and Lusaka), a secondary focus on three Tier 2 cities (Blantyre, Gaborone and Harare), and two self-funded partner cities (Cape Town and eThekwini). 
Work Package 1 (WP1) is an ongoing and sustained activity operating as a learning laboratory for pilot studies to link research from WP2 and 3 to a real world iterative dialogue and decision process. WP1 frames, informs, and steers the research questions of WP2 and 3, and so centres all research on needs for responsible development pathways of city-region systems.
WP2 addresses the decision making space in cities; the political, economic, technical and social determinants of decision making, and seeks to understand the opportunities for better incorporation of climate information into local decision making contexts.
WP3, the majority effort, focuses on advancing understanding of the physical climate processes that govern the regional system, both as observed and simulated. This knowledge grounds the development of robust and scale relevant climate information, and the related analysis and communication. This is steered explicitly by WP1's perspective of urban climate change risk, resilience, impacts, and decisions for adaptation and development.
The project will frame a new paradigm for user-informed, knowledge-based decisions to develop pathways to resilience for the majority population. It will provide a step change in understanding the cross-scale climate processes that drive change and so enable enhanced uptake of climate information in near to medium-term decision making. The project legacy will include improved scientific capacity and collaboration, provide transferable knowledge to enhance decision making on the African continent, and in this make significant contribution to academic disciplines.",1
BB/M026221/1,33685,Risks and Opportunities for Sustainable Aquaculture (ROSA),"The aquaculture of suspension-feeding bivalve shellfish (i.e. mussels, oysters, cockles, clams, scallops) is among the fastest-growing of all food-producing sectors, making a direct contribution of more than &pound;500 million to the UK economy , with much greater multiplier effects, all projected to grow significantly in the coming decade. Despite these contributions, we lack a clear national roadmap that describes how to optimise the growth and integration of this sector with diverse activities now taking place in the coastal zone. 

Aquaculture may have both positive and negative impacts on the marine environment. In particular any overexploitation of an area may have severe effects on commercial productivity and ecosystem health. Consequently UK aquaculture operations are required to conform to strict controls including an environmental impact assessment. The goal of ROSA is to develop management strategies which will allow sustainable development, balancing the potential benefits (e.g. improved water quality, mitigation of biodiversity loss, economic activity) with the risks (e.g. loss of habitat due to both siting of farms and seed collection). Such knowledge is vital for successful promotion, societal acceptance and development of the industry.

A key factor for successful aquaculture is the suitability of farmed species. This depends upon a number of factors including growth rate, cost of production, market price, site location and resistance to disease. Assessing these issues is complicated, because shellfish are highly responsive to fluctuations in temperature, salinity, food availability and food composition, as frequently occur in near-shore environments where most aquaculture takes place. These responses not only affect shellfish population growth, but also the capacity of each host ecosystem within which aquaculture is situated. 

As environmental dynamics alter, for example due to climate change, the risks and opportunities for aquaculture are almost cerain to change. As a result, the species farmed and associated culture practice may also have to change. Consequently, we must consider the potential risks and benefits of environmental change; addressing direct impacts such as increasing temperature, storminess, exposure to wind and waves, plus frequency of harmful algal bloom events. It is also important to identify locations and culture practices that minimise impacts at local and regional scales. Only by modelling how suspension-feeding shellfish interact with ecosystem processes, can environmental impacts of and capacities for culture be realistically assessed. We propose to enable such modelling within a bespoke and portable desktop-based model tool on behalf of the UK aquaculture sector. This will draw upon the best available science and tools, realising the potential of this integrated approach to resolve temporal and spatial variations within a GIS decision support platform tailored according to user requirements. For the first time, at scales ranging from individual farms to regional waters, this will enable the projection of likely risks resulting from interrelations between habitat suitability and culture practise. To ensure immediate applied relevance, the tool will be developed in direct consultation with the aquaculture industry and its regulators.",1
2281483,45024,Blooming blanket weed: managing nuisance algae in National Trust water bodies,"Comprising various filamentous green macroalgae genera (including Cladophora, Ulva, Hydrodictyon and Spirogyra), blanket weed blooms can damage ecosystem services, conservation and amenity value of freshwaters. The algal masses can harbour pathogens, disrupt the ecological balance of ecosystems and reduce access for water-based activities. Reasons for the sudden proliferation of blanket weeds are poorly understood, but probably linked to nutrient (N and P) supply, climate warming, inter-species competition, and trophic interactions. The studentship will focus on understanding the extent of the problem in the UK, the causes of blanket weed blooms, and identifying sustainable management techniques. Support from the National Trust will include access to affected sites and relevant datasets, with a focus on Clumber Park Lake (Nottinghamshire) as a case study site.",1
EP/P004229/1,23071,Dynamically Adaptive and Resilient Water Supply Networks for a Sustainable Future,"Through this Fellowship, I aim to develop fundamental scientific methods for the design, optimisation and control of next generation resilient water supply networks that dynamically adapt their connectivity (topology), hydraulic conditions and operational objectives. A dynamically adaptive water supply network can modify its state in response to changes in the operational conditions, performance objectives, an increase in demand and a failure. This is a new category of engineering (cyber-physical) systems that combine physical processes with computational control in a holistic way in order to achieve dynamic adaptability, resilience, efficiency and sustainability.
 Water utilities are facing an increasing demand for potable water as a result of population growth and urbanisation. Cities are reaching unprecedented scale and complexity and the reliable provision of safe water is a global environmental security challenge. New technologies and knowledge are urgently needed to meet environmental, regulatory and financial pressures. Recent advances in sensor and control technologies, wireless communication and data management allow us to gain extraordinary insights into the operation of complex water supply networks and their control. Novel simulation and optimisation methods are required to make use of the new knowledge about the dynamics of large-scale water supply systems and the ability to control their operation in order to improve resource and asset utilisation.
 In the course of pioneering and leading an extensive programme of applied research in dynamically adaptive water supply networks, I have identified fundamental mathematical and engineering challenges of how such complex systems should be designed, retrofitted, modelled and managed in order to address multiple operational applications either simultaneously or sequentially. For example, the network management can be optimised to reduce leakage, improve water quality and enhance incident response. Furthermore, developing a robustly scalable simulation and control system is extremely challenging due to the complexity of the computational tasks for medium to large-scale water supply systems. This research programme will investigate, develop and validate a novel analytical and robust computational framework for the concurrent design, operation and control of adaptive water supply networks that dynamically configure their connectivity (topology), hydraulic conditions and operational objectives. The proposed framework should simultaneously optimise the design (e.g. placements of advanced network controllers and monitoring devices) and the operational control (e.g. the optimal selection of functions and settings for the valves and pumps). This co-design approach also considers the hydraulic dynamics, uncertainties, environmental changes and the development of mathematical optimisation methods for network operability and controllability in order to manage the operation of complex water supply systems efficiently, intelligently and sustainably. 
 This is an ambitious and transformative research programme that requires solving numerous problems spanning several disciplines in water systems engineering, applied mathematics, control engineering, cyber-physical systems and sensors research. The Fellowship will provide me with a unique opportunity to dedicate most of my time to develop, validate and champion into practice the design and control methods for dynamically adaptive, resilient and sustainable water supply networks.",1
NE/M007413/1,25697,GLORIA - Global Learning Opportunities for Regional Indian ocean Adaptation,"The oceans are not warming evenly and those areas that are warming fastest are becoming the world's natural laboratories for research to increase scientific understanding, knowledge and tools to allow us to adapt wisely, efficiently and effectively in order to meet the challenges of a warming environment. Such 'hotspots' occur in all regions of the globe, from polar to tropical, and affect developed and developing countries. However, poor coastal communities in low-income countries are those where the impact will be felt most acutely, and where impacts of climate change are most likely to exacerbate existing inequalities and social tension.
There are no simple, conventional solutions to addressing adaptation to climate change in poor communities. Practical experience and scientific information from these areas is limited and there is an urgent need to improve and test the theories that underpins existing efforts. This project will develop an innovative rapid approach to integrate and apply global scientific and local information and knowledge. The approach will be applied in Madagascar, one of the poorest countries affected by a marine hotspot and will work as a case study for applying to other global hotspots. At its core is an expert workshop, which will bring together a multi-disciplinary team of world-leading researchers with experience from climate change adaptation on the larger, global-scale, regional experts and specialists with detailed knowledge of the hotspot area, and community representatives who can provide a rich local understanding, knowledge and context. Together they will identify key areas of environmental change and their likely consequences for local populations. They will explore adaptive solutions, develop recommendations for future action to minimize societal impacts on low-income communities in the hotspot region, and most use experiences and information from this participatory process to develop and test current theories for developing climate change adaptation strategies. The scientific insights generated by the research will be included in a synthesis paper, and in dissemination/awareness materials targeting the local audience. 

While this project will not be able to test current theories by implementation, it will provide a valuable opportunity for intensive discussion and exchange on adaptive solutions between experts in the theory and coastal stakeholders who are intimately familiar with their own circumstances and needs. The outcomes from the project will therefore enrich current understanding of adaptation and adaptive capacity and generate proposals for revising it where necessary.",1
NE/P004091/1,1294,ACRES - Agricultural Climate Resilience to El-Nino in sub-Saharan Africa,"El Ni&ntilde;o related droughts are leaving many millions of southern African smallholder farmers facing hunger, whilst at the same time above average rains are being experienced in parts of East Africa. The differential impacts of extreme events on farmers who have adapted their land management practices to become more &quot;climate-smart&quot; are poorly understood and quantified. Assessing the impacts of Conservation Agriculture (CA) on climate resilience of smallholder farming systems is the focus of this comparative ACRES project led by an experienced cross-disciplinary team. 

A temporal component to studies will be enabled by links to past and ongoing studies in SE Kenya and southern Malawi. The wider significance of such new data will be contextualised through a continent wide meta-analysis of past CA studies that will provide an easily accessible database and identification of climate specific land management advice to global partner organisations to provide context-relevant guidance on Climate Smart Agriculture practices. This will provide vital insights on the contributions of CA to enhancing climate resilience of agricultural livelihoods and explicit consideration of societal and gendered components of farmer decision-making which have been stressed as urgent needs by development NGOs and Government agencies alike. 

The current El Ni&ntilde;o event offers an opportunity for repeat study of crop pest issues in the Kenya case, especially given the recognised similarity to the 1997/98 event (NOAA, 2015). This project will also enable comparison with Malawi studies where an ongoing research programme is exploring CA decision-making, use of climate service information and monitoring of crop pests under different land management practices.
Directly comparable integrated participatory and environmental crop pest survey approaches will be adopted in both case study regions. New evidence on crop pests, diseases and land management decisions will be provided by participatory approachegaining farmers' observations about crop pests / diseases and will be cross-validated by sampling of grain stores for pests and diseases in both study areas. The comparative case study approach, and its alignment to the wider meta-analysis study, will allow for improved understanding of what works in terms of land management practices enhancing resilience to extreme climate variability. The project outputs will enable lesson learning across locations with improved understanding of the capabilities and limitations of CA in a contextualised way as required to inform extension messages and to guide future CA project planning and institutional support structures. 

The project stems from a series of multi-stakeholder research planning events led from across the project team in both study countries. This co-production or research priorities will enable us to ensure that ACRES outputs are tailored to the needs of major donors (e.g. World Bank, African Development Bank, DFID), Government Departments, NGOs (Christian Aid, Care International, Concern Worldwide, Total Land Care) and to private sector companies (e.g. Ilovo Sugar in southern Malawi). These multiple stakeholder links (at range of governance levels) will ensure that findings and agricultural land management lessons are shared beyond the smallholder farmers who are the focus of the study.",1
EP/R032041/2,45010,Circular4.0: Data Driven Intelligence for a Circular Economy,"Circular approaches to design, manufacture and services are proposed as one of the most significant opportunities to radically re-think how we use and re-use finite resources. Pairing the digital revolution with the principles of a Circular Economy (CE) has the potential to radically transform the industrial landscape and its relationship to materials and finite resources, thus unlocking additional value for the manufacturing sector. Despite meaningful success by a handful of manufacturers to move towards more sustainable practices through the use of data-driven intelligence, it is unclear which CE strategy is the most valuable for a business and at what time in a products lifecycle it should be implemented. As such, this research aims to identify how data from products in use can inform intelligent decisions surrounding the implementation of Circular Economy strategies so as to accelerate the implementation of circular approaches to resource use within UK manufacturing.

Multiple research efforts and best practice examples have shown that a transition towards a Circular Economy can bring about lasting benefits from a more innovative, resilient and productive economy. This is particularly prevalent for manufacturing as it offers one of the biggest potentials for economic and environmental impact of any sector. It is estimated that materials savings alone in the European Union could amount to USD 630 billion. Digital technology is rapidly becoming a key enabler for unlocking the value from Circular Economy strategies with an estimated 10 billion physical objects with embedded information technology already in existence today and a predicted 50 billion in use by 2020. For the manufacturing sector, the ability to monitor and manage objects in the physical world electronically through data-driven decision-making changes the way that value is created. The capture and analysis of data streams between manufacturing, product and user is already enabling organisations to decouple manufacturing growth from resource consumption through new service offerings, providing customers with added value such as financial savings and safety improvement, and enabling organisations to shift their business model from selling to leasing. This shift in ownership, enabled through access to the right data, brings about a need for manufacturers to design products that last and to integrate processes such as remanufacturing to enable materials and resources to be cycled as many times as possible resulting in significant environmental savings, job creation and up-skilling associated with the development of new processes. Through harnessing digital technological advances to inform decisions on Circular Economy strategies, this research has the opportunity to radically transform UK manufacturing and enable the sector to capture significant value from a Circular Economy that is currently being lost.

The originality of this research lies in using data-driven intelligence to optimise the selection of CE strategies for products and the timings of intervention in the product lifecycle. This challenging three year project will bring together an internationally renowned team of experts in Circular Innovation, Manufacturing Informatics and Information Theory from Cranfield University and University of Sheffield drawing on leading-edge strengths of the host institutions and international connections with research communities, companies, business intermediaries and governance at national and international scales. The research team will partner with key players across the manufacturing sector, capable of initiating system level change, to develop novel methods for acquiring and integrating new data streams, uncovering exciting opportunities for new value creation within manufacturing organisations and enabling informed circular interventions surrounding the manufacture and use of products.",1
1757782,1895,Sustainable Agriculture for Smallholder Farming Communities in Papua New Guinea,"Combining agricultural production with biodiversity conservation will be one of the main challenges of the 21st century. Smallholder farmers in developing countries play a key role in this issue. Smallholders currently supply at least 70% of the global agricultural output. They need to increase their production to meet the food demand of a rapidly growing population. However, smallholder farmers are highly vulnerable to disturbances such as climate change. At the same time, agriculture is already having major negative impacts on the environment. The majority of smallholders live in the most threatened species-rich regions on Earth, so how smallholder farmers manage their environment is of crucial importance to the state of biodiversity. Hence, the question is how smallholder farming communities can produce the food required to feed their families while safeguarding the environment. To answer this question we need to understand the trade-offs between farming and biodiversity, whether enhanced agricultural production by smallholders is feasible, and how sustainable land use planning that balances the objectives of agricultural production and biodiversity conservation can be achieved. So far most research regarding trade-offs between farming and biodiversity, and intensification has been performed on large-scale farms in temperate, developed regions. As a result, there are currently major knowledge gaps with regards to smallholder farming systems in the developing world. Besides, there is a need for the development of participatory planning methods that can be used by organizations and practitioners to engage in future planning and adaptive capacity building with local communities. This study aims to contribute to fill these gaps by investigating how sustainable agriculture in smallholder farming communities can be achieved, taking smallholder farming in Papua New Guinea as a study case. By doing so, the hope is to provide evidence for policies that promote sustainable food security for smallholder farming communities, and ultimately help to contribute to a diverse world with no hunger.

BBSRC Priority Areas: Food, Nutrition and Health &amp; Sustainably Enhancing Agricultural Production
Cross Council Priorities and Programmes: Environment and Land Use &amp; Global Food Security &amp; Living with Environmental Change

AFS",1
NE/N019792/1,3303,Does the potential for AMR selection differ between common UK cattle grazing systems?,"Antimicrobial resistance (AMR) occurs because repeated exposure to antimicrobial drugs kills susceptible bacteria leaving the resistant types to multiply. Recent high-profile reports of the devastating consequences for human health caused by the resistance of disease-causing bacteria to antibiotics have emphasized the need to understand the processes that drive increasing prevalence of antimicrobial resistance in human and animal pathogens.

Farm animals are considered to be a major source of AMR because of the large amounts of antibiotics used both to treat infection (therapeutic use) and to prevent infection (prophylactic use). However, little is known about the background levels of resistance in farming systems, even when animals are only treated with antibiotics when they need them (therapeutically). For instance, the sharing of genetic material by bacteria that are in close proximity is another route where AMR may emerge unexpectedly in otherwise non-related bacteria. AMR transmission between cattle is likely to be greater when they are close together, for example during the winter housed period. In this proposal we will use an experimental farm where cattle being raised for beef production only receive minimal antibiotic treatment described as 'best practice' by vets. We will monitor dynamics of AMR bacteria and genes in cattle dung in summer when the cattle are grazing in the field, and in the winter when they are housed together. We will carefully monitor cattle who have been sick and have been given antibiotics and those in the rest of the herd.

The diet of farm animals may also effect increased AMR in their gut flora. Even common plants ('forage') like grass and clover that cattle commonly eat when they are out grazing produce natural antimicrobial compounds that may continue to be active in the stomach (rumen) where millions of bacteria thrive and multiply. In the winter, cattle are brought indoors and fed silage which is grassland plants that have been fermented to conserve them. Undigested diet and lots of bacteria from the rumen, and therefore perhaps AMR, are excreted in cow dung. We will analyse the dung of cattle that eat different forage types to find out if what they eat affects the likelihood of AMR arising in cattle fed one diet compared to another.

Most cattle farming in the UK is situated in the hilly 'wet West' where the potential for rain to runoff fields into waterways is high. Recent increases in storms that cause lots of runoff and flooding may be due to climate change, are predicted to continue. At the same time, in recent years there has been an increasing recognition that AMR may arise in farm animals and be released from the farm environment to the natural environment in water and might therefore end up in drinking water, bathing water or in seafood. Normally, pollution from cattle dung in water is monitored using faecal indicator organisms (FIOs), which are bacteria that do not usually cause disease but which correlate with those that do (pathogens), and can be handled safely by scientists. It would be useful to know what proportion of FIOs carry AMR, because they are routinely tested for, facilitating estimates of AMR transmission to be estimated in the future. We will sample water flowing from fields that have been grazed by beef cattle or spread with their manure, and analyse the bacteria in the water including the FIOs to see if they are resistant to antibiotics.

The results of this study should help us to understand whether AMR that arises in cattle herds may be transferred to the environment, whether management can limit AMR and its transport, and inform approaches for assessing risks of new antibiotics and managing adverse effects that might be occurring. It is important work for addressing risk in our complex agro-food system that is clearly important for both consumers and farmers.",1
2274919,38252,Sustainable Perovskite Solar Cells,"With the current climate emergency, an alternative to greenhouse-gas producing fossil fuels must be found urgently. More energy, in the form of photons, strikes the Earth's surface in a minute than all the energy used to power the planet in a year, so solar energy is an evident candidate for a renewable alternative. Perovskite solar cells look to address the limitations of established crystalline silicon and thin-film photovoltaics such as copper indium gallium selenide (CIGS) devices. The components of perovskite solar cells are both earth-abundant and can be prepared at low temperature using solution-based methods, whereas established device fabrication methods are energy intensive and metals used are rare. This means fabrication is cheaper and requires less energy, thus these devices will be more market-competitive in the energy sector.

The research undertaken within this PhD aims to accelerate developments towards fully &quot;green&quot; solar technology. Currently, fabrication techniques involve the use of hazardous and environmentally damaging solvents, such as N,N-dimethylformamide (DMF) to form the perovskite absorber layer. Also, commercialisation relies on the removal of lead completely from the perovskite or developing a method to remove and recycle lead from the environment whilst containing it safely in a solar cell.

Part of this project endeavours to find an alternative solvent for device fabrication in order to reduce environmental impact and aid up-scaling of these devices. The question is whether an alternative solvent can be found that forms a uniform Perovskite layer, and whether this solvent has minimal environmental impact. Recently, more 'green' solvents have been developed and are derived from plants or bio-waste, so initially there will be investigations to see if any of these solvents are compatible for perovskite formation and following this, incorporating perovskite absorbers into solar cells. Additionally, there is the potential for creating devices from lead removed from the environment, which addresses the issue of lead-removal from polluted ecosystems. Recent research uses functionalised graphene oxide (GO) sheets or nanoparticles for the selective removal of lead from waste water. A main issue currently is the desorption of lead from the materials for re-use. Throughout the course of this project these will be an additional focus on bio-derived additives or alternatives to improve device stability, increase ease of fabrication, and aid in increasing device efficiency. 
This project is a collaboration between the Gibson and Docampo groups with multidisciplinary teams so access to training of this equipment and facilities can be proved with ease. During this project, methodology will include the full characterisation of novel perovskite devices using an array of new materials in various stages of fabrication. These devices will be characterised by the standard techniques of UV-Vis, current-voltage curves, incident photon conversion efficiency, and impedance. Additionally, electronic properties of these novel devices will be probed using X-ray photoelectron spectroscopy and electrochemical measurements to map energy levels. To analyse the surface of the absorber and assess its compatibility for use in a solar cell, techniques such as scanning electron microscopy, atomic force microscopy and X-ray diffraction will be used. Methods for lead extraction will be explored which will include chemical synthesis techniques for ligand-coated GO sheets or aerogels, in addition to the synthesis of novel nanomaterials for selective lead removal and recovery. Overall, this project will combine materials synthesis, using sustainable approaches, with solar cell assembly and testing.",1
2308574,38948,Long-term temporal dynamics of a migrant bird assemblage,"Critical objectives in contemporary ecology are to understand how species and populations respond to environmental changes resulting from climate change. There is increasing evidence that many species can alter the timing of key life-history events, including seasonal migration. Yet, other species appear less able to track environmental change. Such divergent responses could mean that different species and populations whose migrations are currently synchronous become increasingly asynchronous (or vice-versa) as the climate and environment change. These changes will in turn alter the composition of species assemblages that co-exist at any point in time, potentially altering competitive or synergistic interactions and ultimate biological outcomes.

However, in general, the goals of understanding how species' temporal ecologies and resulting assemblages can change over time have been hampered by a lack of high-quality long-term datasets that quantify timings of key life-history events within and across multiple species and years. Many datasets focus on one or a few species, precluding analysis of changing assemblage composition and synchrony. Analyses of available multi-year multi-species datasets have revealed that some communities have undergone substantial changes across years, but the consequences of these changes for species coexistence remain poorly understood. There consequently remains a need to fully assess the form of changing assemblage composition within and across years.

A migrant bird dataset collected on Fair Isle, Shetland, provides an exciting opportunity to undertake novel analyses of temporal changes in seasonal migration dates, and resulting dynamics of species assemblages across years. The dataset is remarkable in that, each day since 1955, expert observers have counted migrant birds on Fair Isle, following standardised protocols. Initial analyses revealed considerable among-species variation in migration timing across years in 13 long-distance migrant species (Miles et al. 2017). This implies that the temporal composition of the species assemblage must have changed over the years. However, such effects have not yet been directly quantified for this system, or any other. Furthermore, the temporal dynamics of other migrant species using Fair Isle have not yet been evaluated.

The PhD will address two primary questions that lie at the heart of understanding biological and biodiversity responses to climate and environmental change:

1) To what degrees have seasonal migration timings of different guilds of species (i.e. long-distance migrant passerines, short-distance migrant passerines and non-passerines) changed in similar or divergent ways across the observed 60-year timeframe?

2) To what degree have divergent changes in within-year migration timing among species caused changes in the composition of overlapping migrant bird assemblages across years, either within guilds or across all focal species?

To answer these questions, the student will utilise state-of-the-art methods in community ecology and statistical analyses of timeseries data, in which full training will be provided. The student will be embedded in dynamic and supportive research environments in Aberdeen &amp; St Andrews, with additional opportunities to work with major research groups at NTNU, Norway, and to gain experience of fieldwork and public engagement with science through visits to Fair Isle. Overall, the project would suit a highly-motivated and collaborative student with interests in using long-term field datasets to address major questions in ecology.",1
2281494,42563,High speed automotive drive using new grades of soft magnetic composite,"As greenhouse gas and air quality regulations tighten, the automotive industry is challenged to provide sustainable low emission vehicles solutions. To achieve the low emission targets, tremendous focus has been placed on vehicle electrification.

Electric vehicles have the potential to increase vehicle power density and improve the fuel to road efficiency range compared their internal combustion engine counterpart. However, significant design improvements are required to meet the emission regulations. The technical targets set by the automotive council UK for the passenger car traction motor in 2035 are; cost 4.5$/kg, continuous power density 9kW/kg, drive cycle efficiency 93% based on WLTP drive cycle. These technical targets will be used as design requirements for the proposed project's exploratory designs.

To achieve the challenging targets, innovative designs are required for traction motors. The material used in the motor designs directly influences the performance and cost of the system. Typically, laminated electrical steel sheets are used in motor topologies as they can be machined to fine tolerances governed by the designer. However, at high operating frequencies the losses within the laminated electrical steel significantly reduce the performance, size and efficiency of the motor. By replacing the laminated electrical steel with a soft magnetic composite (SMC) a performance benefit can be achieved. At higher frequencies, the performance of SMC is superior when compared to laminated steel. However, at higher frequencies additional design constraints must be considered.

Possible avenues of research to alleviate the motor design constraints are thermal management within the system. Successfully removing of the heat from the system can directly influence the size and efficiency of the system. Additionally, the motor must be designed to minimise the effect of high frequency AC losses within the windings. As the project progresses, the specific loss mechanisms will be identified and supressed by design.",1
320180,21154,Community driven science education and research tool by Interactive Scientific,"Many of the major challenges and opportunities that face our 21st century world are a result of the dynamic behaviour of invisible things <U+2013> atoms and molecules. It is impossible for humans to directly see or interact at the nano-scale due to the size and speed of nano scale particles. A step change is required in the way we, as a whole society, engage with global challenges, such as climate change mitigation, combatting antimicrobial resistance and supplying clean water access for all. My vision is to create a new scientifc ecosystem based around a software platform (Nano Simbox) that is designed (visually, socially and experientially) in a way that changes the way people think about and interact with scientific challenges that affect the world around them. Sharing of user generated content is a vital part of the vision and ultimately the platform will be a place that can be used by cutting edge researchers to crowd source scientific solutions. During this project we will carry out crucial design and development work to provide a mechanism for user generated content in Nano Simbox, so a user can define the scientific world that they want to explore and then step into simulations that are underpinned by real science. The applications of this product are in education and scientific research.",1
2072326,45949,The Southern Ocean: carbon source or carbon sink?,"Background: The Southern Ocean plays a key role in the global carbon system, with many studies indicating that it may account for 40% of anthropogenic carbon dioxide (CO2) ocean uptake, and thus significantly slowing the rate of climate change due to fossil fuel use. Despite it's significance, the Southern Ocean remains one of the most poorly sampled and understood areas of the global ocean, with winter-time measurements of carbon uptake almost non-existent. As a result, large uncertainties remain in quantifying how carbon fluxes may vary both spatially and temporally in the Southern Ocean. For example, recent findings from the US Southern Ocean Carbon and Climate Observations and Modeling program (SOCCOM: https://soccom.princeton.edu/), which has deployed a network of specially equipped floats able to capture winter-time CO2 fluxes, suggest that the Southern Ocean is a net source of CO2 to the atmosphere. The implication of the SOCCOM results is that our understanding of the global carbon system may need some radical revision. This PhD project will tackle the important need for better quantification and understanding of the spatial and temporal patterns of Southern Ocean CO2 flux measurements through both cutting-edge autonomous instrumentation and satellite observations.
Methodology
The student will investigate CO2 flux estimates in the recent Met Office ocean model. Results will be compared with the Surface Ocean Carbon Atlas (SOCAT: www.socat.info) and SOCCOM measurements and possible the MIT GCM.
The student will derive CO2 flux estimates from satellite observations of the Southern Ocean e.g. by exploiting salinity-alkalinity relationships (Land et al., 2015) using the ESA's SMOS satellite, launched in 2009. A recent study, led by the University of Exeter, is the first to demonstrate such techniques. 
Estimated CO2 flux patterns will be used to better understand the physical processes that modulate carbon uptake by the Southern Ocean e.g. upwelling regions, eddy variability, storms, fronts, mixed layer depth, the Southern Annular Mode and potentially the implications for global meridional overturning circulation patterns. 
This work will complement both the US SOCCOM initiative and current NERC funded UK programs: CaPASOS and the Role of the Southern Ocean in the Earth System (RoSES).
The student will also work in collaboration with the recently funded NERC project Calibrated pCO2 in Air and Surface Ocean Sensor (CaPASOS), to aid the development of a novel carbon-flux instrument that can be mounted on unmanned surface vehicles. The student will be immediately integrated into the project (with trials starting in winter 2019/20), for which NEXUSS training will be highly relevant.
Project is partly funded by the NEXUSS CDT and the student will have access to NEXUSS training evens: There will be extensive opportunities for students to expand their multi-disciplinary outlook through interactions with a wide network of academic, research and industrial / government / policy partners",1
ES/T006196/1,38563,Rethinking Climate Change in the Cauvery Delta Through Long Term Historical Data,"According to the 5th Intergovernmental Panel on Climate Change, 230 million people in South Asia are at risk from
Climate Change, the largest of any single region. Recent studies of the Cauvery delta, and more generally climate
change in India, begin largely with World Bank and Indian Space Research Organization (satellite) data from the
1970s, showing the ways in which the climate is acutely changing since then. However, these studies are based on
thirty years of data. This project uses historical data to comprehend the scale of space specific climate change, the
threats posed, effectively predict long-term trends and prepare adaptation strategies. (Mahony and Endfield 2018;
Amrith 2016). Using long term historical data allows researchers to a) eliminate cyclical patterns not as effects of
immediate climate change b) identify long term patterns of change (whether this is a sudden increase, decrease or
gradual) c) identify how older regimes adapted to change in temperature or disasters.
The project will curate a detailed dataset collected from reports that were published by the colonial provincial
government and continued into the postcolonial era. The first is the Seasonal and Crop report of the Madras presidency
(1905-1954). This report contains district wise monthly statistics and qualitative information on rainfall compared to
the average rainfall for the district, the prevalent temperature, level of silt deposits, the crops grown in different
seasons and any shortfall or excess of rain. Data prior to 1905 is not systematic, but data has been gathered through
three sources including the Meteorological Observations Recorded at Six Stations in India (1879-1894);
Meteorological Observations made at the East India Company's Observatory at Madras (1841-1890); Rainfall of
India (1891-1950) and Cyclone Memoirs (1888-1893). The dataset will comprise of a searchable year-wise monthly
index of rainfall, temperature, silt deposit, crops grown, in a systematic manner from 1905-1950, and in a less
systematic manner from 1860-1905.
I will work with GIS technicians at the French Institute of Pondicherry (IFP) to transfer the data on to maps of two
kinds. First, three historical maps (from 1888, 1917 and 1945, all georeferenced) created will include still images of
these years and contain multiple variables (colour coded), to visualize change clearly. Variables will be added as
colour coded graphics which users can then use to simultaneously picture rainfall, temperature and vegetation
changing over a close to a hundred years. Second, certain maps will picture years of floods or drought (for instance
1872 and 1924), to show how extreme weather events have occurred historically (Knowles and Hillier 2008). The
dataset will allow researchers to ask the following questions
What are the patterns in temperature and rainfall from 1860-1950? Is there evidence of increasing heatwaves and
floods up until 1950? Is there any evidence of cyclical weather patterns? At which time period (under what weather
conditions) was agriculture relatively stable? Which regions have seen the greatest change in crop-type? Is this due to
climate conditions or other factors? (hybrid seeds, use of nitrogen based fertilizer etc.)
Alongside the dataset, I will write the life histories of two farmers to tell a story around climate change, adaptation
and economic precarity over the life-course of farmers in the Cauvery delta. The chosen farmers are Octogenarians,
inhabiting different parts of the Cauvery delta. I will record their life stories from the perspective of changing
climate, how they have adapted and the challenges they have faced. The questions asked will pertain to temperature
rise or decline, water quality and availability, change in crops sown, changing levels of silt deposits, coastal erosion
and how these have affected social relations, and findings curated accordingly (Adamson, Hannaford, and Rohland 2018; Singh 2019).",1
2106195,20735,Improving plant cold tolerance to enhance agricultural resilience to abiotic stress,"Abiotic stresses have a substantial impact upon both photosynthesis and crop production, with these losses predicted to grow through the environmental unpredictability arising from climate change. Photosynthesis within chloroplasts underlies all agricultural productivity, so understanding the role of chloroplasts in stress responses is an important part of developing stress-resilient crops for the future. Chloroplasts contain a small circular genome of cyanobacterial origin that encodes essential components of the photosynthetic apparatus. This PhD studentship will build on our recent breakthroughs into the signalling pathways that communicate environmental information to chloroplasts (Noordally et al. Science 2013; Belbin et al. New Phytol. 2017). In this project, the student will investigate how changes in chloroplast gene expression adapt plants to cold temperatures. The research will combine underpinning experiments using the model plant Arabidopsis thaliana, and findings will be translated into wheat to understand how these signalling mechanisms improve the abiotic stress tolerance of a globally-important crop. 

The project will investigate the following questions: 
1. How does chloroplast gene expression increase the cold tolerance of Arabidopsis? This will involve experiments studying ROS production, cellular biochemistry, signal transduction and photosynthesis. 
2. What is the relationship between cold tolerance, chloroplasts and the circadian clock? This will involve physiological and photosynthetic assays, combined with bioluminescence circadian time- course imaging and molecular methods, to address this question. 
3. How is the cold tolerance of wheat enhanced by mechanisms that regulate chloroplast gene expression? These experiments will use a small, rapid cycling variety of wheat called Apogee as an experimental model system. This will involve CRISPR-CAS9 genome editing alongside a range of photosynthetic and physiological studies. 
The project will provide important new insights into molecular and physiological processes that underlie abiotic stress tolerance of plants.",1
NE/S016678/1,43648,FUTURE-DRAINAGE: Ensemble climate change rainfall estimates for sustainable drainage,"The new climate projections from the UK have just been released and as part of this, next year, there will be the release of outputs from a number of very high resolution climate models across the UK. These models are able to represent the daily cycle of rainfall, and rainfall characteristics like intensity, duration and frequency of occurrence, much better than coarser resolution models that have been used previously and can therefore help us to understand how short-duration intense rainfall events and flash floods might change in the future. Here we propose to couple them, for the first time, with new, high-resolution flood models for small rapid response catchments, like Boscastle, or urban areas that suffer from flash floods. Together they will be used to update guidance for urban drainage design and methods for urban surface water flood risk assessment in the UK: priorities identified in the National Flood Resilience Review (2016) and restated in the UK Adaptation Sub-Committee's UK Climate Change Risk Assessment 2017 Synthesis Report: Appendix on Urgency Scoring Tables which identified &quot;Risks of sewer flooding due to heavy rainfall&quot; as an area where &quot;more action is needed to deliver sustainable drainage systems, upgrade sewers where appropriate and tackle drivers increasing surface runoff (e.g. impermeable surfacing in urban areas).&quot; This will include new 'uplifts' that can be applied to design storm events to represent climate change effects on storms and recommendations on the updates of existing methods and tools used to tackle surface water flooding.

FUTURE-DRAINAGE will add to the evidence-base for the UK Climate Change Risk Assessment and the National Adaptation Programme; and is aligned with the UK Government's 25 Year Environment Plan (2018), specifically the goal of reducing risk of harm from environmental hazards and of adapting to climate by improving climate resilience in the UK. The importance of revised rainfall uplifts and new guidance for UK urban drainage design and urban flood resilience is evidenced in the letters of support our project team has solicited from UK water and sewerage companies, the Scottish Environment Protection Agency and informal support from the Environment Agency who considers the work is of particular relevance to applications in surface water management and design of storm water systems. Therefore, FUTURE-DRAINAGE will deliver nationally important research outputs for uptake by government agencies and industrial sectors to improve climate change adaption and resilience in the UK.",1
NE/S004602/2,39591,Emergence of Climate Hazards,"Climate hazards are weather and climate 'extreme events' that can cause loss of life, injury, or other health impacts, as well as damage and loss to property, infrastructure, livelihoods, service provision, and environmental resources. Examples include:
- The summer heat wave of 2003 in Western Europe, thought to be unprecedented in 500 years, which caused more that 20,000 early deaths, mainly among vulnerable groups in society such as the elderly
- South Asian Monsoon monsoon failures and subsequent agricultural losses - agriculture accounts for 18% of GDP, but employs 60% of people in S. Asia (~1 billion people)
- The extreme El Ni&ntilde;o event of 2015/16 that caused floods, droughts and wildfires globally and drove the fastest annual increase in CO2 on record
- A succession of storms reaching southern England in the winter of 2013/2014, causing severe floods and &pound;451 million of insured losses

Such events are, most likely, influenced by global climate change in ways that we do not currently understand. Future climate change may further exacerbate their impacts.

This project will assess the impact of climate change on climate hazards in the past and present and project forward their changes into the future. There is a focus on the next 30 years because of the relevance of this time scale for adaptation strategies produced by governments, businesses and individuals.

EMERGENCE will use information from state-of-the-art climate models, including from models with unprecedented fine detail. It will use cutting edge observations in order to constrain climate model predictions using changes already observed, drawing on new and improved analysis techniques (including event attribution, machine learning and feature tracking) that were not available or not widely applied during previous assessments of climate hazards from older models. The hazards addressed are: extreme heat stress events, tropical deluges and droughts, and storms with their associated extreme winds and rainll. Information will be integrated into global indicators that will form a snapshot summary of climate hazard risks that, in turn, will be an essential resource for policy makers.

The project's assessments of the emergence of climate hazards will be produced in a timely fashion to feed into the next assessment of the Intergovernmental Panel on Climate Change (IPCC), being relevant to both physical climate science and impacts. The team assembled, including a number of leading climate science project partners from the Met Office, has a strong track record in IPCC and is thus ideally placed to provide this input and to further strengthen the profile of UK climate science in the international arena.",1
AH/P013627/1,13845,Local Governance and Community Resilience: How Internal Drainage Boards (IDBs) and Communities Managed Flooding in England,"This project examines forms of community flood risk management in the past through IDBs and their immediate precursors, to determine their viability as a model for future policy. It develops an approach that views flood as a social construction as much as a physical hazard, and that places people and environment at the centre of a more historically oriented understanding of flooding in England. Valuable records are neglected and lessons that might be drawn from first-hand experience overlooked. This is an urgent issue given recent serious floods (e.g. Somerset 2014, Cumbria 2015).

The network of IDBs is an underrated and under-researched factor in flood risk resilience. 18th century Acts of Parliament began to take drainage out of the hands of Commissions of Sewers and place it with local communities, in drainage districts. The legacy of these districts, IDBs, remain integral to community flood risk reduction, yet little is known about their formation, functions, politics or personnel and how these have changed. This project questions the role IDBs have played in flood risk management, the extent to which they constitute an important manifestation of community-level resilience, and the degree to which the changing nature of their governance is crucial to an understanding of effective, future, flood management policy. These are relevant questions given government policies in the wake of the Pitt Review.

IDBs have been instrumental in creating much of England's lowland landscape as well as shaping the nature and extent of local flood risk. Understanding how these boards operated and how decisions were made will reveal much about the extent to which localised flooding has altered, and the relationship between the level of flood risk and the nature, practice and extent of community structures in a given area. We wish to determine the degree to which historically shared risk fosters community cooperation and resilience (social capital), what manner of persons participated in the decision-making process, and whether such community-based models of management proved to be proficient managers of flood risk governance. We will also examine the institutions, practices and policies of IDBs in managing changing levels of flood risk, what factors influence their development, and how local issues relate to wider ones of flood and environmental governance. We wish to appraise whether IDBs represent an effective model for future local flood risk management.

As the political geography of community flood risk management in England is diverse, we will focus on the IDBs role and function in 4 areas: Lincolnshire, the East Riding, Cumbria and Somerset. These counties represent a cross-section of flood risk issues that have historically confronted communities including: storm surge and coastal flooding on the east coast; heavy rainfall from North Atlantic storms along the west coast; land reclamation in Somerset, the East Riding and south Lincolnshire; upland catchment management in Cumbria; and riparian flooding in all areas.

To undertake this research, we adopt an applied history approach that understands flood risk as a historically-generated process that can only be properly understood through an examination of how communities &quot;normalise risk&quot; over time. This is a methodology that Bankoff has long piloted based on a belief in community resilience and local formal and informal institutions of governance. The relevance of community-based disaster risk reduction to England is overdue and can provide practical insights into flood risk management in the present.

The hallmark of this project is outputs based on solid historical research that have practical application to policy. Our intention is to make an important contribution to the literature on the nature, history and management of flooding in England, as well as to consider models of governance to serve as the basis for more devolved forms of flood risk management in the future.",1
BB/R016429/1,33068,Sustainable Fruit farming In the CAatinga: managing ecosystem service trade-offs as agriculture intensifies (SUFICA),"The SUFICA project aims to enhance the competitiveness, sustainability and long-term resilience of fruit farming in the S&atilde;o Francisco valley in north-eastern Brazil, as it intensifies. The project will work with growers and international supply companies to co-design and test nature-based innovations on fruit farms, aiming to generate multiple environmental benefits whilst enhancing fruit yield or quality and reducing inputs. It takes a trans-disciplinary approach, bringing scientists, farmers and industry together to tackle the challenge of managing a sensitive agro-ecosystem at the food-water-environment nexus, in the context of economic development.

 There are three major outcomes: 1) SUFICA experimentally tests 'ecological intensification' as a pathway to sustainable intensive agriculture; 2) SUFICA establishes the necessary research infrastructure and tools to monitor and continually improve biodiversity and ecosystem services on farms in the S&atilde;o Francisco valley; 3) SUFICA demonstrates how a partnership approach enables the benefits of agricultural growth and environmental protection to be combined. This approach can be applied in other developing countries.

The SUFICA partnership is a response to strong market signals in the agri-food sector that farmers should take action to support biodiversity. The project links this biodiversity objective with production-enhancing ecosystem services - pollination and water flow regulation - to assess the potential for management that benefits both biodiversity and production. The approach, termed 'ecological intensification', has shown promise in Europe and North America, but has not been experimentally tested in tropical semi-arid environments.

The underlying scientific hypothesis is that multiple regulating ecosystem services can be co-erced to flow in bundles, and thus be synergistically enhanced in semi-arid agricultural landscapes, with accompanying biodiversity benefits. SUFICA tests this hypothesis using a repcated, farm-scale, Before-After-Control-Impact (BACI) experiment, co-designed with farmers to monitor the effects of management actions that are feasible and attractive to growers in the region. The SUFICA experiment is the first scientifically robust, replicated test of 'ecological intensification', in which multiple environmental and agronomic outcomes are directly monitored. We include carbon sequestration, as climate change mitigation in agriculture is a development goal for Brazil. The research will use state-of-the-art mapping and modelling approaches to explore mechanisms and predict changes to natural capital stock and ecosystem service delivery. 

The SUFICA experiment incorporates different landscape and farming contexts and builds capacity among farmers. Through carefully designed knowledge exchange processes, larger farms will learn from ecological and diversified practices of small farms, while small farms are supported to engage with international export markets. All farmers in the project will be involved in developing globally recognised farm-scale biodiversity assessment tools, through which they can demonstrate their positive actions.

The S&atilde;o Francisco valley lies in the caatinga, a semi-arid ecoregion of seasonally dry tropical forest with globally important biodiversity. The caatinga is threatened by habitat loss and degradation due to agriculture, and predicted increases in aridity due to climate change. Agricultural development is key for both poverty reduction and long-term economic growth in Brazil. With old intensification trajectories, this growth will come at the expense of biodiversity and ecosystems, reducing long-term resilience and disproportionately impacting on smallholder farmers and the rural poor. SUFICA will establish a process and infrastructure to re-direct intensification to a more environmentally sensitive trajectory, aiming to reduce farm inputs and protect biodiversity in highly productive landscapes.",1
NE/R001782/1,29801,Sources and Impacts of Short-Lived Anthropogenic Chlorine,"Depletion of stratospheric ozone allows larger doses of harmful solar UV radiation to reach the surface leading to increases in skin cancer and cataracts in humans and other impacts, such as crop damage. Ozone also affects the Earth's radiation balance and, in particular, ozone depletion in the lower stratosphere (LS) exerts an important climate forcing. While most long-lived ozone-depleting substances (e.g. CFCs) are now controlled by the United Nations Montreal Protocol and their abundances are slowly declining, there remains significant uncertainty surrounding the rate of ozone layer recovery. Changes in the LS may cause delayed ozone recovery or even additional depletion, and can also have important effects on climate. One key uncertainty, highlighted in the WMO/UNEP 2014 Assessment of Stratospheric Ozone Depletion, is the increasing importance of uncontrolled chlorine-containing very short-lived substances (VSLS) which can reach the LS and cause ozone depletion.

While significant amounts of brominated VSLS are known to be emitted naturally from the oceans, recent publications also show a rapid, unexpected and unexplained increase in anthropogenic chlorinated VSLS (Cl-VSLS), especially in E and SE Asia. Some of these Cl-VSLS will reach the stratosphere via deep convection in the tropics (through the tropical tropopause layer) or via the Asian Summer Monsoon (ASM) or the E Asian Winter Monsoon.

The Montreal Protocol is arguably the world's most successful environmental agreement. By controlling the production and emission of long-lived ODSs, it has set the ozone layer on the road to recovery. However, short-lived halogenated compounds (lifetimes &lt;6 months) have so far not been included, based on the belief that they would not be abundant or persistent enough to have an impact. Recent observations suggest otherwise; calculations in this proposal suggest that Cl-VSLS may delay the recovery of the Antarctic Ozone Hole (to 1980 levels) by up to 30 years. Fortunately, the Montreal Protocol has a regular review process which allows amendments to deal with new threats to the ozone layer and climate, e.g. the recent 2016 success of including limits to the production of hydrofluorocarbons (HFCs).

This proposal takes advantage of UEA's heritage in atmospheric halocarbon measurements to obtain novel observations of chlorine compounds in the key E/SE Asia region and in the global mid-upper troposphere. Surface observations will be targeted in the key winter periods when we know that we will be able to detect polluted emissions from China, a likely major emitter of Cl-VSLS globally. We will extend the suite of gases currently measured by the CARIBIC in-service global passenger aircraft to include several newly-identified VSLS. This will allow us to investigate the distribution of these VSLS over a much wider geographical area, to identify source regions and to assess longer term changes in their atmospheric abundance.

Our observations will be combined with detailed 3-D modelling at Leeds and Lancaster, who have world-leading expertise and tools for the study of atmospheric chlorine. One model will be used in an 'inverse' mode to trace back the observations of anthropogenic VSLS to their source regions. Overall, the models will be used to quantify the flux of halogenated ozone-depleting gases to the stratosphere and to determine their ozone and climate impact. We will calculate metrics for ozone depletion and climate change and feed these through to the policy-making process (Montreal Protocol) with the collaboration of expert partners. The results of SISLAC will provide important information for future international assessments e.g. WMO/UNEP and IPCC reports.",1
NE/M022021/1,30914,PP-FOR: Towards Jointly Monitoring Amazon Ecosystems and Biodiversity by PPBio and RAINFOR,"We want to develop an integrated network of permanent plots in Brazil that can monitor forest biodiversity and carbon fluxes through the 21st century in which its natural systems will be increasingly stressed and challenged by climate change. This project will take an important step towards this ambitious goal.
 
Amazonia is vast, so conducting even basic research is challenging. Monitoring ecosystems here requires scientific leadership, vision, and large networks in which researchers apply standardised techniques on-the-ground at many locations. Training must be integrated into the research process to create capacity and assure long-term continuity of monitoring. This project will build on the successes of the pan-Amazon forest monitoring network (RAINFOR- Rede Amaz&ocirc;nica de Invent&aacute;rios Florestais- led by Phillips) by linking with the leading pan-Brazilian biodiversity monitoring network (PPBio).
RAINFOR works with 400 permanent plots and has made several major scientific discoveries in Amazonia and developed unique software (&quot;ForestPlots.net&quot;) to help tropical partners analyse plot data. But due to poor plot coverage in Brazil, RAINFOR cannot yet provide good estimates of forest carbon balance and dynamics fluxes in Brazil. Meanwhile, PPBio has developed a unique biodiversity assessment protocol and applied it across Brazil with more than 30 institutional partners. However few plots - almost all from one site - have been re-measured for vegetation change.
The proposal therefore takes a step towards addressing the needs of both partners. Together we will (1) share techniques and train local participants, (2) recensus 30 PPBio plots in a huge spatial gap, and (3) train young scientists to process, share, and analyse the data using the global protocols of ForestPlots.net. 

In detail, we plan to:
1. Conduct a hands-on field course to prepare teams to conduct forest monitoring. This will be based in a rural community where PPBio has already invested in plots. The cose will teach skills for plant collection, identification and measurement. Young rural community participants will work with ecologists from Brazil and UK. This provides an opportunity to experiment with forest monitoring - sharing protocols, identifying capacities and leaders, and training in technical data collection skills. Key participants will also be involved in the main fieldwork phase (activity 2), and in the data management and analysis workshop (activity 3), with the project helping provide marginalised rural people with new skills.
2. Remeasure 30 plots along the BR-319 road from Manaus to Porto Velho. BR-319 cuts an 850km transect through the least known forests in Amazonia, a true 'black hole' for biogeochemical and biodiversity science. PPBio has established a series of 111 plots along this road. This project will undertake the first recensuses of plots along this transect, providing the first information on forest dynamics and carbon fluxes from the heart of Brazil's Amazon.
3. Joint workshop to train participants in data management and analysis. We will use ForestPlots.net to help partners manage and analyse information from their plots. The workshop will include scientists, students, and rural people from Amazonian Brazil, lasting 8 days plus one rest day. Biodiversity and forest dynamics data will be integrated into ForestPlots.net, to ensure that PPBio data are carefully checked and comparable internationally. Analysis will involve training in the calculations of carbon stock, carbon balance, vegetation dynamics, biodiversity, and interpreting the rich information on useful Amazon forest species within ForestPlots.net, using an R-package which RAINFOR has developed with NERC support. In turn, participants will feedback and educate the RAINFOR/ForestPlots.net team to determine specific user requirements to make information in the future more accessible, interpretable, and useful for forest researchers, forest dwellers, and forest users.",1
NE/S003371/2,38810,SCaRP: Simulating Cascading Rainfall-triggered landslide hazards in the Philippines,"The Philippines is on the eastern edge of the Maritime Continent, the archipelago of tropical islands that sits between the Indian and Pacific Oceans. High solar input warms the surrounding seas, which supply an abundance of moisture to the atmosphere, turning the whole region into an atmospheric &quot;boiler box&quot;. The whole Maritime Continent receives very high rainfall totals throughout the year but due to its location on the eastern edge of the Maritime Continent, the Philippines are also in the firing line of tropical cyclones (also known as typhoons or hurricanes) that form in the Pacific Ocean. Strong tropical cyclones can reach up more than 150 mph and deliver more than 450 mm rainfall in just a a few hours. These extreme rainfall events, combined with the steep, mountainous terrain over the Philippines can produce catastrophic landsliding and related sedimentation in rivers with major societal and economic impacts. The Philippines accounts for half of fatal rainfall triggered landslides in SE Asia despite making up only 6% of the land area. In 2004, a series of typhoons hit Quezon and Aurora Provinces on the east coast of the island of Luzon in the northern Philippines causing landslides and floods that left 1,062 dead, 1,161 injured and 552 missing, displaced almost 7 million people and caused massive economic damage and prolonged human costs. Under climate change, the frequency and intensity of typhoons can be expected to increase with implications for landslide hazards and sedimentation problems in rivers. 

The simulation of landslides resulting from typhoons is a complex problem as landslides are also dependent on weather conditions leading up to the extreme rainfall event that influence the stability of the layer of soil covering hillslopes. If soils are already wet leading up to an extreme rainfall event, landslides are more likely. It is therefore necessary to understand the meteorological patterns operating over the Philippines and how these influence patterns of landslides in typhoons. Another major factor that may limit landslide occurrence and size is the depth of the soil layer. A critical soil depth is needed for a landslide to occur and the size of the landslide will be limited by the depth of the soil. Once a landslide has occurred, it takes time for the soil layer to regenerate, with implications for future landslide hazard in the same area. Whilst landslide scars on hillslopes are exposed landslides may continue to deliver sediment to the downstream river system. Hence sedimentation problems in rivers downstream of landslides may persist for a period of years after the landslide event. 

The SCaRP project combines the research strengths of the UK and the Philippines and brings together experts in geomorphology, meteorology and hydraulic engineering to effectively and efficiently address the need for better understanding of the impact of hydrometeorological hazards and support increased preparedness and resilience to future events. First, the characteristics of past extreme rainfall-triggered landslide events and their meteorological and geological controls over the Philippines will be determined, using a combination of in situ station data from the Philippines and global data sets from satellites to map landslides and determine rainfall patterns. Second, a number of events will be used to develop and test models for simulation of landslides and downstream sedimentation. Once the model has been tuned, it will be used to predict landslide events and river sedimentation in the future using climate projections for the region. In conjunction with our Filipino project partners, PAGASA (Philippine Atmospheric, Geophysical and Astronomical Services Administration), (MGB) Mines and Geosciences Bureau and Weather Philippines Foundation (WPF), we will develop a landslide early warning system for the Philippines using our modeling framework, ensuring a legacy from the SCaRP project.",1
NE/S016155/1,40216,HUGS: a Hub for Uk Greenhouse gas data Science,"Atmospheric observations of greenhouse gas (GHG) concentrations can be used to estimate emissions when combined with models of atmospheric transport and an understanding of the emission sources surrounding the observations. These top-down methods are complementary to the bottom-up, accounting-based, approaches that are currently used to create national GHG inventories. To improve the transparency and accuracy of these inventories and better evaluate progress on emissions reduction policies, scientists and policy makers have been advocating for the integration of top-down methods into the emissions reporting process. The United Nations Framework Convention on Climate Change (UNFCCC) recently acknowledged the important role that emissions quantified through atmospheric observations could have in supporting inventory evaluation (UNFCCC, COP 23, SBSTA/2017/L.21). The UK GHG science community is leading the world in this regard, with a dedicated national monitoring network, a range of regional networks and regular over-passes by various satellites. Currently, the UK is one of only three countries on Earth to include top-down estimates in its National Inventory Report to the UNFCCC.
 
The process of inferring emissions from GHG observations is extremely data intensive. In order to understand the observed variability in GHG concentrations, scientists must combine data from diverse networks in different environments and using different instrumentation, understand the distribution of potential sources and land use types in the vicinity of the sensor and be able to accurately model the atmospheric processes that transport GHGs from sources to the measurement site. Therefore, to date, analysis of GHG data is largely carried out on a case-by-case basis for individual research papers.

Here, we propose that new developments in cloud computing are required to help GHG scientists overcome some of the major obstacles for the integration of GHG networks and the production of operational, higher resolution GHG flux estimates. We will create the cloud-based framework for a UK GHG data science &quot;hub&quot;. This hub will allow users (GHG scientists and, eventually, the public) to:

- Improve the flow of information to and from GHG data providers, because cloud services are not behind institutional firewalls 
- Operationalise the processing of datasets into common formats, which can then be made globally accessible to users (subject to any required usage restrictions) 
- Automatically trigger operations on new data, such as the running of chemical transport models, which are essential for the interpretation of GHG data 
- Analyse data, model output and ancillary information (maps of land use, emissions inventories, etc.) on the cloud, without the need for individual users to download datasets and run models (requiring technical expertise)
- Visualise data, models and other relevant information on a web-based platform

Our team is world leading in the measurement and analysis of GHGs, cloud computing and spatial mapping. This project will rely heavily on a cloud platform (built as part of the EPSRC-funded BioSimSpace project) and GHG analysis codebase that has already been developed by team members. These tools are built on top of standard tools such as Jupyter notebooks, distributed object stores, and serverless functions. It is this expertise and these open tools that will allow us to develop the framework for our data science hub that will be extensible by GHG researchers at the end of this project.

We envisage that such a hub could be at the centre of the UK's large and growing GHG science community, allowing scientists to upload, analyse and visualise their data on a single platform, enhancing data integration and sharing between groups. Ultimately, this platform could be extended to allow the public to interact with GHG data, letting them learn whether the UK's emissions reductions efforts are reflected in atmospheric observations.",1
2133217,41423,Melt-spinning of ionoSolv lignin for sustainable carbon fibre production,"Climate change is one of the most pressing issues that society currently faces. Light-weighting of vehicles could reduce emissions from transportation by 10%. A strategy to reduce the weight is replace steel with carbon fibre reinforced composites, however, they key ingredient, carbon fibre, is currently too expensive. Lignin is a major component of wood biomass (ca. 25%) and a promising alternative carbon fibre precursor to expensive and petroleum derived polyacrylonitrile and pitch. Lignin is a cheap co-product of sustainable biofuel production and has beneficial chemical properties for producing carbon fibres. Certain avenues of converting lignin to carbon fibres have been explored before, but the resulting carbon fibres had low strength. In this project, we will apply the ionoSolv lignin isolation process, state-of-the art lignin characterisation and fibre production technology, and novel chemical modifications to produce lignin fibres via melt-spinning.The goal is to reduce carbon fibre cost drastically by 75% while achieving the strength targets set out by the car industry.",1
EP/N00583X/1,33027,Water Energy Food: STEPPING UP,"More and more people agree that current systems of water, energy and food provision are on an unsustainable course. Policy and decision makers are concerned that overuse of land, high levels of emissions, increasing inequality, unhealthy diets, more frequent extreme weather events and other challenges, threaten food, energy and water availability and security and place pressure on the economy. Moreover, with targets to cut carbon emissions and climate change impacts elevating uncertainty over how resilient our food, water and energy systems are, stakeholders from industry, government, and civil society, are looking for support and help to make 'good' decisions. 

Typically, options for solving problems facing the food, water or energy sectors are assessed in isolation; e.g. exploring how to meet energy needs, whilst overlooking the implications for water use, or setting targets to change land-use, ignoring knock-on impacts for agriculture, water and energy. This 'siloed' mindset is unable to grasp interconnections between these systems, or explore the benefits or trade-offs apparent when exploring one or another issue. Whilst governance structures struggle to take more of a rounded, systems view, there exist real examples in the UK of low impact across water, food and energy systems - at the 'nexus' of Water-Energy-Food (WEF). These examples can be found operating at many scales - from household, community or small business, up to local authorities, catchment areas or large corporations. Although there are important technical reasons why any particular example succeeds, there are many other things that are important for innovation. It could be an unusual system for buying something, such as online marketplaces like the Gleaning Network, that offers farmers and consumers a way of bypassing conventional food supply networks. It could also be because of an inspirational leader or team of committed people.

Understanding what makes innovations have low-impact at the WEF nexus is the first aim of our project. The second is to find out if it is possible to reproduce the conditions for a low-impact WEF nexus at a larger scale, replicate them in other situations, or proliferate them more widely at a smaller scale. Amplifying or multiplying 'good practice' in this way is believed to have the potential to deliver a step-change in terms of impact and resource use. We will also dig deeper into the power structures, behaviours and other important components of governance that can lead to a transformation.

To achieve our aims, we bring together a team with expertise across water, food and energy with physical science, engineering and social science backgrounds. This team will build models of a few case studies that have achieved low-impact across the WEF nexus. These models will not only capture physical attributes such as the source of electricity or food supply chain, but also be able to model how governance, power and behaviour have influence. By considering what might change over time - e.g. rainfall - the model will not only test if an innovation can operate at another scale, but also if it works under changing conditions. The data gathered will involve building solid relationships with stakeholders involved with our case studies, as well as a wider set of policy and decision makers. These stakeholders will be involved directly in the research through workshops and interviews. They will also have an opportunity to work with researchers to build a tool that uses both the findings from the modelling exercise and stakeholder views, to provide assistance with strategic decision making of relevance at different scales. The research will deliver a package of robust numerical and descriptive insights alongside a formal decision support tool and findings will be shared widely with academic as well as government, industry and civil society audiences.",1
35451,35265,RECHIP FLOOD DEFENCE <U+2013> PROVIDING PROTECTION AGAINST THE ENVIRONMENT WHILST SAVING THE ENVIRONMENT,"Flooding and waste plastic pollution are 2 global environmental catastrophes that are continuing to get worse.

Flood damage affects c.17000 UK properties per year, costing &pound;1.3billion. Additionally, 5.2million(1-in-6) properties/assets, worth &pound;200billion are in Flood Risk 3a/3b Zones (FRZ's) with \&gt;1%/year probability of flooding causing considerable disruption&amp;distress to those affected.

Limited availability of development land is SINGLE BIGGEST barrier to meeting national housebuilding targets (300K needed/year to address targets). To meet government targets, 10% of development applications approved by Local Authorities are now in high-FRZs- planning guidance requiring use of non-permeable building materials, but the lack of effective flood-barriers for external doors renders these pointless.

Climate change is expected to increase flooding incidence&amp;impact with &pound;1billion/year government investment required to maintain current defence levels.

Meanwhile, UK's waste plastic arisings (WPA) ~5.2MNt/year, is set to increase to ~6.3MNt/year by 2030\. Due to China's 2018 WPA import ban, UK has a reprocessing gap of 350,000t/year.

Despite the urgency and scale of both of these issues, technological advancements which effectively prevent flooding or efficiently recycle/reuse waste plastic are not yet available, with those under development costly, limited in width, bespoke (further expense), made from non-recyclables.

Rechip's interdisciplinary team expertise including construction and engineering seeks to overcome limitations of current methods to deliver the first and only flood defence system in the world made from 100% recycled plastic using patented Rechip(tm) technology that can be installed without tools or training in minutes and provides 100% effectiveness from water ingress. This solution has a novel deployment and sealing system ensuring 0% leakage with a single board protecting up to 800mm in height. Rechip's technology takes waste plastic to create a solid rigid panel. Each panel uses the equivalent of 660 plastic bottles. This refined plastic is a new workable material that can be transformed in to a solid rigid panel.

With support from Innovate UK, a 12-month programme of research is required to deliver a pre-commercial prototype internally and externally tested and certified. If successful, the solution has the potential to truly revolutionise flood protection with global exploitation potential delivering 191:1 benefit-to-cost ratio, with 5:1 being the target set my central government. The project will deliver export led growth for Rechip, healthy profits and follow on tax returns, increased employment and further opportunity for R&amp;D investment.",1
NE/S003495/1,25621,Community Water Management for a Liveable London (CAMELLIA),"London and the South-East is the economic 'powerhouse' of England contributing 40% of GDP. Currently there is a shortage of housing, particularly affordable homes, and 50,000 new homes per year are planned for London to 2036. The growing population of London and its planned housing require water to be supplied and flooding to be reduced as far as possible. However, the region is vulnerable to water shortages (droughts) and floods. In the spring of 2012 London was facing potentially its worst drought, with concerns whether Affinity Water could provide sufficient water for some Olympic events. By contrast, the prolonged rainfall that then fell over the summer caused localised flooding and the Thames barrier being closed twice. This swing, over half a year, from extreme shortage of water to excess highlights the major challenge London faces to manage the water environment. 

This challenge is likely to worsen with climate change alongside the expected economic growth of London and associated increase in population. It also shows how droughts and flooding are two ends of a hydrological spectrum, whose political oversight, i.e. governance, needs to be managed was a whole. It is this need for integrated, collaborative and appropriate management that lies at the heart of CAMELLIA.
 
Focusing on London, CAMELLIA will bring together environmental, engineering, urban planning and socio-economic experts with governmental and planning authorities, industry, developers and citizens to provide solutions that will enable required housing growth in London whilst sustainably managing water and environment in the city.

CAMELLIA will be led by Imperial College London, working in collaboration with researchers at University College London, the University of Oxford, and the British Geological Survey. The programme is supported by communities, policymakers and industry including: local and national government, environmental regulators, water companies, housing associations and developers, environmental charities and trusts. Ultimately, the programme aims to transform collaborative water management to support the provision of lower cost and better performing water infrastructure in the context of significant housing development, whilst improving people's local environments and their quality of life.

The relationships between the natural environment and urban water infrastructure are highly complex, comprised of ecological, hydrological, economic, technical, political and social elements. It is vital that policy and management are informed by the latest scientific understanding of hydrological and ecological systems. However, for this knowledge to make a change and have an impact, it needs to be positioned within wider socio-technical and economic systems. CAMELLIA will provide a systems framework to translate Natural Environmental Research Council-funded science into decision-making. Enabling a range of organisations and people to contribute to, and apply systems-thinking and co-designed tools to create a paradigm shift in integrated water management and governance underpins CAMELLIA. This will achieve the goal of real stakeholder engagement in water management decisions and provide a template, not just for London's growth, but for other cities, regions and communities both nationally and globally.
 
The proposed work programme consists of four work packages which address 4 key questions, namely: How to understand the system?; How to model the integrated system?; How to analyse that system?; How to apply this systems approach to create impact? To help focus these questions, four London based case studies are being used, each reflecting a key issue: Southwark (urban renewal); Thamesmead (housing development); Mogden (water infrastructure regeneration); Enfield (Flood risk and water quality). From these, an integrated systems model will be applied to the entire city in order to help guide policy, planning and water management decisions.",1
NE/R011044/1,9798,Reef refugia out of the shadows: dynamics of marginal coral reef ecosystems over the past 30 million years in the Coral Triangle,"Coral reefs are the most diverse marine ecosystems on Earth and provide enormous economic value for hundreds of millions of people including fisheries, tourism, and coastal protection. However, these benefits are threatened by the rapid decline of coral reefs resulting from accelerating human impacts on local to global scales. Confronting this reef crisis with limited resources requires prioritisation of protection actions, and many researchers are now turning to reef ecosystems living outside of typical shallow, clear-water habitats as critical priorities for additional research. There is new evidence that these so-called marginal reefs living in turbid or deeper water can be more resilient to bleaching, changes in water quality, and other impacts. Increased bleaching resilience might result from sediments in the water that limit UV stress, or because the corals may be more readily able to take advantage of food sources in the plankton. Thus, marginal reefs potentially serve as refugia for resilient corals, and could be critical for the future recovery of declining clear-water reefs. However, most studies of marginal reefs have focused on contemporary (and in a few cases historical) assessments from sites on the Great Barrier Reef (GBR) and the Caribbean. New datasets from different regions are needed to capture the full range of modern human impacts (especially in areas of the most diverse coral development), and we also need data that spans the timescales (centuries to millennia) necessary to capture coral ecological adaptation and migration within marginal settings. In this context, recent discoveries of exceptionally preserved fossils from the Coral Triangle (CT) region of Southeast Asia provide a unique opportunity to integrate present-day ecological data with information from the geological record to document the evolutionary and ecological history of turbid water reefs in the modern-day global biodiversity hotspot. There is an urgent need for more information on the diversity, structure, and functioning of marginal reefs in the CT in order to help develop management strategies they continue to respond to human impacts.

The long-term temporal scope of our study is thus significant. A growing body of research aims to describe the composition, distribution, and genetic structure of potential present-day reef refugia and we will add data from the fossil record into these analyses. There is a compelling case to do this because reef resilience is likely to be shaped by long-term processes with deep roots in evolutionary history. We will assess the dual role of marginal reefs in the CT as both cradles and refugia of diversity. Key research questions include: 1) has coral diversity of marginal ecosystems changed through time? 2) how have reef communities responded to environmental changes on regional or global scales? 3) how has reef functioning in marginal settings changed and what have been the consequences for reef-associated biota? 4) how easy has it been for reef-corals to move from marginal to clear-water reefs during the evolution of the biodiversity hotspot, and 5) what could be the consequences for the modern biota if clear water habitats become increasingly inhospitable?

To address these questions we will produce new comprehensive datasets of species occurrences, abundances, morphological traits, ecological data, and environments that cover 30 million years of reef history of the CT. With this resource, we will provide rigorous answers to long-debated issues by applying new tools for molecular systematics, geochemistry, and evolutionary patterns to modern reefs and an extensive and well-sampled fossil record. Ultimately, we will be able to reveal the murky history of marginal reefs in the CT and better understand the potential future trajectories of change for coral reefs in the CT and in other regions that depend on coral reefs for their economic and ecological value.",1
2109477,18642,Cryptosporidium movement in water: impact of eutrophication and climate change on the zoonotic disease agent,"This project will be the first to follow the fate of Cryptosporidium oocysts as they enter aquatic food chains in Welsh riparian ecosystems. 
Cryptosporidium is a human pathogen unknown until the mid-1970s; in 1993 0.4 million people were infected in Milwaukee following a water treatment failure, and since then, large outbreaks throughout the developed world (most recently Sweden, 2010) have kept the parasite in the public eye. 
Infected hosts release up to 109 oocysts per day, and the discovery of a single oocyst forces closure and loss of drinking water supplies (e.g. NW England 2015, 0.3 million homes affected). In rural Wales, the different sources of contamination are unknown, but are likely to arise from sheep farming in rural communities. These multiple sources of contamination are difficult to diagnose and monitor, and almost impossible to eliminate due to costs of complex methodologies. 
The huge excess production of oocysts compared to the infective dose (only 10 oocysts can start an infection) suggests that in the natural environment, most oocysts are removed biotically, probably by grazing and suspension feeding invertebrates and protists. These interactions may be adversely affected by eutrophication (connected with land use and climate change), increasing the importance of Cryptosporidium in both the developing world and in 'Blue Marble' situations within the developed world.",1
NE/S008950/1,38383,GCRF One Ocean Hub,"Over 70% of the earth's surface is ocean. As a global population, we are entirely reliant upon a healthy ocean: it contributes to the renewal of freshwater; it absorbs over a quarter of global carbon dioxide, and it produces half the oxygen we breathe. The ocean has the potential to make significant contributions to sustainable development. Many developing countries already depend on their ocean resources for food, work and livelihoods. Yet we are reaching an ocean health crisis: cumulative pressures such as over-exploitation of its resources, ocean plastics and pollution and climate change, all compounded by multiple competing uses, are pushing the ocean ecosystem to a tipping point. 
There is an urgent need for more integrated ocean governance, to ensure greater balance between ocean conservation and sustainable use (Sustainable Development Goal 14) and realise the ocean's potential to contribute to poverty reduction, human health, healthy ecosystems on land, climate change mitigation and adaptation, equitable economic growth and decent employment.
&quot;We are the sea...we must wake up to this ancient truth...It is time to create things for ourselves, to create established standards of excellence that match those of our ancestors.&quot;
It is with this spirit that the ONE OCEAN Hub will transform our response to the urgent challenges facing our ocean. The Hub will weave learning from the ocean, and traditional knowledge of the peoples who rely upon it, with scientific excellence, innovative legal approaches and artistic methods. Our aim is to bridge the disconnections in law, science and policy across all levels from the local to the international. We aim to empower vulnerable communities, woman and youth in the blue economy and catalyse the inclusive and integrated governance approaches required to ensure a healthy ocean and flourishing communities and economies. 
The Hub will specifically address the challenges of South Africa, Namibia, Ghana, Fiji and Solomon Islands in realising the economic, socio-cultural and environmental benefits from the ocean. It aims to support these countries' efforts towards developing a sustainable and fair blue economy by providing new scientific data and tools to engage different sectors and groups within society, particularly vulnerable communities, woman and youth, in identifying opportunities, risks and trade-offs to: i) prevent and mitigate negative development impacts connected to the ocean, ii) participate in traditional and emerging ocean activities, and iii) predict the socioeconomic benefits of ocean conservation. 
The Hub pioneers integrating law and arts, policy, informatics, education, history, anthropology, and philosophy to provide targeted advice on coherent and flexible, pro-poor and gender- sensitive, climate-proofed and transparent laws and policies across the areas of environmental, human rights, science and technology, trade and investment. The Hub will further integrate biology, physics, chemistry, oceanography, ecology, mathematics, socio-environmental sciences and law to advance understanding of sustainable fisheries in the face of climate change impacts, as well as socio-economic and cultural considerations. The Hub will also increase understanding of conservation and extraction options for deep-sea mineral, biological and freshwater resources, integrating biology, ecology, geology, socio-environmental sciences and law. Through innovative use of arts the hub will transcend traditional boundaries in policy, law, and between ocean stakeholders from local communties to international organisatons, to respectfully and effectively include local communities' traditional knowledge in decision-making at the national and local level on the blue economy. The Hub will develop the integrated governance frameworks and strengthen the capacity within commnities to drive innovative approaches to a fair and sustainable blue economy for South Africa, Namibia, Ghana, Fiji and Solomon Islands",1
AH/P008232/1,12444,"Narratives of Conflict, Climate, and Development: Re-envisioning Sustainability from Post-War Northern Uganda","What is the relation between conflict, development, and climate change? This question has taken center stage in policymaking in Africa, as climate change is considered the greatest threat to development as well as a major risk for future conflict. Massive donor funding is being mobilized towards climate change adaptation in the name of averting environmental crisis and promoting development and peace. In this mainstream framework, climate change is to be dealt with through technical fixes to enable African communities to adapt to climatic hazards. These top-down policies are just beginning to be implemented in much of Africa, including in northern Uganda, a highly vulnerable region and the site of this proposed research.
 But this mainstream, technical approach has not gone unchallenged. For, as many scholars have pointed out, without a history of economic and political deprivation and marginalization that renders certain African communities vulnerable to climate change, it would not present the dramatic threat it does. The implication is that, since climate change adaptation policies seek to help existing social structures adapt to future climatic changes, if those structures are characterized by injustice, inequality, and violence, adaptation policies may be building locking in the very structural inequalities that make African communities vulnerable to climate change in the first place.
 In northern Uganda, like many post-conflict situations, today's injustice, deprivation, and inequality is largely a legacy of war, which has left the region far behind the rest of the country in all development indicators. The conflict saw the mass forced displacement of over a million rural people into internment camps by the government, leading to environmental devastation and a legacy that continues today in forceful land dispossession, massive deforestation, pollution from expanding oil extraction, and displacement by infrastructure, all enforced by the Ugandan military. This has led to large inequalities in land access, loss of livelihoods, and a growing, precarious semi-urban population as the resources needed for sustainable development are being stripped away. In the midst of this ongoing environmental devastation, expansive climate change adaptation policies are being inaugurated - but, if they ignore the ongoing violent legacy of conflict and focus on technical fixes, they risk worsening that legacy, setting the stage for future conflict, and foreclosing inclusive and sustainable development.
 This leads to the project's primary question: how can climate change policy for post-conflict northern Uganda - and, by extension, for other post-conflict contexts - be re-envisioned so that it enables peace and development? The project will explore how two different disciplinary frameworks understand the relation between conflict, development, and environmental crisis and how they can be put them into conversation with each other in order to produce highly innovative results both academically and for climate change policy. First, we will employ a political ecology framework to look at the post-conflict situation in northern Uganda. Political ecology understands the relation between conflict, development, and environmental crisis as largely representing struggles over resources between state and capital on one side and the community on the other. Second, we will employ history and literary and cultural studies to explore the community of northern Uganda's own understanding of conflict, development, and climate change, representing very different bases for dealing with the threat it poses. The community's visions are accessible only through intensive knowledge of language and culture and through extended engagement with the northern Ugandan community. It is the creative dialogue between these disciplinary paradigms as they are employed in research in northern Uganda that will produce our innovative answers.",1
NE/S013245/1,36319,Integrated upstream and downstream thinking to mitigate water security challenges from Peruvian glacier retreat,"Acceleration of glacial melt has severe implications for water-food-energy security and inter-connected livelihoods of vulnerable populations in river basins fed by glaciers. For example, in the Ancash Region of Peru, glacial melt from the Andean Mountains provides up to 67% of dry season water supply going up to 91% during extreme drought (annual average 19%). Rapid retreat of glaciers in the Cordillera Blanca has already had notable impact on that supply, with evidence to suggest the majority of rivers now exhibit decreasing dry-season discharge i.e. have reached and passed 'peak water'. Challenges associated with a reduced supply of water to downstream agriculture, industry and hydropower generation are exacerbated by enhanced sediment and contaminant flux in extreme wet season floods.

Climate change impacts compromise ecosystem service provision at times of both augmented low and high flow. While low flows and water supply are being increasingly impacted by the huge loss of water storage in shrinking glaciers, ENSO-related extreme events are leading to catastrophic delivery of excess water and sediment during high flows which compromise water and environmental quality downstream. Climate change is driving a hydrological regime of extremes with no advantage at either end: from supply and quality issues at low flow to more water than the system can handle at high flow, compromising water and soil quality downstream. Understanding the changing dynamics of glacial melt, hydrology and regional climate change is crucial in order for the design of infrastructure solutions and planning to be effective and resilient.

Responsible, efficient and sustainable water use is necessary in national and transboundary watersheds, to ensure adequate supply and mitigate emerging quality problems. In order to achieve this consultancies and advisory organisations require high quality robust scientific evidence to underpin their design decisions for watershed management. This entails moving from (inefficient) sectorial management of water to a more integrated and holistic approach that takes into account the need for conserving ecosystems services. Indeed, while the Peruvian Congress passed a historic Ecosystem Services law in 2014 to take a holistic approach to tackling these challenges, implementation of integrated action to achieve Sustainable Development Goals has been hampered by a lack of evidence of glacial-fed watershed processes and function. While studies to date have been conducted in the Cordillera Blanca in relation to dynamics of glacial retreat, associated natural disaster risk, hydrology and past glaciations we do not have a sufficiently holistic and integrated knowledge of the wider impacts of glacial melt on current and future ecosystem service provision which is hampered by complexity of human-environment feedbacks, a knowledge base essential for mitigation of future uncertainty and risks.

We propose that a basin-wide understanding of water, sediment and contaminant budgets within Peruvian glacial-fed basins is required to bring policy change for socio-economic benefits through (a) offsetting storage lost from shrinking glaciers through augmentation of mountain ecosystem service provision for landscape water retention and (b) providing the foundation for adaptive management strategies to support and enhance livelihoods under threat from high flows and downstream environmental quality consequences. This research is essential for the design of large-scale energy infrastructure, such as hydropower in glacier-fed regions. Likewise, bringing back and maintaining a balance between sustainable livelihoods and the environment is critical to build community resilience to environmental change.",1
NE/T008814/1,46310,The Time Of flight Isotopic and elemental Concentration (TOPIC) Facility for nano- to micrometer scale analysis of Earth and anthropogenic materials,"Anthropogenic activities are having a dramatic effect on Earth's climate, its ecosystems and humanity. Although the sum total of these changes manifests at a global scale, many of the processes involved in causing anthropogenic environmental change operate at the micron and nanometre-scale (i.e. 10-1000x smaller than the width of a human hair). This is important because in order for environmental scientists to design strategies to solve these environmental problems we need to first fully understand them, and all the processes involved, across all the relevant scales. Addressing the micron to nano-scale however currently represents a huge analytical challenge that has, up to now, been the preserve of very large and expensive machines such as synchrotrons and nanoSIMS that have limited access. They also frequently require highly specialised sample preparation that prohibits the analysis of some materials and are often challenging to use to obtain fully quantitative analyses. On the other hand, more flexible and/or more readily available techniques such as laser ablation (LA) inductively coupled plasma mass spectrometry (ICPMS) or electron microprobe either don't have the spatial resolution or the detection limits to provide quantitative analysis of elements present at low concentrations on the sub-5 um scale required. In addition, they struggle to quantify the transient signals (frequently less than one second) that result from single micro-/nano-particle analysis. Consequently, developing solutions to some of the most pressing problems on the planet does not simply require more research - it requires a major advance in the capabilities of the tools of research.

Here we request funding for a new type of mass spectrometer that combines the flexibility of sample introduction (e.g. solids or liquids) of a traditional ICPMS with the time-resolved capabilities of time of flight mass spectrometry where all elements in a sample are measured simultaneously. This allows for a crucial advance - the accurate and precise full elemental determination of transient ion signals, with resulting potential for: (i) the analysis of single nanoparticles introduced into the ICPMS source one at a time; (ii) the generation of elemental maps of 2D surfaces (and 3D through depth profiling) at a sub-5 um resolution through the simultaneous full elemental analysis of each laser pulse.

The potential for such an analytical tool is enormous and the TOPIC facility housed at the University of Southampton will support a number of funded proposals and existing research. It will also enable new research by the UK environmental science community that ranges across NERCs remit from improving reconstructions of climate change over the last 100 years and better determining the sources of air pollution to improving our understanding of the growth of minerals to lock away carbon dioxide from the atmosphere and providing new resources to support green technologies. The facility will not only enrich our existing research in the School of Ocean and Earth Science and the UK science community, but we will also use this unique facility to leverage new research funding including from industry. Access and training will be provided to researchers from across academia and industry, building on our existing extensive collaborative network and commercial activities. By housing the facility in an existing UK and world leading geochemistry group, that is well-supported with considerable expertise with laser ablation and mass spectrometry, we will ensure the maximum value for the investment on behalf of the UK science and technology community.",1
2285051,45905,Weighing the interactions made by Small Heat-Shock,"Small Heat-Shock Proteins (sHSPs) are ATP-independent molecular chaperones that prevent the heat stress cell damage by inhibiting proteins from aggregation. sHSPs interact with unfolded proteins and hand them over to ATP-dependent chaperones, whereupon
further processing restores the native structure of substrates. The mechanisms of sHSP activity require further exploration to understand this mechanism of cell protection that is common to all organisms. This will impact on our understanding of diseases such as Alzheimer's associated with protein aggregation, as well as the thermo-tolerance of organisms exposed to environmental change. The aim of this project is an analysis of interactions between sHSPs, substrates, and other chaperones from heat-sensitive organisms in order to explore their mechanism of activity. I will use a combination of advanced mass spectrometry (MS) approaches to quantify the protein-protein interactions, and probe their structures and dynamics. This project is also an opportunity to advance MS techniques, both in solution and in vacuum, for identifying structural conformations of proteins, especially gas-phase Hydrogen-Deuterium Exchange MS, which is very unexplored.
This project involves collaboration with Professor Elizabeth Vierling (University of Massachusetts), who is a world expert on plant thermo-tolerance; and Professor Adrian Smith (Department of Zoology, University of Oxford) and expert in protein expression in corals found
in shallow reefs. This project aligns with the EPSRC portfolio themes of &quot;physical sciences&quot;, and &quot;living with environmental change&quot;.",1
1838005,5748,Essays in environmental economics: assessing externalities from distributed infrastructure,"With a move to a sustainable energy system distributed energy technologies (such as solar, wind, small hydro) have become much more common, contributing a significant amount to overall energy generation. While these technologies have gained wide political support as means to reduce negative externalities associated with the current fossil fuel-based energy production that is driving climate change they may themselves be associated with other (negative and positive) externalities. 

This is so, as the deployment of renewables not only brings grave changes to the energy landscape but also literally changed the face of the landscape. Different to traditional energy generation methods that tend to require few facilities and generate power in a (fairly) centralized manner, renewable technologies require a far larger number of installations that also tend to be distributed more widely. 

Equally, distributed energy has in many countries reached a stage where the first turbines have extended their useful lifetime. In practice this means that they will be decommissioned and either replaced or removed. Decommissioning may present opportunities for policies pushing accelerated expansion of renewables or to fine-tune policies to make sure support mechanisms are efficient (improve allocation, efficiency).

This thesis will deal with two core issues related to the developments outlined above, in particular those pertaining to countries that have reached decommissioning. Firstly. It will investigate the externalities from distributed energy, considering also later stage issues such as decommissioning and repowering. This will focus on both the externalities from wind power as measured by residential house prices as well as the option value of land as well as impacts on local employment outcomes. Secondly, the thesis will also consider issues of inefficiency in the current allocation of renewables. More precisely, the degree of spatial misallocation, the role of heterogeneous investor preferences and whether learning improves the efficiency of spatial outcomes as owners experience increases over time.",1
2280710,41537,Investigation of the Impact of Thermal Plumes on Aquifer Properties and Ground water quality,"Global energy needs are steadily rising with a predicted increase of 45% within the next 15 years. In the long-term, sustainable energy is hoped to connect economic growth to increased social equity while preserving natural resources in line with the UN sustainable development goals. Geothermal energy presents one of the key pillars to achieve this goal. The application of shallow geothermal energy systems has been increasing over the past decades with &gt;1.7 million units installed across the EU in 2015. One of the commonly applied designs for geothermal installations are open loop systems consisting of abstraction and re-injection wells installed in the aquifer system/groundwater body to extract heat from or to inject/store heat into the aquifer. The efficiency of the system relies on the productivity of the well installations as well as suitable aquifer properties (incl. aquifer permeability &amp; porosity). At the same time, groundwater bodies are also increasingly targeted for water supply as surface water resources become threatened by the effects of climate change. 

The research project will investigate the impact of thermal plumes associated with geothermal installations on aquifer parameters (e.g., porosity &amp; permeability) and water quality. Thermal plumes are not only likely to reduce aquifer porosities &amp; permeabilities by facilitating inorganic precipitation and secondary mineralisation but also by promoting microbial activity within the aquifer with the additional biomass adding to the reduction of aquifer porosities. This in turn will affect the overall efficiency and sustainability of the geothermal installation and reduce the sustainable yield of the groundwater body for water supplies. 

The project will use the Triassic Sherwood Sandstone Aquifer (SSA) as a case study example. The SSA is an important regional aquifer across central England and Northern Ireland hosting potable groundwater to depth &gt;100m. The study will combine bench-scale tank experiments with full-scale field experiments utilising existing borehole installations at Queen's University Belfast. The study will combine the baseline characterisation of the aquifer system by completing a series of active borehole geophysical measurements, hydraulic tests, hydrochemical sampling and microbial profiling with the long-term monitoring of experimental thermal injection tests. Hydrochemical and microbial sampling &amp; analysis will be supplemented with downhole temperature monitoring using fibre optic sensors and biogeophysical monitoring of microbial activity. Collected monitoring data will be integrated into numerical heat transport models to evaluate field-scale thermal properties of the aquifer and to better understand the impact of thermal plumes on aquifer properties. 

The project will be run in close collaboration with the British Geological Survey (BGS) and the Geological Survey of Northern Ireland (GSNI).",1
EP/P004237/1,11568,Urban Flood Resilience in an Uncertain Future,"Summary

The engineering core of this project couples an array of carefully selected, physics-based models to support investigation of how stormwater cascades through a city's drainage system, accounting for the dynamics of not just water, but also sediment, debris, natural solutes and contaminants carried by urban runoff. Based on the capability of this suite of models to simulate water flow, storage and quality within an urban system, we will investigate how the performance of grey systems (composed mainly of lined channels, pipes and detention tanks) can be improved by adding Blue-Green Infrastructure and Sustainable Drainage System (SuDS) to create treatment trains designed to manage both the quantity and quality of urban runoff. Models and design solutions will be developed and tested in the contexts of retro-fit (as part of urban renewal and uplift in Newcastle-upon-Tyne) and new build (as part of creation of a 'garden city' in Ebbsfleet, Kent). Our intent is to work out and demonstrate how resilience to floods and droughts can be achieved using integrated systems of Blue-Green and Grey assets, no matter how climate changes in future, assuring continuous, long term service delivery. 

The work will adopt throughout a whole systems perspective that recognises interdependencies with other urban systems, including transport, energy and land-use. This will identify new opportunities for managing stormwater as a resource that will then be explored. This will add to the multi-functional benefits of using Blue-Green infrastructure to manage flood risk by increasing water security. Possibilities range from non-potable uses in homes or commercial buildings (based on rainwater harvesting) to irrigating green infrastructure (e.g. street trees), managing subsidence in clay soils, soil moisture enhancement and groundwater recharge. Wider benefits may extend to local energy generation using drainage infrastructure (i.e. micro-hydropower) and enhancement of urban watercourses and ecosystem services. 

The models and protocols developed will form the basis for assessment of the potential for the optimised combinations of Blue, Green, Grey and smart infrastructure to deliver multiple-benefits in UK cities nationwide.

However, the goal of optimising urban flood and water management can only be achieved through a deep understanding citizen and community preferences with respect to managing flood risk. In short, engineering solutions must be better informed and explicitly accounted for in urban planning and development at all spatial scales. For this reason, our research will extend to investigation of the planning, development and organisational systems that govern urban flood risk management. This will be addressed using Participatory Action Research and Social Practice Theory to examine the attitudes and responses of citizens and communities to innovation in flood and water management, with the context of urban planning. 

This aspect of the work is essential to underpin and enable implementation of the engineering analyses and solutions identified in the core research outlined above.

The mechanism for bringing together engineering, social and planning components of the project will be co-location research in Newcastle-upon-Tyne and Ebbsfleet, Kent. Team research in these case study cities will establish how barriers to innovation can be overcome despite uncertainties in future urban climates, land-use, development and political leadership. Critical engagement with planners, developers and land-owners throughout the project will feed back and inform the core engineering focus of the work, building on the current trend towards the development of urban infrastructure observatories to explore responses to the innovative changes needed to achieve urban flood resilience.",1
NE/M019977/1,11587,AMMA-2050 NEC05274,"The climate of West Africa is subject to some of the most variable rainfall patterns observed anywhere in the world. In the past, the region has suffered several decades of severe droughts, whilst more recently major flood events have struck a number of the region's rapidly expanding cities. The consequences of these climatic extremes for the population have been particularly pronounced due to widespread and severe poverty. Global climate change, coming on top of such a variable and unpredictable regional climate, poses a major threat to the populations and economies of West Africa. Although the pathway from climate change to human suffering in West Africa is very short, there are some key bottlenecks to using climate projections to mitigate against risks to the population. Critical gaps exist in knowledge of how West African climate will change over the course of the 21st century, and the uncertainties make it almost impossible for agencies to deliver well-informed plans for the coming decades in critical areas such as food security, urban development and water. Even with the best climate information, it remains a significant challenge to integrate the scientific knowledge into planning and management structures. This collaborative project between scientists and policy makers in West Africa and Europe will, on the one hand, increase understanding of the regional climate and how it will change, and on the other, apply that knowledge to practical development questions.

One of the key challenges for climate science is to understand how the changing composition of the atmosphere (notably CO2) will impact on the frequency and intensity of extreme events such as floods and droughts. In West Africa, these events are tied to the behaviour of convective rain storms; when storms are particularly intense or occur in rapid succession, devastating floods may result, whilst a week or two without storms during the wet season can trigger crop failure. Climate scientists rely on computer simulations of the global atmosphere, oceans and continents, yet these models have a very crude description of convective storms. For the first time, a new generation of regional climate models is emerging which realistically depict storms, and critically, how storms respond to factors such as land and ocean conditions, and increases in CO2. AMMA-2050 will use these new computer simulations alongside conventional climate models and historical observations, to understand why the statistics of key climate extremes are changing, and what this tells us about climate and its extremes in future decades. 

The outputs from the models will be used to examine impacts on key sectors in West African society, notably water and agriculture. Adaptation options will be explored, for example through the use of alternative crops, taking account of the inherent uncertainties in climate information, and the ways in which it is interpreted by decision-makers. We will focus on two questions. Firstly, in Senegal we will identify sustainable agricultural adaptation strategies and the policy frameworks to support those options. Secondly, we will examine how climate changes are likely to affect flooding in the rapidly growing city of Ouagadougou in Burkina Faso. The research and capacity building work of AMMA-2050 will help develop a new generation of African researchers and decision-makers, well-placed to respond to the requirements of West African nations. Within AMMA-2050, end-users have an important role, and their needs are embedded in project design and delivery, such that outputs will be responsive to their needs, and delivered in a format that is easily used. Enhanced resilience is an important aim of the project: it starts with improving our understanding of the climate signal over West Africa and leads through to decisions being made in specific pilot studies that showcase the importance of using improved and impact-sensitive science outputs.",1
NE/N018087/1,31159,Land Ocean CArbon TransfEr (LOCATE),"Our climate, and hence our lifestyle and economy, is profoundly influenced by the concentration of carbon dioxide in our atmosphere, which regulates the amount of heat which arrives on earth from the sun that returns to outer space. Human activities such as land clearance and the burning of fossil fuels have increased atmospheric carbon dioxide levels by about 40% in the last 250 years, with most of this increase occurring since the Second World War. This has caused a measurable increase in our temperature, with many of the warmest years on record occurring in the last decade. For this reason our interest is now firmly focused on other natural parts of the carbon cycle, in particular other reservoirs of carbon which are currently locked away from the atmosphere but which might enter the atmosphere as climate changes. One key pool is soil carbon - soils across the globe contain about 4 times as much carbon as the fossil fuel carbon which to date has entered the atmosphere via combustion, with this pool being largest at high latitudes such as northern Scotland. The British pool of soil carbon is a large element of our 'natural capital' - the value that the ecosystem represents to us. It is so large that restoring some damaged elements of it, such as upland peat bogs, would probably save us 570 million pounds over the next 40 years in carbon values alone. Each year some of this leaches into rivers and streams, with the concentration of carbon in rivers gradually increasing in Britain and Europe. As this material gets into estuaries and coastal waters some of it gets returned to the atmosphere when bacteria use it to grow or when it's destroyed by sunlight, some is buried and some enters the open ocean. We don't understand what controls these various processes, so aren't currently in a position to say how they will change into the future. For these reasons we plan to undertake a programme called LOCATE, which will establish the current status of our peatland stocks is (how much soil carbon is getting into our rivers and estuaries), and then determine what happens to this material in our estuaries (including measuring the key processes). Based on this we will do some accurate up to date carbon accounts for the GB landmass and also produce some simple mathematical equations describing what happens to soil organic matter in our rivers and estuaries. These equations will then be embedded into a much larger model of the Earth System so that we can begin to answer questions about the long term fate of the soil organic carbon pool over the next 50 or 100 years.",1
2132367,13912,Intelligent Additive Construction using Geomaterials,"Modern developments have led to the availability of an extremely high level of computing power at low cost, while at the same time, material resources and CO2 are becoming increasingly expensive both economically and in terms of environmental impact. This has created the opportunity to envision a 'high intelligence, low resource' construction technology using computing power and robotics to allow complex adaptive assembly of unprocessed raw materials into suitably performing structures. This PhD project will pioneer practical aspects of this approach utilising little more than in-situ geo-materials i.e soils and raw cobbles/rocks, combined with minimal but strategically placed reinforcing materials where appropriate.

Geo-materials are generally good in compression and shear but lack tensile capacity. However, when strongly interlocked they show significant strength. Historic structures have worked with these materials and properties for millennia and there are many examples around the world of long-lived structures using soil and mortarless rock from the ubiquitous dry stone wall, through stone arches to large scale castles and fortresses. The challenge for modern construction using these approaches is speed, cost, precision and low risk. 

The overarching hypothesis in this project is that it can be cost effective to take this 'high intelligence, low resource' approach. Specifically in this project the hypothesis is that such precision assembled systems (optimised both locally and globally) can outperform conventional low technology bulk earthworks approaches or high resource input approaches (e.g. use of concrete) in one or more construction scenarios.

The hypothesis will be tested through investigation of:

(i) optimal dry packing of cobbles/gravel and characterisation of their performance through conventional geotechnical testing
(ii) performance enhancement with minimal bonding applied to contact points using fine grained soils with/without additional binding agents
(iii) strategic inclusion of reinforcement elements

Experiments will be conducted on soil elements using conventional geotechnical test methods and later on, scale model earthwork constructions. At all stages the ability to automate the processes adopted will be evaluated and specifications written. Underpinning theory will also be developed, together with pilot systems demonstrating the automation concepts, adapting existing robotic equipment.

Co-supervisors both from within the Civil Engineering Department (Dr Jonathan Black) and ACSE (Dr Jonathan Aitken) will give strong support to the cross-disciplinary aspects of this project. 

Applications span a large range from low cost, locally sourced construction in developing countries (including use of demolition rubble), through low carbon resource construction in developed countries, to planetary applications (e.g. construction on the moon where raw material transport would be prohibitive).

A brief timetable of envisaged work is as follows:

Year 1: Literature review, testing of unbonded optimally packed materials
Year 2: Theory development. Investigation of bonding agents and tensile reinforcement
Year 3: Engineering application and automation model demonstrators. Thesis write up.

This project links in with and builds on existing projects and expertise within the Department, Faculty and University in masonry arch construction, chemical and biological stabilization of soils, robotics, soil reinforcement and engineering optimization, building a critical mass from which to springboard major projects in this area.",1
NE/P000703/1,32961,Determining Extreme Values for the Insurance Sector,"Several industrial sectors require knowledge of climate extremes above and beyond those experienced during the satellite era. Examples include the insurance industry where regulators will soon require adequate capital to cover a 1 in 200 year event; and the nuclear industry which is required to prepare against a 1 in 10,000 year event. The common approach to determine these is to extrapolate from observations over the past 50 years or so, either directly or through the use of a catastrophe model. Often these estimates do not include a quantification of the uncertainties arising from either natural climate variability or climate change. This project aims to determine the risks that are missed by these standard practices.",1
NE/P021247/2,35150,Carbon Uptake and Seasonal Traits in Antarctic Remineralisation Depth (CUSTARD),"The surface ocean is home to billions of microscopic plants called phytoplankton which produce organic matter in the surface ocean using sunlight and carbon dioxide. When they die many of them sink, taking this carbon into the deep ocean, where it may be stored for hundreds to thousands of years, which helps keep our climate the way it is today.
 In general terms the size of the effect they have on our climate is linked to how deep they sink before they dissolve - the deeper they sink, the more carbon is stored. This effect is particularly important in the northern part of the Southern Ocean where the pattern of ocean currents means that the difference between shallow and deep dissolution controls whether this carbon is locked away from the surface ocean for just a few years or for centuries. This is because the area is a junction in the ocean circulation. Stacked up on each other from the surface to the seafloor at almost 5km depth are four oceanic 'motorways', taking water to different parts of the global ocean. The motorway that the carbon is dissolved into determines how long it will be kept away from the atmosphere.
 For this reason, if we want to understand the role of this northern part of the Southern Ocean in regulating global climate we need to understand both how big carbon uptake is at the ocean surface and also how deep sinking material dissolves. Unfortunately we don't understand either well; data are scarce in the Southern Ocean as the weather is poor and few commercial vessels pass through there. Consequently, our theories about the pattern of the fate of sinking carbon and what controls this are untested. As a result the models that we use for predicting future climate have massive uncertainty in this region. However, the evidence that we have suggests that changes in the depth of carbon dissolution are key to understanding how the system works. 
 In this project we will tackle this by making new observations in a remote region of the Southern Ocean using an exciting combination of robotic vehicles and sophisticated new sensors. We will make new observations of how much carbon the ocean takes up in this key motorway junction of the Southern Ocean. We will examine the processes that control the uptake of carbon and its fate, in particular how seasonal availability of nutrients can affect the make-up of the phytoplankton which changes the depth to which carbon sinks before being dissolved.
 We will combine these observations with a novel modelling approach that allows us to run the ocean part of our climate model much faster than normally. This allows us to explore the consequences of the seasonal interplay between nutrients and phytoplankton found in our data. In particular, the model allows us to 'tag' carbon so that we can trace where it goes. In this way we can measure the amount of sinking carbon ending up on each motorway and how this varies through the year. 
 Together with observations of the seasonal changes in nutrients and sinking carbon the model will allow us to determine the key processes regulating carbon uptake in this important area. This will provide important information to those building the UK's climate model at a time when it is being developed to provide input to a future high profile report (from the IPCC) on the state of the world's climate.",1
NE/T008830/1,40209,Seaquest DSV: a compact Deep-water Sonar and Visual sampler for exploring the marine twilight zone,"Animals in the deep sea, including a diverse array of fish, squid and zooplankton, are hard to sample, but play important roles in ocean ecosystem function (e.g. they are food for species such as tuna and some cetaceans), biogeochemical cycling (e.g. helping transport atmospheric carbon to the deep sea, buffering climate change), and may be targeted directly by fishers. We need fundamentally to gain a good understanding of which species are where, and in what abundance. We propose an acoustic and optical sampling device that will help with this, opening a new window on the mesopelagic zone (200 to 1,000 meter depth range) by overcoming some present day sampling difficulties.

Traditional net surveys suggest that there are about 1,000 million metric tonnes (MT) of fish in the mesopelagic zone. In 2014, an international team suggested, controversially, that these old estimates were an order of magnitude too low, and that there may in fact be more than 10,000 MT of mesopelagic fish [1]. Their estimate was made using single-frequency (38 kHz) scientific echosounder data collected on a single circumnavigation of the globe. They assumed that all of the echo energy from the mesopelagic came from fish but did not have any net samples to confirm this. Different sized fish return different intensities of echo energy, and some zooplankton thought to be abundant in the mesopelagic (siphonophores) have gas-bearing pneumatophores that can return stronger echoes than some fish. In the absence of species or size information, therefore, there is scope for considerable uncertainty in any 'fish' biomass estimate arising from a blanket scaling of echo intensity to fish biomass. Due to this headline figure, there is now growing commercial interest in mesopelagic biomass as a potential major source of protein. We need as a scientific community to better understand mesopelagic community composition so we can better inform society of the ecosystem services of the organisms that live there and their potential for harvest.

Basic acoustic theory (e.g. [2]), our own work [3] and that of colleagues [4] focusing on the mesopelagic, has shown that fish and siphonophores cannot be differentiated by single frequency sampling. Multiple frequency data can however give information on size and, in some circumstances, can enable separation of species [5]. Typical ranges of frequencies used for fish/zooplankton identification/sizing range from tens to several hundred kHz. The physics of sound propagation limits the effective range of the high end of this spectrum to a few tens of m in seawater, so in order to acoustically sample the mesopelagic we need to lower the echosounder into deep water. The instrument we propose will enable this. Furthermore, we will use stereo video to capture images of some of the organisms we detect acoustically. This will enable us to determine the acoustic target strength (TS, a ratio measure of the proportion of sound energy backscattered from a target) of species of known size (size influences TS) across a spectrum of frequencies and so enable quantitative evaluation of acoustic survey data and progress towards better understanding of global biomass distribution. Combining acoustic and stereo optics provides an innovative and world-leading new way to sample the mesopelagic.

1. Irigoien, X. et al. 2014. Large mesopelagic fishes biomass and trophic efficiency in the open ocean. Nat Comm, 5: 3271. 
2. Simmonds, E., and MacLennan, D. 2005. Fisheries acoustics. Blackwell Science Ltd. 
3. Proud, R., et al. 2018. From siphonophores to deep scattering layers: uncertainty ranges for the estimation of global mesopelagic fish biomass. ICES JMS.
4. Kloser, R. J. et al. 2016. Deep-scattering layer, gas-bladder density, and size estimates using a two-frequency acoustic and optical probe. ICES JMS. 73: 2037-2048. 
5. Brierley, A. S. et al. 1998. Acoustic discrimination of Southern Ocean zooplankton. DSR Part II:TSIO. 45: 1155-1173.",1
AH/P004431/1,20469,Soviet climate science and its intellectual legacies,"Anthropogenic climate change is arguably the most significant threat confronting humankind in the early 21st Century. The intellectual history underpinning our growing insight into the nature and scale of the problem has received marked attention in recent years and yet the specifics of the Soviet Union's contribution in this respect have been marginalised in the English-language literature. This lacuna is significant not only in view of the Soviet Union's (and latterly the Soviet successor states') size and importance for global environmental systems, but also because of the contribution made by Soviet scientists to the international understanding and associated debate in this area post-1945. The Russian Federation remains a major contributor to global greenhouse gas emissions. At the same time, it has adopted a relatively negative stance with respect to recent and ongoing international efforts to curtail such emissions.

In view of this, the overarching aim of this research project is to explore the development of Soviet climate science post-1945, with a particular focus on the debates concerning humankind's influence on climate systems and on Soviet contributions to related international initiatives. The research will also examine the intellectual legacies of these debates for Russia's positioning in post-1991 climate discussions. As part of this, the research will provide a first detailed account of Soviet engagement with international debate concerning climate change and key organisations such as the World Meteorological Organisation (WMO) and Intergovernmental Panel on Climate Change (IPCC).

The project will make extensive use of both Russian- and English language archival materials located in Russia, Europe and the USA. In addition, it will generate a series of oral history interviews with scientists involved in Soviet climate science. The contemporary element of the research will be underpinned by interviews with relevant policy and state actors and supported by secondary data analysis.

The project's output will consist of a series of published works and reports in addition to workshops and a project conference to be held in St. Petersburg. In addition, it will produce a block of work for use in Schools concerning Russia and climate change in collaboration with the Royal Geographical Society (RGS). This would take advantage of the introduction of Russia as a required element of study within the Key Stage 3 (11-14) National Curriculum and help to strengthen the coverage of key themes including climate change, biomes, and carbon cycle within KS3 and the new GCSE and A level specifications effective from September 2016. Further outputs will include Master classes for teachers, public lectures outlining the main findings of the research, policy briefings, and materials for the project and RGS websites.",1
133326,20029,Halogenated Organic Lasers Integrated on Silicon for Transforming Internet Communications (HOLISTIC),"Optical communication is the future of high speed data networks. Although virtually all long distance data transfer is sent at the speed of light down optical fibres, the technology required to do this is too expensive for shorter distance links. As such datacentres, which currently consume about 3% of the world's electricity generation and are responsible for around 2% of all greenhouse gas emissions, are forced to rely on electrical connections for short range data transfer, an energy intensive process which also provides a bottleneck in the data transfer rate. This project aims to further develop a new range of laser materials derived from novel chemistry which can be deposited directly onto silicon chips in order to allow the integration of lasers. This will overcome the bottleneck in data communications and facilitate ultra-high speed communications right down to the chip level, a fundamental aim of those in the silicon photonics field which is seen as the underpinning technology for next generation computing. The project brings together a new spin-out company with Queen Mary University of London and IP Group, an early stage technology development company. We will support Chromosol to produce, test and characterise these new and novel laser materials and use them to fabricate devices demonstrating the commercial viability of the approach.",1
NE/N01801X/1,18004,The UK Earth system modelling project.,"Global climate change is one of the leading environmental threats facing mankind. To develop appropriate mitigation and adaptation strategies requires accurate projections of the future state of the Earth's climate. To address this, the research community have developed Global Climate Models (GCMs) that describe the main physical processes in the coupled climate system. These mathematical-computer models are integrated forwards in simulated time, from a pre-industrial period(before ~1850) to present-day, forced by observed estimates of key greenhouse gases (e.g. carbon dioxide, methane, ozone), aerosols and land-use. The models are then continued into the simulated future forced by a range of greenhouse gas, aerosol and land-use scenarios representing plausible future socio-economic development pathways. Each of the time-evolving model future climates are then compared to the pre-industrial and present-day climates from the same model. This analysis results in an ensemble of climate change estimates, linked to each of the applied development pathways, that can be used to assess potential socio-economic and ecological impacts and aid in the development of climate change mitigation and adaptation policies.

GCMs have recently been further developed into Earth system models (ESMs). A key difference between ESMs and GCMs is the former include an interactive description of the global carbon cycle. Climate change is primarily driven by human emissions of carbon dioxide which traps a fraction of the Earth's emitted radiation in the atmosphere, warming it and the Earth's surface. This direct warming from increasing carbon dioxide can be amplified or damped by various feedbacks in the climate system (e.g. involving water vapour, clouds or sea-ice). A key determinant of the climate change impact of human-emitted carbon dioxide is how much of the emitted gas actually stays in the atmosphere where it can interact with the Earth's emitted radiation. Presently, around 50% of the carbon dioxide emitted by humans stays in the atmosphere, the remaining 50% being taken up, in roughly equal measures, by the terrestrial biosphere and the world oceans. There is increasing evidence to suggest the efficiency of these natural carbon reservoirs in absorbing human-emitted carbon dioxide may change in the future, being sensitive to both the concentration of carbon dioxide in the Earth system and to the induced climate change. A reduction in the uptake efficiency of Earth's natural carbon reservoirs would result in a larger fraction of emitted carbon dioxide remaining in the atmosphere and thereby a larger climate change (warming) for a given cumulative emission of carbon dioxide.

To address the need to simulate both the changing global climate and the carbon cycle response to a changing climate and changing atmospheric composition, we are developing the 1st UK Earth system model, based on the core physical GCM, HadGEM3, developed at the Met Office. This development is a major collaboration between NERC centres and the Met Office, integrating a large body of core research and development into a single, world-leading ESM. This proposal aims to secure the NERC funding to maintain this collaboration. The project will support the final development and community release of the 1st UKESM models, as well as application of these models to a range of collaborative science experiments carried out at the international level to support the IPCC AR6. The project has a major emphasis on evaluating the full range of climate and biogeochemical processes and interactions simulated by UKESM1 models with an aim to increase confidence in future projections made with the models. The project will also generate and analyse a suite of such projections and deliver a set of robust estimates of Earth system change to UK government, business and the public.
Finally, the project will initiate long-term development of a 2nd version of the UKESM model, for release ~2023.",1
BB/S013954/1,45518,MillNET_i: Millets and Nutritional Enhancement Traits for Iron bioavailability,"Iron deficiency remains the most prevalent nutritional deficiency worldwide, affecting an estimated 4 to 6 billion people. Iron deficiency anaemia (IDA) is the largest nutritional deficiency disorder in the world and one of the five leading causes of global disease burden. At any given moment, more individuals suffer from IDA than any other health problem with a staggering 1.24 billion affected individuals worldwide.

In developing countries, millets are the most common form of cereals, often cultivated by female small holders in semi-arid tropic regions. Their resistance to drought and climate variability, along with nutrient dense characteristics, is attracting an increasing number of small scale farmers and governments in Sub Saharan Africa. While the nutritional value of millets has been identified, there has been limited progress on the creation of functional foods that are readily acceptable to populations. Biofortification of millets is also an emerging area research for enhancing nutritional quality.
The goals of the two-year MillNETi are to tackle the major issue of iron bioavailability (relative to biofortification) by promoting the use and preparation of pearl and finger millets, initially in Ethiopia and The Gambia, but of wider relevance for many semi-arid regions of Africa. The programme has been co-created with colleagues in India, Ethiopia and The Gambia, and a consortium of UK expertise and will undertake fundamental scientific investigations for the GROWTH, PROCESSING and monitoring of iron BIOAVAILABILTY, allied to social science methodologies to disseminate knowledge and improved practices in cultivation and food preparation (EXTENSION) to regional populations. The programme builds on an existing programme of biofortification (ICRISAT), bioavailability testing (MRC- Gambia), and social science studies indicating that rural - urban migration is creating a demand for more nutritious foods such as millets both in The Gambia and Ethiopia.

We will explore the basis of variation in crop iron uptake and availability traits in millets from contrasting regions and cropping practices (GROWTH: NIAB, UCAM, ICRISAT, EIAR). Additional research in Ethiopia on food preparation and processing (PROCESSING: BDU, ICRISAT, UCAM, MRC-Gambia) will be linked with a programme of internationally-validated human nutrition intervention studies (BIOAVAILABILITY: MRC-Gambia, UCAM), analysing plasma bioavailability of iron in healthy adult female representatives from local populations. As well as outreach to improve the nutrition and health of rural communities (EXTENSION (CGE/JeCCDO, BDU, UCAM: CGC, GFS IRC, CAPREX) additional insights from MillNETi on rural-urban linkages will be associated with the practice of food remitting, and potential role in food security, improved nutritional status and marketing opportunities for rural populations. These highly original observations will be of international significance for many populations in Africa and India, where the rural-urban divide represents a complex and interlinked reality of 'stretched' or 'multi-nodal' households.",1
EP/N010779/1,25554,City-Wide Analysis to Propel Cities towards Resource Efficiency and Better Wellbeing,"Many cities in the world are putting in place their own robust carbon reduction strategies in response to, or in advance of, leadership from central government. As the powerhouses of economic growth, cities use vast amounts of energy and consume resources from hinterlands that stretch across international borders. However, the population density of cities can also provide opportunities for significant efficiencies in terms of the provision of building services and the mobility of people and goods. In this programme of work, we propose to centre our activities on two cities: Xi'an, China and Portsmouth, UK which are notable both for their cultural heritage and for their population density (Portsmouth has the highest population density of any city in the UK). Both cities have published ambitious plans for reducing city-wide carbon emissions but also have large stocks of ageing buildings and infrastructure. This programme of work will: (a) develop an overall understanding of current buildings, mobility and energy services in both cities; (b) identify low disruption and scaled-up retrofit methodologies taking into account the particular characteristics of the two cities; (c) carry out modelling of city-wide retrofit and systems integration, at both the neighbourhood and district scales including building refurbishment, district energy and micro generation geared to improve buildings for their users. In all our modelling and building performance evaluation, we will take into account anticipated climate change projections and the adaptation required to maintain or exceed current levels of thermal comfort. (d) Address adaptive urban logistics to meet mobility needs within the two cities while pursuing carbon reduction targets through a series of targeted workshops with practitioners in the field from both countries. (e) Through a combination of modelling and monitoring, we will identify smart solutions harnessed to inform users and reduce consumption. Crucially, the modelling will be validated by real energy consumption datasets, gathered from both secondary sources (provided by our partners and from others) and primary, from a combination of sensor deployments and surveys. The latter will take the form of monitoring of a sample of multi occupancy buildings for a range of relevant parameters including temperature, power consumption, humidity and carbon dioxide. The building performance data provided by the sensor deployment will be supported by user survey data exploring perceptions of thermal comfort, overall wellbeing (satisfaction with life, health, employment and so on) and attitudes to energy saving and the cost of energy. This will link the purely techno-economic assessment of energy saving interventions to their potential social impacts. The outcomes of this programme will take the form of validated tools and guidance distilled from the project results in order to support city planners in their decision making processes concerning building asset refurbishments and the likely impact on wellbeing resulting from such improvements. A central aspect of the programme will be to foster collaboration and knowledge transfer between both researchers and practitioners in China and the UK. There are areas, for example district heating, of which there is far more experience of in China than the UK, very relevant to densely populated UK cities like Portsmouth. In other areas such as energy efficiency standards for new buildings and building energy assessment techniques, there is potential for knowledge transfer from the UK to China. In the final year of the project a joint UK-China workshop will be held to bring together researchers and practitioners in the fields of planning, energy, building services and local government, in order to disseminate the results of the programme, to test out and receive feedback on the support tools and to foster further collaboration.",1
EP/S030328/1,36146,Boosting Reduction of Energy Intensity in cleaN STeelwork platfORM,"Iron and steel is the largest UK manufacturing industry in terms of energy demand and greenhouse gas (GHG) emissions. Currently, more than 6 Mt of steel per year are produced in six blast furnaces at two steelworks with specific energy consumptions of 19 GJ/t of steel and overall direct CO2 emissions of 13 Mt, contributing 25% to GHG emissions from UK manufacturing. Combustion of blast furnace gas (BFG) in the power station causes ~ 50% of CO2 emissions.

In BREIN-STORM we propose to convert the BFG from steel mills into valuable products, such as hydrogen and pure carbon dioxide. This will be achieved by combining calcium and chemical looping gas-solid reactions (CaL-CLC). This four-year project comprises four interlinked work packages (WPs):
1. WP1 will develop and scale up different multi-functional materials based on calcium oxide as sorbent and copper-oxide oxygen carriers. We will focus on increasing the stability over cycling operation and the sorption capacity of the materials. The produced material will be tested and characterised to examine longevity. The kinetics models will be derived to enable the scale up.
2. WP2 will focus on the development and testing of the reactor. We will carry out the experimental demonstration and long-term testing under different reactive conditions in packed and fluidised bed configurations. The experimental results will be used to validate the reactor model. The knowledge gained both from the experimental and numerical activities will be used as guidance for future pilot-scale demonstration of the technology.
3. In WP3, the CaL-CLC process will be integrated into the steelworks through a conceptual design. The techno-economic performance of the process will be compared with standard state-of-the-art technologies in the steel sector. The integration of renewables sources will be studied with the aim of designing a first 'green' steelworks plant.
4. In WP4, the developed process will be evaluated on environmental impacts as well as social and policy implications.",1
NE/N004728/1,7263,Development of a UK Extreme Gust Climatology and Linked Damage Tool,"WORK TO BE UNDERTAKEN:

The proposed Pathfinder project will undertake a market research exercise comprised of four work stages: 

Stage 1 - Telephone Interviews: 
The interviews will be conducted either by telephone or through a site visit and each will last ~30 minutes. The interviews will be structured around a questionnaire with core questions (see below) but will be conducted in the form of a discussion in order to develop insights into the business issues of the user. The interviews will also be used to identify potential commercial collaborators and end-users. The aim will be to carry out interviews with 10-12 companies which are representative of the UK (re)insurance market.

Stage 2 - Desk Research: 
The desk research will collate information and data on the UK insurance / reinsurance market, information on the current data employed for benchmarking UK wind hazard, and information on competitor products and companies.

Stage 3 - Analysis:
Output from the desk research and interviews will be used to construct realistic information on the product's likely pricing and scale of sales, and on the level of marketing and resources necessary to gain market traction. Appropriate routes to market will be developed. A revenue model for the application will be constructed which will estimate potential revenues in the 3-5 year timeframe. Opportunities for additional spin-out products will be considered.

Stage 4 - Report and Recommendations: 
Output from stages 1-3 will be presented in a document. This report will include recommendations for the commercial potential and route to market for the technology.


HOW THE PATHFINDER WORK WILL INFORM UNDERSTANDING:

The knowledge and insights gained from the Pathfinder work will inform understanding on:

1. The size and scale of the current commercial need within the insurance sector for an improved UK extreme gust climatology and linked damage tool. 
2. The nature and level of further technical developments that would be desirable to maximize the commercial opportunity. 
3. The market opportunities to prioritise and why. 
4. The strengths and weaknesses of the project's intellectual property position.
5. The resources required to gain market traction. 
6. The stakeholders with whom a meaningful dialogue could be established prior to submission of the Follow-on-Fund proposal. 
7. The appropriate pathway to impact.
8. The likelihood of securing Follow-on funding and whether a submission in spring 2015 is appropriate.


HOW THE PATHFINDER WORK WILL BE USED TO SHAPE A ROBUST CASE FOR FOLLOW-ON FUNDING: 

The work undertaken by the Pathfinder project will influence the nature and content of the work programme for the proposed Follow-on project by:

1. Providing a sound understanding of the needs and requirements of end-users. This information will guide the focus and direction of the technical development plan and ensure that it is informed by the findings of the market assessment.
2. Clarifying the nature of the competition. This knowledge combined with the needs of stakeholders will determine which market opportunities to prioritise.
3. Clarifying the nature of the further technical developments necessary to maximise the commercial opportunity. This information will strengthen the content of the technical development plan and improve the likelihood of commercialisation success.
4. Determining the likely challenges and resources necessary to obtain commercial customers and what is the most appropriate route to market. This information will underpin the development of a credible plan to drive the project towards an appropriate commercial outcome.
5. Establishing those end-users to target as most likely to adopt the technology and who would be most appropriate to approach for letters of support.",1
EP/R005761/1,1372,"Smart-GeoWells: Smart technologies for optimal design, drilling, completion and management of geothermal wells","A novel product will be developed for designing, drilling, completing and managing well systems that incorporate many laterals with increased reservoir contact for geothermal industry. A hybrid drilling approach, based on conventional and jetting (water and supercritical-CO2) technologies, will be employed along with advanced numerical models to help optimise the deployment and management of the well system. The product targets the fast-growing geothermal industry, and can be readily re-applied to oil/gas production, with a particular focus on intermediate-deep geothermal resources. Objectives of this work include: (1) application of advanced well drilling and completion technologies for more efficient well system construction; (2) evaluation of new-generation numerical models for solving fluid flow and heat transfer problems in complex well-reservoir systems, (3) optimisation of well design and management for cost-effective production, and (4) deployment of the product to geothermal reservoirs for field trials. The novelty of this project comes from the unique combination of new drilling and completion technologies with novel computational methodologies for well management and production.

China's current energy demands require innovative, cost-effective and environment-friendly solutions. We are proposing an innovative multi-lateral well system Smart-GeoWells to help meet these challenges. This will be used to develop cleaner, more affordable, localised (building, village, town, city) heating/hot water and electricity, harnessing almost limitless, sustainable and secure geothermal energy. In order to develop the new multi-lateral wells (with potentially hundreds of laterals), the proposed team (each member a world-leader in their fields) will apply their specialised knowledge in testing and exploiting the new well engineering solutions, hybrid drilling technologies, advanced numerical modelling and optimal well design and management methods. For the UK and China teams, this will be the first stepping stone towards long-term collaboration, aiming at optimal exploitation of geothermal resources and if successful will have a massive impact on the energy sector. However, the scope of the work is also immense and thus our initial product (that we aim to develop rapidly) will be focussed on geothermal hot water production, although the developed technology can serve as a longer term product for geothermal electricity generation as well as O&amp;G production. The new multi-lateral drilling concepts of XLTL (project partner) together with the novel techniques in modelling multiphase fluid flows and heat transfer through these large number of laterals (similar to the fishbone structure), will lead to economic and efficient ways of drilling financially-competitive multi-lateral wells through: a) enhanced contact and connectivity with geothermal regions; b) minimisation of environmental damage i.e. pollution of groundwater sources/surrounding countryside and c) optimal control/management of the production wells. During the project, Sinopec will provide geothermal sites, test equipment and specialised engineers/technicans for field trials (the company's funding contribution amounts to 5 million RMB) with which the advanced drilling techniques will be examined and the prediction software will be validated. The developed Smart-GeoWells platform will be made available to the interested local and other companies/businesses, as well as public services, and will also benefit them through enhanced knowledge and technology transfer. The longer-term implications on the welfare of the local and other communities are immense, both directly through reduced pollution (water and air) and climate change impacts and, indirectly, through economic impacts.",1
NE/S016457/1,40457,Climate Risk Indicators: developing indicators of climate risk using UKCP18 to support risk assessments and enhance resilience,"In order to enhance resilience to weather events and climate change, it is necessary to assess risk. This project provides first estimates of a series of indicators of climate risk, using UKCP18, relevant to climate risk assessments at national, devolved, and local levels, and over different time horizons. It will provide information valuable to the next Climate Change Risk Assessment, and help organisations understand their current and future risks.

The project will also provide information about the relationship between future increases in temperature and future risk. For some indicators, risk will increase rapidly as temperature increases, but for others risk may only begin to increase significantly at higher temperature increases. Changes in risk will also be uncertain because we cannot yet predict future climate very precisely, so the project will also allow us to assess the confidence in projections of future risk.

The project uses the new UKCP18 climate projections, and concentrates in the first instance on risks of weather extremes, floods and droughts, and risks to agricultural productivity.",1
BB/S006567/1,39010,Elucidating bovine host genomic links with rumen microbial genes to improve sustainably feed conversion efficiency using unique selection criteria,"The Food and Agriculture Organisation of the United Nations has predicted an increase in global meat and milk demand of 76% and 63% by 2050 due to increasing income and growing world population. This will require improved sustainable systems for livestock production. The large fore-gut of cattle, the rumen, contains billions of microbes (the microbiome) per gram of digesta (which is the substance as food undergoes digestion). These microbes ferment human inedible food (e.g. grass) into nutrients the host animal converts into high quality products such as meat and milk. This rumen microbial eco-system is essential for the animal but has one disadvantage for the environment because some microbes produce the potent greenhouse gas methane. This project will address these challenges by using rumen microbial information as animal breeding criteria for improvement of feed conversion efficiency with simultaneous mitigation of methane emissions. In this research we will estimate the extent of the link between animal genome and its rumen microbiome and investigate the causes for their link using a large breeding population. This population is provided by our commercial partner Genus plc and is well structured to ensure accurate estimation of host genetic effects on the microbiome. Our previous research showed that rumen microbial gene abundances are closely related to feed conversion efficiency and methane emissions. However, how and to what extent the host animal genome affects the abundances of microbial genes is unknown and will be investigated within this project. Because the metabolic functions of these microbial genes are mostly known, we expect to identify many novel genetic links between the host animal and specific rumen microbial functions that may even be conserved across species. Networks and functional pathways of rumen microbial genes linked to the animal genome will provide a new level of understanding of the symbiosis between microbiome and host animal. We are expecting to identify pathways of microbial genes, e.g. to provide insight into the &quot;cross-talk&quot; between the rumen microbes and the host animal, being a route by which the host genome controls its own rumen microbiome. Based on these findings, optimised selection criteria and strategies to improve feed conversion ratio and mitigate methane emissions will be developed. In addition, we will use biomarkers to control that there are no adverse effects of selection using microbial genes on rumen health with potential consequences for animal health and welfare. Our large commercial partner will ensure that the outcomes of the project can be immediately implemented in the routine breeding activities and thus contribute to address the challenges of food security and environmental impact of animal production. This project is expected to provide an enormous increase in fundamental knowledge of the links between host animal genome and the rumen microbiome, which may be also relevant in other species including humans, and at the same time will develop methods and strategies to use this new knowledge for practical application in animal breeding.",1
EP/P033229/1,17872,Unravelling halide segregation in hybrid perovskites for Si tandem photovoltaics,"Renewable energy sources offer exciting opportunities to address challenges caused by energy security and climate change. Photovoltaic (PV) cells in particular can enable sustainable generation of electricity on a large scale: the solar energy incident on the surface of the earth in one hour is enough to provide the whole world's current yearly energy requirements. As an exciting newcomer to the PV landscape, organic-inorganic metal halide perovskites now show certified power conversion efficiencies for single-junctions thin film solar cells in excess of 22%. The best performing single-junction cells are currently all based on lead iodide perovskites with A-PbI3 formula, where the cation A is typically methylammonium (MA), formamidinium (FA), Caesium (Cs) or a mixture thereof. 

Many analysts in the renewable energy sector believe that the most effective commercialisation of these novel perovskites is in combination with existing, well-established silicon technology. Here, a perovskite thin-film cell is combined with a silicon cell in a 2- or 4-terminal tandem cell, boosting efficiency at small additional cost. For optimised tandem architectures, the photocurrents created by each cell need to be balanced, which requires a perovskite with band gap near 1.75eV, significantly above the typical bandgap of ~1.5eV displayed by the established A-PbI3 materials. To date, the only high-performance perovskite thin-film materials ideally matched for tandem applications with silicon are based on the A-Pb(Br_x I_(1-x))3 system, which allows band gap tunability from ~1.5 to ~2.2eV when the bromide content is varied between x=0 (iodide only) and x=1 (bromide only). 

However, the mixed halide perovskites are affected by an instability whose origin mystifies researchers. When illuminated with visible light, the material segregates spontaneously into iodide-rich and bromide-rich domains. This effect is transient, and recovers in the dark over the timescale of minutes. For photovoltaic applications, the potential voltage shifts and charge trapping associated with this effect are highly detrimental to the aim of stable PV operation. Recent research at Oxford and in the international research community has shown that materials can sometimes be stabilized through choice of A-cation and enhanced crystallinity. However, photo-stability was found to depend sensitively on processing conditions, with instability recurring when protocols or environmental conditions were varied. These incipient studies suggest that the photo-induced halide segregation is not as such intrinsic and therefore can be remedied, but a global picture of how this can be done remains elusive. 

Our programme will identify the causes underlying this effect and pioneer new materials that are photo-stable over projected solar cell life spans. We will achieve these aims through a novel programme that brings together a team of world-leading investigators with complementary skills in photovoltaic materials and devices, advanced spectroscopy and high-resolution electron microscopy, and in-situ crystal structure analysis. The outcomes of this programme will enable the development of long-term photo-stable, fully optimized materials for use in tandem cells with established silicon photovoltaic technology.",1
NE/N013840/1,20451,"GENESIS: Dynamics and parametrisation of deep convective triggering, maintenance and updraughts","Physically, deep convection is a key process in the atmosphere, particularly in the tropics, where it is the dominant driver of the weather as well as playing a key role in forcing global circulation. Despite this key role on the large scale, convection is inherently a relatively small-scale process with convective clouds typically being on the scale of 100's of metres to a few kms, and therefore unresolved in global numerical weather predicition (NWP) and climate models. &quot;Parametrisation&quot; of convection is therefore critical to accurately represent the impact of convection on the larger scale flow. This is not a simple problem, and deficiencies in current convective parametrisation schemes lead to significant model biases, the wrong diurnal cycle of convection in the tropics (with knock-on effects on rainfall and surface heating by radiation) and inadequate representation of important atmospheric circulations such as the Madden-Julien Oscillation, which are driven by convection. Two particular, and linked, problems which contribute to these deficiencies are the triggering of convection (timing, location and the stochastic nature of triggering) and the subsequent organisation of convection into larger convective systems.

The overarching aim of this project is to bring together our understanding of the various physical processes which control the triggering and organisation of deep convection, and to use this to develop a framework in which these processes can be integrated in a consistent way. Such a framework will allow these important processes to be represented in new convective parametrisation schemes in a more physically realistic and consistent manner. In particular, a physically-based convective triggering scheme should be easier to integrate into the new generation of stochastic convective parametrisation schemes which are being developed. Such schemes will also be easier to make scale-aware, i.e. to adapt with the model resolution to only parametrise the necessary sub-grid processes, while allowing the model to resolve larger-scale features of the convection. This is particularly important for the latest NWP and regional climate model simulations which are of sufficiently high resolution that they permit the explicit representation of convection, albeit rather crudely. 

A further limitation of current parametrisation schemes is that they tend to be instantaneous. Where convection organised, the system has &quot;memory&quot;, i.e. the occurrence and organisation of convection will impact on the local development of further convection. We will use techniques from other branches of fluid dynamics to understand and quantify organisation in convective systems and develop measures which can be used as the basis for new stochastic convection parametrisations.

This project will consider both internal processes and external processes. Internal processes generated by the convection itself, such as gravity waves and cold pools, play a key role in the triggering and organisation of convection. Over land external factors such as surface heterogeneity and topography also play an important role in triggering convection and controlling how it can organise. Integrating these various competing influences into a consistent framework will be a significant step forward for parametrisation schemes. Having developed the framework from studying individual processes through idealised numerical simulations with the Met Office Unified Model (MetUM) and the Met Office-NERC cloud resolving model (MONC) we will test the ideas in more realistic large-domain simulations to help quantify the important scale interactions between small scale convection and the larger scale fields. 

The output of this project will be a series of generic physically-based model frameworks which can be used as components in different convective parametrisations schemes which are being proposed or developed, both within this programme and internationally",1
NE/S009019/1,42234,GCRF South Asian Nitrogen Hub,"Humans have massively altered flows of nitrogen on our planet, leading to both benefits for food production and multiple threats to the environment. There are few places on Earth more affected than South Asia, with levels of nitrogen pollution rapidly increasing. The result is a web of interlinked problems, as nitrogen losses from agriculture and from fossil fuel combustion cause air and water pollution. This damages human health, threatens biodiversity of forests and rivers, and leads to coastal and marine pollution that exacerbates the effects of climate change, such as by predisposing reefs to coral bleaching. Altogether, it is clear that nitrogen pollution is something we should be taking very seriously.

The amazing thing is that so few people have heard of the problem. Everyone knows about climate change and carbon footprints, but how many people are aware that nitrogen pollution is just as significant? One reason for this is that scientists and policy makers have traditionally specialised. Different experts have focused on different parts of the nitrogen story, and few have the expertise to see how all the issues fit together.

This challenge is taken up by a major new research hub established under the UK Global Challenge Research Fund. The &quot;GCRF South Asian Nitrogen Hub&quot; is a partnership that brings together 32 leading research organisations with project engagement partners from the UK and South Asia. All eight countries of the South Asia Co-operative Environment Programme (SACEP) are included. The hub includes research on how to improve nitrogen management in agriculture, saving money on fertilizers and making better use of manure, urine and natural nitrogen fixation processes. It highlights options for more profitable and cleaner farming for India, Pakistan, Bangladesh, Nepal, Afghanistan, Sri Lanka, Bhutan and the Maldives. At the same time, the hub considers how nitrogen pollution could be turned back to fertilizer, for example by capturing nitrogen oxide gas from factories and converting it into nitrate.

The fact that all the SACEP countries are included is really important. It means that lessons can be shared on good experiences as well as on whether there are cultural, economic and environmental differences that prevent better management practices from being adopted. It is also important from the perspective of international diplomacy, and provides an example to demonstrate how working together on a common problem is in everyone's interest. It puts the focus on future cooperation for a healthier planet, rather than on the past.

The South Asian case provides for some exciting scientific, social, cultural and economic research challenges. The first is simply to get all the researchers talking together and understanding each other. There are dozens of languages in South Asia, matching the challenge met when different research disciplines come together. This is where developing a shared language around nitrogen can really help. There are lots of nitrogen forms ranging from unreactive atmospheric nitrogen (N2), to the air pollutants ammonia (NH3) and nitrogen dioxide (NO2), to nitrate (NO3-) which contaminates watercourses, and nitrous oxide (N2O) which is a greenhouse gas. The impacts of each of these are being studied to provide a better understanding of how they all fit together.

The result is an approach that aims to give a much more coherent picture of the nitrogen cycle in South Asia: What is stopping us from taking action, and what can be done about it. One of the big expectations is that the economic value of nitrogen will help. India alone spends around &pound;6 billion per year subsidising fertilizer supply. It means that South Asian governments are strongly motivated to use nitrogen better. At which point research from the South Asian hub can provide guidance on where they might start.",1
2113232,12583,Public engagement and opportunities for 'shared infrastructure' in the UK,"Context and significance Although public consultation is enshrined in policy as an expected and desirable part of the planning process, in the last decade this has taken on a changing form. The Planning Act 2008 reduced consultation for nationally-important infrastructure projects (NSIPs) by establishing the Infrastructure Planning Commission (IPC) as the relevant decision-making body. Subsequently, the Localism Act (2011) was established, which saw the abolishment of the IPC. Although the legislative structure remains broadly similar, final decision-making power reverted to the relevant secretary of state. The Infrastructure Act (2015) changed the consent stream for fracking projects, reversing UK case law by removing the ability of homeowners to object at horizontal drilling underneath their property (Cotton, 2017). In addition to the above pieces of legislation, the main legislative requirement regarding public participation in NSIPs is the Environmental Impact Assessment process, but this applies only if a project is classified in a certain category within EU law. The recent streamlining reduced opportunities for the public to shape projects and engage in non-adversarial dialogue with developers, simultaneously making it easier for developers to carry out projects. This is especially apparent in the example of fracking. There appears to be a gap between policy rhetoric around providing for appropriate public consultation, and opportunities that actually exist for communities and individuals who are affected by NSIPs to engage in the planning process. Causes include complex presentation of the data that is made available to the public, short time windows for public responses to proposals, and limitations in community capacity to engage (including a lack of capacity-building initiatives). What is seen to constitute 'engagement' is influenced by the way 'the public' and local communities are framed/conceptualised by the government and developers. These processes have resulted in democratically-inadequate methods of public consultation. This is problematic because the costs and benefits of NSIPs are not equally divided between places (e.g. large urban hubs vs. small rural communities situated along the planned routes) or people (e.g. socio-economic classes), meaning people are not able to engage in a manner corresponding to the degree to which they are affected. Aim and objectives In their position as developer, contracted by the Government, the consultancy firm Amp is engaged in public consultation for the following four projects. These will provide case studies for the research: - HS2 (high speed national rail network) - Fracking (hydraulic fracturing) in Lancashire - Hydrogen gas supply for household energy consumption in Leeds - Heathrow Airport's third runway The research aims to provide answers to the following questions emerging from the above case studies: 1. To what extent does the nature of public consultation during the planning process affect the distribution of social benefits from, or public engagement with, NSIPs when carried out? NB: explore how policy changes in the last decade have affected this. 2. What constitutes 'community' as defined by the regulations controlling public consultation and does this definition accurately reflect its complex reality? 3. Regarding public perception of the stakeholders who carry out consultation for NSIPs, which actors may enhance or reduce trust in the developer-community relationship? Methodologies An initial systematic literature review will provide context and direction for the research.",1
NE/T00858X/2,40236,UK-OSNAP-Decade: 10 years of observing and understanding the overturning circulation in the subpolar North Atlantic (2014-2024),"There is mounting evidence from measurements and models of the importance of the transports of heat and freshwater by the Subpolar North Atlantic Ocean. They impact on North Atlantic, European and global climate via temperature, precipitation and wind strength, and also on marine ecosystems, hurricanes, even rainfall in the Sahel, the Amazon and parts of the US. The subpolar North Atlantic behaves substantially differently from the subtropical North Atlantic circulation, and their mechanisms and timescales for transport and storage of heat and freshwater are very different. Prior to 2014 the subpolar North Atlantic was inadequately measured, and it is still the case that no ocean general circulation or climate model represents it accurately. 

UK-OSNAP-Decade aims to generate new knowledge and understanding of the subpolar North Atlantic to improve predictions of the contribution of the region to climate, by building on the successes of NERC Large Grant UK OSNAP, and as a contribution to the international collaborative project OSNAP (Overturning in the Subpolar North Atlantic Programme). We propose a programme of sustained observation of subpolar North Atlantic circulation and fluxes; a UK contribution to an international trans-basin, full-depth ocean observation array.",1
NE/S012427/1,37887,River basins as 'living laboratories' for achieving sustainable development goals across national and sub-national scales,"While countries around the world are striving to achieve the UN Sustainable Development Goals (SDGs), policies and actions put in place to achieve the 17 goals and 169 targets may lead to inequitable development at the sub-national scale. Although this possibility is recognized, it is currently under-investigated. This project addresses this gap by analysing cross-scale synergies and trade-offs between goals and targets, while also considering how national level policies related to the SDGs impact development at the sub-national scale, represented here by a large river basin. More generally, the project aims to develop an approach that is replicable in other river basins globally and to provide policy recommendations to remove or mitigate the trade-offs so helping to achieve equitable development across river basins.

The analysis will be carried out at the scale of a large river basin, which is a relevant geography to analyse human-environment interactions at the sub-national scale because it provides natural boundaries where upstream-downstream processes can be analysed precisely. Most river basins globally are highly managed to provide various services to populations both locally and further afield, including at the national level (e.g. for food, water and energy security). It is therefore possible for policies to be enacted that, for example, favour food production in a specific location of a river basin (e.g. a delta) to achieve national food security goals at the expense of the environment locally (e.g. through excessive use of agricultural inputs). Upstream development, such as dams can help deliver national-level energy security targets but can negatively impact downstream locations from environmental (e.g. reduction of sediment flows) or natural hazard perspectives (e.g. increasing risk of flooding in case of structural failure).

We will focus on the Luanhe river basin in China, a sub-basin of the Haihe, one of the seven largest basins in China. This basin is relevant because of its extent, and because of the rapid development that is taking place within its boundaries, including construction of the Panjiakou and Daheiting reservoirs on the Luanhe River which supply the mega-city of Tianjin and other cities. It suffers from a severe imbalance between water supply and demand and many initiatives are underway to address this, allowing for a detailed analysis of synergies and trade-offs generated by these activities. Rural transformation in parts of the Luanhe is applicable in other countries as is urbanisation in its lower reaches, which will allow for the research to be of relevance internationally. The trade-offs between rapid economic development, increases in people's living standards and environmental degradation/protection issues, which are characteristics of China's development in general, are also present in the basin. The basin is data rich, its development is directly linked to enforcement of national level policies, and various non-academic stakeholders, representing actors from the national to the community levels, have already agreed to co-develop the research with us.

Initially, we will investigate interlinkages between environmental hazards (relevant for various Goals), climate change (SDG13), water resources (SDG6), energy (SDG7), ecological health (with a focus on SDG15), and urbanization (SDG11). We will focus on policy incentives and interventions in terms of infrastructure development, water, disaster risk reduction, energy security and urbanization. To achieve this, we will co-develop basin development and land use change scenarios with a wide range of stakeholders. These scenarios will serve as a basis to capture changes in hydrology, sediment transport, water quality, and ecosystem services within the basin. The outputs from these assessments will subsequently be used in a modified version of the SDG Interlinkages Tool which has already been tested for China at the national scale.",1
AH/S010793/1,38867,The Global Green Media Production Network,"The British Academy of Film and Television Arts (BAFTA) estimates that the annual emissions from UK film production total in excess of 149.000 tonnes of CO2 (the equivalent of the total CO2 output of a small village), while Greenpeace suggests Information and Communications Technologies generate up to 3% of global carbon emissions (on par with air travel). To counteract such emissions, screen media organisations including Producers Guild of America and BAFTA have developed green production guidelines. However, the industry remains largely blinkered to the significance of these concerns and continues to be shielded from effective public regulation, which tends to focus on heavy industries.

The Global Green Media Production Network (GGMPN) provides a platform for scholars, media practitioners, environmental advocates, and NGOs to explore the environmental footprint of media production. It will make two key methodological contributions. Firstly, it uses an expansive interdisciplinary approach missing from previous studies. Scholars and industry analysts have approached these considerations from a largely technical perspective that focuses on the most efficient means of reducing emissions or of developing managerial strategies to shape work practice. This network starts from the premise that it is not sufficient to consider media production as a purely economic or technocratic activity, as production practices are invariably implicated in local environmental, cultural, political and social realities. GGMPN represents a unique opportunity for arts and humanities scholars to work with the sciences, technology, policy, economics and business studies to provide entirely new perspectives and, most importantly, to develop shared research methods and vocabulary to address how systems of cultural values and everyday social habits influence environmental practices and policy.

Secondly, the network will be informed by the experiences of four highly diverse screen industries (India, Hong Kong, Ghana, United Kingdom) whose environmental policies are determined by distinctive social, political and cultural circumstances, where the environmental, social, economic and cultural realities of these contexts will influence the adoption and form of green production practice. Accordingly, we aim to facilitate dialogue between these industries to generate innovative approaches for positive change that guides the industry as a whole but accommodates local cultural and environmental specificity.

To facilitate this discussion, our network will 

Evaluate the relationship between media's ability to generate environmental knowledge and the industry's evaluation of its own environmental ramifications. How do we draw lines of causality between the material consequences of media production, its translation to media texts, and the reception of these messages by audiences?

Assess the environmental impacts of digital media technologies. The wide range of impacts of digital media are only beginning to be understood-what are the levels of impact, from production methods to server storage? How do such concerns extend to content analysis, and how are they connected to systems of cultural values or everyday social habits?

Address the role of regional, national and local cultural practices in examining whether disparate industries might be accommodated by the development of general principles on environmentally conscious media production. For example, how might Nigerian video culture differ from Bollywood's mass production infrastructure or the European co-production system?

Explore the political and economic underpinnings of media production practices. How are environmental production incentives for the media shaped by larger industrial, economic and political considerations, and what can other sectors learn from environmental media policy, as well as the sector's unique ability to communicate these incentives to a general audience?",1
1643655,20622,Downstream control of blocking and Rossby wave breaking by extratropical cyclones,"Skillful weather and climate forecasts on timescales from hours to centuries are vital for protecting lives and livelihoods and managing the effects of climate change. The Observing System Research and Predictability Experiment (THORPEX) of the World Meteorological Organization grew out of a recognition that, despite continued improvements in numerical weather prediction forecasts (THORPEX specifically considered 1-14 day lead times), further improvements needed to be made. Errors in these forecasts arise due to errors in the initial conditions (the chaotic `butterfly effect'), boundary conditions (e.g. sea surface temperature errors in a weather forecast) and errors in the model formulation (so-called model error). Errors occurring at tropopause level propagate downstream due to their influence on the development, propagation and breaking of the planetary-scale Rossby waves associated with meanders of the upper-level (~10 km high) jet stream. Ridges and troughs in the jet stream are the major driver of the development of extratropical cyclones (a.k.a winter storms) associated with strong surface winds and rain as well as blocking events associated with e.g. summer heatwaves and health impacts due to the trapping of pollutants. One type of systematic error is that due to the mis-representation of diabatic processes such as clouds and radiation in extratropical cyclones, resulting from the necessity to parametrize convection and other moist processes in global (and most regional) weather forecast models. The influence of errors in the representation of these processes in a given storm are propagated downstream and so can affect the forecast of future developing storms or blocking episodes, leading to so-called 'forecast busts'. Identification of such systematic errors is the first step to determining model improvements to reduce them. The CASE partner for this project is the Met Office and our collaboration is with both the 'ensemble forecasting' and 'model evaluation and diagnostics' research groups. In a seamless model prediction system, such as the Met Office's operational climate and weather forecast model (known as the Unified Model), identification and reduction of systematic errors using one component of the system (here we use the weather forecasting component) can potentially improve forecasts across all forecast time horizons from hours to centuries. In this project we causally associate errors in tropopause structure caused by the mis-representation of diabatic processes in extratropical cyclones and determine their influence on downstream error in Rossby-wave breaking and blocking.",1
MR/S034293/1,38391,Fate of ocean oxygenation in a warming world,"Oxygen is critical to the health of all higher life. In the oceans dissolved oxygen concentrations have declined by 2% since 1960, and are expected to continue to decline into the future in relation to man-made climate change. Future deoxygenation, along with overfishing, threatens the sustainability of economically important fisheries and marine ecosystems and will impact global biogeochemical cycles. It is therefore crucial that we obtain a well-informed view about what the future may hold.

Current model simulations that predict the future carry considerable uncertainties; they do not all agree and grossly underestimate the document decrease of the last 50 years. This suggests the models are missing key interactions, calling for urgent action and a dedicated and inclusive scientific approach. 

FARGO provides such an approach by addressing why, and to what extent, seawater dissolved oxygen concentrations may change in a warming world. FARGO will study dissolved oxygen concentrations in the Pacific Ocean, the largest low-oxic water body in the current ocean, through an innovative and dedicated research programme incorporating a novel multi-proxy approach feeding IPCC-type climate model simulations across key warm time intervals:
i- warmer climates across the closure of the American sea-way (4-15 million years);
ii- warmer climates as future analogue (mid-Pliocene Warm Period, 3.3 to 3 million years ago);
iii- Pleistocene warm intervals (interglacials of the last ca. 800,000 years). 

FARGO is structured into two phases: Phase I (years 1-4), and Phase II (years 5-7). The focus of the first four years is analytical, to advance method development and reconstruct time-series of oxygen concentrations and associated processes that drive changes (seawater warming, stratification, productivity, ventilation). The material FARGO will use to create these time-series involves the shells of microorganisms called foraminifera. Some species float near the ocean surface, called planktonic foraminifera, and can be used to assess the presence of subsurface oxygen minimum zones, seawater temperatures, etc. Species that live on or in sediments at the bottom of the ocean are termed benthic foraminifera and can be used to reconstruct bottom water oxygen concentrations and ventilation. FARGO will use sediments from the International Ocean Discovery Program to determine if there have been changes in the natural extent and intensity of the shallow Pacific Ocean OMZ oxygen minimum, or 'dead', zones (e.g. areas where oxygen levels are too low to support aerobic life), during the key warm intervals. The original time-series will feed the IPCC-type climate model simulations and provide robust tests to investigate if the simulations are realistic and correct for the specific time periods, and identify routes to improve the model simulations. Utilizing these improvements, FARGO will carry out simulations for future, including 1.5 and 2 degree warming scenarios.

To raise awareness of ocean deoxygenation FARGO plans several bespoke impact and engagement activities aimed at scientific peers, policy makers, and the general public. To slow/reduce deoxygenation and protect our marine environment FARGO plans to work with government (Scottish and UK) to develop regional legislation to manage nutrient inputs from aquaculture and agriculture of UK waters.",1
NE/M004740/1,4063,Can metabolic traits limit species invasions under climate change?,"Invasive species are currently considered second only to habitat loss as a cause of rapid and undesirable changes in the functioning of ecosystems worldwide. In the United Kingdom alone, the annual cost of invasive species is estimated to be ~&pound;1.7 billion. In this context, major cause for concern is that human-mediated species translocations and global warming are both causing rapid shifts in species' ranges and phonologies at an escalating rate. For example, a Pacific diatom Neodenticula seminae was documented into the North Atlantic for the first time in 800,000 years due to climate-driven melting of the Arctic ice cap and changes in ocean circulation. Such abrupt introductions can result in novel interactions (e.g., predator-prey or resource competition), which then have the potential to result in disruptive invasions of non-native species into local communities. 

In this project, we will meet the challenge of developing a general framework for predicting invasion success by building the first-ever global database on the temperature dependence of metabolic (physiological) traits relevant to species invasions through interactions, use these data to develop and parameterize a novel theoretical framework, and test some key predictions of this theory using laboratory experiments with a globally important functional group, the Phytoplankton (photosynthetic unicellular marine and freshwater algae and bacteria). Phytoplankton form the base of form the base of most aquatic food webs and contribute over half of global primary production. 

We will address three core questions: 

(1) How will mismatches in how metabolic traits (e.g., respiration and photosynthesis rate) of natives and non-native species respond to temperature change affect invasions? 
This question is important because new species often arrive with the physiological &quot;baggage&quot; of the environment they originated in, and therefore may be poorly adapted to their new environment (at least initially).

(2) Doe the rate and magnitude of thermal acclimation (defined as phenotypic changes in thermal-response with change in environmental temperature) in a non-native species to its new environment influence its invasion success? 
This question is important because many species can overcome the initial disadvantage of a novel environment by rapidly adjusting the way their metabolism responds to temperature. 

(3) Are natural temperature cycles important determinants of invasion success? 
This question is important because species invasions, especially in temperate regions, take place in climates that change cyclically at daily (say-night cycles) and seasonal (e.g., winter-summer) scales. Therefore, a non-native species that arrives, say, in winter, may have a lesser chance of invading successfully than if it arrived in summer. 

 Overall, this study will fill a major gap in our understanding of the importance of metabolic constraints on species interactions for species invasions. We expect our results to form a new and robust foundation for predicting species invasions in natural as well as human-dominated environments. Our global database on metabolic traits will be a valuable, long-term resource for mapping metabolic traits onto potentially invasive species, and also for parameterizing ongoing efforts to model the effects of climate change on ecosystem services, including the carbon cycle.",1