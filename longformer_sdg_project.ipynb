{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "longformer_sdg_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6pCrpmtZKzG"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Joqu_t1aaDa"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soGdKRIeYmJc"
      },
      "source": [
        "import pandas as pd\n",
        "import datasets\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZo2unoQZW3e"
      },
      "source": [
        "config = LongformerConfig(hidden_size=512)\n",
        "config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti1RWPGXyRx-"
      },
      "source": [
        "# Read in dataset\n",
        "df = pd.read_csv('training_set.csv')\n",
        "df = df[['text','label']]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2oWA4uqZpSY"
      },
      "source": [
        "# Split dataset into train and test sets\n",
        "train, test = train_test_split(df, test_size=0.2, shuffle=True)\n",
        "train_data = datasets.Dataset.from_pandas(train, features=datasets.Features({'text':datasets.Value('string'),'label':datasets.Value('int64')}))\n",
        "test_data = datasets.Dataset.from_pandas(test, features=datasets.Features({'text':datasets.Value('string'),'label':datasets.Value('int64')}))\n",
        "\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph08yaFmalWN"
      },
      "source": [
        "# Load model and tokenizer\n",
        "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096',\n",
        "                                                           gradient_checkpointing=False,\n",
        "                                                           attention_window = 512)\n",
        "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096', max_length = 1024)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_CKU50Ya3Py"
      },
      "source": [
        "model.config\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "th1CGeHba-pu"
      },
      "source": [
        "# Tokenize text\n",
        "def tokenization(batched_text):\n",
        "    return tokenizer(batched_text['text'], padding = 'max_length', truncation=True, max_length = 1024)\n",
        "\n",
        "train_data = train_data.map(tokenization, batched = True, batch_size = len(train_data))\n",
        "test_data = test_data.map(tokenization, batched = True, batch_size = len(test_data))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdGW_mKcdYGj"
      },
      "source": [
        "train_data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "test_data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cozp4fUkdazh"
      },
      "source": [
        "# Accuracy metrics\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6KxmOA9bo7X"
      },
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    learning_rate = 3e-5,\n",
        "    output_dir = 'results/',\n",
        "    num_train_epochs = 1,\n",
        "    per_device_train_batch_size = 2,\n",
        "    gradient_accumulation_steps = 1,    \n",
        "    per_device_eval_batch_size= 16,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    disable_tqdm = False, \n",
        "    load_best_model_at_end=True,\n",
        "    warmup_steps=200,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps = 4,\n",
        "    fp16 = True,\n",
        "    logging_dir='results/',\n",
        "    dataloader_num_workers = 0,\n",
        "    run_name = 'longformer-classification-updated-rtx3090_paper_replication_2_warm'\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhoVKOxOdgcd"
      },
      "source": [
        "# Instantiate trainer class\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=test_data\n",
        ")\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3QALHDqdlTm"
      },
      "source": [
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLHrkfgvbsPJ"
      },
      "source": [
        "# Save the model\n",
        "trainer.save_model('model')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfJW--H8buLK"
      },
      "source": [
        "# Evaluate the model on test set\n",
        "trainer.evaluate()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wL-Pf2p3mbK"
      },
      "source": [
        "# Predict labels for test set\n",
        "logits, label_ids, metrics = trainer.predict(test_data)\n",
        "pred_0 = []\n",
        "pred_1 = []\n",
        "for pair in logits:\n",
        "  prediction = torch.nn.functional.softmax(torch.tensor(pair),dim=0)\n",
        "  pred_0.append(prediction.numpy()[0])\n",
        "  pred_1.append(prediction.numpy()[1])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anEWeNzwFmW5"
      },
      "source": [
        "# Save predicted labels\n",
        "d = {'text':test_data['text'],'label':test_data['label'],'predicted prob of being pos':pred_1}\n",
        "df_results = pd.DataFrame(data=d)\n",
        "df_results['correct prediction?'] = np.where(abs(df_results['label']-df_results['predicted prob of being pos'])<0.5,'Yes','No')\n",
        "\n",
        "df_results.to_csv(\"test_set_results.csv\")"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}